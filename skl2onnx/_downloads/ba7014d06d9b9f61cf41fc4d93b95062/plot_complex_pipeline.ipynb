{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nConvert a pipeline with ColumnTransformer\n=========================================\n\n*scikit-learn* recently shipped\n`ColumnTransformer <https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html>`_\nwhich lets the user define complex pipeline where each\ncolumn may be preprocessed with a different transformer.\n*sklearn-onnx* still works in this case as shown in Section\n`l-complex-pipeline`.\n\nCreate and train a complex pipeline\n+++++++++++++++++++++++++++++++++++\n\nWe reuse the pipeline implemented in example\n`Column Transformer with Mixed Types\n<https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py>`_.\nThere is one change because\n`ONNX-ML Imputer <https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md#ai.onnx.ml.Imputer>`_\ndoes not handle string type. This cannot be part of the final ONNX pipeline\nand must be removed. Look for comment starting with ``---`` below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ntitanic_url = ('https://raw.githubusercontent.com/amueller/'\n               'scipy-2017-sklearn/091d371/notebooks/datasets/titanic3.csv')\ndata = pd.read_csv(titanic_url)\nX = data.drop('survived', axis=1)\ny = data['survived']\n\n# SimpleImputer on string is not available for string in ONNX-ML specifications.\n# So we do it beforehand.\nfor cat in ['embarked', 'sex', 'pclass']:\n    X[cat].fillna('missing', inplace=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nnumeric_features = ['age', 'fare']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\ncategorical_features = ['embarked', 'sex', 'pclass']\ncategorical_transformer = Pipeline(steps=[\n    # --- SimpleImputer is not available for strings in ONNX-ML specifications. \n    # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features),\n        ])\n\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', LogisticRegression(solver='lbfgs'))])\n\n\nclf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the inputs of the ONNX graph\n+++++++++++++++++++++++++++++++++++\n\n*sklearn-onnx* does not know the features used to train the model\nbut it needs to know which feature has which name.\nWe simply reuse the dataframe column definition.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(X_train.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx.common.data_types import FloatTensorType, StringTensorType, Int64TensorType\n\ndef convert_dataframe_schema(df, drop=None):\n    inputs = []\n    for k, v in zip(df.columns, df.dtypes):\n        if drop is not None and k in drop:\n            continue\n        if v == 'int64':\n            t = Int64TensorType([1, 1])\n        elif v == 'float64':\n            t = FloatTensorType([1, 1])\n        else:\n            t = StringTensorType([1, 1])\n        inputs.append((k, t))\n    return inputs\n    \ninputs = convert_dataframe_schema(X_train)\n\nimport pprint\npprint.pprint(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging single column into vectors is not \nthe most efficient way to compute the prediction.\nIt could be done before converting the pipeline into a graph.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert the pipeline into ONNX\n++++++++++++++++++++++++++++++\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx import convert_sklearn\ntry:\n    model_onnx = convert_sklearn(clf, 'pipeline_titanic', inputs)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions are more efficient if the graph is small.\nThat's why the converter checks that there is no unused input.\nThey need to be removed from the graph inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "to_drop = {'parch', 'sibsp', 'cabin', 'ticket', 'name', 'body', 'home.dest', 'boat'}\ninputs = convert_dataframe_schema(X_train, to_drop)\ntry:\n    model_onnx = convert_sklearn(clf, 'pipeline_titanic', inputs)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*scikit-learn* does implicit conversions when it can.\n*sklearn-onnx* does not. The ONNX version of *OneHotEncoder*\nmust be applied on columns of the same type.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train['pclass'] = X_train['pclass'].astype(str)\nX_test['pclass'] = X_test['pclass'].astype(str)\ninputs = convert_dataframe_schema(X_train, to_drop)\n\nmodel_onnx = convert_sklearn(clf, 'pipeline_titanic', inputs)\n\n\n# And save.\nwith open(\"pipeline_titanic.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the predictions\n+++++++++++++++++++++++\n\nFinal step, we need to ensure the converted model\nproduces the same predictions, labels and probabilities.\nLet's start with *scikit-learn*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"predict\", clf.predict(X_test[:5]))\nprint(\"predict_proba\", clf.predict_proba(X_test[:1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions with onnxruntime.\nWe need to remove the dropped columns and to change\nthe double vectors into float vectors as *onnxruntime*\ndoes not support double floats.\n*onnxruntime* does not accept *dataframe*.\ninputs must be given as a list of dictionary.\nLast detail, every column was described  not really as a vector\nbut as a matrix of one column which explains the last line\nwith the *reshape*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_test2 = X_test.drop(to_drop, axis=1)\ninputs = {c: X_test2[c].values for c in X_test2.columns}\nfor c in numeric_features:\n    inputs[c] = inputs[c].astype(np.float32)\nfor k in inputs:\n    inputs[k] = inputs[k].reshape((inputs[k].shape[0], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are ready to run *onnxruntime*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnxruntime as rt\nimport numpy\nsess = rt.InferenceSession(\"pipeline_titanic.onnx\")\npred_onx = sess.run(None, inputs)\nprint(\"predict\", pred_onx[0][:5])\nprint(\"predict_proba\", pred_onx[1][:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the ONNX graph\n++++++++++++++++++++++\n\nFinally, let's see the graph converted with *sklearn-onnx*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\npydot_graph = GetPydotGraph(model_onnx.graph, name=model_onnx.graph.name, rankdir=\"TB\",\n                            node_producer=GetOpNodeProducer(\"docstring\", color=\"yellow\",\n                                                            fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline_titanic.dot\")\n\nimport os\nos.system('dot -O -Gdpi=300 -Tpng pipeline_titanic.dot')\n\nimport matplotlib.pyplot as plt\nimage = plt.imread(\"pipeline_titanic.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy, sklearn\nprint(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nimport onnx, onnxruntime, skl2onnx, onnxmltools, lightgbm\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", onnxruntime.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}