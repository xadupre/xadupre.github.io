{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nConvert a pipeline with a LightGbm model\n========================================\n\n.. index:: LightGbm\n\n*sklearn-onnx* only converts *scikit-learn* models into *ONNX*\nbut many libraries implement *scikit-learn* API so that their models\ncan be included in a *scikit-learn* pipeline. This example considers\na pipeline including a *LightGbm* model. *sklearn-onnx* can convert\nthe whole pipeline as long as it knows the converter associated to\na *LGBMClassifier*. Let's see how to do it.\n\nA couple of errors might happen while trying to convert\nyour own pipeline, some of them are described\nand explained in `errors-pipeline`.\n\nTrain a LightGBM classifier\n+++++++++++++++++++++++++++\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nfrom sklearn.datasets import load_iris\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMClassifier\ndata = load_iris()\nX = data.data[:, :2]\ny = data.target\n\nind = numpy.arange(X.shape[0])\nnumpy.random.shuffle(ind)\nX = X[ind, :].copy()\ny = y[ind].copy()\n\npipe = Pipeline([('scaler', StandardScaler()),\n                 ('lgbm', LGBMClassifier(n_estimators=3))])\npipe.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Register the converter for LGBMClassifier\n+++++++++++++++++++++++++++++++++++++++++\n\nThe converter is implemented in *onnxmltools* and\nfollows a different design than the current one\nof *sklearn-onnx*. This will change in a short future.\nSee also `l-register-converter`.\nFirst the converter implemented in\n`onnxmltools...LightGbm.py <https://github.com/onnx/onnxmltools/blob/master/onnxmltools/convert/lightgbm/operator_converters/LightGbm.py>`_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The shape calculator of *onnxmltools* must be adapted for our case.\nThis will change in a short future.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numbers\nfrom skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import Int64TensorType, FloatTensorType, StringTensorType, DictionaryType, SequenceType\n\ndef lightgbm_classifier_shape_extractor(operator):\n    N = operator.inputs[0].type.shape[0]\n\n    class_labels = operator.raw_operator.classes_\n    if all(isinstance(i, numpy.ndarray) for i in class_labels):\n        class_labels = numpy.concatenate(class_labels)\n    if all(isinstance(i, str) for i in class_labels):\n        operator.outputs[0].type = StringTensorType(shape=[N])\n        operator.outputs[1].type = SequenceType(DictionaryType(StringTensorType([]), FloatTensorType([])), N)\n    elif all(isinstance(i, (numbers.Real, bool, numpy.bool_)) for i in class_labels):\n        operator.outputs[0].type = Int64TensorType(shape=[N])\n        operator.outputs[1].type = SequenceType(DictionaryType(Int64TensorType([]), FloatTensorType([])), N)\n    else:\n        raise ValueError('Unsupported or mixed label types')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's register the new converter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx import update_registered_converter\nupdate_registered_converter(LGBMClassifier, 'LightGbmLGBMClassifier',                                    \n                            lightgbm_classifier_shape_extractor,\n                            convert_lightgbm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert again\n+++++++++++++\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = convert_sklearn(pipe, 'pipeline_lightgbm',\n                             [('input', FloatTensorType([1, 2]))])\n\n# And save.\nwith open(\"pipeline_lightgbm.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the predictions\n+++++++++++++++++++++++\n\nPredictions with LightGbm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"predict\", pipe.predict(X[:5]))\nprint(\"predict_proba\", pipe.predict_proba(X[:1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions with onnxruntime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnxruntime as rt\nimport numpy\nsess = rt.InferenceSession(\"pipeline_lightgbm.onnx\")\npred_onx = sess.run(None, {\"input\": X[:5].astype(numpy.float32)})\nprint(\"predict\", pred_onx[0])\nprint(\"predict_proba\", pred_onx[1][:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the ONNX graph\n++++++++++++++++++++++\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\npydot_graph = GetPydotGraph(model_onnx.graph, name=model_onnx.graph.name, rankdir=\"TB\",\n                            node_producer=GetOpNodeProducer(\"docstring\", color=\"yellow\",\n                                                            fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline.dot\")\n\nimport os\nos.system('dot -O -Gdpi=300 -Tpng pipeline.dot')\n\nimport matplotlib.pyplot as plt\nimage = plt.imread(\"pipeline.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy, sklearn\nprint(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nimport onnx, onnxruntime, skl2onnx, onnxmltools, lightgbm\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", onnxruntime.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)\nprint(\"onnxmltools: \", onnxmltools.__version__)\nprint(\"lightgbm: \", lightgbm.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}