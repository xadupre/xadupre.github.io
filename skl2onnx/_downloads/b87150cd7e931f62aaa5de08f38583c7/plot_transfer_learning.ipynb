{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nTransfer learning with ONNX\n===========================\n\n`Transfer learning <https://en.wikipedia.org/wiki/Transfer_learning>`_\nis usually useful to adapt a deep learning model to some\nnew problem for which the number of images is not enough\nto train a deep learning model. The proposed solution\nimplies the use of class *OnnxTransformer* which wraps\n*OnnxRuntime* into a *scikit-learn* transformer\neasily pluggable into a pipeline.\n\nTrain a model\n+++++++++++++\n\nA very basic example using random forest and\nthe iris dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nclr = RandomForestClassifier(n_estimators=1, max_depth=2)\nclr.fit(X_train, y_train)\nprint(clr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert a model into ONNX\n+++++++++++++++++++++++++\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType\ninitial_type = [('float_input', FloatTensorType([1, 4]))]\nonx = convert_sklearn(clr, initial_types=initial_type)\n\nwith open(\"rf_iris.onnx\", \"wb\") as f:\n    f.write(onx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute ONNX prediction similarly as scikit-learn transformer\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnxruntime.sklapi import OnnxTransformer\n\nwith open(\"rf_iris.onnx\", \"rb\") as f:\n    content = f.read()\n\not = OnnxTransformer(content, output_name=\"output_probability\")\not.fit(X_train, y_train)\n\nprint(ot.transform(X_test[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. index:: transfer learning, MobileNet, ImageNet\n\nTransfer Learning with MobileNet\n++++++++++++++++++++++++++++++++\n\nDeep learning models started to win\nthe `ImageNet <http://www.image-net.org/>`_\ncompetition in 2012 and most the winners\nare available on the web as pre-trained models.\nTransfer Learning is computed by wrapping\na backend into a *scikit-learn*\ntransformers which *onnxruntime* does.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nmodel_file = \"mobilenetv2-1.0.onnx\"\nif not os.path.exists(model_file):\n    print(\"Download '{0}'...\".format(model_file))\n    import urllib.request\n    url = \"https://s3.amazonaws.com/onnx-model-zoo/mobilenet/mobilenetv2-1.0/mobilenetv2-1.0.onnx\"\n    urllib.request.urlretrieve(url, model_file)\n    print(\"Done.\")\n\nclass_names = \"imagenet_class_index.json\"\nif not os.path.exists(class_names):\n    print(\"Download '{0}'...\".format(class_names))\n    import urllib.request\n    url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n    urllib.request.urlretrieve(url, class_names)\n    print(\"Done.\")\n\nimport json\nwith open(class_names, \"r\", encoding=\"utf-8\") as f:\n    content_classes = f.read()\nlabels = json.loads(content_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's consider one image form *wikipedia*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nimport numpy\n\nimg = Image.open('daisy_wikipedia.jpg')\nplt.imshow(img)\nplt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create the OnnxTransformer\nwhich we apply on that particular image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(model_file, \"rb\") as f:\n    model_bytes = f.read()\n    \not = OnnxTransformer(model_bytes)\n\nimg2 = img.resize((224, 224))\nX = numpy.asarray(img2).transpose((2, 0, 1))\nX = X[numpy.newaxis, :, :, :] / 255.0\nprint(X.shape, X.min(), X.max())\n\npred = ot.fit_transform(X)[0, :]\nprint(pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the best classes are...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from heapq import nlargest\nresults = nlargest(10, range(pred.shape[0]), pred.take)\nprint(results)\n\nimport pandas\ndata=[{\"index\": i, \"label\": labels.get(str(i), ('?', '?'))[1], 'score': pred[i]} \\\n      for i in results]\ndf = pandas.DataFrame(data)\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. index:: Yolo\n\nTransfer Learning with Yolo\n+++++++++++++++++++++++++++\n\n`yolo <https://pjreddie.com/darknet/yolo/>`_\nis quite popular among the framework\nwhich can identity objects in images in real time.\nOne of the models is available in \n`ONNX zoo <https://github.com/onnx/models>`_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfilename = \"tiny_yolov2.tar.gz\"\nif not os.path.exists(filename):\n    print(\"Download '{0}'...\".format(filename))\n    import urllib.request\n    url = \"https://onnxzoo.blob.core.windows.net/models/opset_8/tiny_yolov2/tiny_yolov2.tar.gz\"\n    urllib.request.urlretrieve(url, filename)\n    print(\"Done.\")\n\nmodel_file = \"tiny_yolov2/model.onnx\"\nif not os.path.exists(model_file):\n    print(\"Unzip '{0}'.\".format(model_file))\n    import tarfile\n    tfile = tarfile.open(filename, 'r:gz')\n    tfile.extractall()\n    print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's retrieve an image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nimport numpy\n\nimg = Image.open('Au-Salon-de-l-agriculture-la-campagne-recrute.jpg')\nplt.imshow(img)\nplt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It needs to be zoomed, converted into an array,\nresized, transposed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img2 = img.resize((416, 416))\nX = numpy.asarray(img2)\nX = X.transpose(2,0,1)\nX = X.reshape(1,3,416,416)\nX = X.astype(numpy.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create the OnnxTransformer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(model_file, \"rb\") as f:\n    model_bytes = f.read()\n    \not = OnnxTransformer(model_bytes)\npred = ot.fit_transform(X)\nprint(pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's display the results on the image itself\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def display_yolo(img, out, threshold):\n    \"\"\"\n    Displays yolo results *out* on an image *img*.\n    *threshold* filters out uncertain results.\n    \"\"\"\n    import numpy as np\n    numClasses = 20\n    anchors = [1.08, 1.19, 3.42, 4.41, 6.63, 11.38, 9.42, 5.11, 16.62, 10.52]\n\n    def sigmoid(x, derivative=False):\n        return x*(1-x) if derivative else 1/(1+np.exp(-x))\n\n    def softmax(x):\n        scoreMatExp = np.exp(np.asarray(x))\n        return scoreMatExp / scoreMatExp.sum(0)\n\n    clut = [(0,0,0),(255,0,0),(255,0,255),(0,0,255),(0,255,0),(0,255,128),\n            (128,255,0),(128,128,0),(0,128,255),(128,0,128),\n            (255,0,128),(128,0,255),(255,128,128),(128,255,128),(255,255,0),\n            (255,128,128),(128,128,255),(255,128,128),(128,255,128),(128,255,128)]\n    label = [\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\n             \"bus\",\"car\",\"cat\",\"chair\",\"cow\",\"diningtable\",\n             \"dog\",\"horse\",\"motorbike\",\"person\",\"pottedplant\",\n             \"sheep\",\"sofa\",\"train\",\"tvmonitor\"]\n\n    draw = ImageDraw.Draw(img)\n    for cy in range(0,13):\n        for cx in range(0,13):\n            for b in range(0,5):\n                channel = b*(numClasses+5)\n                tx = out[channel  ][cy][cx]\n                ty = out[channel+1][cy][cx]\n                tw = out[channel+2][cy][cx]\n                th = out[channel+3][cy][cx]\n                tc = out[channel+4][cy][cx]\n\n                x = (float(cx) + sigmoid(tx))*32\n                y = (float(cy) + sigmoid(ty))*32\n\n                w = np.exp(tw) * 32 * anchors[2*b  ]\n                h = np.exp(th) * 32 * anchors[2*b+1]\n\n                confidence = sigmoid(tc)\n\n                classes = np.zeros(numClasses)\n                for c in range(0, numClasses):\n                    classes[c] = out[channel + 5 +c][cy][cx]\n                    classes = softmax(classes)\n                detectedClass = classes.argmax()\n\n                if threshold < classes[detectedClass] * confidence:\n                    color = clut[detectedClass]\n                    x = x - w/2\n                    y = y - h/2\n                    draw.line((x  ,y  ,x+w,y ),fill=color, width=3)\n                    draw.line((x  ,y  ,x  ,y+h),fill=color, width=3)\n                    draw.line((x+w,y  ,x+w,y+h),fill=color, width=3)\n                    draw.line((x  ,y+h,x+w,y+h),fill=color, width=3)\n\n    return img\n\nimg_results = display_yolo(img2, pred[0], 0.038)\nplt.imshow(img_results)\nplt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy, sklearn\nprint(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nimport onnx, onnxruntime, skl2onnx, onnxmltools, lightgbm\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", onnxruntime.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}