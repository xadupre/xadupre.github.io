{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nErrors while converting a pipeline\n==================================\n\nA pipeline is a patchwork of many different pieces\nand the probability of the first try to convert it fails\nis quite high. This script gathers the most frequent one\nand suggest a solution.\n\nConverter not registered\n++++++++++++++++++++++++\n\n*LightGBM* implements random forest which follow\n*scikit-learn* API. Due to that, they can be included a\n*scikit-learn* pipeline which can be used to optimize\nhyperparameters in grid search or to validate the model\nwith a cross validation. However, *sklearn-onnx* does not\nimplement a converter for an instance of\n`LGBMClassifier <https://lightgbm.readthedocs.io/en/latest/Python-API.html?highlight=LGBMClassifier#lightgbm.LGBMClassifier>`_.\nLet's see what happens when a simple pipeline is being converted.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nfrom sklearn.datasets import load_iris\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMClassifier\ndata = load_iris()\nX = data.data[:, :2]\ny = data.target\n\nind = numpy.arange(X.shape[0])\nnumpy.random.shuffle(ind)\nX = X[ind, :].copy()\ny = y[ind].copy()\n\npipe = Pipeline([('scaler', StandardScaler()),\n                 ('lgbm', LGBMClassifier(n_estimators=1, max_depth=1))])\npipe.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The conversion happens here and fails.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType\n\ntry:\n    model_onnx = convert_sklearn(pipe, 'pipeline',\n                                 [('input', FloatTensorType([1, 2]))])\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*sklearn-onnx* needs to know the appropriate converter\nfor class *LGBMClassifier*, the converter needs to be registered.\nThe converter comes with two pieces: a shape calculator which \ncomputes output shapes based on inputs shapes and the converter\nitself which extracts the coefficients of the random forest\nand converts them into *ONNX* format.\nFirst, the shape calculator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numbers\nfrom skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import Int64TensorType, FloatTensorType, StringTensorType, DictionaryType, SequenceType\n\ndef lightgbm_classifier_shape_extractor(operator):\n    N = operator.inputs[0].type.shape[0]\n\n    class_labels = operator.raw_operator.classes_\n    if all(isinstance(i, numpy.ndarray) for i in class_labels):\n        class_labels = numpy.concatenate(class_labels)\n    if all(isinstance(i, str) for i in class_labels):\n        operator.outputs[0].type = StringTensorType(shape=[N])\n        operator.outputs[1].type = SequenceType(DictionaryType(StringTensorType([]), FloatTensorType([])), N)\n    elif all(isinstance(i, (numbers.Real, bool, numpy.bool_)) for i in class_labels):\n        operator.outputs[0].type = Int64TensorType(shape=[N])\n        operator.outputs[1].type = SequenceType(DictionaryType(Int64TensorType([]), FloatTensorType([])), N)\n    else:\n        raise ValueError('Unsupported or mixed label types')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then the converter itself:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "They are both registered with the following instruction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx import update_registered_converter\nupdate_registered_converter(LGBMClassifier, 'LightGbmLGBMClassifier',                                    \n                            lightgbm_classifier_shape_extractor,\n                            convert_lightgbm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's convert again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = convert_sklearn(pipe, 'pipeline',\n                             [('input', FloatTensorType([1, 2]))])\n\nprint(str(model_onnx)[:300] + \"\\n...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nWorking with dataframes\n+++++++++++++++++++++++\n\n*sklearn-onnx* converts a pipeline without knowing the training data,\nmore specifically, it does not know the input variables. This is why\nit complain when the parameter *initial_type* is not filled\nwhen function :func:`skl2onnx.convert_sklearn`\nis called. Let's see what happens without it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\nimport pandas\n\ndata = load_iris()\nX = data.data[:, :2]\ny = data.target\n\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nclf.fit(X, y)\n\nfrom skl2onnx import convert_sklearn\ntry:\n    model_onnx = convert_sklearn(clf)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to define the initial type.\nLet's write some code to automatically\nfill that parameter from a dataframe.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx.common.data_types import Int64TensorType, FloatTensorType, StringTensorType\n\n\ndef convert_dataframe_schema(df, drop=None):\n    inputs = []\n    for k, v in zip(df.columns, df.dtypes):\n        if drop is not None and k in drop:\n            continue\n        if v == 'int64':\n            t = Int64TensorType([1, 1])\n        elif v == 'float64':\n            t = FloatTensorType([1, 1])\n        else:\n            t = StringTensorType([1, 1])\n        inputs.append((k, t))\n    return inputs\n\nfrom pandas import DataFrame\ndata = DataFrame(X, columns=[\"X1\", \"X2\"])\n        \ninputs = convert_dataframe_schema(data)\nprint(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's convert again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    model_onnx = convert_sklearn(clf, initial_types=inputs)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*sklean-onnx* tells it cannot match two single inputs\nwith one input vector of dimension 2.\nLet's try it that way:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = convert_sklearn(clf, initial_types=[('X', FloatTensorType([1, 2]))])\nprint(str(model_onnx)[:300] + \"\\n...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What if now this model is included in a pipeline\nwith a `ColumnTransformer <https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html>`_.\nThe following pipeline is a way to concatenate multiple\ncolumns into a single one with a \n`FunctionTransformer <https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html>`_\nwith identify function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import FunctionTransformer\n\npipe = Pipeline(steps=[\n            ('select', ColumnTransformer([('id', FunctionTransformer(), ['X1', 'X2'])])),\n            ('logreg', clf)\n                      ])\npipe.fit(data[['X1', 'X2']], y)\n\npipe_onnx = convert_sklearn(pipe, initial_types=inputs)\nprint(str(pipe_onnx)[:300] + \"\\n...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's draw the pipeline for a better understanding.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\npydot_graph = GetPydotGraph(pipe_onnx.graph, name=model_onnx.graph.name, rankdir=\"TB\",\n                            node_producer=GetOpNodeProducer(\"docstring\", color=\"orange\",\n                                                            fillcolor=\"orange\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline_concat.dot\")\n\nimport os\nos.system('dot -O -Gdpi=300 -Tpng pipeline_concat.dot')\n\nimport matplotlib.pyplot as plt\nimage = plt.imread(\"pipeline_concat.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unused inputs\n+++++++++++++\n\n*sklearn-onnx* converts a model into a ONNX graph\nand this graph is then used to compute predictions\nwith a backend. The smaller the graph is, the faster\nthe computation is. That's why *sklearn-onnx* raises some\nexception when it detects when something can be optimized.\nThat's the case when more inputs than needed are declared.\nLet's reuse the previous example with a new dummy feature.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data[\"dummy\"] = 4.5\ninputs = convert_dataframe_schema(data)\nprint(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The new *initial_types* makes the conversion fail.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    pipe_onnx = convert_sklearn(pipe, initial_types=inputs)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy, sklearn\nprint(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nimport onnx, onnxruntime, skl2onnx\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", onnxruntime.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}