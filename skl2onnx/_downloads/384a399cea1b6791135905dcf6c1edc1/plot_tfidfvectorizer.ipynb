{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nTfIdfVectorizer with ONNX\n=========================\n\nThis example is inspired from the following example:\n`Column Transformer with Heterogeneous Data Sources <https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html>`_\nwhich builds a pipeline to classify text.\n\nTrain a pipeline with TfidfVectorizer\n+++++++++++++++++++++++++++++++++++++\n\nIt replicates the same pipeline taken from *scikit-learn* documentation\nbut reduces it to the part ONNX actually supports without implementing\na custom converter. Let's get the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.datasets.twenty_newsgroups import strip_newsgroup_footer\nfrom sklearn.datasets.twenty_newsgroups import strip_newsgroup_quoting\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\n\n\n# limit the list of categories to make running this example faster.\ncategories = ['alt.atheism', 'talk.religion.misc']\ntrain = fetch_20newsgroups(random_state=1,\n                           subset='train',\n                           categories=categories,\n                           )\ntest = fetch_20newsgroups(random_state=1,\n                          subset='test',\n                          categories=categories,\n                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first transform extract two fields from the data.\nWe take it out form the pipeline and assume\nthe data is defined by two text columns.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SubjectBodyExtractor(BaseEstimator, TransformerMixin):\n    \"\"\"Extract the subject & body from a usenet post in a single pass.\n    Takes a sequence of strings and produces a dict of sequences. Keys are\n    `subject` and `body`.\n    \"\"\"\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, posts):\n        # construct object dtype array with two columns\n        # first column = 'subject' and second column = 'body'\n        features = np.empty(shape=(len(posts), 2), dtype=object)\n        for i, text in enumerate(posts):\n            headers, _, bod = text.partition('\\n\\n')\n            bod = strip_newsgroup_footer(bod)\n            bod = strip_newsgroup_quoting(bod)\n            features[i, 1] = bod\n\n            prefix = 'Subject:'\n            sub = ''\n            for line in headers.split('\\n'):\n                if line.startswith(prefix):\n                    sub = line[len(prefix):]\n                    break\n            features[i, 0] = sub\n\n        return features\n        \ntrain_data = SubjectBodyExtractor().fit_transform(train.data)\ntest_data = SubjectBodyExtractor().fit_transform(test.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pipeline is almost the same except\nwe remove the custom features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n    ('union', ColumnTransformer(\n        [\n            ('subject', TfidfVectorizer(min_df=50), 0),\n\n            ('body_bow', Pipeline([\n                ('tfidf', TfidfVectorizer()),\n                ('best', TruncatedSVD(n_components=50)),\n            ]), 1),\n\n            # Removed from the original example as it requires a custom converter.\n            # ('body_stats', Pipeline([\n            #     ('stats', TextStats()),  # returns a list of dicts\n            #     ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n            # ]), 1),\n        ],\n\n        transformer_weights={\n            'subject': 0.8,\n            'body_bow': 0.5,\n            # 'body_stats': 1.0,\n        }\n    )),\n\n    # Use a LogisticRegression classifier on the combined features.\n    # Instead of LinearSVC (not fully ready in onnxruntime).\n    ('logreg', LogisticRegression()),\n])\n\npipeline.fit(train_data, train.target)\nprint(classification_report(pipeline.predict(test_data), test.target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ONNX conversion\n+++++++++++++++\n\nIt is difficult to replicate the exact same tokenizer\nbehaviour if the tokeniser comes from space, gensim or nltk.\nThe default one used by *scikit-learn* uses regular expressions\nand is currently being implementing. The current implementation\nonly considers a list of separators which can is defined\nin variable *seps*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import StringTensorType\n\nseps = {TfidfVectorizer: {\"sep\": [' ', '.', '?', ',', ';', ':', '!', '(', ')',\n                                   '\\n', '\"', \"'\", \"-\", \"[\", \"]\", \"@\"]}}\nmodel_onnx = convert_sklearn(pipeline, \"tfidf\",\n                             initial_types=[(\"input\", StringTensorType([1, 2]))],\n                             options=seps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And save.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(\"pipeline_tfidf.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions with onnxruntime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnxruntime as rt\nimport numpy\nsess = rt.InferenceSession(\"pipeline_tfidf.onnx\")\nprint('---', train_data[0])\ninputs = {'input': train_data[0]}\npred_onx = sess.run(None, inputs)\nprint(\"predict\", pred_onx[0])\nprint(\"predict_proba\", pred_onx[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With *scikit-learn*:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(pipeline.predict(train_data[0:1]))\nprint(pipeline.predict_proba(train_data[0:1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are discrepencies for this model because\nthe tokenization is not exactly the same.\nThis is a work in progress.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the ONNX graph\n++++++++++++++++++++++\n\nFinally, let's see the graph converted with *sklearn-onnx*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\npydot_graph = GetPydotGraph(model_onnx.graph, name=model_onnx.graph.name, rankdir=\"TB\",\n                            node_producer=GetOpNodeProducer(\"docstring\", color=\"yellow\",\n                                                            fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline_tfidf.dot\")\n\nimport os\nos.system('dot -O -Gdpi=300 -Tpng pipeline_tfidf.dot')\n\nimport matplotlib.pyplot as plt\nimage = plt.imread(\"pipeline_tfidf.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}