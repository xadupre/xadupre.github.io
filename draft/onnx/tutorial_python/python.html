
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>ONNX with Python &#8212; ONNX 1.12.0 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorial_python/python';</script>
    <link rel="shortcut icon" href="../_static/onnx-favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Converters" href="converters.html" />
    <link rel="prev" title="ONNX Concepts" href="concepts.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="auto">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fas fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://github.com/onnx/onnx" title="GitHub" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://github.com/onnx/onnx" title="GitHub" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
<nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
  </p><div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Introduction to ONNX
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label class="toctree-toggle" for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="concepts.html">
     ONNX Concepts
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     ONNX with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="converters.html">
     Converters
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_python/index.html">
   API Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_doc_folder/index.html">
   ONNX Operators
  </a>
 </li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="onnx-with-python">
<h1>ONNX with Python<a class="headerlink" href="#onnx-with-python" title="Permalink to this heading">#</a></h1>
<p>Next sections highlight the main functions used to build
an ONNX graph with the <a class="reference internal" href="../onnx_python/index.html#l-python-onnx-api"><span class="std std-ref">Python API</span></a>
<em>onnx</em> offers.</p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#a-simple-example-a-linear-regression" id="id1">A simple example: a linear regression</a></p></li>
<li><p><a class="reference internal" href="#serialization" id="id2">Serialization</a></p></li>
<li><p><a class="reference internal" href="#initializer-default-value" id="id3">Initializer, default value</a></p></li>
<li><p><a class="reference internal" href="#attributes" id="id4">Attributes</a></p></li>
<li><p><a class="reference internal" href="#opset-and-metadata" id="id5">Opset and metadata</a></p></li>
<li><p><a class="reference internal" href="#subgraph-test-and-loops" id="id6">Subgraph: test and loops</a></p></li>
<li><p><a class="reference internal" href="#functions" id="id7">Functions</a></p></li>
<li><p><a class="reference internal" href="#parsing" id="id8">Parsing</a></p></li>
<li><p><a class="reference internal" href="#checker-and-shape-inference" id="id9">Checker and Shape Inference</a></p></li>
<li><p><a class="reference internal" href="#implementation-details" id="id10">Implementation details</a></p></li>
</ul>
</nav>
<section id="a-simple-example-a-linear-regression">
<span id="l-onnx-linear-regression-onnx-api"></span><h2><a class="toc-backref" href="#id1" role="doc-backlink">A simple example: a linear regression</a><a class="headerlink" href="#a-simple-example-a-linear-regression" title="Permalink to this heading">#</a></h2>
<p>The linear regression is the most simple model
in machine learning described by the following expression
<span class="math">Y = XA + B</span>. We can see it as a function of three
variables <span class="math">Y = f(X, A, B)</span> decomposed into
<cite>y = Add(MatMul(X, A), B))</cite>. That what’s we need to represent
with ONNX operators. The first thing is to implement a function
with <a class="reference internal" href="../onnx_doc_folder/index.html#l-onnx-operators"><span class="std std-ref">ONNX operators</span></a>.
ONNX is strongly typed. Shape and type must be defined for both
input and output of the function. That said, we need four functions
to build the graph among the <a class="reference internal" href="../onnx_python/helper.html#l-onnx-make-function"><span class="std std-ref">make function</span></a>:</p>
<ul class="simple">
<li><p><cite>make_tensor_value_info</cite>: declares a variable (input or output)
given its shape and type</p></li>
<li><p><cite>make_node</cite>: creates a node defined by an operation
(an operator type), its inputs and outputs</p></li>
<li><p><cite>make_graph</cite>: a function to create an ONNX graph with
the objects created by the two previous functions</p></li>
<li><p><cite>make_model</cite>: a last function with merges the graph and
additional metadata</p></li>
</ul>
<p>All along the creation, we need to give a name to every input,
output of every node of the graph. Input and output of the graph
are defined by onnx objects, strings are used to refer to
intermediate results. This is how it looks like.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># imports</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>
    <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="c1"># inputs</span>

<span class="c1"># &#39;X&#39; is the name, TensorProto.FLOAT the type, [None, None] the shape</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>

<span class="c1"># outputs, the shape is left undefined</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="c1"># nodes</span>

<span class="c1"># It creates a node defined by the operator type MatMul,</span>
<span class="c1"># &#39;X&#39;, &#39;A&#39; are the inputs of the node, &#39;XA&#39; the output.</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>

<span class="c1"># from nodes to graph</span>
<span class="c1"># the graph is built from the list of nodes, the list of inputs,</span>
<span class="c1"># the list of outputs and a name.</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span>  <span class="c1"># nodes</span>
                    <span class="s1">&#39;lr&#39;</span><span class="p">,</span>  <span class="c1"># a name</span>
                    <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span>  <span class="c1"># inputs</span>
                    <span class="p">[</span><span class="n">Y</span><span class="p">])</span>  <span class="c1"># outputs</span>

<span class="c1"># onnx graph</span>
<span class="c1"># there is no metata in this case.</span>

<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>

<span class="c1"># Let&#39;s check the model is consistent,</span>
<span class="c1"># this function is described in section</span>
<span class="c1"># Checker and Shape Inference.</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># the work is done, let&#39;s display it...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  name: &quot;lr&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;B&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 18
}
</pre></div>
</div>
<img alt="../_images/dot_linreg.png" src="../_images/dot_linreg.png" />
<p>An empty shape (<cite>None</cite>) means any shape, a shape defined as <cite>[None, None]</cite>
tells this object is a tensor with two dimensions without any further precision.
The ONNX graph can also be inspected by looking into the fields
of each object of the graph.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>
    <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="k">def</span> <span class="nf">shape2tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s1">&#39;dim_value&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">shape</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">])</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># the list of inputs</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;** inputs **&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>

<span class="c1"># in a more nicely format</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;** inputs **&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;name=</span><span class="si">%r</span><span class="s2"> dtype=</span><span class="si">%r</span><span class="s2"> shape=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">obj</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">elem_type</span><span class="p">,</span>
        <span class="n">shape2tuple</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>

<span class="c1"># the list of outputs</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;** outputs **&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

<span class="c1"># in a more nicely format</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;** outputs **&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;name=</span><span class="si">%r</span><span class="s2"> dtype=</span><span class="si">%r</span><span class="s2"> shape=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">obj</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">elem_type</span><span class="p">,</span>
        <span class="n">shape2tuple</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>

<span class="c1"># the list of nodes</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;** nodes **&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span>

<span class="c1"># in a more nicely format</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;** nodes **&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;name=</span><span class="si">%r</span><span class="s2"> type=</span><span class="si">%r</span><span class="s2"> input=</span><span class="si">%r</span><span class="s2"> output=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>** inputs **
[name: &quot;X&quot;
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
, name: &quot;A&quot;
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
, name: &quot;B&quot;
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
]
** inputs **
name=&#39;X&#39; dtype=1 shape=(0, 0)
name=&#39;A&#39; dtype=1 shape=(0, 0)
name=&#39;B&#39; dtype=1 shape=(0, 0)
** outputs **
[name: &quot;Y&quot;
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
    }
  }
}
]
** outputs **
name=&#39;Y&#39; dtype=1 shape=(0,)
** nodes **
[input: &quot;X&quot;
input: &quot;A&quot;
output: &quot;XA&quot;
op_type: &quot;MatMul&quot;
, input: &quot;XA&quot;
input: &quot;B&quot;
output: &quot;Y&quot;
op_type: &quot;Add&quot;
]
** nodes **
name=&#39;&#39; type=&#39;MatMul&#39; input=[&#39;X&#39;, &#39;A&#39;] output=[&#39;XA&#39;]
name=&#39;&#39; type=&#39;Add&#39; input=[&#39;XA&#39;, &#39;B&#39;] output=[&#39;Y&#39;]
</pre></div>
</div>
<p>The tensor type is an integer (= 1). The following array gives the
equivalent type with numpy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">from</span> <span class="nn">onnx.mapping</span> <span class="kn">import</span> <span class="n">TENSOR_TYPE_TO_NP_TYPE</span>

<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">TENSOR_TYPE_TO_NP_TYPE</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>{1: dtype(&#39;float32&#39;),
 2: dtype(&#39;uint8&#39;),
 3: dtype(&#39;int8&#39;),
 4: dtype(&#39;uint16&#39;),
 5: dtype(&#39;int16&#39;),
 6: dtype(&#39;int32&#39;),
 7: dtype(&#39;int64&#39;),
 8: dtype(&#39;O&#39;),
 9: dtype(&#39;bool&#39;),
 10: dtype(&#39;float16&#39;),
 11: dtype(&#39;float64&#39;),
 12: dtype(&#39;uint32&#39;),
 13: dtype(&#39;uint64&#39;),
 14: dtype(&#39;complex64&#39;),
 15: dtype(&#39;complex128&#39;),
 16: dtype(&#39;float32&#39;)}
</pre></div>
</div>
</section>
<section id="serialization">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Serialization</a><a class="headerlink" href="#serialization" title="Permalink to this heading">#</a></h2>
<p>ONNX is built on the top of protobuf. It adds the necessary definitions
to describes a machine learned and most of the time, ONNX is used
to serialize or deserialize a model. First section addresses this need.
Second section introduces the serialization and deserialization of
data such as tensors, sparse tensors…</p>
<section id="model-serialization">
<h3>Model Serialization<a class="headerlink" href="#model-serialization" title="Permalink to this heading">#</a></h3>
<p>The model needs to be saved to be deployed.
ONNX is based on protobuf. It minimizes the space needed
to save the graph on disk. Every object (see <a class="reference internal" href="../onnx_python/classes.html#l-onnx-classes"><span class="std std-ref">Protos</span></a>)
in onnx can be serialized with method <cite>SerializeToString</cite>. That’s
the case for the whole model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>
    <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="k">def</span> <span class="nf">shape2tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s1">&#39;dim_value&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">shape</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">])</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># The serialization</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;linear_regression.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="c1"># display</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  name: &quot;lr&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;B&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 18
}
</pre></div>
</div>
<p>The graph can be restored with function <cite>load</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">load</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;linear_regression.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># display</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  name: &quot;lr&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;B&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 18
}
</pre></div>
</div>
<p>It looks exactly the same. Any model can be serialized this way
unless they are bigger than 2 Gb. protobuf is limited to size
smaller than this threshold. Next sections will show how to
overcome that limit.</p>
</section>
<section id="data-serialization">
<h3>Data Serialization<a class="headerlink" href="#data-serialization" title="Permalink to this heading">#</a></h3>
<p>The serialization of tensor usually happens the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.numpy_helper</span> <span class="kn">import</span> <span class="n">from_array</span>

<span class="n">numpy_tensor</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">numpy_tensor</span><span class="p">))</span>

<span class="n">onnx_tensor</span> <span class="o">=</span> <span class="n">from_array</span><span class="p">(</span><span class="n">numpy_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">onnx_tensor</span><span class="p">))</span>

<span class="n">serialized_tensor</span> <span class="o">=</span> <span class="n">onnx_tensor</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">serialized_tensor</span><span class="p">))</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;saved_tensor.pb&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">serialized_tensor</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
&lt;class &#39;onnx.onnx_ml_pb2.TensorProto&#39;&gt;
&lt;class &#39;bytes&#39;&gt;
</pre></div>
</div>
<p>And the deserialization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.numpy_helper</span> <span class="kn">import</span> <span class="n">to_array</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;saved_tensor.pb&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">serialized_tensor</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">serialized_tensor</span><span class="p">))</span>

<span class="n">onnx_tensor</span> <span class="o">=</span> <span class="n">TensorProto</span><span class="p">()</span>
<span class="n">onnx_tensor</span><span class="o">.</span><span class="n">ParseFromString</span><span class="p">(</span><span class="n">serialized_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">onnx_tensor</span><span class="p">))</span>

<span class="n">numpy_tensor</span> <span class="o">=</span> <span class="n">to_array</span><span class="p">(</span><span class="n">onnx_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy_tensor</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;bytes&#39;&gt;
&lt;class &#39;onnx.onnx_ml_pb2.TensorProto&#39;&gt;
[0. 1. 4. 5. 3.]
</pre></div>
</div>
<p>The same schema can be used for <a class="reference internal" href="../onnx_python/classes.html#l-tensorproto"><span class="std std-ref">TensorProto</span></a> but not only:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">pprint</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">([</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">onnx</span><span class="p">)</span>
               <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;Proto&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;_&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;AttributeProto&#39;,
 &#39;FunctionProto&#39;,
 &#39;GraphProto&#39;,
 &#39;MapProto&#39;,
 &#39;ModelProto&#39;,
 &#39;NodeProto&#39;,
 &#39;OperatorProto&#39;,
 &#39;OperatorSetIdProto&#39;,
 &#39;OperatorSetProto&#39;,
 &#39;OptionalProto&#39;,
 &#39;SequenceProto&#39;,
 &#39;SparseTensorProto&#39;,
 &#39;StringStringEntryProto&#39;,
 &#39;TensorProto&#39;,
 &#39;TensorShapeProto&#39;,
 &#39;TrainingInfoProto&#39;,
 &#39;TypeProto&#39;,
 &#39;ValueInfoProto&#39;]
</pre></div>
</div>
<p>This code can be simplified with function <em>load_tensor_from_string</em>
(see <a class="reference internal" href="../onnx_python/serialization.html#l-onnx-load-data"><span class="std std-ref">Load a Proto</span></a>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">load_tensor_from_string</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;saved_tensor.pb&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">serialized</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">proto</span> <span class="o">=</span> <span class="n">load_tensor_from_string</span><span class="p">(</span><span class="n">serialized</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">proto</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;onnx.onnx_ml_pb2.TensorProto&#39;&gt;
</pre></div>
</div>
</section>
</section>
<section id="initializer-default-value">
<span id="l-onnx-linear-regression-onnx-api-init"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">Initializer, default value</a><a class="headerlink" href="#initializer-default-value" title="Permalink to this heading">#</a></h2>
<p>The previous model assumed the coefficients of the linear regression
were also input of the model. That’s not very convenient. They should be
part of the model itself as constant or <strong>initializer</strong> to follow
onnx semantic. Next example modifies the previous one to change inputs
<cite>A</cite> and <cite>B</cite> into initializers. The package implements two functions to
convert from numpy into onnx and the other way around
(see <a class="reference internal" href="../onnx_python/numpy_helper.html#l-numpy-helper-onnx-array"><span class="std std-ref">array</span></a>).</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">onnx.numpy_helper.to_array</span></code>: converts from onnx to numpy</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">onnx.numpy_helper.from_array</span></code>: converts from numpy to onnx</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span> <span class="n">make_graph</span><span class="p">,</span>
    <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="c1"># initializers</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>

<span class="c1"># the part which does not change</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;AX&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;AX&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">C</span><span class="p">])</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;AX&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;AX&quot;
    input: &quot;C&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  name: &quot;lr&quot;
  initializer {
    dims: 2
    data_type: 1
    name: &quot;A&quot;
    raw_data: &quot;\000\000\000?\232\231\031\277&quot;
  }
  initializer {
    dims: 1
    data_type: 1
    name: &quot;C&quot;
    raw_data: &quot;\315\314\314&gt;&quot;
  }
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 18
}
</pre></div>
</div>
<img alt="../_images/dot_linreg2.png" src="../_images/dot_linreg2.png" />
<p>Again, it is possible to go through the onnx structure to check
how the initializers look like.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span> <span class="n">make_graph</span><span class="p">,</span>
    <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="c1"># initializers</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>

<span class="c1"># the part which does not change</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;AX&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;AX&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">C</span><span class="p">])</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;** intializer **&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">init</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>** intializer **
dims: 2
data_type: 1
name: &quot;A&quot;
raw_data: &quot;\000\000\000?\232\231\031\277&quot;

dims: 1
data_type: 1
name: &quot;C&quot;
raw_data: &quot;\315\314\314&gt;&quot;
</pre></div>
</div>
<p>The type is defined as integer as well with the same meaning.
In this second example, there is only one input left.
Input <cite>A</cite> and <cite>B</cite> were removed. They could be kept. In that case,
they are optional: every initiliazer sharing the same name as input
is considered as a default value. It replaces the input if this one
is not given.</p>
</section>
<section id="attributes">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Attributes</a><a class="headerlink" href="#attributes" title="Permalink to this heading">#</a></h2>
<p>Some operators need attributes such as <a class="reference internal" href="../onnx_doc_folder/onnx__Transpose.html#l-onnx-doc-transpose"><span class="std std-ref">Transpose</span></a> operator.
Let’s build the graph for expression <span class="math">y = XA' + B</span> or
<cite>y = Add(MatMul(X, Transpose(A)) + B)</cite>. Tranpose needs an attribute
defining the permutation of axes: <cite>perm=[1, 0]</cite>. It is added
as a named attribute in function <cite>make_node</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>
    <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="c1"># unchanged</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="c1"># added</span>
<span class="n">node_transpose</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Transpose&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;tA&#39;</span><span class="p">],</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># unchanged except A is replaced by tA</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;tA&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>

<span class="c1"># node_transpose is added to the list</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">node_transpose</span><span class="p">,</span> <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span>
                   <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">])</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># the work is done, let&#39;s display it...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;A&quot;
    output: &quot;tA&quot;
    op_type: &quot;Transpose&quot;
    attribute {
      name: &quot;perm&quot;
      ints: 1
      ints: 0
      type: INTS
    }
  }
  node {
    input: &quot;X&quot;
    input: &quot;tA&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  name: &quot;lr&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;B&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 18
}
</pre></div>
</div>
<img alt="../_images/dot_att.png" src="../_images/dot_att.png" />
<p>The whole list of <em>make</em> functions is the following. Many of them
are described in section <a class="reference internal" href="../onnx_python/helper.html#l-onnx-make-function"><span class="std std-ref">make function</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">pprint</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">([</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="p">)</span>
               <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;make&#39;</span><span class="p">)])</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;make_attribute&#39;,
 &#39;make_attribute_ref&#39;,
 &#39;make_empty_tensor_value_info&#39;,
 &#39;make_function&#39;,
 &#39;make_graph&#39;,
 &#39;make_map&#39;,
 &#39;make_model&#39;,
 &#39;make_model_gen_version&#39;,
 &#39;make_node&#39;,
 &#39;make_operatorsetid&#39;,
 &#39;make_opsetid&#39;,
 &#39;make_optional&#39;,
 &#39;make_optional_type_proto&#39;,
 &#39;make_sequence&#39;,
 &#39;make_sequence_type_proto&#39;,
 &#39;make_sparse_tensor&#39;,
 &#39;make_sparse_tensor_type_proto&#39;,
 &#39;make_sparse_tensor_value_info&#39;,
 &#39;make_tensor&#39;,
 &#39;make_tensor_sequence_value_info&#39;,
 &#39;make_tensor_type_proto&#39;,
 &#39;make_tensor_value_info&#39;,
 &#39;make_training_info&#39;,
 &#39;make_value_info&#39;]
</pre></div>
</div>
</section>
<section id="opset-and-metadata">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Opset and metadata</a><a class="headerlink" href="#opset-and-metadata" title="Permalink to this heading">#</a></h2>
<p>Let’s load the ONNX file previously created and check
what kind of metadata it has.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">load</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;linear_regression.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;doc_string&#39;</span><span class="p">,</span> <span class="s1">&#39;domain&#39;</span><span class="p">,</span> <span class="s1">&#39;functions&#39;</span><span class="p">,</span>
              <span class="s1">&#39;ir_version&#39;</span><span class="p">,</span> <span class="s1">&#39;metadata_props&#39;</span><span class="p">,</span> <span class="s1">&#39;model_version&#39;</span><span class="p">,</span>
              <span class="s1">&#39;opset_import&#39;</span><span class="p">,</span> <span class="s1">&#39;producer_name&#39;</span><span class="p">,</span> <span class="s1">&#39;producer_version&#39;</span><span class="p">,</span>
              <span class="s1">&#39;training_info&#39;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span> <span class="n">field</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>doc_string 
domain 
functions []
ir_version 8
metadata_props []
model_version 0
opset_import [version: 18
]
producer_name 
producer_version 
training_info []
</pre></div>
</div>
<p>Most of them are empty because it was not filled when the ONNX
graph was created. Two of them have a value:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">load</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;linear_regression.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ir_version:&quot;</span><span class="p">,</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">ir_version</span><span class="p">)</span>
<span class="k">for</span> <span class="n">opset</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;opset domain=</span><span class="si">%r</span><span class="s2"> version=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">opset</span><span class="o">.</span><span class="n">domain</span><span class="p">,</span> <span class="n">opset</span><span class="o">.</span><span class="n">version</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
opset domain=&#39;&#39; version=18
</pre></div>
</div>
<p><cite>IR</cite> defined the version of ONNX language.
Opset defines the version of operators being used.
Without any precision, ONNX uses the latest version available
coming from the installed package.
Another one can be used.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">load</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;linear_regression.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="k">del</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="p">[:]</span>
<span class="n">opset</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
<span class="n">opset</span><span class="o">.</span><span class="n">domain</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="n">opset</span><span class="o">.</span><span class="n">version</span> <span class="o">=</span> <span class="mi">14</span>

<span class="k">for</span> <span class="n">opset</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;opset domain=</span><span class="si">%r</span><span class="s2"> version=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">opset</span><span class="o">.</span><span class="n">domain</span><span class="p">,</span> <span class="n">opset</span><span class="o">.</span><span class="n">version</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>opset domain=&#39;&#39; version=14
</pre></div>
</div>
<p>Any opset can be used as long as all operators are defined
the way ONNX specifies it. Version 5 of operator <em>Reshape</em>
defines the shape as an input and not as an attribute like in
version 1. The opset tells which specifications is followed
while describing the graph.</p>
<p>The other metadata can be used to store any information,
to store information about the way the model was generated,
a way to distinguish a model from another one with a version
number.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">load</span><span class="p">,</span> <span class="n">helper</span><span class="p">,</span> <span class="n">TrainingInfoProto</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;linear_regression.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">onnx_model</span><span class="o">.</span><span class="n">model_version</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">producer_name</span> <span class="o">=</span> <span class="s2">&quot;something&quot;</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">producer_version</span> <span class="o">=</span> <span class="s2">&quot;some other thing&quot;</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">doc_string</span> <span class="o">=</span> <span class="s2">&quot;documentation about this model&quot;</span>
<span class="n">prop</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">metadata_props</span>

<span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="s2">&quot;value1&quot;</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="s2">&quot;value2&quot;</span><span class="p">)</span>
<span class="n">helper</span><span class="o">.</span><span class="n">set_model_props</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
producer_name: &quot;something&quot;
producer_version: &quot;some other thing&quot;
model_version: 15
doc_string: &quot;documentation about this model&quot;
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  name: &quot;lr&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;B&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 18
}
metadata_props {
  key: &quot;key1&quot;
  value: &quot;value1&quot;
}
metadata_props {
  key: &quot;key2&quot;
  value: &quot;value2&quot;
}
</pre></div>
</div>
<p>Field <cite>training_info</cite> can be used to store additional graphs.
See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/onnx/test/training_tool_test.py">training_tool_test.py</a>
to see how it works.</p>
</section>
<section id="subgraph-test-and-loops">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Subgraph: test and loops</a><a class="headerlink" href="#subgraph-test-and-loops" title="Permalink to this heading">#</a></h2>
<p>They are usually grouped in a category called <em>control flow</em>.
It is usually better to avoid them as they are not as efficient
as the matrix operation are much faster and optimized.</p>
<section id="if">
<h3>If<a class="headerlink" href="#if" title="Permalink to this heading">#</a></h3>
<p>A test can be implemented with operator <a class="reference internal" href="../onnx_doc_folder/onnx__If.html#l-onnx-doc-if"><span class="std std-ref">If</span></a>.
It executes one subgraph or another depending on one
boolean. This is not used very often as a function usually
needs the result of many comparisons in a batch.
The following example computes the sum of all floats
in a matrix based on the sign, returns 1 or -1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_node</span><span class="p">,</span> <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_model</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.numpy_helper</span> <span class="kn">import</span> <span class="n">from_array</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>

<span class="c1"># initializers</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">zero</span> <span class="o">=</span> <span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;zero&#39;</span><span class="p">)</span>

<span class="c1"># Same as before, X is the input, Y is the output.</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="c1"># The node building the condition. The first one</span>
<span class="c1"># sum over all axes.</span>
<span class="n">rsum</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;ReduceSum&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;rsum&#39;</span><span class="p">])</span>
<span class="c1"># The second compares the result to 0.</span>
<span class="n">cond</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Greater&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;rsum&#39;</span><span class="p">,</span> <span class="s1">&#39;zero&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;cond&#39;</span><span class="p">])</span>

<span class="c1"># Builds the graph is the condition is True.</span>
<span class="c1"># Input for then</span>
<span class="n">then_out</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span>
    <span class="s1">&#39;then_out&#39;</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="c1"># The constant to return.</span>
<span class="n">then_cst</span> <span class="o">=</span> <span class="n">from_array</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># The only node.</span>
<span class="n">then_const_node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Constant&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;then_out&#39;</span><span class="p">],</span>
    <span class="n">value</span><span class="o">=</span><span class="n">then_cst</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cst1&#39;</span><span class="p">)</span>

<span class="c1"># And the graph wrapping these elements.</span>
<span class="n">then_body</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">(</span>
    <span class="p">[</span><span class="n">then_const_node</span><span class="p">],</span> <span class="s1">&#39;then_body&#39;</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="n">then_out</span><span class="p">])</span>

<span class="c1"># Same process for the else branch.</span>
<span class="n">else_out</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span>
    <span class="s1">&#39;else_out&#39;</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">])</span>
<span class="n">else_cst</span> <span class="o">=</span> <span class="n">from_array</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">else_const_node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Constant&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;else_out&#39;</span><span class="p">],</span>
    <span class="n">value</span><span class="o">=</span><span class="n">else_cst</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cst2&#39;</span><span class="p">)</span>

<span class="n">else_body</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">(</span>
    <span class="p">[</span><span class="n">else_const_node</span><span class="p">],</span> <span class="s1">&#39;else_body&#39;</span><span class="p">,</span>
    <span class="p">[],</span> <span class="p">[</span><span class="n">else_out</span><span class="p">])</span>

<span class="c1"># Finally the node If taking both graphs as attributes.</span>
<span class="n">if_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;If&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;cond&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span>
    <span class="n">then_branch</span><span class="o">=</span><span class="n">then_body</span><span class="p">,</span>
    <span class="n">else_branch</span><span class="o">=</span><span class="n">else_body</span><span class="p">)</span>

<span class="c1"># The final graph.</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">rsum</span><span class="p">,</span> <span class="n">cond</span><span class="p">,</span> <span class="n">if_node</span><span class="p">],</span> <span class="s1">&#39;if&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">],</span> <span class="p">[</span><span class="n">zero</span><span class="p">])</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># Let&#39;s freeze the opset.</span>
<span class="k">del</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="p">[:]</span>
<span class="n">opset</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
<span class="n">opset</span><span class="o">.</span><span class="n">domain</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="n">opset</span><span class="o">.</span><span class="n">version</span> <span class="o">=</span> <span class="mi">15</span>

<span class="c1"># Save.</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;onnx_if_sign.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="c1"># Let&#39;s see the output.</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">})</span>

<span class="c1"># It works.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Some display.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>result [array([1.], dtype=float32)]

ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    output: &quot;rsum&quot;
    op_type: &quot;ReduceSum&quot;
  }
  node {
    input: &quot;rsum&quot;
    input: &quot;zero&quot;
    output: &quot;cond&quot;
    op_type: &quot;Greater&quot;
  }
  node {
    input: &quot;cond&quot;
    output: &quot;Y&quot;
    op_type: &quot;If&quot;
    attribute {
      name: &quot;else_branch&quot;
      g {
        node {
          output: &quot;else_out&quot;
          name: &quot;cst2&quot;
          op_type: &quot;Constant&quot;
          attribute {
            name: &quot;value&quot;
            t {
              dims: 1
              data_type: 1
              raw_data: &quot;\000\000\200\277&quot;
            }
            type: TENSOR
          }
        }
        name: &quot;else_body&quot;
        output {
          name: &quot;else_out&quot;
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                  dim_value: 5
                }
              }
            }
          }
        }
      }
      type: GRAPH
    }
    attribute {
      name: &quot;then_branch&quot;
      g {
        node {
          output: &quot;then_out&quot;
          name: &quot;cst1&quot;
          op_type: &quot;Constant&quot;
          attribute {
            name: &quot;value&quot;
            t {
              dims: 1
              data_type: 1
              raw_data: &quot;\000\000\200?&quot;
            }
            type: TENSOR
          }
        }
        name: &quot;then_body&quot;
        output {
          name: &quot;then_out&quot;
          type {
            tensor_type {
              elem_type: 1
            }
          }
        }
      }
      type: GRAPH
    }
  }
  name: &quot;if&quot;
  initializer {
    dims: 1
    data_type: 1
    name: &quot;zero&quot;
    raw_data: &quot;\000\000\000\000&quot;
  }
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  domain: &quot;&quot;
  version: 15
}
</pre></div>
</div>
<p>The whole is easier to visualize with the following image.</p>
<img alt="../_images/dot_if_py.png" src="../_images/dot_if_py.png" />
<p>Both else and then branches are very simple.
Node <em>If</em> could even be replace with a node <em>Where</em> and
that would be faster. It becomes interesting when both branches
are bigger and skipping one is more efficient.</p>
</section>
<section id="scan">
<h3>Scan<a class="headerlink" href="#scan" title="Permalink to this heading">#</a></h3>
<p><a class="reference internal" href="../onnx_doc_folder/onnx__Scan.html#l-onnx-doc-scan"><span class="std std-ref">Scan</span></a> seems quite complex when reading the specifications.
It is useful to loop over one dimension of a tensor and store
the results in a preallocated tensor.</p>
<p>The following example implements a classic nearest neighbors for
a regression problem. The first step consists in computing the
pairwise distances between the input features <em>X</em> and the training
set <em>W</em>: <span class="math">dist(X,W) = (M_{ij}) = (\norm{X_i - W_j}^2)_{ij}</span>. It is
followed by an operator <a class="reference internal" href="../onnx_doc_folder/onnx__TopK.html#l-onnx-doc-topk"><span class="std std-ref">TopK</span></a> which extracts the <em>k</em> nearest
neighbors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span> <span class="n">make_graph</span><span class="p">,</span>
    <span class="n">make_tensor_value_info</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="c1"># subgraph</span>
<span class="n">initializers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;next_in&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;next&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>
<span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;next_out&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;scan_out&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Identity&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;next_in&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;next_out&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cdistd_17_Identity&#39;</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Sub&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;next_in&#39;</span><span class="p">,</span> <span class="s1">&#39;next&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;cdistdf_17_C0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cdistdf_17_Sub&#39;</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;ReduceSumSquare&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;cdistdf_17_C0&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;cdistdf_17_reduced0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cdistdf_17_ReduceSumSquare&#39;</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Identity&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;cdistdf_17_reduced0&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;scan_out&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cdistdf_17_Identity&#39;</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="s1">&#39;OnnxIdentity&#39;</span><span class="p">,</span>
                   <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">initializers</span><span class="p">)</span>

<span class="c1"># main graph</span>

<span class="n">initializers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">opsets</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;ai.onnx.ml&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">}</span>
<span class="n">target_opset</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># subgraphs</span>

<span class="c1"># initializers</span>
<span class="n">list_value</span> <span class="o">=</span> <span class="p">[</span><span class="mf">23.29599822460675</span><span class="p">,</span> <span class="o">-</span><span class="mf">120.86516699239603</span><span class="p">,</span> <span class="o">-</span><span class="mf">144.70495899914215</span><span class="p">,</span> <span class="o">-</span><span class="mf">260.08772982740413</span><span class="p">,</span>
              <span class="mf">154.65272105889147</span><span class="p">,</span> <span class="o">-</span><span class="mf">122.23295157108991</span><span class="p">,</span> <span class="mf">247.45232560871727</span><span class="p">,</span> <span class="o">-</span><span class="mf">182.83789715805776</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">132.92727431421793</span><span class="p">,</span> <span class="mf">147.48710175784703</span><span class="p">,</span> <span class="mf">88.27761768038069</span><span class="p">,</span> <span class="o">-</span><span class="mf">14.87785569894749</span><span class="p">,</span>
              <span class="mf">111.71487894705504</span><span class="p">,</span> <span class="mf">301.0518319089629</span><span class="p">,</span> <span class="o">-</span><span class="mf">29.64235742280055</span><span class="p">,</span> <span class="o">-</span><span class="mf">113.78493504731911</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">204.41218591022718</span><span class="p">,</span> <span class="mf">112.26561056133608</span><span class="p">,</span> <span class="mf">66.04032954135549</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">229.5428380626701</span><span class="p">,</span> <span class="o">-</span><span class="mf">33.549262642481615</span><span class="p">,</span> <span class="o">-</span><span class="mf">140.95737409864623</span><span class="p">,</span> <span class="o">-</span><span class="mf">87.8145187836131</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">90.61397011283958</span><span class="p">,</span> <span class="mf">57.185488100413366</span><span class="p">,</span> <span class="mf">56.864151796743855</span><span class="p">,</span> <span class="mf">77.09054590340892</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">187.72501631246712</span><span class="p">,</span> <span class="o">-</span><span class="mf">42.779503579806025</span><span class="p">,</span> <span class="o">-</span><span class="mf">21.642642730674076</span><span class="p">,</span> <span class="o">-</span><span class="mf">44.58517761667535</span><span class="p">,</span>
              <span class="mf">78.56025104939847</span><span class="p">,</span> <span class="o">-</span><span class="mf">23.92423223842056</span><span class="p">,</span> <span class="mf">234.9166231927213</span><span class="p">,</span> <span class="o">-</span><span class="mf">73.73512816431007</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">10.150864499514297</span><span class="p">,</span> <span class="o">-</span><span class="mf">70.37105466673813</span><span class="p">,</span> <span class="mf">65.5755688281476</span><span class="p">,</span> <span class="mf">108.68676290979731</span><span class="p">,</span> <span class="o">-</span><span class="mf">78.36748960443065</span><span class="p">]</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">list_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span>
    <span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;knny_ArrayFeatureExtractorcst&#39;</span><span class="p">)</span>
<span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<span class="n">list_value</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.1394007205963135</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6848101019859314</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.234825849533081</span><span class="p">,</span> <span class="mf">0.4023416340351105</span><span class="p">,</span>
              <span class="mf">0.17742614448070526</span><span class="p">,</span> <span class="mf">0.46278226375579834</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4017809331417084</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.630198359489441</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.5096521973609924</span><span class="p">,</span> <span class="mf">0.7774903774261475</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4380742907524109</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2527953386306763</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">1.0485529899597168</span><span class="p">,</span> <span class="mf">1.950775384902954</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.420017957687378</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7062702178955078</span><span class="p">,</span>
              <span class="mf">1.8675580024719238</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.15135720372200012</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9772778749465942</span><span class="p">,</span> <span class="mf">0.9500884413719177</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">2.5529897212982178</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7421650290489197</span><span class="p">,</span> <span class="mf">0.653618574142456</span><span class="p">,</span> <span class="mf">0.8644362092018127</span><span class="p">,</span>
              <span class="mf">1.5327792167663574</span><span class="p">,</span> <span class="mf">0.37816253304481506</span><span class="p">,</span> <span class="mf">1.4693588018417358</span><span class="p">,</span> <span class="mf">0.154947429895401</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.6724604368209839</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7262825965881348</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.35955315828323364</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8131462931632996</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.8707971572875977</span><span class="p">,</span> <span class="mf">0.056165341287851334</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5788496732711792</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3115525245666504</span><span class="p">,</span>
              <span class="mf">1.2302906513214111</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.302302747964859</span><span class="p">,</span> <span class="mf">1.202379822731018</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.38732680678367615</span><span class="p">,</span>
              <span class="mf">2.269754648208618</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18718385696411133</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4543657302856445</span><span class="p">,</span> <span class="mf">0.04575851559638977</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.9072983860969543</span><span class="p">,</span> <span class="mf">0.12898291647434235</span><span class="p">,</span> <span class="mf">0.05194539576768875</span><span class="p">,</span> <span class="mf">0.7290905714035034</span><span class="p">,</span>
              <span class="mf">1.4940791130065918</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8540957570075989</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2051582634449005</span><span class="p">,</span> <span class="mf">0.3130677044391632</span><span class="p">,</span>
              <span class="mf">1.764052391052246</span><span class="p">,</span> <span class="mf">2.2408931255340576</span><span class="p">,</span> <span class="mf">0.40015721321105957</span><span class="p">,</span> <span class="mf">0.978738009929657</span><span class="p">,</span>
              <span class="mf">0.06651721894741058</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3627411723136902</span><span class="p">,</span> <span class="mf">0.30247190594673157</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6343221068382263</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.5108051300048828</span><span class="p">,</span> <span class="mf">0.4283318817615509</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.18063223361969</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02818222902715206</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">1.6138978004455566</span><span class="p">,</span> <span class="mf">0.38690251111984253</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.21274028718471527</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8954665660858154</span><span class="p">,</span>
              <span class="mf">0.7610377073287964</span><span class="p">,</span> <span class="mf">0.3336743414402008</span><span class="p">,</span> <span class="mf">0.12167501449584961</span><span class="p">,</span> <span class="mf">0.44386324286460876</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.10321885347366333</span><span class="p">,</span> <span class="mf">1.4542734622955322</span><span class="p">,</span> <span class="mf">0.4105985164642334</span><span class="p">,</span> <span class="mf">0.14404356479644775</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.8877857327461243</span><span class="p">,</span> <span class="mf">0.15634897351264954</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.980796456336975</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.34791216254234314</span><span class="p">]</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">list_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Sc_Scancst&#39;</span><span class="p">)</span>
<span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;To_TopKcst&#39;</span><span class="p">)</span>
<span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;knny_Reshapecst&#39;</span><span class="p">)</span>
<span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<span class="c1"># inputs</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="c1"># outputs</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="c1"># nodes</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Scan&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;Sc_Scancst&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;UU032UU&#39;</span><span class="p">,</span> <span class="s1">&#39;UU033UU&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Sc_Scan&#39;</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">graph</span><span class="p">,</span> <span class="n">num_scan_inputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Transpose&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;UU033UU&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Tr_transposed0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Tr_Transpose&#39;</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Sqrt&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Tr_transposed0&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Sq_Y0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Sq_Sqrt&#39;</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;TopK&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Sq_Y0&#39;</span><span class="p">,</span> <span class="s1">&#39;To_TopKcst&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;To_Values0&#39;</span><span class="p">,</span> <span class="s1">&#39;To_Indices1&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;To_TopK&#39;</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Flatten&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;To_Indices1&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;knny_output0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;knny_Flatten&#39;</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;ArrayFeatureExtractor&#39;</span><span class="p">,</span>
    <span class="p">[</span><span class="s1">&#39;knny_ArrayFeatureExtractorcst&#39;</span><span class="p">,</span> <span class="s1">&#39;knny_output0&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;knny_Z0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;knny_ArrayFeatureExtractor&#39;</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;ai.onnx.ml&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Reshape&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;knny_Z0&#39;</span><span class="p">,</span> <span class="s1">&#39;knny_Reshapecst&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;knny_reshaped0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;knny_Reshape&#39;</span><span class="p">,</span> <span class="n">allowzero</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Transpose&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;knny_reshaped0&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;knny_transposed0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;knny_Transpose&#39;</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Cast&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;knny_transposed0&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Ca_output0&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Ca_Cast&#39;</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;ReduceMean&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Ca_output0&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Re_ReduceMean&#39;</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="c1"># graph</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="s1">&#39;KNN regressor&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">initializers</span><span class="p">)</span>

<span class="c1"># model</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">ir_version</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">producer_name</span> <span class="o">=</span> <span class="s1">&#39;skl2onnx&#39;</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">producer_version</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">domain</span> <span class="o">=</span> <span class="s1">&#39;ai.onnx&#39;</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">model_version</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">onnx_model</span><span class="o">.</span><span class="n">doc_string</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="n">set_model_props</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span> <span class="p">{})</span>

<span class="c1"># opsets</span>
<span class="k">del</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="p">[:]</span>  <span class="c1"># pylint: disable=E1101</span>
<span class="k">for</span> <span class="n">dom</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">opsets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">op_set</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">opset_import</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
    <span class="n">op_set</span><span class="o">.</span><span class="n">domain</span> <span class="o">=</span> <span class="n">dom</span>
    <span class="n">op_set</span><span class="o">.</span><span class="n">version</span> <span class="o">=</span> <span class="n">value</span>

<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;knnr.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
producer_name: &quot;skl2onnx&quot;
producer_version: &quot;&quot;
domain: &quot;ai.onnx&quot;
model_version: 0
doc_string: &quot;&quot;
graph {
  node {
    input: &quot;input&quot;
    input: &quot;Sc_Scancst&quot;
    output: &quot;UU032UU&quot;
    output: &quot;UU033UU&quot;
    name: &quot;Sc_Scan&quot;
    op_type: &quot;Scan&quot;
    attribute {
      name: &quot;body&quot;
      g {
        node {
          input: &quot;next_in&quot;
          output: &quot;next_out&quot;
          name: &quot;cdistd_17_Identity&quot;
          op_type: &quot;Identity&quot;
          domain: &quot;&quot;
        }
        node {
          input: &quot;next_in&quot;
          input: &quot;next&quot;
          output: &quot;cdistdf_17_C0&quot;
          name: &quot;cdistdf_17_Sub&quot;
          op_type: &quot;Sub&quot;
          domain: &quot;&quot;
        }
        node {
          input: &quot;cdistdf_17_C0&quot;
          output: &quot;cdistdf_17_reduced0&quot;
          name: &quot;cdistdf_17_ReduceSumSquare&quot;
          op_type: &quot;ReduceSumSquare&quot;
          attribute {
            name: &quot;axes&quot;
            ints: 1
            type: INTS
          }
          attribute {
            name: &quot;keepdims&quot;
            i: 0
            type: INT
          }
          domain: &quot;&quot;
        }
        node {
          input: &quot;cdistdf_17_reduced0&quot;
          output: &quot;scan_out&quot;
          name: &quot;cdistdf_17_Identity&quot;
          op_type: &quot;Identity&quot;
          domain: &quot;&quot;
        }
        name: &quot;OnnxIdentity&quot;
        input {
          name: &quot;next_in&quot;
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
                dim {
                  dim_value: 4
                }
              }
            }
          }
        }
        input {
          name: &quot;next&quot;
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
              }
            }
          }
        }
        output {
          name: &quot;next_out&quot;
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
                dim {
                }
              }
            }
          }
        }
        output {
          name: &quot;scan_out&quot;
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
              }
            }
          }
        }
      }
      type: GRAPH
    }
    attribute {
      name: &quot;num_scan_inputs&quot;
      i: 1
      type: INT
    }
    domain: &quot;&quot;
  }
  node {
    input: &quot;UU033UU&quot;
    output: &quot;Tr_transposed0&quot;
    name: &quot;Tr_Transpose&quot;
    op_type: &quot;Transpose&quot;
    attribute {
      name: &quot;perm&quot;
      ints: 1
      ints: 0
      type: INTS
    }
    domain: &quot;&quot;
  }
  node {
    input: &quot;Tr_transposed0&quot;
    output: &quot;Sq_Y0&quot;
    name: &quot;Sq_Sqrt&quot;
    op_type: &quot;Sqrt&quot;
    domain: &quot;&quot;
  }
  node {
    input: &quot;Sq_Y0&quot;
    input: &quot;To_TopKcst&quot;
    output: &quot;To_Values0&quot;
    output: &quot;To_Indices1&quot;
    name: &quot;To_TopK&quot;
    op_type: &quot;TopK&quot;
    attribute {
      name: &quot;largest&quot;
      i: 0
      type: INT
    }
    attribute {
      name: &quot;sorted&quot;
      i: 1
      type: INT
    }
    domain: &quot;&quot;
  }
  node {
    input: &quot;To_Indices1&quot;
    output: &quot;knny_output0&quot;
    name: &quot;knny_Flatten&quot;
    op_type: &quot;Flatten&quot;
    domain: &quot;&quot;
  }
  node {
    input: &quot;knny_ArrayFeatureExtractorcst&quot;
    input: &quot;knny_output0&quot;
    output: &quot;knny_Z0&quot;
    name: &quot;knny_ArrayFeatureExtractor&quot;
    op_type: &quot;ArrayFeatureExtractor&quot;
    domain: &quot;ai.onnx.ml&quot;
  }
  node {
    input: &quot;knny_Z0&quot;
    input: &quot;knny_Reshapecst&quot;
    output: &quot;knny_reshaped0&quot;
    name: &quot;knny_Reshape&quot;
    op_type: &quot;Reshape&quot;
    attribute {
      name: &quot;allowzero&quot;
      i: 0
      type: INT
    }
    domain: &quot;&quot;
  }
  node {
    input: &quot;knny_reshaped0&quot;
    output: &quot;knny_transposed0&quot;
    name: &quot;knny_Transpose&quot;
    op_type: &quot;Transpose&quot;
    attribute {
      name: &quot;perm&quot;
      ints: 1
      ints: 0
      ints: 2
      type: INTS
    }
    domain: &quot;&quot;
  }
  node {
    input: &quot;knny_transposed0&quot;
    output: &quot;Ca_output0&quot;
    name: &quot;Ca_Cast&quot;
    op_type: &quot;Cast&quot;
    attribute {
      name: &quot;to&quot;
      i: 1
      type: INT
    }
    domain: &quot;&quot;
  }
  node {
    input: &quot;Ca_output0&quot;
    output: &quot;variable&quot;
    name: &quot;Re_ReduceMean&quot;
    op_type: &quot;ReduceMean&quot;
    attribute {
      name: &quot;axes&quot;
      ints: 2
      type: INTS
    }
    attribute {
      name: &quot;keepdims&quot;
      i: 0
      type: INT
    }
    domain: &quot;&quot;
  }
  name: &quot;KNN regressor&quot;
  initializer {
    dims: 2
    dims: 20
    data_type: 11
    name: &quot;knny_ArrayFeatureExtractorcst&quot;
    raw_data: &quot;,\\&amp;\212\306K7@\333z`\345^7^\300\304\312,\006\217\026b\300Z9dWgAp\300.+F\027\343Tc@\203\330\264\255\350\216^\300\260\022\216sy\356n@\237h\263\r\320\332f\300\224\277.;\254\235`\300\336\370lV\226ob@\261\201\362|\304\021V@c,[Mv\301-\300\322\214\240\223\300\355[@)\036\262M\324\320r@nE;\211q\244=\300\021n5`&lt;r\\\300\207\211\201\2400\215i\300H\232p\303\377\020\\@\317K[\302\224\202P@&amp;\306\355\355^\261l\300\301/\377&lt;N\306@\300#w\001\317\242\236a\300$fd\023!\364U\300\204\327LIK\247V\300J\211\366\022\276\227L@\262\345\254\206\234nL@f{\013\201\313ES@\234\343hU3wg\300\3370\367\305\306cE\300\336A\347;\204\2445\300f\374\242\031\347JF\300\325\2557\&#39;\333\243S@\331\354\345{\232\3547\300\307o)\372T]m@#\005\000W\014oR\300\&#39;\025\227\034&gt;M$\300\310\252\022\\\277\227Q\300l_\243\036\326dP@\333kk\354\363+[@\223)\036\363\204\227S\300&quot;
  }
  initializer {
    dims: 20
    dims: 4
    data_type: 1
    name: &quot;Sc_Scancst&quot;
    raw_data: &quot;\342\327\221?\267O/\277\306\016\236\277\271\377\315&gt;3\2575&gt;\314\361\354&gt;;\266\315\276W\252\320\277\221x\002\277\234\tG?FK\340\276\231[\240\277\3746\206\277\002\263\371?&amp;\303\265\277\020g\332\277$\014\357?b\375\032\276\342.z\277\3778s?/d#\300\207\376=\277\214S\&#39;?\261K]?\0342\304?\205\236\301&gt;\363\023\274?\212\252\036&gt;^&amp;,\277\324\366\334\277Z\027\270\276[*P\277\220\354^\277\241\rf=~/\024\277\320\203\237\276*z\235?m\307\232\276\225\347\231?\263O\306\276\251C\021@ \255?\276\250(\272\277Hm;=\265Dh\277\031\024\004&gt;\262\304T=\256\245:?\374=\277?\005\246Z\277\002\025R\276iJ\240&gt;x\314\341?\313j\017@h\341\314&gt;\223\216z?.:\210=6\271\271\276\231\335\232&gt;\357b\&quot;\277 \304\002\277QN\333&gt;\365\036\227\277k\336\346\2744\224\316\277\026\030\306&gt;\227\330Y\276L=e\277^\323B?]\327\252&gt;\3000\371=\013B\343&gt;hd\323\275\242%\272?\3709\322&gt;(\200\023&gt;\355Ec\277\362\031 &gt;\275\212\375\277\213!\262\276&quot;
  }
  initializer {
    dims: 1
    data_type: 7
    name: &quot;To_TopKcst&quot;
    raw_data: &quot;\002\000\000\000\000\000\000\000&quot;
  }
  initializer {
    dims: 3
    data_type: 7
    name: &quot;knny_Reshapecst&quot;
    raw_data: &quot;\002\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\002\000\000\000\000\000\000\000&quot;
  }
  input {
    name: &quot;input&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
            dim_value: 4
          }
        }
      }
    }
  }
  output {
    name: &quot;variable&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
            dim_value: 2
          }
        }
      }
    }
  }
}
opset_import {
  domain: &quot;&quot;
  version: 15
}
opset_import {
  domain: &quot;ai.onnx.ml&quot;
  version: 15
}
</pre></div>
</div>
<p>Visually it looks like the following:</p>
<img alt="../_images/dot_scan_py.png" src="../_images/dot_scan_py.png" />
<p>The subgraph is executed by operator <a class="reference internal" href="../onnx_doc_folder/onnx__Scan.html#l-onnx-doc-scan"><span class="std std-ref">Scan</span></a>. In this case,
there is one <em>scan</em> input meaning the operator only builds one output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;Scan&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">,</span> <span class="s1">&#39;X2&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">,</span> <span class="s1">&#39;Y2&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Sc_Scan&#39;</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">graph</span><span class="p">,</span> <span class="n">num_scan_inputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>At the first iteration, the subgraph gets <em>X1</em> and the first row of <em>X2</em>.
The graph produces two outputs. The first one replaces <em>X1</em> in the next iteration,
the second one is store in a container to form <em>Y2</em>. At the second iteration,
second input of the subgraph is the second row of <em>X2</em>.
Here is a short summary. Green is the first iteration, blue the second.</p>
<a class="reference internal image-reference" href="../_images/scanop.png"><img alt="../_images/scanop.png" src="../_images/scanop.png" style="width: 400px;" /></a>
</section>
</section>
<section id="functions">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Functions</a><a class="headerlink" href="#functions" title="Permalink to this heading">#</a></h2>
<p>As mentioned in previous chapter, functions can be used to shorten
the code to build the model and offer more possibilities to the runtime
running predictions to be faster if there exists a specific implementation
of this function. If it is not the case, the runtime can still use
the default implementation based on existing operators.</p>
<p>Function <cite>make_function</cite> is used to define a function.
It works like a graph with less types. It is more like a
template. This API may evolve. It does not include intializers either.</p>
<section id="a-function-with-no-attribute">
<h3>A function with no attribute<a class="headerlink" href="#a-function-with-no-attribute" title="Permalink to this heading">#</a></h3>
<p>That’s the more simple case. Every input of the function is a dynamic
object known at execution time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>
    <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">,</span> <span class="n">make_opsetid</span><span class="p">,</span>
    <span class="n">make_function</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="n">new_domain</span> <span class="o">=</span> <span class="s1">&#39;custom&#39;</span>
<span class="n">opset_imports</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_opsetid</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">make_opsetid</span><span class="p">(</span><span class="n">new_domain</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

<span class="c1"># Let&#39;s define a function for a linear regression</span>

<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>

<span class="n">linear_regression</span> <span class="o">=</span> <span class="n">make_function</span><span class="p">(</span>
    <span class="n">new_domain</span><span class="p">,</span>            <span class="c1"># domain name</span>
    <span class="s1">&#39;LinearRegression&#39;</span><span class="p">,</span>     <span class="c1"># function name</span>
    <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span>        <span class="c1"># input names</span>
    <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span>                  <span class="c1"># output names</span>
    <span class="p">[</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span>         <span class="c1"># nodes</span>
    <span class="n">opset_imports</span><span class="p">,</span>          <span class="c1"># opsets</span>
    <span class="p">[])</span>                     <span class="c1"># attribute names</span>

<span class="c1"># Let&#39;s use it in a graph.</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">(</span>
    <span class="p">[</span><span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;LinearRegression&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">],</span> <span class="n">domain</span><span class="o">=</span><span class="n">new_domain</span><span class="p">),</span>
     <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Abs&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])],</span>
    <span class="s1">&#39;example&#39;</span><span class="p">,</span>
    <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">])</span>

<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span>
    <span class="n">graph</span><span class="p">,</span> <span class="n">opset_imports</span><span class="o">=</span><span class="n">opset_imports</span><span class="p">,</span>
    <span class="n">functions</span><span class="o">=</span><span class="p">[</span><span class="n">linear_regression</span><span class="p">])</span>  <span class="c1"># functions to add)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># the work is done, let&#39;s display it...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    input: &quot;B&quot;
    output: &quot;Y1&quot;
    op_type: &quot;LinearRegression&quot;
    domain: &quot;custom&quot;
  }
  node {
    input: &quot;Y1&quot;
    output: &quot;Y&quot;
    op_type: &quot;Abs&quot;
  }
  name: &quot;example&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;B&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  domain: &quot;&quot;
  version: 14
}
opset_import {
  domain: &quot;custom&quot;
  version: 1
}
functions {
  name: &quot;LinearRegression&quot;
  input: &quot;X&quot;
  input: &quot;A&quot;
  input: &quot;B&quot;
  output: &quot;Y&quot;
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  opset_import {
    domain: &quot;&quot;
    version: 14
  }
  opset_import {
    domain: &quot;custom&quot;
    version: 1
  }
  domain: &quot;custom&quot;
}
</pre></div>
</div>
</section>
<section id="a-function-with-attributes">
<h3>A function with attributes<a class="headerlink" href="#a-function-with-attributes" title="Permalink to this heading">#</a></h3>
<p id="index-0">The following functions is equivalent as the previous one except
one input, <em>B</em>, was converted into an argument named <em>bias</em>.
The code is almost the same except the bias is now a constant.
Inside the function definition, a node <em>Constant</em> is created
to insert the argument as a result. It is linked to the argument
with the attribute <cite>ref_attr_name</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span><span class="p">,</span> <span class="n">AttributeProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>
    <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">,</span> <span class="n">make_opsetid</span><span class="p">,</span>
    <span class="n">make_function</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="n">new_domain</span> <span class="o">=</span> <span class="s1">&#39;custom&#39;</span>
<span class="n">opset_imports</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_opsetid</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">make_opsetid</span><span class="p">(</span><span class="n">new_domain</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

<span class="c1"># Let&#39;s define a function for a linear regression</span>
<span class="c1"># The first step consists in creating a constant</span>
<span class="c1"># equal to the input parameter of the function.</span>
<span class="n">cst</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Constant&#39;</span><span class="p">,</span>  <span class="p">[],</span> <span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">])</span>

<span class="n">att</span> <span class="o">=</span> <span class="n">AttributeProto</span><span class="p">()</span>
<span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;value&quot;</span>

<span class="c1"># This line indicates the value comes from the argument</span>
<span class="c1"># named &#39;bias&#39; the function is given.</span>
<span class="n">att</span><span class="o">.</span><span class="n">ref_attr_name</span> <span class="o">=</span> <span class="s2">&quot;bias&quot;</span>
<span class="n">att</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">AttributeProto</span><span class="o">.</span><span class="n">TENSOR</span>
<span class="n">cst</span><span class="o">.</span><span class="n">attribute</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">att</span><span class="p">)</span>

<span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">])</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>

<span class="n">linear_regression</span> <span class="o">=</span> <span class="n">make_function</span><span class="p">(</span>
    <span class="n">new_domain</span><span class="p">,</span>            <span class="c1"># domain name</span>
    <span class="s1">&#39;LinearRegression&#39;</span><span class="p">,</span>     <span class="c1"># function name</span>
    <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span>             <span class="c1"># input names</span>
    <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span>                  <span class="c1"># output names</span>
    <span class="p">[</span><span class="n">cst</span><span class="p">,</span> <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span>    <span class="c1"># nodes</span>
    <span class="n">opset_imports</span><span class="p">,</span>          <span class="c1"># opsets</span>
    <span class="p">[</span><span class="s2">&quot;bias&quot;</span><span class="p">])</span>               <span class="c1"># attribute names</span>

<span class="c1"># Let&#39;s use it in a graph.</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">(</span>
    <span class="p">[</span><span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;LinearRegression&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">],</span> <span class="n">domain</span><span class="o">=</span><span class="n">new_domain</span><span class="p">,</span>
               <span class="c1"># bias is now an argument of the function and defined as a tensor</span>
               <span class="n">bias</span><span class="o">=</span><span class="n">make_tensor</span><span class="p">(</span><span class="s1">&#39;former_B&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.67</span><span class="p">])),</span>
     <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Abs&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])],</span>
    <span class="s1">&#39;example&#39;</span><span class="p">,</span>
    <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">A</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">])</span>

<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span>
    <span class="n">graph</span><span class="p">,</span> <span class="n">opset_imports</span><span class="o">=</span><span class="n">opset_imports</span><span class="p">,</span>
    <span class="n">functions</span><span class="o">=</span><span class="p">[</span><span class="n">linear_regression</span><span class="p">])</span>  <span class="c1"># functions to add)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># the work is done, let&#39;s display it...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;Y1&quot;
    op_type: &quot;LinearRegression&quot;
    attribute {
      name: &quot;bias&quot;
      t {
        dims: 1
        data_type: 1
        float_data: 0.6700000166893005
        name: &quot;former_B&quot;
      }
      type: TENSOR
    }
    domain: &quot;custom&quot;
  }
  node {
    input: &quot;Y1&quot;
    output: &quot;Y&quot;
    op_type: &quot;Abs&quot;
  }
  name: &quot;example&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  domain: &quot;&quot;
  version: 14
}
opset_import {
  domain: &quot;custom&quot;
  version: 1
}
functions {
  name: &quot;LinearRegression&quot;
  input: &quot;X&quot;
  input: &quot;A&quot;
  output: &quot;Y&quot;
  attribute: &quot;bias&quot;
  node {
    output: &quot;B&quot;
    op_type: &quot;Constant&quot;
    attribute {
      name: &quot;value&quot;
      type: TENSOR
      ref_attr_name: &quot;bias&quot;
    }
  }
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
  }
  opset_import {
    domain: &quot;&quot;
    version: 14
  }
  opset_import {
    domain: &quot;custom&quot;
    version: 1
  }
  domain: &quot;custom&quot;
}
</pre></div>
</div>
</section>
</section>
<section id="parsing">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Parsing</a><a class="headerlink" href="#parsing" title="Permalink to this heading">#</a></h2>
<p>Module onnx provides a faster way to define a graph
a lot easier to read. That’s easy to use when the graph is built
in a single function, less easy when the graph is built from many
different functions converting each piece of a machine learning
pipeline.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx.parser</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>

<span class="nb">input</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="s1">    &lt;</span>
<span class="s1">        ir_version: 8,</span>
<span class="s1">        opset_import: [ &#39;&#39; : 15]</span>
<span class="s1">    &gt;</span>
<span class="s1">    agraph (float[I,J] X, float[I] A, float[I] B) =&gt; (float[I] Y) {</span>
<span class="s1">        XA = MatMul(X, A)</span>
<span class="s1">        Y = Add(XA, B)</span>
<span class="s1">    }</span>
<span class="s1">    &#39;&#39;&#39;</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">parse_model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ir_version</span><span class="p">:</span> <span class="mi">8</span>
<span class="n">graph</span> <span class="p">{</span>
<span class="n">node</span> <span class="p">{</span>
    <span class="nb">input</span><span class="p">:</span> <span class="s2">&quot;X&quot;</span>
    <span class="nb">input</span><span class="p">:</span> <span class="s2">&quot;A&quot;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s2">&quot;XA&quot;</span>
    <span class="n">op_type</span><span class="p">:</span> <span class="s2">&quot;MatMul&quot;</span>
    <span class="n">domain</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
<span class="p">}</span>
<span class="n">node</span> <span class="p">{</span>
    <span class="nb">input</span><span class="p">:</span> <span class="s2">&quot;XA&quot;</span>
    <span class="nb">input</span><span class="p">:</span> <span class="s2">&quot;B&quot;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s2">&quot;Y&quot;</span>
    <span class="n">op_type</span><span class="p">:</span> <span class="s2">&quot;Add&quot;</span>
    <span class="n">domain</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
<span class="p">}</span>
<span class="n">name</span><span class="p">:</span> <span class="s2">&quot;agraph&quot;</span>
<span class="nb">input</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="s2">&quot;X&quot;</span>
    <span class="nb">type</span> <span class="p">{</span>
    <span class="n">tensor_type</span> <span class="p">{</span>
        <span class="n">elem_type</span><span class="p">:</span> <span class="mi">1</span>
        <span class="n">shape</span> <span class="p">{</span>
        <span class="n">dim</span> <span class="p">{</span>
            <span class="n">dim_param</span><span class="p">:</span> <span class="s2">&quot;I&quot;</span>
        <span class="p">}</span>
        <span class="n">dim</span> <span class="p">{</span>
            <span class="n">dim_param</span><span class="p">:</span> <span class="s2">&quot;J&quot;</span>
        <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="nb">input</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="s2">&quot;A&quot;</span>
    <span class="nb">type</span> <span class="p">{</span>
    <span class="n">tensor_type</span> <span class="p">{</span>
        <span class="n">elem_type</span><span class="p">:</span> <span class="mi">1</span>
        <span class="n">shape</span> <span class="p">{</span>
        <span class="n">dim</span> <span class="p">{</span>
            <span class="n">dim_param</span><span class="p">:</span> <span class="s2">&quot;I&quot;</span>
        <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="nb">input</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="s2">&quot;B&quot;</span>
    <span class="nb">type</span> <span class="p">{</span>
    <span class="n">tensor_type</span> <span class="p">{</span>
        <span class="n">elem_type</span><span class="p">:</span> <span class="mi">1</span>
        <span class="n">shape</span> <span class="p">{</span>
        <span class="n">dim</span> <span class="p">{</span>
            <span class="n">dim_param</span><span class="p">:</span> <span class="s2">&quot;I&quot;</span>
        <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="n">output</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="s2">&quot;Y&quot;</span>
    <span class="nb">type</span> <span class="p">{</span>
    <span class="n">tensor_type</span> <span class="p">{</span>
        <span class="n">elem_type</span><span class="p">:</span> <span class="mi">1</span>
        <span class="n">shape</span> <span class="p">{</span>
        <span class="n">dim</span> <span class="p">{</span>
            <span class="n">dim_param</span><span class="p">:</span> <span class="s2">&quot;I&quot;</span>
        <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="p">}</span>
<span class="n">opset_import</span> <span class="p">{</span>
<span class="n">domain</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
<span class="n">version</span><span class="p">:</span> <span class="mi">15</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This way is used to create small models but it is rarely used
in converting libraries.</p>
</section>
<section id="checker-and-shape-inference">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">Checker and Shape Inference</a><a class="headerlink" href="#checker-and-shape-inference" title="Permalink to this heading">#</a></h2>
<p>onnx provides a function to check the model is valid.
It checks input type or shapes whenever it can detect inconsistency.
The following example multiplies two matrices of different types
which is not allowed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx.parser</span>
<span class="kn">import</span> <span class="nn">onnx.checker</span>

<span class="nb">input</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="s1">    &lt;</span>
<span class="s1">        ir_version: 8,</span>
<span class="s1">        opset_import: [ &quot;&quot; : 15]</span>
<span class="s1">    &gt;</span>
<span class="s1">    agraph (float[I,4] X, float[4,2] A, int[4] B) =&gt; (float[I] Y) {</span>
<span class="s1">        XA = MatMul(X, A)</span>
<span class="s1">        Y = Add(XA, B)</span>
<span class="s1">    }</span>
<span class="s1">    &#39;&#39;&#39;</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">parse_model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">onnx</span><span class="o">.</span><span class="n">checker</span><span class="o">.</span><span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>b&#39;[ParseError at position (line: 6 column: 44)]\nError context:     agraph (float[I,4] X, float[4,2] A, int[4] B) =&gt; (float[I] Y) {\nExpected character ) not found.&#39;
</pre></div>
</div>
<p><cite>check_model</cite> raises an error due to that inconsistency.
This work for all operators defined in the main domain or the ML domain.
It remains silent for any custom operator not defined in any specification.</p>
<p>Shape inference serves one purpose: estimate the shape
and the type of intermediate results.
If known, the runtime can estimate the memory consumption
beforehand and optimize the computation. It can fuse some
operators, it can do the computation inplace…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx.parser</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">helper</span><span class="p">,</span> <span class="n">shape_inference</span>

<span class="nb">input</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="s1">    &lt;</span>
<span class="s1">        ir_version: 8,</span>
<span class="s1">        opset_import: [ &quot;&quot; : 15]</span>
<span class="s1">    &gt;</span>
<span class="s1">    agraph (float[I,4] X, float[4,2] A, float[4] B) =&gt; (float[I] Y) {</span>
<span class="s1">        XA = MatMul(X, A)</span>
<span class="s1">        Y = Add(XA, B)</span>
<span class="s1">    }</span>
<span class="s1">    &#39;&#39;&#39;</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">parse_model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">inferred_model</span> <span class="o">=</span> <span class="n">shape_inference</span><span class="o">.</span><span class="n">infer_shapes</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">inferred_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ir_version: 8
graph {
  node {
    input: &quot;X&quot;
    input: &quot;A&quot;
    output: &quot;XA&quot;
    op_type: &quot;MatMul&quot;
    domain: &quot;&quot;
  }
  node {
    input: &quot;XA&quot;
    input: &quot;B&quot;
    output: &quot;Y&quot;
    op_type: &quot;Add&quot;
    domain: &quot;&quot;
  }
  name: &quot;agraph&quot;
  input {
    name: &quot;X&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_param: &quot;I&quot;
          }
          dim {
            dim_value: 4
          }
        }
      }
    }
  }
  input {
    name: &quot;A&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 2
          }
        }
      }
    }
  }
  input {
    name: &quot;B&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
        }
      }
    }
  }
  output {
    name: &quot;Y&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_param: &quot;I&quot;
          }
        }
      }
    }
  }
  value_info {
    name: &quot;XA&quot;
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_param: &quot;I&quot;
          }
          dim {
            dim_value: 2
          }
        }
      }
    }
  }
}
opset_import {
  domain: &quot;&quot;
  version: 15
}
</pre></div>
</div>
<p>There is a new attribute <cite>value_info</cite> which stores the inferred shapes.
Letter <cite>I</cite> in <code class="docutils literal notranslate"><span class="pre">dim_param:</span> <span class="pre">&quot;I&quot;</span></code> can be seen as a variable. It depends on the inputs
but the function is able to tell which intermediate result will share
the same dimension.
Shape inference does not work all the time. For example,
a Reshape operator. Shape inference only works if the shape is constant.
If not constant, the shape cannot be easily inferred unless
the following nodes expect specific shape.</p>
</section>
<section id="implementation-details">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">Implementation details</a><a class="headerlink" href="#implementation-details" title="Permalink to this heading">#</a></h2>
<section id="python-and-c">
<h3>Python and C++<a class="headerlink" href="#python-and-c" title="Permalink to this heading">#</a></h3>
<p>onnx relies on protobuf to define its type.
You would assume that a python object is just a wrapper around
a C pointer on the internal structure. Therefore, it should be
possible to access internal data from a function receiving a python
object of type <cite>ModelProto</cite>. But it is not. According to
<a class="reference external" href="https://developers.google.com/protocol-buffers/docs/news/2022-05-06">Protobuf 4, changes</a>,
this is no longer possible after version 4 and it is safer to assume the
only way to get a hold on the content is to serialize the model
into bytes, give it the C function, then deserialize it.
Functions like <cite>check_model</cite> or
<cite>shape_inference</cite> are calling <cite>SerializeToString</cite> then
<cite>ParseFromString</cite> before checking the model with a C code.</p>
</section>
<section id="attributes-and-inputs">
<h3>Attributes and inputs<a class="headerlink" href="#attributes-and-inputs" title="Permalink to this heading">#</a></h3>
<p>There is a clear distinction between the two. Inputs are dynamic and
may change at every execution. Attributes never changes and an optimizer
can improve the execution graph assuming it never changes.
Therefore, it is impossible to turn an input into an attribute.
And the operator <em>Constant</em> is the only operator changing an
attribute into an input.</p>
</section>
<section id="shape-or-no-shape">
<h3>Shape or no shape<a class="headerlink" href="#shape-or-no-shape" title="Permalink to this heading">#</a></h3>
<p>onnx usually expects a shape for every input or output
assuming the rank (or the number of dimensions) is known.
What if we need to create a valid graph for every dimension?
This case is still puzzling.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span><span class="p">,</span> <span class="n">FunctionProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_model</span><span class="p">,</span> <span class="n">make_node</span><span class="p">,</span> <span class="n">set_model_props</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>
    <span class="n">make_graph</span><span class="p">,</span> <span class="n">make_tensor_value_info</span><span class="p">,</span> <span class="n">make_opsetid</span><span class="p">,</span>
    <span class="n">make_function</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnx.checker</span> <span class="kn">import</span> <span class="n">check_model</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>

<span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">shapes</span><span class="p">):</span>
    <span class="n">new_domain</span> <span class="o">=</span> <span class="s1">&#39;custom&#39;</span>
    <span class="n">opset_imports</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_opsetid</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">make_opsetid</span><span class="p">(</span><span class="n">new_domain</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="n">node1</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">])</span>
    <span class="n">node2</span> <span class="o">=</span> <span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;XA&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="n">shapes</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">])</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="n">shapes</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">])</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="n">shapes</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>

    <span class="n">graph</span> <span class="o">=</span> <span class="n">make_graph</span><span class="p">([</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span> <span class="s1">&#39;example&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">A</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">])</span>

    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">opset_imports</span><span class="o">=</span><span class="n">opset_imports</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">onnx_model</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------- case 1: 2D x 2D -&gt; 2D&quot;</span><span class="p">)</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]})</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span>
    <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------- case 2: 2D x 1D -&gt; 1D&quot;</span><span class="p">)</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">]})</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span>
    <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------- case 3: 2D x 0D -&gt; 0D&quot;</span><span class="p">)</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="p">[]})</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------- case 4: 2D x None -&gt; None&quot;</span><span class="p">)</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">})</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">),</span> <span class="n">e</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span>
    <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------- end&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>----------- case 1: 2D x 2D -&gt; 2D
[array([[-3.909173  ,  1.1797273 ],
       [-5.0370026 ,  0.02031612]], dtype=float32)]
----------- case 2: 2D x 1D -&gt; 1D
[array([0.64249563, 0.14326349], dtype=float32)]
----------- case 3: 2D x 0D -&gt; 0D
[ONNXRuntimeError] : 1 : FAIL : Node () Op (MatMul) [ShapeInferenceError] Input tensors of wrong rank (0).
----------- case 4: 2D x None -&gt; None
&lt;class &#39;onnx.onnx_cpp2py_export.checker.ValidationError&#39;&gt; Field &#39;shape&#39; of &#39;type&#39; is required but missing.
[array([-1.9411099 ,  0.98187816], dtype=float32)]
----------- end
</pre></div>
</div>
</section>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="concepts.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">ONNX Concepts</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="converters.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Converters</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.2.1.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>