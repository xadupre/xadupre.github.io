
.. _l-onnx-doc-GRU:

===
GRU
===

.. contents::
    :local:


.. _l-onnx-op-gru-14:

GRU - 14
========

**Version**

* **name**: `GRU (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU>`_
* **domain**: **main**
* **since_version**: **14**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 14**.

**Summary**

Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.

Notations:

`X` - input tensor

`z` - update gate

`r` - reset gate

`h` - hidden gate

`t` - time step (t-1 means previous time step)

`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates

`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates

`Wb[zrh]` - W bias vectors for update, reset, and hidden gates

`Rb[zrh]` - R bias vectors for update, reset, and hidden gates

`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates

`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates

`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates

`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates

`H` - Hidden state

`num_directions` - 2 if direction == bidirectional else 1

Activation functions:

  Relu(x)                - max(0, x)

  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})

  Sigmoid(x)             - 1/(1 + e^{-x})

  (NOTE: Below are optional)

  Affine(x)              - alpha*x + beta

  LeakyRelu(x)           - x if x >= 0 else alpha * x

  ThresholdedRelu(x)     - x if x >= alpha else 0

  ScaledTanh(x)          - alpha*Tanh(beta*x)

  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)

  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)

  Softsign(x)            - x/(1 + |x|)

  Softplus(x)            - log(1 + e^x)

Equations (Default: f=Sigmoid, g=Tanh):

  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)

  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)

  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0

  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0

  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.

**Attributes**

* **activation_alpha**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM. Default values are the same as of
  corresponding ONNX operators.For example with LeakyRelu, the default
  alpha is 0.01.
* **activation_beta**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM. Default values are the same as of
  corresponding ONNX operators.
* **activations**:
  A list of 2 (or 4 if bidirectional) activation functions for update,
  reset, and hidden gates. The activation functions must be one of the
  activation functions specified above. Optional: See the equations
  for default if not specified.
* **clip**:
  Cell clip threshold. Clipping bounds the elements of a tensor in the
  range of [-threshold, +threshold] and is applied to the input of
  activations. No clip if not specified.
* **direction**:
  Specify if the RNN is forward, reverse, or bidirectional. Must be
  one of forward (default), reverse, or bidirectional.
* **hidden_size**:
  Number of neurons in the hidden layer
* **layout**:
  The shape format of inputs X, initial_h and outputs Y, Y_h. If 0,
  the following shapes are expected: X.shape = [seq_length,
  batch_size, input_size], Y.shape = [seq_length, num_directions,
  batch_size, hidden_size], initial_h.shape = Y_h.shape =
  [num_directions, batch_size, hidden_size]. If 1, the following
  shapes are expected: X.shape = [batch_size, seq_length, input_size],
  Y.shape = [batch_size, seq_length, num_directions, hidden_size],
  initial_h.shape = Y_h.shape = [batch_size, num_directions,
  hidden_size].
* **linear_before_reset**:
  When computing the output of the hidden gate, apply the linear
  transformation before multiplying by the output of the reset gate.

**Inputs**

Between 3 and 6 inputs.

* **X** (heterogeneous) - **T**:
  The input sequences packed (and potentially padded) into one 3-D
  tensor with the shape of `[seq_length, batch_size, input_size]`.
* **W** (heterogeneous) - **T**:
  The weight tensor for the gates. Concatenation of `W[zrh]` and
  `WB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, input_size]`.
* **R** (heterogeneous) - **T**:
  The recurrence weight tensor. Concatenation of `R[zrh]` and
  `RB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, hidden_size]`.
* **B** (optional, heterogeneous) - **T**:
  The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]`
  and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0.
  This tensor has shape `[num_directions, 6*hidden_size]`. Optional:
  If not specified - assumed to be 0
* **sequence_lens** (optional, heterogeneous) - **T1**:
  Optional tensor specifying lengths of the sequences in a batch. If
  not specified - assumed all sequences in the batch to have length
  `seq_length`. It has shape `[batch_size]`.
* **initial_h** (optional, heterogeneous) - **T**:
  Optional initial value of the hidden. If not specified - assumed to
  be 0. It has shape `[num_directions, batch_size, hidden_size]`.

**Outputs**

Between 0 and 2 outputs.

* **Y** (optional, heterogeneous) - **T**:
  A tensor that concats all the intermediate output values of the
  hidden. It has shape `[seq_length, num_directions, batch_size,
  hidden_size]`.
* **Y_h** (optional, heterogeneous) - **T**:
  The last output value of the hidden. It has shape `[num_directions,
  batch_size, hidden_size]`.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
* **T1** in (
  tensor(int32)
  ):
  Constrain seq_lens to integer tensor.

**Examples**

**_defaults**

::

    input = np.array([[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]]).astype(np.float32)

    input_size = 2
    hidden_size = 5
    weight_scale = 0.1
    number_of_gates = 3

    node = onnx.helper.make_node(
        "GRU", inputs=["X", "W", "R"], outputs=["", "Y_h"], hidden_size=hidden_size
    )

    W = weight_scale * np.ones(
        (1, number_of_gates * hidden_size, input_size)
    ).astype(np.float32)
    R = weight_scale * np.ones(
        (1, number_of_gates * hidden_size, hidden_size)
    ).astype(np.float32)

    gru = GRU_Helper(X=input, W=W, R=R)
    _, Y_h = gru.step()
    expect(
        node,
        inputs=[input, W, R],
        outputs=[Y_h.astype(np.float32)],
        name="test_gru_defaults",
    )

**_initial_bias**

::

    input = np.array([[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]]).astype(
        np.float32
    )

    input_size = 3
    hidden_size = 3
    weight_scale = 0.1
    custom_bias = 0.1
    number_of_gates = 3

    node = onnx.helper.make_node(
        "GRU",
        inputs=["X", "W", "R", "B"],
        outputs=["", "Y_h"],
        hidden_size=hidden_size,
    )

    W = weight_scale * np.ones(
        (1, number_of_gates * hidden_size, input_size)
    ).astype(np.float32)
    R = weight_scale * np.ones(
        (1, number_of_gates * hidden_size, hidden_size)
    ).astype(np.float32)

    # Adding custom bias
    W_B = custom_bias * np.ones((1, number_of_gates * hidden_size)).astype(
        np.float32
    )
    R_B = np.zeros((1, number_of_gates * hidden_size)).astype(np.float32)
    B = np.concatenate((W_B, R_B), axis=1)

    gru = GRU_Helper(X=input, W=W, R=R, B=B)
    _, Y_h = gru.step()
    expect(
        node,
        inputs=[input, W, R, B],
        outputs=[Y_h.astype(np.float32)],
        name="test_gru_with_initial_bias",
    )

**_seq_length**

::

    input = np.array(
        [
            [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]],
            [[10.0, 11.0, 12.0], [13.0, 14.0, 15.0], [16.0, 17.0, 18.0]],
        ]
    ).astype(np.float32)

    input_size = 3
    hidden_size = 5
    number_of_gates = 3

    node = onnx.helper.make_node(
        "GRU",
        inputs=["X", "W", "R", "B"],
        outputs=["", "Y_h"],
        hidden_size=hidden_size,
    )

    W = np.random.randn(1, number_of_gates * hidden_size, input_size).astype(
        np.float32
    )
    R = np.random.randn(1, number_of_gates * hidden_size, hidden_size).astype(
        np.float32
    )

    # Adding custom bias
    W_B = np.random.randn(1, number_of_gates * hidden_size).astype(np.float32)
    R_B = np.random.randn(1, number_of_gates * hidden_size).astype(np.float32)
    B = np.concatenate((W_B, R_B), axis=1)

    gru = GRU_Helper(X=input, W=W, R=R, B=B)
    _, Y_h = gru.step()
    expect(
        node,
        inputs=[input, W, R, B],
        outputs=[Y_h.astype(np.float32)],
        name="test_gru_seq_length",
    )

**_batchwise**

::

    input = np.array([[[1.0, 2.0]], [[3.0, 4.0]], [[5.0, 6.0]]]).astype(np.float32)

    input_size = 2
    hidden_size = 6
    number_of_gates = 3
    weight_scale = 0.2
    layout = 1

    node = onnx.helper.make_node(
        "GRU",
        inputs=["X", "W", "R"],
        outputs=["Y", "Y_h"],
        hidden_size=hidden_size,
        layout=layout,
    )

    W = weight_scale * np.ones(
        (1, number_of_gates * hidden_size, input_size)
    ).astype(np.float32)
    R = weight_scale * np.ones(
        (1, number_of_gates * hidden_size, hidden_size)
    ).astype(np.float32)

    gru = GRU_Helper(X=input, W=W, R=R, layout=layout)
    Y, Y_h = gru.step()
    expect(
        node,
        inputs=[input, W, R],
        outputs=[Y.astype(np.float32), Y_h.astype(np.float32)],
        name="test_gru_batchwise",
    )

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to66__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to66__0">f</a></td><td class="diff_header" id="from66_1">1</td><td nowrap="nowrap">Computes&nbsp;an&nbsp;one-layer&nbsp;GRU.&nbsp;This&nbsp;operator&nbsp;is&nbsp;usually&nbsp;supported&nbsp;via&nbsp;some&nbsp;custom</td><td class="diff_next"><a href="#difflib_chg_to66__0">f</a></td><td class="diff_header" id="to66_1">1</td><td nowrap="nowrap">Computes&nbsp;an&nbsp;one-layer&nbsp;GRU.&nbsp;This&nbsp;operator&nbsp;is&nbsp;usually&nbsp;supported&nbsp;via&nbsp;some&nbsp;custom</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_2">2</td><td nowrap="nowrap">implementation&nbsp;such&nbsp;as&nbsp;CuDNN.</td><td class="diff_next"></td><td class="diff_header" id="to66_2">2</td><td nowrap="nowrap">implementation&nbsp;such&nbsp;as&nbsp;CuDNN.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_3">3</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_4">4</td><td nowrap="nowrap">Notations:</td><td class="diff_next"></td><td class="diff_header" id="to66_4">4</td><td nowrap="nowrap">Notations:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_5">5</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_6">6</td><td nowrap="nowrap">X&nbsp;-&nbsp;input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to66_6">6</td><td nowrap="nowrap">X&nbsp;-&nbsp;input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_8">8</td><td nowrap="nowrap">z&nbsp;-&nbsp;update&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to66_8">8</td><td nowrap="nowrap">z&nbsp;-&nbsp;update&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_10">10</td><td nowrap="nowrap">r&nbsp;-&nbsp;reset&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to66_10">10</td><td nowrap="nowrap">r&nbsp;-&nbsp;reset&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_11">11</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_11">11</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_12">12</td><td nowrap="nowrap">h&nbsp;-&nbsp;hidden&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to66_12">12</td><td nowrap="nowrap">h&nbsp;-&nbsp;hidden&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_13">13</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_14">14</td><td nowrap="nowrap">t&nbsp;-&nbsp;time&nbsp;step&nbsp;(t-1&nbsp;means&nbsp;previous&nbsp;time&nbsp;step)</td><td class="diff_next"></td><td class="diff_header" id="to66_14">14</td><td nowrap="nowrap">t&nbsp;-&nbsp;time&nbsp;step&nbsp;(t-1&nbsp;means&nbsp;previous&nbsp;time&nbsp;step)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_15">15</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_16">16</td><td nowrap="nowrap">W[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_16">16</td><td nowrap="nowrap">W[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_18">18</td><td nowrap="nowrap">R[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_18">18</td><td nowrap="nowrap">R[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_20">20</td><td nowrap="nowrap">Wb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_20">20</td><td nowrap="nowrap">Wb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_21">21</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_22">22</td><td nowrap="nowrap">Rb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_22">22</td><td nowrap="nowrap">Rb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_23">23</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_24">24</td><td nowrap="nowrap">WB[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_24">24</td><td nowrap="nowrap">WB[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_25">25</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_25">25</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_26">26</td><td nowrap="nowrap">RB[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_26">26</td><td nowrap="nowrap">RB[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_28">28</td><td nowrap="nowrap">WBb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_28">28</td><td nowrap="nowrap">WBb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_30">30</td><td nowrap="nowrap">RBb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to66_30">30</td><td nowrap="nowrap">RBb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_31">31</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_31">31</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_32">32</td><td nowrap="nowrap">H&nbsp;-&nbsp;Hidden&nbsp;state</td><td class="diff_next"></td><td class="diff_header" id="to66_32">32</td><td nowrap="nowrap">H&nbsp;-&nbsp;Hidden&nbsp;state</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_33">33</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_34">34</td><td nowrap="nowrap">num_directions&nbsp;-&nbsp;2&nbsp;if&nbsp;direction&nbsp;==&nbsp;bidirectional&nbsp;else&nbsp;1</td><td class="diff_next"></td><td class="diff_header" id="to66_34">34</td><td nowrap="nowrap">num_directions&nbsp;-&nbsp;2&nbsp;if&nbsp;direction&nbsp;==&nbsp;bidirectional&nbsp;else&nbsp;1</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_35">35</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_35">35</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_36">36</td><td nowrap="nowrap">Activation&nbsp;functions:</td><td class="diff_next"></td><td class="diff_header" id="to66_36">36</td><td nowrap="nowrap">Activation&nbsp;functions:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_37">37</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_37">37</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Relu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;max(0,&nbsp;x)</td><td class="diff_next"></td><td class="diff_header" id="to66_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Relu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;max(0,&nbsp;x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_39">39</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_39">39</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Tanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;(1&nbsp;-&nbsp;e^{-2x})/(1&nbsp;+&nbsp;e^{-2x})</td><td class="diff_next"></td><td class="diff_header" id="to66_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Tanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;(1&nbsp;-&nbsp;e^{-2x})/(1&nbsp;+&nbsp;e^{-2x})</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_41">41</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_41">41</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Sigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;1/(1&nbsp;+&nbsp;e^{-x})</td><td class="diff_next"></td><td class="diff_header" id="to66_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Sigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;1/(1&nbsp;+&nbsp;e^{-x})</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_43">43</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_43">43</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;(NOTE:&nbsp;Below&nbsp;are&nbsp;optional)</td><td class="diff_next"></td><td class="diff_header" id="to66_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;(NOTE:&nbsp;Below&nbsp;are&nbsp;optional)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_45">45</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_45">45</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;Affine(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*x&nbsp;+&nbsp;beta</td><td class="diff_next"></td><td class="diff_header" id="to66_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;Affine(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*x&nbsp;+&nbsp;beta</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_47">47</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_47">47</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;LeakyRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha&nbsp;*&nbsp;x</td><td class="diff_next"></td><td class="diff_header" id="to66_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;LeakyRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha&nbsp;*&nbsp;x</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_49">49</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_49">49</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;ThresholdedRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;alpha&nbsp;else&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to66_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;ThresholdedRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;alpha&nbsp;else&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_51">51</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_51">51</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;ScaledTanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*Tanh(beta*x)</td><td class="diff_next"></td><td class="diff_header" id="to66_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;ScaledTanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*Tanh(beta*x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_53">53</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_53">53</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;HardSigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;min(max(alpha*x&nbsp;+&nbsp;beta,&nbsp;0),&nbsp;1)</td><td class="diff_next"></td><td class="diff_header" id="to66_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;HardSigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;min(max(alpha*x&nbsp;+&nbsp;beta,&nbsp;0),&nbsp;1)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_55">55</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_55">55</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;Elu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha*(e^x&nbsp;-&nbsp;1)</td><td class="diff_next"></td><td class="diff_header" id="to66_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;Elu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha*(e^x&nbsp;-&nbsp;1)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_57">57</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_57">57</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;Softsign(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x/(1&nbsp;+&nbsp;|x|)</td><td class="diff_next"></td><td class="diff_header" id="to66_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;Softsign(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x/(1&nbsp;+&nbsp;|x|)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_59">59</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_59">59</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;Softplus(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;log(1&nbsp;+&nbsp;e^x)</td><td class="diff_next"></td><td class="diff_header" id="to66_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;Softplus(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;log(1&nbsp;+&nbsp;e^x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_61">61</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_61">61</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_62">62</td><td nowrap="nowrap">Equations&nbsp;(Default:&nbsp;f=Sigmoid,&nbsp;g=Tanh):</td><td class="diff_next"></td><td class="diff_header" id="to66_62">62</td><td nowrap="nowrap">Equations&nbsp;(Default:&nbsp;f=Sigmoid,&nbsp;g=Tanh):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_63">63</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_63">63</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;zt&nbsp;=&nbsp;f(Xt*(Wz^T)&nbsp;+&nbsp;Ht-1*(Rz^T)&nbsp;+&nbsp;Wbz&nbsp;+&nbsp;Rbz)</td><td class="diff_next"></td><td class="diff_header" id="to66_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;zt&nbsp;=&nbsp;f(Xt*(Wz^T)&nbsp;+&nbsp;Ht-1*(Rz^T)&nbsp;+&nbsp;Wbz&nbsp;+&nbsp;Rbz)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_65">65</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_65">65</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;rt&nbsp;=&nbsp;f(Xt*(Wr^T)&nbsp;+&nbsp;Ht-1*(Rr^T)&nbsp;+&nbsp;Wbr&nbsp;+&nbsp;Rbr)</td><td class="diff_next"></td><td class="diff_header" id="to66_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;rt&nbsp;=&nbsp;f(Xt*(Wr^T)&nbsp;+&nbsp;Ht-1*(Rr^T)&nbsp;+&nbsp;Wbr&nbsp;+&nbsp;Rbr)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_67">67</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_67">67</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;Ht-1)*(Rh^T)&nbsp;+&nbsp;Rbh&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;default,&nbsp;when&nbsp;linear_before_reset&nbsp;=&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to66_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;Ht-1)*(Rh^T)&nbsp;+&nbsp;Rbh&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;default,&nbsp;when&nbsp;linear_before_reset&nbsp;=&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_69">69</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_69">69</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;(Ht-1*(Rh^T)&nbsp;+&nbsp;Rbh))&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;when&nbsp;linear_before_reset&nbsp;!=&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to66_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;(Ht-1*(Rh^T)&nbsp;+&nbsp;Rbh))&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;when&nbsp;linear_before_reset&nbsp;!=&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_71">71</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_71">71</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;Ht&nbsp;=&nbsp;(1&nbsp;-&nbsp;zt)&nbsp;(.)&nbsp;ht&nbsp;+&nbsp;zt&nbsp;(.)&nbsp;Ht-1</td><td class="diff_next"></td><td class="diff_header" id="to66_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;Ht&nbsp;=&nbsp;(1&nbsp;-&nbsp;zt)&nbsp;(.)&nbsp;ht&nbsp;+&nbsp;zt&nbsp;(.)&nbsp;Ht-1</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_73">73</td><td nowrap="nowrap">This&nbsp;operator&nbsp;has&nbsp;**optional**&nbsp;inputs/outputs.&nbsp;See&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/IR.md&gt;_&nbsp;for&nbsp;more&nbsp;details&nbsp;about&nbsp;the&nbsp;representation&nbsp;of&nbsp;optional&nbsp;arguments.&nbsp;An&nbsp;empty&nbsp;string&nbsp;may&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;place&nbsp;of&nbsp;an&nbsp;actual&nbsp;argument's&nbsp;name&nbsp;to&nbsp;indicate&nbsp;a&nbsp;missing&nbsp;argument.&nbsp;Trailing&nbsp;optional&nbsp;arguments&nbsp;(those&nbsp;not&nbsp;followed&nbsp;by&nbsp;an&nbsp;argument&nbsp;that&nbsp;is&nbsp;present)&nbsp;may&nbsp;also&nbsp;be&nbsp;simply&nbsp;omitted.</td><td class="diff_next"></td><td class="diff_header" id="to66_73">73</td><td nowrap="nowrap">This&nbsp;operator&nbsp;has&nbsp;**optional**&nbsp;inputs/outputs.&nbsp;See&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/IR.md&gt;_&nbsp;for&nbsp;more&nbsp;details&nbsp;about&nbsp;the&nbsp;representation&nbsp;of&nbsp;optional&nbsp;arguments.&nbsp;An&nbsp;empty&nbsp;string&nbsp;may&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;place&nbsp;of&nbsp;an&nbsp;actual&nbsp;argument's&nbsp;name&nbsp;to&nbsp;indicate&nbsp;a&nbsp;missing&nbsp;argument.&nbsp;Trailing&nbsp;optional&nbsp;arguments&nbsp;(those&nbsp;not&nbsp;followed&nbsp;by&nbsp;an&nbsp;argument&nbsp;that&nbsp;is&nbsp;present)&nbsp;may&nbsp;also&nbsp;be&nbsp;simply&nbsp;omitted.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_74">74</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_74">74</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_75">75</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to66_75">75</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_76">76</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_76">76</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_77">77</td><td nowrap="nowrap">*&nbsp;**activation_alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to66_77">77</td><td nowrap="nowrap">*&nbsp;**activation_alpha**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to66_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td><td class="diff_next"></td><td class="diff_header" id="to66_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to66_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.For&nbsp;example&nbsp;with&nbsp;LeakyRelu,&nbsp;the&nbsp;default</td><td class="diff_next"></td><td class="diff_header" id="to66_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.For&nbsp;example&nbsp;with&nbsp;LeakyRelu,&nbsp;the&nbsp;default</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;alpha&nbsp;is&nbsp;0.01.</td><td class="diff_next"></td><td class="diff_header" id="to66_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;alpha&nbsp;is&nbsp;0.01.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_83">83</td><td nowrap="nowrap">*&nbsp;**activation_beta**:</td><td class="diff_next"></td><td class="diff_header" id="to66_83">83</td><td nowrap="nowrap">*&nbsp;**activation_beta**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_84">84</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to66_84">84</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td><td class="diff_next"></td><td class="diff_header" id="to66_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to66_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_87">87</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.</td><td class="diff_next"></td><td class="diff_header" id="to66_87">87</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_88">88</td><td nowrap="nowrap">*&nbsp;**activations**:</td><td class="diff_next"></td><td class="diff_header" id="to66_88">88</td><td nowrap="nowrap">*&nbsp;**activations**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_89">89</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;2&nbsp;(or&nbsp;4&nbsp;if&nbsp;bidirectional)&nbsp;activation&nbsp;functions&nbsp;for&nbsp;update,</td><td class="diff_next"></td><td class="diff_header" id="to66_89">89</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;2&nbsp;(or&nbsp;4&nbsp;if&nbsp;bidirectional)&nbsp;activation&nbsp;functions&nbsp;for&nbsp;update,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_90">90</td><td nowrap="nowrap">&nbsp;&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates.&nbsp;The&nbsp;activation&nbsp;functions&nbsp;must&nbsp;be&nbsp;one&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to66_90">90</td><td nowrap="nowrap">&nbsp;&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates.&nbsp;The&nbsp;activation&nbsp;functions&nbsp;must&nbsp;be&nbsp;one&nbsp;of&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_91">91</td><td nowrap="nowrap">&nbsp;&nbsp;activation&nbsp;functions&nbsp;specified&nbsp;above.&nbsp;Optional:&nbsp;See&nbsp;the&nbsp;equations</td><td class="diff_next"></td><td class="diff_header" id="to66_91">91</td><td nowrap="nowrap">&nbsp;&nbsp;activation&nbsp;functions&nbsp;specified&nbsp;above.&nbsp;Optional:&nbsp;See&nbsp;the&nbsp;equations</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_92">92</td><td nowrap="nowrap">&nbsp;&nbsp;for&nbsp;default&nbsp;if&nbsp;not&nbsp;specified.</td><td class="diff_next"></td><td class="diff_header" id="to66_92">92</td><td nowrap="nowrap">&nbsp;&nbsp;for&nbsp;default&nbsp;if&nbsp;not&nbsp;specified.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_93">93</td><td nowrap="nowrap">*&nbsp;**clip**:</td><td class="diff_next"></td><td class="diff_header" id="to66_93">93</td><td nowrap="nowrap">*&nbsp;**clip**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_94">94</td><td nowrap="nowrap">&nbsp;&nbsp;Cell&nbsp;clip&nbsp;threshold.&nbsp;Clipping&nbsp;bounds&nbsp;the&nbsp;elements&nbsp;of&nbsp;a&nbsp;tensor&nbsp;in&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to66_94">94</td><td nowrap="nowrap">&nbsp;&nbsp;Cell&nbsp;clip&nbsp;threshold.&nbsp;Clipping&nbsp;bounds&nbsp;the&nbsp;elements&nbsp;of&nbsp;a&nbsp;tensor&nbsp;in&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_95">95</td><td nowrap="nowrap">&nbsp;&nbsp;range&nbsp;of&nbsp;[-threshold,&nbsp;+threshold]&nbsp;and&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;input&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to66_95">95</td><td nowrap="nowrap">&nbsp;&nbsp;range&nbsp;of&nbsp;[-threshold,&nbsp;+threshold]&nbsp;and&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;input&nbsp;of</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_96">96</td><td nowrap="nowrap">&nbsp;&nbsp;activations.&nbsp;No&nbsp;clip&nbsp;if&nbsp;not&nbsp;specified.</td><td class="diff_next"></td><td class="diff_header" id="to66_96">96</td><td nowrap="nowrap">&nbsp;&nbsp;activations.&nbsp;No&nbsp;clip&nbsp;if&nbsp;not&nbsp;specified.</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to66__0"></td><td class="diff_header" id="from66_97">97</td><td nowrap="nowrap">*&nbsp;**direction**:</td><td class="diff_next"></td><td class="diff_header" id="to66_97">97</td><td nowrap="nowrap">*&nbsp;**direction**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_98">98</td><td nowrap="nowrap">&nbsp;&nbsp;Specify&nbsp;if&nbsp;the&nbsp;RNN&nbsp;is&nbsp;forward,&nbsp;reverse,&nbsp;or&nbsp;bidirectional.&nbsp;Must&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to66_98">98</td><td nowrap="nowrap">&nbsp;&nbsp;Specify&nbsp;if&nbsp;the&nbsp;RNN&nbsp;is&nbsp;forward,&nbsp;reverse,&nbsp;or&nbsp;bidirectional.&nbsp;Must&nbsp;be</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_99">99</td><td nowrap="nowrap">&nbsp;&nbsp;one&nbsp;of&nbsp;forward&nbsp;(default),&nbsp;reverse,&nbsp;or&nbsp;bidirectional.</td><td class="diff_next"></td><td class="diff_header" id="to66_99">99</td><td nowrap="nowrap">&nbsp;&nbsp;one&nbsp;of&nbsp;forward&nbsp;(default),&nbsp;reverse,&nbsp;or&nbsp;bidirectional.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_100">100</td><td nowrap="nowrap">*&nbsp;**hidden_size**:</td><td class="diff_next"></td><td class="diff_header" id="to66_100">100</td><td nowrap="nowrap">*&nbsp;**hidden_size**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_101">101</td><td nowrap="nowrap">&nbsp;&nbsp;Number&nbsp;of&nbsp;neurons&nbsp;in&nbsp;the&nbsp;hidden&nbsp;layer</td><td class="diff_next"></td><td class="diff_header" id="to66_101">101</td><td nowrap="nowrap">&nbsp;&nbsp;Number&nbsp;of&nbsp;neurons&nbsp;in&nbsp;the&nbsp;hidden&nbsp;layer</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to66__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to66__top">t</a></td><td class="diff_header" id="to66_102">102</td><td nowrap="nowrap"><span class="diff_add">*&nbsp;**layout**:</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_103">103</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;The&nbsp;shape&nbsp;format&nbsp;of&nbsp;inputs&nbsp;X,&nbsp;initial_h&nbsp;and&nbsp;outputs&nbsp;Y,&nbsp;Y_h.&nbsp;If&nbsp;0,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_104">104</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;the&nbsp;following&nbsp;shapes&nbsp;are&nbsp;expected:&nbsp;X.shape&nbsp;=&nbsp;[seq_length,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_105">105</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;batch_size,&nbsp;input_size],&nbsp;Y.shape&nbsp;=&nbsp;[seq_length,&nbsp;num_directions,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_106">106</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;batch_size,&nbsp;hidden_size],&nbsp;initial_h.shape&nbsp;=&nbsp;Y_h.shape&nbsp;=</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_107">107</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;[num_directions,&nbsp;batch_size,&nbsp;hidden_size].&nbsp;If&nbsp;1,&nbsp;the&nbsp;following</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_108">108</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;shapes&nbsp;are&nbsp;expected:&nbsp;X.shape&nbsp;=&nbsp;[batch_size,&nbsp;seq_length,&nbsp;input_size],</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_109">109</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Y.shape&nbsp;=&nbsp;[batch_size,&nbsp;seq_length,&nbsp;num_directions,&nbsp;hidden_size],</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_110">110</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;initial_h.shape&nbsp;=&nbsp;Y_h.shape&nbsp;=&nbsp;[batch_size,&nbsp;num_directions,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_111">111</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;hidden_size].</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_102">102</td><td nowrap="nowrap">*&nbsp;**linear_before_reset**:</td><td class="diff_next"></td><td class="diff_header" id="to66_112">112</td><td nowrap="nowrap">*&nbsp;**linear_before_reset**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_103">103</td><td nowrap="nowrap">&nbsp;&nbsp;When&nbsp;computing&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;hidden&nbsp;gate,&nbsp;apply&nbsp;the&nbsp;linear</td><td class="diff_next"></td><td class="diff_header" id="to66_113">113</td><td nowrap="nowrap">&nbsp;&nbsp;When&nbsp;computing&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;hidden&nbsp;gate,&nbsp;apply&nbsp;the&nbsp;linear</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_104">104</td><td nowrap="nowrap">&nbsp;&nbsp;transformation&nbsp;before&nbsp;multiplying&nbsp;by&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;reset&nbsp;gate.</td><td class="diff_next"></td><td class="diff_header" id="to66_114">114</td><td nowrap="nowrap">&nbsp;&nbsp;transformation&nbsp;before&nbsp;multiplying&nbsp;by&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;reset&nbsp;gate.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_105">105</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_115">115</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_106">106</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to66_116">116</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_107">107</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_117">117</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_108">108</td><td nowrap="nowrap">Between&nbsp;3&nbsp;and&nbsp;6&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to66_118">118</td><td nowrap="nowrap">Between&nbsp;3&nbsp;and&nbsp;6&nbsp;inputs.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_109">109</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_119">119</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_110">110</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to66_120">120</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_111">111</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;sequences&nbsp;packed&nbsp;(and&nbsp;potentially&nbsp;padded)&nbsp;into&nbsp;one&nbsp;3-D</td><td class="diff_next"></td><td class="diff_header" id="to66_121">121</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;sequences&nbsp;packed&nbsp;(and&nbsp;potentially&nbsp;padded)&nbsp;into&nbsp;one&nbsp;3-D</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_112">112</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;with&nbsp;the&nbsp;shape&nbsp;of&nbsp;[seq_length,&nbsp;batch_size,&nbsp;input_size].</td><td class="diff_next"></td><td class="diff_header" id="to66_122">122</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;with&nbsp;the&nbsp;shape&nbsp;of&nbsp;[seq_length,&nbsp;batch_size,&nbsp;input_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_113">113</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to66_123">123</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_114">114</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;W[zrh]&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to66_124">124</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;W[zrh]&nbsp;and</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_115">115</td><td nowrap="nowrap">&nbsp;&nbsp;WB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to66_125">125</td><td nowrap="nowrap">&nbsp;&nbsp;WB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_116">116</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;input_size].</td><td class="diff_next"></td><td class="diff_header" id="to66_126">126</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;input_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_117">117</td><td nowrap="nowrap">*&nbsp;**R**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to66_127">127</td><td nowrap="nowrap">*&nbsp;**R**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_118">118</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;recurrence&nbsp;weight&nbsp;tensor.&nbsp;Concatenation&nbsp;of&nbsp;R[zrh]&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to66_128">128</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;recurrence&nbsp;weight&nbsp;tensor.&nbsp;Concatenation&nbsp;of&nbsp;R[zrh]&nbsp;and</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_119">119</td><td nowrap="nowrap">&nbsp;&nbsp;RB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to66_129">129</td><td nowrap="nowrap">&nbsp;&nbsp;RB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_120">120</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to66_130">130</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_121">121</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to66_131">131</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_122">122</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;bias&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;[Wb[zrh],&nbsp;Rb[zrh]]</td><td class="diff_next"></td><td class="diff_header" id="to66_132">132</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;bias&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;[Wb[zrh],&nbsp;Rb[zrh]]</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_123">123</td><td nowrap="nowrap">&nbsp;&nbsp;and&nbsp;[WBb[zrh],&nbsp;RBb[zrh]]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.</td><td class="diff_next"></td><td class="diff_header" id="to66_133">133</td><td nowrap="nowrap">&nbsp;&nbsp;and&nbsp;[WBb[zrh],&nbsp;RBb[zrh]]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_124">124</td><td nowrap="nowrap">&nbsp;&nbsp;This&nbsp;tensor&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;6*hidden_size].&nbsp;Optional:</td><td class="diff_next"></td><td class="diff_header" id="to66_134">134</td><td nowrap="nowrap">&nbsp;&nbsp;This&nbsp;tensor&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;6*hidden_size].&nbsp;Optional:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_125">125</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to&nbsp;be&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to66_135">135</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to&nbsp;be&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_126">126</td><td nowrap="nowrap">*&nbsp;**sequence_lens**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T1**:</td><td class="diff_next"></td><td class="diff_header" id="to66_136">136</td><td nowrap="nowrap">*&nbsp;**sequence_lens**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T1**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_127">127</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;tensor&nbsp;specifying&nbsp;lengths&nbsp;of&nbsp;the&nbsp;sequences&nbsp;in&nbsp;a&nbsp;batch.&nbsp;If</td><td class="diff_next"></td><td class="diff_header" id="to66_137">137</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;tensor&nbsp;specifying&nbsp;lengths&nbsp;of&nbsp;the&nbsp;sequences&nbsp;in&nbsp;a&nbsp;batch.&nbsp;If</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_128">128</td><td nowrap="nowrap">&nbsp;&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;all&nbsp;sequences&nbsp;in&nbsp;the&nbsp;batch&nbsp;to&nbsp;have&nbsp;length</td><td class="diff_next"></td><td class="diff_header" id="to66_138">138</td><td nowrap="nowrap">&nbsp;&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;all&nbsp;sequences&nbsp;in&nbsp;the&nbsp;batch&nbsp;to&nbsp;have&nbsp;length</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_129">129</td><td nowrap="nowrap">&nbsp;&nbsp;seq_length.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[batch_size].</td><td class="diff_next"></td><td class="diff_header" id="to66_139">139</td><td nowrap="nowrap">&nbsp;&nbsp;seq_length.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[batch_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_130">130</td><td nowrap="nowrap">*&nbsp;**initial_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to66_140">140</td><td nowrap="nowrap">*&nbsp;**initial_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_131">131</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;initial&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to66_141">141</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;initial&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_132">132</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;0.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;batch_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to66_142">142</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;0.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;batch_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_133">133</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_143">143</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_134">134</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to66_144">144</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_135">135</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_145">145</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_136">136</td><td nowrap="nowrap">Between&nbsp;0&nbsp;and&nbsp;2&nbsp;outputs.</td><td class="diff_next"></td><td class="diff_header" id="to66_146">146</td><td nowrap="nowrap">Between&nbsp;0&nbsp;and&nbsp;2&nbsp;outputs.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_137">137</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_147">147</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_138">138</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to66_148">148</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_139">139</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;tensor&nbsp;that&nbsp;concats&nbsp;all&nbsp;the&nbsp;intermediate&nbsp;output&nbsp;values&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to66_149">149</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;tensor&nbsp;that&nbsp;concats&nbsp;all&nbsp;the&nbsp;intermediate&nbsp;output&nbsp;values&nbsp;of&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_140">140</td><td nowrap="nowrap">&nbsp;&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[seq_length,&nbsp;num_directions,&nbsp;batch_size,</td><td class="diff_next"></td><td class="diff_header" id="to66_150">150</td><td nowrap="nowrap">&nbsp;&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[seq_length,&nbsp;num_directions,&nbsp;batch_size,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_141">141</td><td nowrap="nowrap">&nbsp;&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to66_151">151</td><td nowrap="nowrap">&nbsp;&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_142">142</td><td nowrap="nowrap">*&nbsp;**Y_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to66_152">152</td><td nowrap="nowrap">*&nbsp;**Y_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_143">143</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;last&nbsp;output&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,</td><td class="diff_next"></td><td class="diff_header" id="to66_153">153</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;last&nbsp;output&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_144">144</td><td nowrap="nowrap">&nbsp;&nbsp;batch_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to66_154">154</td><td nowrap="nowrap">&nbsp;&nbsp;batch_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_145">145</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_155">155</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_146">146</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to66_156">156</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_147">147</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to66_157">157</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_148">148</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to66_158">158</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_149">149</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to66_159">159</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_150">150</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to66_160">160</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_151">151</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to66_161">161</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_152">152</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to66_162">162</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_153">153</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to66_163">163</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_154">154</td><td nowrap="nowrap">*&nbsp;**T1**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to66_164">164</td><td nowrap="nowrap">*&nbsp;**T1**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_155">155</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32)</td><td class="diff_next"></td><td class="diff_header" id="to66_165">165</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_156">156</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to66_166">166</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from66_157">157</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;seq_lens&nbsp;to&nbsp;integer&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to66_167">167</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;seq_lens&nbsp;to&nbsp;integer&nbsp;tensor.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-gru-7:

GRU - 7
=======

**Version**

* **name**: `GRU (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU>`_
* **domain**: **main**
* **since_version**: **7**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 7**.

**Summary**

Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.

Notations:

`X` - input tensor

`z` - update gate

`r` - reset gate

`h` - hidden gate

`t` - time step (t-1 means previous time step)

`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates

`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates

`Wb[zrh]` - W bias vectors for update, reset, and hidden gates

`Rb[zrh]` - R bias vectors for update, reset, and hidden gates

`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates

`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates

`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates

`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates

`H` - Hidden state

`num_directions` - 2 if direction == bidirectional else 1

Activation functions:

  Relu(x)                - max(0, x)

  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})

  Sigmoid(x)             - 1/(1 + e^{-x})

  (NOTE: Below are optional)

  Affine(x)              - alpha*x + beta

  LeakyRelu(x)           - x if x >= 0 else alpha * x

  ThresholdedRelu(x)     - x if x >= alpha else 0

  ScaledTanh(x)          - alpha*Tanh(beta*x)

  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)

  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)

  Softsign(x)            - x/(1 + |x|)

  Softplus(x)            - log(1 + e^x)

Equations (Default: f=Sigmoid, g=Tanh):

  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)

  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)

  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0

  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0

  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.

**Attributes**

* **activation_alpha**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM. Default values are the same as of
  corresponding ONNX operators.For example with LeakyRelu, the default
  alpha is 0.01.
* **activation_beta**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM. Default values are the same as of
  corresponding ONNX operators.
* **activations**:
  A list of 2 (or 4 if bidirectional) activation functions for update,
  reset, and hidden gates. The activation functions must be one of the
  activation functions specified above. Optional: See the equations
  for default if not specified.
* **clip**:
  Cell clip threshold. Clipping bounds the elements of a tensor in the
  range of [-threshold, +threshold] and is applied to the input of
  activations. No clip if not specified.
* **direction**:
  Specify if the RNN is forward, reverse, or bidirectional. Must be
  one of forward (default), reverse, or bidirectional.
* **hidden_size**:
  Number of neurons in the hidden layer
* **linear_before_reset**:
  When computing the output of the hidden gate, apply the linear
  transformation before multiplying by the output of the reset gate.

**Inputs**

Between 3 and 6 inputs.

* **X** (heterogeneous) - **T**:
  The input sequences packed (and potentially padded) into one 3-D
  tensor with the shape of `[seq_length, batch_size, input_size]`.
* **W** (heterogeneous) - **T**:
  The weight tensor for the gates. Concatenation of `W[zrh]` and
  `WB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, input_size]`.
* **R** (heterogeneous) - **T**:
  The recurrence weight tensor. Concatenation of `R[zrh]` and
  `RB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, hidden_size]`.
* **B** (optional, heterogeneous) - **T**:
  The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]`
  and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0.
  This tensor has shape `[num_directions, 6*hidden_size]`. Optional:
  If not specified - assumed to be 0
* **sequence_lens** (optional, heterogeneous) - **T1**:
  Optional tensor specifying lengths of the sequences in a batch. If
  not specified - assumed all sequences in the batch to have length
  `seq_length`. It has shape `[batch_size]`.
* **initial_h** (optional, heterogeneous) - **T**:
  Optional initial value of the hidden. If not specified - assumed to
  be 0. It has shape `[num_directions, batch_size, hidden_size]`.

**Outputs**

Between 0 and 2 outputs.

* **Y** (optional, heterogeneous) - **T**:
  A tensor that concats all the intermediate output values of the
  hidden. It has shape `[seq_length, num_directions, batch_size,
  hidden_size]`.
* **Y_h** (optional, heterogeneous) - **T**:
  The last output value of the hidden. It has shape `[num_directions,
  batch_size, hidden_size]`.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
* **T1** in (
  tensor(int32)
  ):
  Constrain seq_lens to integer tensor.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to67__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to67__0">f</a></td><td class="diff_header" id="from67_1">1</td><td nowrap="nowrap">Computes&nbsp;an&nbsp;one-layer&nbsp;GRU.&nbsp;This&nbsp;operator&nbsp;is&nbsp;usually&nbsp;supported&nbsp;via&nbsp;some&nbsp;custom</td><td class="diff_next"><a href="#difflib_chg_to67__0">f</a></td><td class="diff_header" id="to67_1">1</td><td nowrap="nowrap">Computes&nbsp;an&nbsp;one-layer&nbsp;GRU.&nbsp;This&nbsp;operator&nbsp;is&nbsp;usually&nbsp;supported&nbsp;via&nbsp;some&nbsp;custom</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_2">2</td><td nowrap="nowrap">implementation&nbsp;such&nbsp;as&nbsp;CuDNN.</td><td class="diff_next"></td><td class="diff_header" id="to67_2">2</td><td nowrap="nowrap">implementation&nbsp;such&nbsp;as&nbsp;CuDNN.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_3">3</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_4">4</td><td nowrap="nowrap">Notations:</td><td class="diff_next"></td><td class="diff_header" id="to67_4">4</td><td nowrap="nowrap">Notations:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_5">5</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_6">6</td><td nowrap="nowrap">X&nbsp;-&nbsp;input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to67_6">6</td><td nowrap="nowrap">X&nbsp;-&nbsp;input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_8">8</td><td nowrap="nowrap">z&nbsp;-&nbsp;update&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to67_8">8</td><td nowrap="nowrap">z&nbsp;-&nbsp;update&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_10">10</td><td nowrap="nowrap">r&nbsp;-&nbsp;reset&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to67_10">10</td><td nowrap="nowrap">r&nbsp;-&nbsp;reset&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_11">11</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_11">11</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_12">12</td><td nowrap="nowrap">h&nbsp;-&nbsp;hidden&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to67_12">12</td><td nowrap="nowrap">h&nbsp;-&nbsp;hidden&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_13">13</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_14">14</td><td nowrap="nowrap">t&nbsp;-&nbsp;time&nbsp;step&nbsp;(t-1&nbsp;means&nbsp;previous&nbsp;time&nbsp;step)</td><td class="diff_next"></td><td class="diff_header" id="to67_14">14</td><td nowrap="nowrap">t&nbsp;-&nbsp;time&nbsp;step&nbsp;(t-1&nbsp;means&nbsp;previous&nbsp;time&nbsp;step)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_15">15</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_16">16</td><td nowrap="nowrap">W[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_16">16</td><td nowrap="nowrap">W[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_18">18</td><td nowrap="nowrap">R[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_18">18</td><td nowrap="nowrap">R[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_20">20</td><td nowrap="nowrap">Wb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_20">20</td><td nowrap="nowrap">Wb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_21">21</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_22">22</td><td nowrap="nowrap">Rb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_22">22</td><td nowrap="nowrap">Rb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_23">23</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_24">24</td><td nowrap="nowrap">WB[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_24">24</td><td nowrap="nowrap">WB[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_25">25</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_25">25</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_26">26</td><td nowrap="nowrap">RB[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_26">26</td><td nowrap="nowrap">RB[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_28">28</td><td nowrap="nowrap">WBb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_28">28</td><td nowrap="nowrap">WBb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_30">30</td><td nowrap="nowrap">RBb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to67_30">30</td><td nowrap="nowrap">RBb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_31">31</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_31">31</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_32">32</td><td nowrap="nowrap">H&nbsp;-&nbsp;Hidden&nbsp;state</td><td class="diff_next"></td><td class="diff_header" id="to67_32">32</td><td nowrap="nowrap">H&nbsp;-&nbsp;Hidden&nbsp;state</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_33">33</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_34">34</td><td nowrap="nowrap">num_directions&nbsp;-&nbsp;2&nbsp;if&nbsp;direction&nbsp;==&nbsp;bidirectional&nbsp;else&nbsp;1</td><td class="diff_next"></td><td class="diff_header" id="to67_34">34</td><td nowrap="nowrap">num_directions&nbsp;-&nbsp;2&nbsp;if&nbsp;direction&nbsp;==&nbsp;bidirectional&nbsp;else&nbsp;1</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_35">35</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_35">35</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_36">36</td><td nowrap="nowrap">Activation&nbsp;functions:</td><td class="diff_next"></td><td class="diff_header" id="to67_36">36</td><td nowrap="nowrap">Activation&nbsp;functions:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_37">37</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_37">37</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Relu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;max(0,&nbsp;x)</td><td class="diff_next"></td><td class="diff_header" id="to67_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Relu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;max(0,&nbsp;x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_39">39</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_39">39</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Tanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;(1&nbsp;-&nbsp;e^{-2x})/(1&nbsp;+&nbsp;e^{-2x})</td><td class="diff_next"></td><td class="diff_header" id="to67_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Tanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;(1&nbsp;-&nbsp;e^{-2x})/(1&nbsp;+&nbsp;e^{-2x})</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_41">41</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_41">41</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Sigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;1/(1&nbsp;+&nbsp;e^{-x})</td><td class="diff_next"></td><td class="diff_header" id="to67_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Sigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;1/(1&nbsp;+&nbsp;e^{-x})</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_43">43</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_43">43</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;(NOTE:&nbsp;Below&nbsp;are&nbsp;optional)</td><td class="diff_next"></td><td class="diff_header" id="to67_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;(NOTE:&nbsp;Below&nbsp;are&nbsp;optional)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_45">45</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_45">45</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;Affine(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*x&nbsp;+&nbsp;beta</td><td class="diff_next"></td><td class="diff_header" id="to67_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;Affine(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*x&nbsp;+&nbsp;beta</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_47">47</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_47">47</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;LeakyRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha&nbsp;*&nbsp;x</td><td class="diff_next"></td><td class="diff_header" id="to67_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;LeakyRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha&nbsp;*&nbsp;x</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_49">49</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_49">49</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;ThresholdedRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;alpha&nbsp;else&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to67_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;ThresholdedRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;alpha&nbsp;else&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_51">51</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_51">51</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;ScaledTanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*Tanh(beta*x)</td><td class="diff_next"></td><td class="diff_header" id="to67_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;ScaledTanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*Tanh(beta*x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_53">53</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_53">53</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;HardSigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;min(max(alpha*x&nbsp;+&nbsp;beta,&nbsp;0),&nbsp;1)</td><td class="diff_next"></td><td class="diff_header" id="to67_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;HardSigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;min(max(alpha*x&nbsp;+&nbsp;beta,&nbsp;0),&nbsp;1)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_55">55</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_55">55</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;Elu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha*(e^x&nbsp;-&nbsp;1)</td><td class="diff_next"></td><td class="diff_header" id="to67_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;Elu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha*(e^x&nbsp;-&nbsp;1)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_57">57</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_57">57</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;Softsign(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x/(1&nbsp;+&nbsp;|x|)</td><td class="diff_next"></td><td class="diff_header" id="to67_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;Softsign(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x/(1&nbsp;+&nbsp;|x|)</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to67__0"></td><td class="diff_header" id="from67_59">59</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_59">59</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;Softplus(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;log(1&nbsp;+&nbsp;e^x)</td><td class="diff_next"></td><td class="diff_header" id="to67_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;Softplus(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;log(1&nbsp;+&nbsp;e^x)</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to67__1"></td><td class="diff_header" id="from67_61">61</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_61">61</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_62">62</td><td nowrap="nowrap">Equations&nbsp;(Default:&nbsp;f=Sigmoid,&nbsp;g=Tanh):</td><td class="diff_next"></td><td class="diff_header" id="to67_62">62</td><td nowrap="nowrap">Equations&nbsp;(Default:&nbsp;f=Sigmoid,&nbsp;g=Tanh):</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to67__2"></td><td class="diff_header" id="from67_63">63</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_63">63</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to67__1">n</a></td><td class="diff_header" id="from67_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;zt&nbsp;=&nbsp;f(Xt*(Wz^T)&nbsp;+&nbsp;Ht-1*Rz&nbsp;+&nbsp;Wbz&nbsp;+&nbsp;Rbz)</td><td class="diff_next"><a href="#difflib_chg_to67__1">n</a></td><td class="diff_header" id="to67_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;zt&nbsp;=&nbsp;f(Xt*(Wz^T)&nbsp;+&nbsp;Ht-1*<span class="diff_add">(</span>Rz<span class="diff_add">^T)</span>&nbsp;+&nbsp;Wbz&nbsp;+&nbsp;Rbz)</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to67__3"></td><td class="diff_header" id="from67_65">65</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_65">65</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to67__2">n</a></td><td class="diff_header" id="from67_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;rt&nbsp;=&nbsp;f(Xt*(Wr^T)&nbsp;+&nbsp;Ht-1*Rr&nbsp;+&nbsp;Wbr&nbsp;+&nbsp;Rbr)</td><td class="diff_next"><a href="#difflib_chg_to67__2">n</a></td><td class="diff_header" id="to67_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;rt&nbsp;=&nbsp;f(Xt*(Wr^T)&nbsp;+&nbsp;Ht-1*<span class="diff_add">(</span>Rr<span class="diff_add">^T)</span>&nbsp;+&nbsp;Wbr&nbsp;+&nbsp;Rbr)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_67">67</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_67">67</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to67__4"><a href="#difflib_chg_to67__3">n</a></td><td class="diff_header" id="from67_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;Ht-1)*Rh&nbsp;+&nbsp;Rbh&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;default,&nbsp;when&nbsp;linear_before_reset&nbsp;=&nbsp;0</td><td class="diff_next"><a href="#difflib_chg_to67__3">n</a></td><td class="diff_header" id="to67_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;Ht-1)*<span class="diff_add">(</span>Rh<span class="diff_add">^T)</span>&nbsp;+&nbsp;Rbh&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;default,&nbsp;when&nbsp;linear_before_reset&nbsp;=&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_69">69</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_69">69</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to67__4">n</a></td><td class="diff_header" id="from67_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;(Ht-1*Rh&nbsp;+&nbsp;Rbh)&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;when&nbsp;linear_before_reset&nbsp;!=&nbsp;0</td><td class="diff_next"><a href="#difflib_chg_to67__4">n</a></td><td class="diff_header" id="to67_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;(Ht-1*<span class="diff_add">(</span>Rh<span class="diff_add">^T)</span>&nbsp;+&nbsp;Rbh)<span class="diff_add">)</span>&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;when&nbsp;linear_before_reset&nbsp;!=&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_71">71</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_71">71</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;Ht&nbsp;=&nbsp;(1&nbsp;-&nbsp;zt)&nbsp;(.)&nbsp;ht&nbsp;+&nbsp;zt&nbsp;(.)&nbsp;Ht-1</td><td class="diff_next"></td><td class="diff_header" id="to67_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;Ht&nbsp;=&nbsp;(1&nbsp;-&nbsp;zt)&nbsp;(.)&nbsp;ht&nbsp;+&nbsp;zt&nbsp;(.)&nbsp;Ht-1</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to67__5">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to67__5">n</a></td><td class="diff_header" id="to67_73">73</td><td nowrap="nowrap"><span class="diff_add">This&nbsp;operator&nbsp;has&nbsp;**optional**&nbsp;inputs/outputs.&nbsp;See&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/IR.md&gt;_&nbsp;for&nbsp;more&nbsp;details&nbsp;about&nbsp;the&nbsp;representation&nbsp;of&nbsp;optional&nbsp;arguments.&nbsp;An&nbsp;empty&nbsp;string&nbsp;may&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;place&nbsp;of&nbsp;an&nbsp;actual&nbsp;argument's&nbsp;name&nbsp;to&nbsp;indicate&nbsp;a&nbsp;missing&nbsp;argument.&nbsp;Trailing&nbsp;optional&nbsp;arguments&nbsp;(those&nbsp;not&nbsp;followed&nbsp;by&nbsp;an&nbsp;argument&nbsp;that&nbsp;is&nbsp;present)&nbsp;may&nbsp;also&nbsp;be&nbsp;simply&nbsp;omitted.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_73">73</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_74">74</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_74">74</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to67_75">75</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_75">75</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_76">76</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_76">76</td><td nowrap="nowrap">*&nbsp;**activation_alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to67_77">77</td><td nowrap="nowrap">*&nbsp;**activation_alpha**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_77">77</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to67_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td><td class="diff_next"></td><td class="diff_header" id="to67_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to67_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.For&nbsp;example&nbsp;with&nbsp;LeakyRelu,&nbsp;the&nbsp;default</td><td class="diff_next"></td><td class="diff_header" id="to67_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.For&nbsp;example&nbsp;with&nbsp;LeakyRelu,&nbsp;the&nbsp;default</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;alpha&nbsp;is&nbsp;0.01.</td><td class="diff_next"></td><td class="diff_header" id="to67_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;alpha&nbsp;is&nbsp;0.01.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_82">82</td><td nowrap="nowrap">*&nbsp;**activation_beta**:</td><td class="diff_next"></td><td class="diff_header" id="to67_83">83</td><td nowrap="nowrap">*&nbsp;**activation_beta**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_83">83</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to67_84">84</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_84">84</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td><td class="diff_next"></td><td class="diff_header" id="to67_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to67_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.</td><td class="diff_next"></td><td class="diff_header" id="to67_87">87</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_87">87</td><td nowrap="nowrap">*&nbsp;**activations**:</td><td class="diff_next"></td><td class="diff_header" id="to67_88">88</td><td nowrap="nowrap">*&nbsp;**activations**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_88">88</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;2&nbsp;(or&nbsp;4&nbsp;if&nbsp;bidirectional)&nbsp;activation&nbsp;functions&nbsp;for&nbsp;update,</td><td class="diff_next"></td><td class="diff_header" id="to67_89">89</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;2&nbsp;(or&nbsp;4&nbsp;if&nbsp;bidirectional)&nbsp;activation&nbsp;functions&nbsp;for&nbsp;update,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_89">89</td><td nowrap="nowrap">&nbsp;&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates.&nbsp;The&nbsp;activation&nbsp;functions&nbsp;must&nbsp;be&nbsp;one&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to67_90">90</td><td nowrap="nowrap">&nbsp;&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates.&nbsp;The&nbsp;activation&nbsp;functions&nbsp;must&nbsp;be&nbsp;one&nbsp;of&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_90">90</td><td nowrap="nowrap">&nbsp;&nbsp;activation&nbsp;functions&nbsp;specified&nbsp;above.&nbsp;Optional:&nbsp;See&nbsp;the&nbsp;equations</td><td class="diff_next"></td><td class="diff_header" id="to67_91">91</td><td nowrap="nowrap">&nbsp;&nbsp;activation&nbsp;functions&nbsp;specified&nbsp;above.&nbsp;Optional:&nbsp;See&nbsp;the&nbsp;equations</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_91">91</td><td nowrap="nowrap">&nbsp;&nbsp;for&nbsp;default&nbsp;if&nbsp;not&nbsp;specified.</td><td class="diff_next"></td><td class="diff_header" id="to67_92">92</td><td nowrap="nowrap">&nbsp;&nbsp;for&nbsp;default&nbsp;if&nbsp;not&nbsp;specified.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_92">92</td><td nowrap="nowrap">*&nbsp;**clip**:</td><td class="diff_next"></td><td class="diff_header" id="to67_93">93</td><td nowrap="nowrap">*&nbsp;**clip**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_93">93</td><td nowrap="nowrap">&nbsp;&nbsp;Cell&nbsp;clip&nbsp;threshold.&nbsp;Clipping&nbsp;bounds&nbsp;the&nbsp;elements&nbsp;of&nbsp;a&nbsp;tensor&nbsp;in&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to67_94">94</td><td nowrap="nowrap">&nbsp;&nbsp;Cell&nbsp;clip&nbsp;threshold.&nbsp;Clipping&nbsp;bounds&nbsp;the&nbsp;elements&nbsp;of&nbsp;a&nbsp;tensor&nbsp;in&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_94">94</td><td nowrap="nowrap">&nbsp;&nbsp;range&nbsp;of&nbsp;[-threshold,&nbsp;+threshold]&nbsp;and&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;input&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to67_95">95</td><td nowrap="nowrap">&nbsp;&nbsp;range&nbsp;of&nbsp;[-threshold,&nbsp;+threshold]&nbsp;and&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;input&nbsp;of</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_95">95</td><td nowrap="nowrap">&nbsp;&nbsp;activations.&nbsp;No&nbsp;clip&nbsp;if&nbsp;not&nbsp;specified.</td><td class="diff_next"></td><td class="diff_header" id="to67_96">96</td><td nowrap="nowrap">&nbsp;&nbsp;activations.&nbsp;No&nbsp;clip&nbsp;if&nbsp;not&nbsp;specified.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_96">96</td><td nowrap="nowrap">*&nbsp;**direction**:</td><td class="diff_next"></td><td class="diff_header" id="to67_97">97</td><td nowrap="nowrap">*&nbsp;**direction**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_97">97</td><td nowrap="nowrap">&nbsp;&nbsp;Specify&nbsp;if&nbsp;the&nbsp;RNN&nbsp;is&nbsp;forward,&nbsp;reverse,&nbsp;or&nbsp;bidirectional.&nbsp;Must&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to67_98">98</td><td nowrap="nowrap">&nbsp;&nbsp;Specify&nbsp;if&nbsp;the&nbsp;RNN&nbsp;is&nbsp;forward,&nbsp;reverse,&nbsp;or&nbsp;bidirectional.&nbsp;Must&nbsp;be</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_98">98</td><td nowrap="nowrap">&nbsp;&nbsp;one&nbsp;of&nbsp;forward&nbsp;(default),&nbsp;reverse,&nbsp;or&nbsp;bidirectional.</td><td class="diff_next"></td><td class="diff_header" id="to67_99">99</td><td nowrap="nowrap">&nbsp;&nbsp;one&nbsp;of&nbsp;forward&nbsp;(default),&nbsp;reverse,&nbsp;or&nbsp;bidirectional.</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to67__5"></td><td class="diff_header" id="from67_99">99</td><td nowrap="nowrap">*&nbsp;**hidden_size**:</td><td class="diff_next"></td><td class="diff_header" id="to67_100">100</td><td nowrap="nowrap">*&nbsp;**hidden_size**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_100">100</td><td nowrap="nowrap">&nbsp;&nbsp;Number&nbsp;of&nbsp;neurons&nbsp;in&nbsp;the&nbsp;hidden&nbsp;layer</td><td class="diff_next"></td><td class="diff_header" id="to67_101">101</td><td nowrap="nowrap">&nbsp;&nbsp;Number&nbsp;of&nbsp;neurons&nbsp;in&nbsp;the&nbsp;hidden&nbsp;layer</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_101">101</td><td nowrap="nowrap">*&nbsp;**linear_before_reset**:</td><td class="diff_next"></td><td class="diff_header" id="to67_102">102</td><td nowrap="nowrap">*&nbsp;**linear_before_reset**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_102">102</td><td nowrap="nowrap">&nbsp;&nbsp;When&nbsp;computing&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;hidden&nbsp;gate,&nbsp;apply&nbsp;the&nbsp;linear</td><td class="diff_next"></td><td class="diff_header" id="to67_103">103</td><td nowrap="nowrap">&nbsp;&nbsp;When&nbsp;computing&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;hidden&nbsp;gate,&nbsp;apply&nbsp;the&nbsp;linear</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_103">103</td><td nowrap="nowrap">&nbsp;&nbsp;transformation&nbsp;before&nbsp;multiplying&nbsp;by&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;reset&nbsp;gate.</td><td class="diff_next"></td><td class="diff_header" id="to67_104">104</td><td nowrap="nowrap">&nbsp;&nbsp;transformation&nbsp;before&nbsp;multiplying&nbsp;by&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;reset&nbsp;gate.</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to67__6">n</a></td><td class="diff_header" id="from67_104">104</td><td nowrap="nowrap"><span class="diff_sub">*&nbsp;**output_sequence**:</span></td><td class="diff_next"><a href="#difflib_chg_to67__6">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_105">105</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;The&nbsp;sequence&nbsp;output&nbsp;for&nbsp;the&nbsp;hidden&nbsp;is&nbsp;optional&nbsp;if&nbsp;0.&nbsp;Default&nbsp;0.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_106">106</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_105">105</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_107">107</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to67_106">106</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_108">108</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_107">107</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_109">109</td><td nowrap="nowrap">Between&nbsp;3&nbsp;and&nbsp;6&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to67_108">108</td><td nowrap="nowrap">Between&nbsp;3&nbsp;and&nbsp;6&nbsp;inputs.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_110">110</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_109">109</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_111">111</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to67_110">110</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_112">112</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;sequences&nbsp;packed&nbsp;(and&nbsp;potentially&nbsp;padded)&nbsp;into&nbsp;one&nbsp;3-D</td><td class="diff_next"></td><td class="diff_header" id="to67_111">111</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;sequences&nbsp;packed&nbsp;(and&nbsp;potentially&nbsp;padded)&nbsp;into&nbsp;one&nbsp;3-D</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_113">113</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;with&nbsp;the&nbsp;shape&nbsp;of&nbsp;[seq_length,&nbsp;batch_size,&nbsp;input_size].</td><td class="diff_next"></td><td class="diff_header" id="to67_112">112</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;with&nbsp;the&nbsp;shape&nbsp;of&nbsp;[seq_length,&nbsp;batch_size,&nbsp;input_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_114">114</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to67_113">113</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_115">115</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;W[zrh]&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to67_114">114</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;W[zrh]&nbsp;and</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_116">116</td><td nowrap="nowrap">&nbsp;&nbsp;WB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to67_115">115</td><td nowrap="nowrap">&nbsp;&nbsp;WB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_117">117</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;input_size].</td><td class="diff_next"></td><td class="diff_header" id="to67_116">116</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;input_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_118">118</td><td nowrap="nowrap">*&nbsp;**R**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to67_117">117</td><td nowrap="nowrap">*&nbsp;**R**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_119">119</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;recurrence&nbsp;weight&nbsp;tensor.&nbsp;Concatenation&nbsp;of&nbsp;R[zrh]&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to67_118">118</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;recurrence&nbsp;weight&nbsp;tensor.&nbsp;Concatenation&nbsp;of&nbsp;R[zrh]&nbsp;and</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_120">120</td><td nowrap="nowrap">&nbsp;&nbsp;RB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to67_119">119</td><td nowrap="nowrap">&nbsp;&nbsp;RB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_121">121</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to67_120">120</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_122">122</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to67_121">121</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_123">123</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;bias&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;[Wb[zrh],&nbsp;Rb[zrh]]</td><td class="diff_next"></td><td class="diff_header" id="to67_122">122</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;bias&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;[Wb[zrh],&nbsp;Rb[zrh]]</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_124">124</td><td nowrap="nowrap">&nbsp;&nbsp;and&nbsp;[WBb[zrh],&nbsp;RBb[zrh]]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.</td><td class="diff_next"></td><td class="diff_header" id="to67_123">123</td><td nowrap="nowrap">&nbsp;&nbsp;and&nbsp;[WBb[zrh],&nbsp;RBb[zrh]]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_125">125</td><td nowrap="nowrap">&nbsp;&nbsp;This&nbsp;tensor&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;6*hidden_size].&nbsp;Optional:</td><td class="diff_next"></td><td class="diff_header" id="to67_124">124</td><td nowrap="nowrap">&nbsp;&nbsp;This&nbsp;tensor&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;6*hidden_size].&nbsp;Optional:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_126">126</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to&nbsp;be&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to67_125">125</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to&nbsp;be&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_127">127</td><td nowrap="nowrap">*&nbsp;**sequence_lens**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T1**:</td><td class="diff_next"></td><td class="diff_header" id="to67_126">126</td><td nowrap="nowrap">*&nbsp;**sequence_lens**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T1**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_128">128</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;tensor&nbsp;specifying&nbsp;lengths&nbsp;of&nbsp;the&nbsp;sequences&nbsp;in&nbsp;a&nbsp;batch.&nbsp;If</td><td class="diff_next"></td><td class="diff_header" id="to67_127">127</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;tensor&nbsp;specifying&nbsp;lengths&nbsp;of&nbsp;the&nbsp;sequences&nbsp;in&nbsp;a&nbsp;batch.&nbsp;If</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_129">129</td><td nowrap="nowrap">&nbsp;&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;all&nbsp;sequences&nbsp;in&nbsp;the&nbsp;batch&nbsp;to&nbsp;have&nbsp;length</td><td class="diff_next"></td><td class="diff_header" id="to67_128">128</td><td nowrap="nowrap">&nbsp;&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;all&nbsp;sequences&nbsp;in&nbsp;the&nbsp;batch&nbsp;to&nbsp;have&nbsp;length</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_130">130</td><td nowrap="nowrap">&nbsp;&nbsp;seq_length.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[batch_size].</td><td class="diff_next"></td><td class="diff_header" id="to67_129">129</td><td nowrap="nowrap">&nbsp;&nbsp;seq_length.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[batch_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_131">131</td><td nowrap="nowrap">*&nbsp;**initial_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to67_130">130</td><td nowrap="nowrap">*&nbsp;**initial_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_132">132</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;initial&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to67_131">131</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;initial&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_133">133</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;0.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;batch_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to67_132">132</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;0.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;batch_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_134">134</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_133">133</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_135">135</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to67_134">134</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_136">136</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_135">135</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to67__6"></td><td class="diff_header" id="from67_137">137</td><td nowrap="nowrap">Between&nbsp;0&nbsp;and&nbsp;2&nbsp;outputs.</td><td class="diff_next"></td><td class="diff_header" id="to67_136">136</td><td nowrap="nowrap">Between&nbsp;0&nbsp;and&nbsp;2&nbsp;outputs.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_138">138</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_137">137</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_139">139</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to67_138">138</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_140">140</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;tensor&nbsp;that&nbsp;concats&nbsp;all&nbsp;the&nbsp;intermediate&nbsp;output&nbsp;values&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to67_139">139</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;tensor&nbsp;that&nbsp;concats&nbsp;all&nbsp;the&nbsp;intermediate&nbsp;output&nbsp;values&nbsp;of&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_141">141</td><td nowrap="nowrap">&nbsp;&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[seq_length,&nbsp;num_directions,&nbsp;batch_size,</td><td class="diff_next"></td><td class="diff_header" id="to67_140">140</td><td nowrap="nowrap">&nbsp;&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[seq_length,&nbsp;num_directions,&nbsp;batch_size,</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to67__top">t</a></td><td class="diff_header" id="from67_142">142</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;hidden_size].&nbsp;It&nbsp;is&nbsp;optional&nbsp;if&nbsp;output_sequence&nbsp;is&nbsp;0.</span></td><td class="diff_next"><a href="#difflib_chg_to67__top">t</a></td><td class="diff_header" id="to67_141">141</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;hidden_size].</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_143">143</td><td nowrap="nowrap">*&nbsp;**Y_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to67_142">142</td><td nowrap="nowrap">*&nbsp;**Y_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_144">144</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;last&nbsp;output&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,</td><td class="diff_next"></td><td class="diff_header" id="to67_143">143</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;last&nbsp;output&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_145">145</td><td nowrap="nowrap">&nbsp;&nbsp;batch_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to67_144">144</td><td nowrap="nowrap">&nbsp;&nbsp;batch_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_146">146</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_145">145</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_147">147</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to67_146">146</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_148">148</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to67_147">147</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_149">149</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to67_148">148</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_150">150</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to67_149">149</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_151">151</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to67_150">150</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_152">152</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to67_151">151</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_153">153</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to67_152">152</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_154">154</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to67_153">153</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_155">155</td><td nowrap="nowrap">*&nbsp;**T1**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to67_154">154</td><td nowrap="nowrap">*&nbsp;**T1**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_156">156</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32)</td><td class="diff_next"></td><td class="diff_header" id="to67_155">155</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_157">157</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to67_156">156</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from67_158">158</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;seq_lens&nbsp;to&nbsp;integer&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to67_157">157</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;seq_lens&nbsp;to&nbsp;integer&nbsp;tensor.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-gru-3:

GRU - 3
=======

**Version**

* **name**: `GRU (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU>`_
* **domain**: **main**
* **since_version**: **3**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 3**.

**Summary**

Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.

Notations:

`X` - input tensor

`z` - update gate

`r` - reset gate

`h` - hidden gate

`t` - time step (t-1 means previous time step)

`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates

`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates

`Wb[zrh]` - W bias vectors for update, reset, and hidden gates

`Rb[zrh]` - R bias vectors for update, reset, and hidden gates

`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates

`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates

`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates

`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates

`H` - Hidden state

`num_directions` - 2 if direction == bidirectional else 1

Activation functions:

  Relu(x)                - max(0, x)

  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})

  Sigmoid(x)             - 1/(1 + e^{-x})

  (NOTE: Below are optional)

  Affine(x)              - alpha*x + beta

  LeakyRelu(x)           - x if x >= 0 else alpha * x

  ThresholdedRelu(x)     - x if x >= alpha else 0

  ScaledTanh(x)          - alpha*Tanh(beta*x)

  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)

  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)

  Softsign(x)            - x/(1 + |x|)

  Softplus(x)            - log(1 + e^x)

Equations (Default: f=Sigmoid, g=Tanh):

  - zt = f(Xt*(Wz^T) + Ht-1*Rz + Wbz + Rbz)

  - rt = f(Xt*(Wr^T) + Ht-1*Rr + Wbr + Rbr)

  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*Rh + Rbh + Wbh) # default, when linear_before_reset = 0

  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*Rh + Rbh) + Wbh) # when linear_before_reset != 0

  - Ht = (1 - zt) (.) ht + zt (.) Ht-1

**Attributes**

* **activation_alpha**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM. Default values are the same as of
  corresponding ONNX operators.For example with LeakyRelu, the default
  alpha is 0.01.
* **activation_beta**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM. Default values are the same as of
  corresponding ONNX operators.
* **activations**:
  A list of 2 (or 4 if bidirectional) activation functions for update,
  reset, and hidden gates. The activation functions must be one of the
  activation functions specified above. Optional: See the equations
  for default if not specified.
* **clip**:
  Cell clip threshold. Clipping bounds the elements of a tensor in the
  range of [-threshold, +threshold] and is applied to the input of
  activations. No clip if not specified.
* **direction**:
  Specify if the RNN is forward, reverse, or bidirectional. Must be
  one of forward (default), reverse, or bidirectional.
* **hidden_size**:
  Number of neurons in the hidden layer
* **linear_before_reset**:
  When computing the output of the hidden gate, apply the linear
  transformation before multiplying by the output of the reset gate.
* **output_sequence**:
  The sequence output for the hidden is optional if 0. Default 0.

**Inputs**

Between 3 and 6 inputs.

* **X** (heterogeneous) - **T**:
  The input sequences packed (and potentially padded) into one 3-D
  tensor with the shape of `[seq_length, batch_size, input_size]`.
* **W** (heterogeneous) - **T**:
  The weight tensor for the gates. Concatenation of `W[zrh]` and
  `WB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, input_size]`.
* **R** (heterogeneous) - **T**:
  The recurrence weight tensor. Concatenation of `R[zrh]` and
  `RB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, hidden_size]`.
* **B** (optional, heterogeneous) - **T**:
  The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]`
  and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0.
  This tensor has shape `[num_directions, 6*hidden_size]`. Optional:
  If not specified - assumed to be 0
* **sequence_lens** (optional, heterogeneous) - **T1**:
  Optional tensor specifying lengths of the sequences in a batch. If
  not specified - assumed all sequences in the batch to have length
  `seq_length`. It has shape `[batch_size]`.
* **initial_h** (optional, heterogeneous) - **T**:
  Optional initial value of the hidden. If not specified - assumed to
  be 0. It has shape `[num_directions, batch_size, hidden_size]`.

**Outputs**

Between 0 and 2 outputs.

* **Y** (optional, heterogeneous) - **T**:
  A tensor that concats all the intermediate output values of the
  hidden. It has shape `[seq_length, num_directions, batch_size,
  hidden_size]`. It is optional if `output_sequence` is 0.
* **Y_h** (optional, heterogeneous) - **T**:
  The last output value of the hidden. It has shape `[num_directions,
  batch_size, hidden_size]`.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
* **T1** in (
  tensor(int32)
  ):
  Constrain seq_lens to integer tensor.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to68__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to68__0">f</a></td><td class="diff_header" id="from68_1">1</td><td nowrap="nowrap">Computes&nbsp;an&nbsp;one-layer&nbsp;GRU.&nbsp;This&nbsp;operator&nbsp;is&nbsp;usually&nbsp;supported&nbsp;via&nbsp;some&nbsp;custom</td><td class="diff_next"><a href="#difflib_chg_to68__0">f</a></td><td class="diff_header" id="to68_1">1</td><td nowrap="nowrap">Computes&nbsp;an&nbsp;one-layer&nbsp;GRU.&nbsp;This&nbsp;operator&nbsp;is&nbsp;usually&nbsp;supported&nbsp;via&nbsp;some&nbsp;custom</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_2">2</td><td nowrap="nowrap">implementation&nbsp;such&nbsp;as&nbsp;CuDNN.</td><td class="diff_next"></td><td class="diff_header" id="to68_2">2</td><td nowrap="nowrap">implementation&nbsp;such&nbsp;as&nbsp;CuDNN.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_3">3</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_4">4</td><td nowrap="nowrap">Notations:</td><td class="diff_next"></td><td class="diff_header" id="to68_4">4</td><td nowrap="nowrap">Notations:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_5">5</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_6">6</td><td nowrap="nowrap">X&nbsp;-&nbsp;input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to68_6">6</td><td nowrap="nowrap">X&nbsp;-&nbsp;input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_8">8</td><td nowrap="nowrap">z&nbsp;-&nbsp;update&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to68_8">8</td><td nowrap="nowrap">z&nbsp;-&nbsp;update&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_10">10</td><td nowrap="nowrap">r&nbsp;-&nbsp;reset&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to68_10">10</td><td nowrap="nowrap">r&nbsp;-&nbsp;reset&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_11">11</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_11">11</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_12">12</td><td nowrap="nowrap">h&nbsp;-&nbsp;hidden&nbsp;gate</td><td class="diff_next"></td><td class="diff_header" id="to68_12">12</td><td nowrap="nowrap">h&nbsp;-&nbsp;hidden&nbsp;gate</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_13">13</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_14">14</td><td nowrap="nowrap">t&nbsp;-&nbsp;time&nbsp;step&nbsp;(t-1&nbsp;means&nbsp;previous&nbsp;time&nbsp;step)</td><td class="diff_next"></td><td class="diff_header" id="to68_14">14</td><td nowrap="nowrap">t&nbsp;-&nbsp;time&nbsp;step&nbsp;(t-1&nbsp;means&nbsp;previous&nbsp;time&nbsp;step)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_15">15</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_16">16</td><td nowrap="nowrap">W[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_16">16</td><td nowrap="nowrap">W[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_18">18</td><td nowrap="nowrap">R[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_18">18</td><td nowrap="nowrap">R[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_20">20</td><td nowrap="nowrap">Wb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_20">20</td><td nowrap="nowrap">Wb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_21">21</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_22">22</td><td nowrap="nowrap">Rb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_22">22</td><td nowrap="nowrap">Rb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_23">23</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_24">24</td><td nowrap="nowrap">WB[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_24">24</td><td nowrap="nowrap">WB[zrh]&nbsp;-&nbsp;W&nbsp;parameter&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_25">25</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_25">25</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_26">26</td><td nowrap="nowrap">RB[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_26">26</td><td nowrap="nowrap">RB[zrh]&nbsp;-&nbsp;R&nbsp;recurrence&nbsp;weight&nbsp;matrix&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_28">28</td><td nowrap="nowrap">WBb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_28">28</td><td nowrap="nowrap">WBb[zrh]&nbsp;-&nbsp;W&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_30">30</td><td nowrap="nowrap">RBb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td><td class="diff_next"></td><td class="diff_header" id="to68_30">30</td><td nowrap="nowrap">RBb[zrh]&nbsp;-&nbsp;R&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;backward&nbsp;update,&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_31">31</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_31">31</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_32">32</td><td nowrap="nowrap">H&nbsp;-&nbsp;Hidden&nbsp;state</td><td class="diff_next"></td><td class="diff_header" id="to68_32">32</td><td nowrap="nowrap">H&nbsp;-&nbsp;Hidden&nbsp;state</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_33">33</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_34">34</td><td nowrap="nowrap">num_directions&nbsp;-&nbsp;2&nbsp;if&nbsp;direction&nbsp;==&nbsp;bidirectional&nbsp;else&nbsp;1</td><td class="diff_next"></td><td class="diff_header" id="to68_34">34</td><td nowrap="nowrap">num_directions&nbsp;-&nbsp;2&nbsp;if&nbsp;direction&nbsp;==&nbsp;bidirectional&nbsp;else&nbsp;1</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_35">35</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_35">35</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_36">36</td><td nowrap="nowrap">Activation&nbsp;functions:</td><td class="diff_next"></td><td class="diff_header" id="to68_36">36</td><td nowrap="nowrap">Activation&nbsp;functions:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_37">37</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_37">37</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Relu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;max(0,&nbsp;x)</td><td class="diff_next"></td><td class="diff_header" id="to68_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Relu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;max(0,&nbsp;x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_39">39</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_39">39</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Tanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;(1&nbsp;-&nbsp;e^{-2x})/(1&nbsp;+&nbsp;e^{-2x})</td><td class="diff_next"></td><td class="diff_header" id="to68_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Tanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;(1&nbsp;-&nbsp;e^{-2x})/(1&nbsp;+&nbsp;e^{-2x})</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_41">41</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_41">41</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Sigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;1/(1&nbsp;+&nbsp;e^{-x})</td><td class="diff_next"></td><td class="diff_header" id="to68_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Sigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;1/(1&nbsp;+&nbsp;e^{-x})</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_43">43</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_43">43</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;(NOTE:&nbsp;Below&nbsp;are&nbsp;optional)</td><td class="diff_next"></td><td class="diff_header" id="to68_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;(NOTE:&nbsp;Below&nbsp;are&nbsp;optional)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_45">45</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_45">45</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;Affine(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*x&nbsp;+&nbsp;beta</td><td class="diff_next"></td><td class="diff_header" id="to68_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;Affine(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*x&nbsp;+&nbsp;beta</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_47">47</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_47">47</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;LeakyRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha&nbsp;*&nbsp;x</td><td class="diff_next"></td><td class="diff_header" id="to68_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;LeakyRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha&nbsp;*&nbsp;x</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_49">49</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_49">49</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;ThresholdedRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;alpha&nbsp;else&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to68_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;ThresholdedRelu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;alpha&nbsp;else&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_51">51</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_51">51</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;ScaledTanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*Tanh(beta*x)</td><td class="diff_next"></td><td class="diff_header" id="to68_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;ScaledTanh(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alpha*Tanh(beta*x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_53">53</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_53">53</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;HardSigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;min(max(alpha*x&nbsp;+&nbsp;beta,&nbsp;0),&nbsp;1)</td><td class="diff_next"></td><td class="diff_header" id="to68_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;HardSigmoid(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;min(max(alpha*x&nbsp;+&nbsp;beta,&nbsp;0),&nbsp;1)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_55">55</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_55">55</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;Elu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha*(e^x&nbsp;-&nbsp;1)</td><td class="diff_next"></td><td class="diff_header" id="to68_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;Elu(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x&nbsp;if&nbsp;x&nbsp;&gt;=&nbsp;0&nbsp;else&nbsp;alpha*(e^x&nbsp;-&nbsp;1)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_57">57</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_57">57</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;Softsign(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x/(1&nbsp;+&nbsp;|x|)</td><td class="diff_next"></td><td class="diff_header" id="to68_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;Softsign(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;x/(1&nbsp;+&nbsp;|x|)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_59">59</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_59">59</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;Softplus(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;log(1&nbsp;+&nbsp;e^x)</td><td class="diff_next"></td><td class="diff_header" id="to68_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;Softplus(x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;log(1&nbsp;+&nbsp;e^x)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_61">61</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_61">61</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_62">62</td><td nowrap="nowrap">Equations&nbsp;(Default:&nbsp;f=Sigmoid,&nbsp;g=Tanh):</td><td class="diff_next"></td><td class="diff_header" id="to68_62">62</td><td nowrap="nowrap">Equations&nbsp;(Default:&nbsp;f=Sigmoid,&nbsp;g=Tanh):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_63">63</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_63">63</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;zt&nbsp;=&nbsp;f(Xt*(Wz^T)&nbsp;+&nbsp;Ht-1*Rz&nbsp;+&nbsp;Wbz&nbsp;+&nbsp;Rbz)</td><td class="diff_next"></td><td class="diff_header" id="to68_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;zt&nbsp;=&nbsp;f(Xt*(Wz^T)&nbsp;+&nbsp;Ht-1*Rz&nbsp;+&nbsp;Wbz&nbsp;+&nbsp;Rbz)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_65">65</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_65">65</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;rt&nbsp;=&nbsp;f(Xt*(Wr^T)&nbsp;+&nbsp;Ht-1*Rr&nbsp;+&nbsp;Wbr&nbsp;+&nbsp;Rbr)</td><td class="diff_next"></td><td class="diff_header" id="to68_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;rt&nbsp;=&nbsp;f(Xt*(Wr^T)&nbsp;+&nbsp;Ht-1*Rr&nbsp;+&nbsp;Wbr&nbsp;+&nbsp;Rbr)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_67">67</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_67">67</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;Ht-1)*Rh&nbsp;+&nbsp;Rbh&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;default,&nbsp;when&nbsp;linear_before_reset&nbsp;=&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to68_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;Ht-1)*Rh&nbsp;+&nbsp;Rbh&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;default,&nbsp;when&nbsp;linear_before_reset&nbsp;=&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_69">69</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_69">69</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;(Ht-1*Rh&nbsp;+&nbsp;Rbh)&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;when&nbsp;linear_before_reset&nbsp;!=&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to68_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;ht&nbsp;=&nbsp;g(Xt*(Wh^T)&nbsp;+&nbsp;(rt&nbsp;(.)&nbsp;(Ht-1*Rh&nbsp;+&nbsp;Rbh)&nbsp;+&nbsp;Wbh)&nbsp;#&nbsp;when&nbsp;linear_before_reset&nbsp;!=&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_71">71</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_71">71</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;Ht&nbsp;=&nbsp;(1&nbsp;-&nbsp;zt)&nbsp;(.)&nbsp;ht&nbsp;+&nbsp;zt&nbsp;(.)&nbsp;Ht-1</td><td class="diff_next"></td><td class="diff_header" id="to68_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;-&nbsp;Ht&nbsp;=&nbsp;(1&nbsp;-&nbsp;zt)&nbsp;(.)&nbsp;ht&nbsp;+&nbsp;zt&nbsp;(.)&nbsp;Ht-1</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_73">73</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_73">73</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to68__0"></td><td class="diff_header" id="from68_74">74</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to68_74">74</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_75">75</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_75">75</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_76">76</td><td nowrap="nowrap">*&nbsp;**activation_alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to68_76">76</td><td nowrap="nowrap">*&nbsp;**activation_alpha**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_77">77</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to68_77">77</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td><td class="diff_next"></td><td class="diff_header" id="to68_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to68__1">n</a></td><td class="diff_header" id="from68_79">79</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.</span></td><td class="diff_next"><a href="#difflib_chg_to68__1">n</a></td><td class="diff_header" id="to68_79">79</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to68__1"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_80">80</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.For&nbsp;example&nbsp;with&nbsp;LeakyRelu,&nbsp;the&nbsp;default</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_81">81</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;alpha&nbsp;is&nbsp;0.01.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_80">80</td><td nowrap="nowrap">*&nbsp;**activation_beta**:</td><td class="diff_next"></td><td class="diff_header" id="to68_82">82</td><td nowrap="nowrap">*&nbsp;**activation_beta**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to68_83">83</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;scaling&nbsp;values&nbsp;used&nbsp;by&nbsp;some&nbsp;activation&nbsp;functions.&nbsp;The</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td><td class="diff_next"></td><td class="diff_header" id="to68_84">84</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;consumed&nbsp;in&nbsp;the&nbsp;order&nbsp;of&nbsp;activation&nbsp;functions,&nbsp;for</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to68__2">n</a></td><td class="diff_header" id="from68_83">83</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.</span></td><td class="diff_next"><a href="#difflib_chg_to68__2">n</a></td><td class="diff_header" id="to68_85">85</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;example&nbsp;(f,&nbsp;g,&nbsp;h)&nbsp;in&nbsp;LSTM.&nbsp;Default&nbsp;values&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;of</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_86">86</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;corresponding&nbsp;ONNX&nbsp;operators.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_84">84</td><td nowrap="nowrap">*&nbsp;**activations**:</td><td class="diff_next"></td><td class="diff_header" id="to68_87">87</td><td nowrap="nowrap">*&nbsp;**activations**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;2&nbsp;(or&nbsp;4&nbsp;if&nbsp;bidirectional)&nbsp;activation&nbsp;functions&nbsp;for&nbsp;update,</td><td class="diff_next"></td><td class="diff_header" id="to68_88">88</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;2&nbsp;(or&nbsp;4&nbsp;if&nbsp;bidirectional)&nbsp;activation&nbsp;functions&nbsp;for&nbsp;update,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates.&nbsp;The&nbsp;activation&nbsp;functions&nbsp;must&nbsp;be&nbsp;one&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to68_89">89</td><td nowrap="nowrap">&nbsp;&nbsp;reset,&nbsp;and&nbsp;hidden&nbsp;gates.&nbsp;The&nbsp;activation&nbsp;functions&nbsp;must&nbsp;be&nbsp;one&nbsp;of&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_87">87</td><td nowrap="nowrap">&nbsp;&nbsp;activation&nbsp;functions&nbsp;specified&nbsp;above.&nbsp;Optional:&nbsp;See&nbsp;the&nbsp;equations</td><td class="diff_next"></td><td class="diff_header" id="to68_90">90</td><td nowrap="nowrap">&nbsp;&nbsp;activation&nbsp;functions&nbsp;specified&nbsp;above.&nbsp;Optional:&nbsp;See&nbsp;the&nbsp;equations</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_88">88</td><td nowrap="nowrap">&nbsp;&nbsp;for&nbsp;default&nbsp;if&nbsp;not&nbsp;specified.</td><td class="diff_next"></td><td class="diff_header" id="to68_91">91</td><td nowrap="nowrap">&nbsp;&nbsp;for&nbsp;default&nbsp;if&nbsp;not&nbsp;specified.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_89">89</td><td nowrap="nowrap">*&nbsp;**clip**:</td><td class="diff_next"></td><td class="diff_header" id="to68_92">92</td><td nowrap="nowrap">*&nbsp;**clip**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_90">90</td><td nowrap="nowrap">&nbsp;&nbsp;Cell&nbsp;clip&nbsp;threshold.&nbsp;Clipping&nbsp;bounds&nbsp;the&nbsp;elements&nbsp;of&nbsp;a&nbsp;tensor&nbsp;in&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to68_93">93</td><td nowrap="nowrap">&nbsp;&nbsp;Cell&nbsp;clip&nbsp;threshold.&nbsp;Clipping&nbsp;bounds&nbsp;the&nbsp;elements&nbsp;of&nbsp;a&nbsp;tensor&nbsp;in&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_91">91</td><td nowrap="nowrap">&nbsp;&nbsp;range&nbsp;of&nbsp;[-threshold,&nbsp;+threshold]&nbsp;and&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;input&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to68_94">94</td><td nowrap="nowrap">&nbsp;&nbsp;range&nbsp;of&nbsp;[-threshold,&nbsp;+threshold]&nbsp;and&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;input&nbsp;of</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_92">92</td><td nowrap="nowrap">&nbsp;&nbsp;activations.&nbsp;No&nbsp;clip&nbsp;if&nbsp;not&nbsp;specified.</td><td class="diff_next"></td><td class="diff_header" id="to68_95">95</td><td nowrap="nowrap">&nbsp;&nbsp;activations.&nbsp;No&nbsp;clip&nbsp;if&nbsp;not&nbsp;specified.</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to68__2"></td><td class="diff_header" id="from68_93">93</td><td nowrap="nowrap">*&nbsp;**direction**:</td><td class="diff_next"></td><td class="diff_header" id="to68_96">96</td><td nowrap="nowrap">*&nbsp;**direction**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_94">94</td><td nowrap="nowrap">&nbsp;&nbsp;Specify&nbsp;if&nbsp;the&nbsp;RNN&nbsp;is&nbsp;forward,&nbsp;reverse,&nbsp;or&nbsp;bidirectional.&nbsp;Must&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to68_97">97</td><td nowrap="nowrap">&nbsp;&nbsp;Specify&nbsp;if&nbsp;the&nbsp;RNN&nbsp;is&nbsp;forward,&nbsp;reverse,&nbsp;or&nbsp;bidirectional.&nbsp;Must&nbsp;be</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_95">95</td><td nowrap="nowrap">&nbsp;&nbsp;one&nbsp;of&nbsp;forward&nbsp;(default),&nbsp;reverse,&nbsp;or&nbsp;bidirectional.</td><td class="diff_next"></td><td class="diff_header" id="to68_98">98</td><td nowrap="nowrap">&nbsp;&nbsp;one&nbsp;of&nbsp;forward&nbsp;(default),&nbsp;reverse,&nbsp;or&nbsp;bidirectional.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_96">96</td><td nowrap="nowrap">*&nbsp;**hidden_size**:</td><td class="diff_next"></td><td class="diff_header" id="to68_99">99</td><td nowrap="nowrap">*&nbsp;**hidden_size**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_97">97</td><td nowrap="nowrap">&nbsp;&nbsp;Number&nbsp;of&nbsp;neurons&nbsp;in&nbsp;the&nbsp;hidden&nbsp;layer</td><td class="diff_next"></td><td class="diff_header" id="to68_100">100</td><td nowrap="nowrap">&nbsp;&nbsp;Number&nbsp;of&nbsp;neurons&nbsp;in&nbsp;the&nbsp;hidden&nbsp;layer</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to68__3">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to68__3">n</a></td><td class="diff_header" id="to68_101">101</td><td nowrap="nowrap"><span class="diff_add">*&nbsp;**linear_before_reset**:</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_102">102</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;When&nbsp;computing&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;hidden&nbsp;gate,&nbsp;apply&nbsp;the&nbsp;linear</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_103">103</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;transformation&nbsp;before&nbsp;multiplying&nbsp;by&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;reset&nbsp;gate.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_98">98</td><td nowrap="nowrap">*&nbsp;**output_sequence**:</td><td class="diff_next"></td><td class="diff_header" id="to68_104">104</td><td nowrap="nowrap">*&nbsp;**output_sequence**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_99">99</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;sequence&nbsp;output&nbsp;for&nbsp;the&nbsp;hidden&nbsp;is&nbsp;optional&nbsp;if&nbsp;0.&nbsp;Default&nbsp;0.</td><td class="diff_next"></td><td class="diff_header" id="to68_105">105</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;sequence&nbsp;output&nbsp;for&nbsp;the&nbsp;hidden&nbsp;is&nbsp;optional&nbsp;if&nbsp;0.&nbsp;Default&nbsp;0.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_100">100</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_106">106</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_101">101</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to68_107">107</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_102">102</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_108">108</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_103">103</td><td nowrap="nowrap">Between&nbsp;3&nbsp;and&nbsp;6&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to68_109">109</td><td nowrap="nowrap">Between&nbsp;3&nbsp;and&nbsp;6&nbsp;inputs.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_104">104</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_110">110</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_105">105</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to68_111">111</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_106">106</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;sequences&nbsp;packed&nbsp;(and&nbsp;potentially&nbsp;padded)&nbsp;into&nbsp;one&nbsp;3-D</td><td class="diff_next"></td><td class="diff_header" id="to68_112">112</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;sequences&nbsp;packed&nbsp;(and&nbsp;potentially&nbsp;padded)&nbsp;into&nbsp;one&nbsp;3-D</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_107">107</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;with&nbsp;the&nbsp;shape&nbsp;of&nbsp;[seq_length,&nbsp;batch_size,&nbsp;input_size].</td><td class="diff_next"></td><td class="diff_header" id="to68_113">113</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;with&nbsp;the&nbsp;shape&nbsp;of&nbsp;[seq_length,&nbsp;batch_size,&nbsp;input_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_108">108</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to68_114">114</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_109">109</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;W[zrh]&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to68_115">115</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;W[zrh]&nbsp;and</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_110">110</td><td nowrap="nowrap">&nbsp;&nbsp;WB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to68_116">116</td><td nowrap="nowrap">&nbsp;&nbsp;WB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_111">111</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;input_size].</td><td class="diff_next"></td><td class="diff_header" id="to68_117">117</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;input_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_112">112</td><td nowrap="nowrap">*&nbsp;**R**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to68_118">118</td><td nowrap="nowrap">*&nbsp;**R**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_113">113</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;recurrence&nbsp;weight&nbsp;tensor.&nbsp;Concatenation&nbsp;of&nbsp;R[zrh]&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to68_119">119</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;recurrence&nbsp;weight&nbsp;tensor.&nbsp;Concatenation&nbsp;of&nbsp;R[zrh]&nbsp;and</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_114">114</td><td nowrap="nowrap">&nbsp;&nbsp;RB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to68_120">120</td><td nowrap="nowrap">&nbsp;&nbsp;RB[zrh]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.&nbsp;This&nbsp;tensor&nbsp;has</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_115">115</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to68_121">121</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;[num_directions,&nbsp;3*hidden_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_116">116</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to68_122">122</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_117">117</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;bias&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;[Wb[zrh],&nbsp;Rb[zrh]]</td><td class="diff_next"></td><td class="diff_header" id="to68_123">123</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;bias&nbsp;tensor&nbsp;for&nbsp;the&nbsp;gates.&nbsp;Concatenation&nbsp;of&nbsp;[Wb[zrh],&nbsp;Rb[zrh]]</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_118">118</td><td nowrap="nowrap">&nbsp;&nbsp;and&nbsp;[WBb[zrh],&nbsp;RBb[zrh]]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.</td><td class="diff_next"></td><td class="diff_header" id="to68_124">124</td><td nowrap="nowrap">&nbsp;&nbsp;and&nbsp;[WBb[zrh],&nbsp;RBb[zrh]]&nbsp;(if&nbsp;bidirectional)&nbsp;along&nbsp;dimension&nbsp;0.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_119">119</td><td nowrap="nowrap">&nbsp;&nbsp;This&nbsp;tensor&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;6*hidden_size].&nbsp;Optional:</td><td class="diff_next"></td><td class="diff_header" id="to68_125">125</td><td nowrap="nowrap">&nbsp;&nbsp;This&nbsp;tensor&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;6*hidden_size].&nbsp;Optional:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_120">120</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to&nbsp;be&nbsp;0</td><td class="diff_next"></td><td class="diff_header" id="to68_126">126</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to&nbsp;be&nbsp;0</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_121">121</td><td nowrap="nowrap">*&nbsp;**sequence_lens**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T1**:</td><td class="diff_next"></td><td class="diff_header" id="to68_127">127</td><td nowrap="nowrap">*&nbsp;**sequence_lens**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T1**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_122">122</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;tensor&nbsp;specifying&nbsp;lengths&nbsp;of&nbsp;the&nbsp;sequences&nbsp;in&nbsp;a&nbsp;batch.&nbsp;If</td><td class="diff_next"></td><td class="diff_header" id="to68_128">128</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;tensor&nbsp;specifying&nbsp;lengths&nbsp;of&nbsp;the&nbsp;sequences&nbsp;in&nbsp;a&nbsp;batch.&nbsp;If</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_123">123</td><td nowrap="nowrap">&nbsp;&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;all&nbsp;sequences&nbsp;in&nbsp;the&nbsp;batch&nbsp;to&nbsp;have&nbsp;length</td><td class="diff_next"></td><td class="diff_header" id="to68_129">129</td><td nowrap="nowrap">&nbsp;&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;all&nbsp;sequences&nbsp;in&nbsp;the&nbsp;batch&nbsp;to&nbsp;have&nbsp;length</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_124">124</td><td nowrap="nowrap">&nbsp;&nbsp;seq_length.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[batch_size].</td><td class="diff_next"></td><td class="diff_header" id="to68_130">130</td><td nowrap="nowrap">&nbsp;&nbsp;seq_length.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[batch_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_125">125</td><td nowrap="nowrap">*&nbsp;**initial_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to68_131">131</td><td nowrap="nowrap">*&nbsp;**initial_h**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to68__3"></td><td class="diff_header" id="from68_126">126</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;initial&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to68_132">132</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;initial&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;If&nbsp;not&nbsp;specified&nbsp;-&nbsp;assumed&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_127">127</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;0.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;batch_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to68_133">133</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;0.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,&nbsp;batch_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_128">128</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_134">134</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_129">129</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to68_135">135</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_130">130</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_136">136</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to68__4">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to68__4">n</a></td><td class="diff_header" id="to68_137">137</td><td nowrap="nowrap"><span class="diff_add">Between&nbsp;0&nbsp;and&nbsp;2&nbsp;outputs.</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to68__4"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_138">138</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_131">131</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to68_139">139</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_132">132</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;tensor&nbsp;that&nbsp;concats&nbsp;all&nbsp;the&nbsp;intermediate&nbsp;output&nbsp;values&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to68_140">140</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;tensor&nbsp;that&nbsp;concats&nbsp;all&nbsp;the&nbsp;intermediate&nbsp;output&nbsp;values&nbsp;of&nbsp;the</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_133">133</td><td nowrap="nowrap">&nbsp;&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[seq_length,&nbsp;num_directions,&nbsp;batch_size,</td><td class="diff_next"></td><td class="diff_header" id="to68_141">141</td><td nowrap="nowrap">&nbsp;&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[seq_length,&nbsp;num_directions,&nbsp;batch_size,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_134">134</td><td nowrap="nowrap">&nbsp;&nbsp;hidden_size].&nbsp;It&nbsp;is&nbsp;optional&nbsp;if&nbsp;output_sequence&nbsp;is&nbsp;0.</td><td class="diff_next"></td><td class="diff_header" id="to68_142">142</td><td nowrap="nowrap">&nbsp;&nbsp;hidden_size].&nbsp;It&nbsp;is&nbsp;optional&nbsp;if&nbsp;output_sequence&nbsp;is&nbsp;0.</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to68__top">t</a></td><td class="diff_header" id="from68_135">135</td><td nowrap="nowrap">*&nbsp;**Y_h**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"><a href="#difflib_chg_to68__top">t</a></td><td class="diff_header" id="to68_143">143</td><td nowrap="nowrap">*&nbsp;**Y_h**&nbsp;(<span class="diff_add">optional,&nbsp;</span>heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_136">136</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;last&nbsp;output&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,</td><td class="diff_next"></td><td class="diff_header" id="to68_144">144</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;last&nbsp;output&nbsp;value&nbsp;of&nbsp;the&nbsp;hidden.&nbsp;It&nbsp;has&nbsp;shape&nbsp;[num_directions,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_137">137</td><td nowrap="nowrap">&nbsp;&nbsp;batch_size,&nbsp;hidden_size].</td><td class="diff_next"></td><td class="diff_header" id="to68_145">145</td><td nowrap="nowrap">&nbsp;&nbsp;batch_size,&nbsp;hidden_size].</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_138">138</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_146">146</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_139">139</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to68_147">147</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_140">140</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to68_148">148</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_141">141</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to68_149">149</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_142">142</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to68_150">150</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_143">143</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to68_151">151</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_144">144</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to68_152">152</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_145">145</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to68_153">153</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_146">146</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to68_154">154</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_147">147</td><td nowrap="nowrap">*&nbsp;**T1**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to68_155">155</td><td nowrap="nowrap">*&nbsp;**T1**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_148">148</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32)</td><td class="diff_next"></td><td class="diff_header" id="to68_156">156</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_149">149</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to68_157">157</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from68_150">150</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;seq_lens&nbsp;to&nbsp;integer&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to68_158">158</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;seq_lens&nbsp;to&nbsp;integer&nbsp;tensor.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-gru-1:

GRU - 1
=======

**Version**

* **name**: `GRU (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.

Notations:

`X` - input tensor

`z` - update gate

`r` - reset gate

`h` - hidden gate

`t` - time step (t-1 means previous time step)

`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates

`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates

`Wb[zrh]` - W bias vectors for update, reset, and hidden gates

`Rb[zrh]` - R bias vectors for update, reset, and hidden gates

`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates

`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates

`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates

`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates

`H` - Hidden state

`num_directions` - 2 if direction == bidirectional else 1

Activation functions:

  Relu(x)                - max(0, x)

  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})

  Sigmoid(x)             - 1/(1 + e^{-x})

  (NOTE: Below are optional)

  Affine(x)              - alpha*x + beta

  LeakyRelu(x)           - x if x >= 0 else alpha * x

  ThresholdedRelu(x)     - x if x >= alpha else 0

  ScaledTanh(x)          - alpha*Tanh(beta*x)

  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)

  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)

  Softsign(x)            - x/(1 + |x|)

  Softplus(x)            - log(1 + e^x)

Equations (Default: f=Sigmoid, g=Tanh):

  - zt = f(Xt*(Wz^T) + Ht-1*Rz + Wbz + Rbz)

  - rt = f(Xt*(Wr^T) + Ht-1*Rr + Wbr + Rbr)

  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*Rh + Rbh + Wbh) # default, when linear_before_reset = 0

  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*Rh + Rbh) + Wbh) # when linear_before_reset != 0

  - Ht = (1 - zt) (.) ht + zt (.) Ht-1

**Attributes**

* **activation_alpha**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM.
* **activation_beta**:
  Optional scaling values used by some activation functions. The
  values are consumed in the order of activation functions, for
  example (f, g, h) in LSTM.
* **activations**:
  A list of 2 (or 4 if bidirectional) activation functions for update,
  reset, and hidden gates. The activation functions must be one of the
  activation functions specified above. Optional: See the equations
  for default if not specified.
* **clip**:
  Cell clip threshold. Clipping bounds the elements of a tensor in the
  range of [-threshold, +threshold] and is applied to the input of
  activations. No clip if not specified.
* **direction**:
  Specify if the RNN is forward, reverse, or bidirectional. Must be
  one of forward (default), reverse, or bidirectional.
* **hidden_size**:
  Number of neurons in the hidden layer
* **output_sequence**:
  The sequence output for the hidden is optional if 0. Default 0.

**Inputs**

Between 3 and 6 inputs.

* **X** (heterogeneous) - **T**:
  The input sequences packed (and potentially padded) into one 3-D
  tensor with the shape of `[seq_length, batch_size, input_size]`.
* **W** (heterogeneous) - **T**:
  The weight tensor for the gates. Concatenation of `W[zrh]` and
  `WB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, input_size]`.
* **R** (heterogeneous) - **T**:
  The recurrence weight tensor. Concatenation of `R[zrh]` and
  `RB[zrh]` (if bidirectional) along dimension 0. This tensor has
  shape `[num_directions, 3*hidden_size, hidden_size]`.
* **B** (optional, heterogeneous) - **T**:
  The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]`
  and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0.
  This tensor has shape `[num_directions, 6*hidden_size]`. Optional:
  If not specified - assumed to be 0
* **sequence_lens** (optional, heterogeneous) - **T1**:
  Optional tensor specifying lengths of the sequences in a batch. If
  not specified - assumed all sequences in the batch to have length
  `seq_length`. It has shape `[batch_size]`.
* **initial_h** (optional, heterogeneous) - **T**:
  Optional initial value of the hidden. If not specified - assumed to
  be 0. It has shape `[num_directions, batch_size, hidden_size]`.

**Outputs**

* **Y** (optional, heterogeneous) - **T**:
  A tensor that concats all the intermediate output values of the
  hidden. It has shape `[seq_length, num_directions, batch_size,
  hidden_size]`. It is optional if `output_sequence` is 0.
* **Y_h** (heterogeneous) - **T**:
  The last output value of the hidden. It has shape `[num_directions,
  batch_size, hidden_size]`.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
* **T1** in (
  tensor(int32)
  ):
  Constrain seq_lens to integer tensor.
