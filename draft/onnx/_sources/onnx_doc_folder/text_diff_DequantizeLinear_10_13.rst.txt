DequantizeLinear - 10 vs 13
===========================

.. raw:: html


    <div id="div_DequantizeLinear_2"></div>
    <link rel="stylesheet" type="text/css" href="../_static/diff2html.min.css" />
    <script type="text/javascript" src="../_static/diff2html-ui.min.js"></script>
    <script>
    const diffString = `
    --- a/DequantizeLinear10
    +++ b/DequantizeLinear13
    @@ -1 +1 @@
    - The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.
    + The linear dequantization operator. It consumes a quantized tensor, a scale, and a zero point to compute the full precision tensor.
    ?                                                                               ++++
    - The dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.
    ?                                                                                               ^   ^         --
    + The dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' must have same shape, and can be either a scalar
    ?                                                                                              ++++++ ^  ++++++++++++++++++++ ^^^^  ++++
    + for per-tensor / per layer quantization, or a 1-D tensor for per-axis quantization.
      'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,
      there's no zero point (zero point is supposed to be 0).
    + 
    + **Attributes**
    + 
    + * **axis**:
    +   (Optional) The axis of the dequantizing dimension of the input
    +   tensor. Ignored for per-tensor quantization. Negative value means
    +   counting dimensions from the back. Accepted range is [-r, r-1] where
    +   r = rank(input).
  
      **Inputs**
  
      Between 2 and 3 inputs.
  
      * **x** (heterogeneous) - **T**:
        N-D quantized input tensor to be de-quantized.
      * **x_scale** (heterogeneous) - **tensor(float)**:
    -   Scale for input 'x'. It's a scalar, which means a per-tensor/layer
    ?                          ^^                             ------------
    +   Scale for input 'x'. It can be a scalar, which means a per-
    ?                          ^^^^^^^
    +   tensor/layer dequantization, or a 1-D tensor for per-axis
    -   quantization.
    +   dequantization.
    ?   ++
      * **x_zero_point** (optional, heterogeneous) - **T**:
    +   Zero point for input 'x'. Shape must match x_scale. It's optional.
    -   Zero point for input 'x'. It's a scalar, which means a per-
    -   tensor/layer quantization. It's optional. 0 is the default value
    -   when it's not specified.
    +   Zero point is 0 when it's not specified.
    ?  ++++++++++++++++
  
      **Outputs**
  
      * **y** (heterogeneous) - **tensor(float)**:
        N-D full precision output tensor. It has same shape as input 'x'.
  
      **Type Constraints**
  
      * **T** in (
        tensor(int32),
        tensor(int8),
        tensor(uint8)
        ):
        Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
    `;

    document.addEventListener('DOMContentLoaded', function () {
    var targetElement = document.getElementById('div_DequantizeLinear_2');
    var configuration = {
        drawFileList: true,
        fileListToggle: false,
        fileListStartVisible: false,
        fileContentToggle: false,
        matching: 'lines',
        outputFormat: 'line-by-line',
        synchronisedScroll: true,
        highlight: true,
        renderNothingWhenEmpty: false,
    };
    var diff2htmlUi = new Diff2HtmlUI(targetElement, diffString, configuration);
    diff2htmlUi.draw();
    diff2htmlUi.highlightCode();
    });
    </script>