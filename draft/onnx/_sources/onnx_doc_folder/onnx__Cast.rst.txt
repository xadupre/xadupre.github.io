
.. _l-onnx-doc-Cast:

====
Cast
====

.. contents::
    :local:


.. _l-onnx-op-cast-13:

Cast - 13
=========

**Version**

* **name**: `Cast (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

The operator casts the elements of a given input tensor to a data type
specified by the &#39;to&#39; argument and returns an output tensor of the same size in
the converted type. The &#39;to&#39; argument must be one of the data types specified
in the &#39;DataType&#39; enum field in the TensorProto message.

Casting from string tensor in plain (e.g., &#34;3.14&#34; and &#34;1000&#34;) and scientific numeric representations
(e.g., &#34;1e-5&#34; and &#34;1E8&#34;) to float types is supported. For example, converting string &#34;100.5&#34; to an integer may
result 100. There are some string literals reserved for special floating-point values;
&#34;+INF&#34; (and &#34;INF&#34;), &#34;-INF&#34;, and &#34;NaN&#34; are positive infinity, negative infinity, and not-a-number, respectively.
Any string which can exactly match &#34;+INF&#34; in a case-insensitive way would be mapped to positive infinite. Similarly,
this case-insensitive rule is applied to &#34;INF&#34; and &#34;NaN&#34;. When casting from numeric tensors
to string tensors, plain floating-point representation (such as &#34;314.15926&#34;) would be used.
Converting non-numerical-literal string such as &#34;Hello World!&#34; is an undefined behavior. Cases
of converting string representing floating-point arithmetic value, such as &#34;2.718&#34;, to INT is an undefined behavior.

Conversion from a numerical type to any numerical type is always allowed.
User must be aware of precision loss and value change caused by range difference between two types.
For example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting
an integer 36 to Boolean may produce 1 because we truncate bits which can&#39;t be stored in the targeted type.

In more detail, the conversion among numerical types should follow these rules:

* Casting from floating point to:
  * floating point: +/- infinity if OOR (out of range).
  * fixed point: undefined if OOR.
  * bool: +/- 0.0 to False; all else to True.
* Casting from fixed point to:
  * floating point: +/- infinity if OOR. (+ infinity in the case of uint)
  * fixed point: when OOR, discard higher bits and reinterpret (with respect to two&#39;s complement representation for
signed types). For example, 200 (int16) -&gt; -56 (int8).
  * bool: zero to False; nonzero to True.
* Casting from bool to:
  * floating point: `{1.0, 0.0}`.
  * fixed point: `{1, 0}`.
  * bool: no change.

**Attributes**

* **to** (required):
  The data type to which the elements of the input tensor are cast.
  Strictly must be one of the types from DataType enum in TensorProto

**Inputs**

* **input** (heterogeneous) - **T1**:
  Input tensor to be cast.

**Outputs**

* **output** (heterogeneous) - **T2**:
  Output tensor with the same shape as input with type specified by
  the &#39;to&#39; argument

**Type Constraints**

* **T1** in (
  tensor(bfloat16),
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input types. Casting from complex is not supported.
* **T2** in (
  tensor(bfloat16),
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain output types. Casting to complex is not supported.

**Examples**

**default**

::

    import numpy as np
    import onnx

    shape = (3, 4)
    test_cases = [
        (&#34;FLOAT&#34;, &#34;FLOAT16&#34;),
        (&#34;FLOAT&#34;, &#34;DOUBLE&#34;),
        (&#34;FLOAT16&#34;, &#34;FLOAT&#34;),
        (&#34;FLOAT16&#34;, &#34;DOUBLE&#34;),
        (&#34;DOUBLE&#34;, &#34;FLOAT&#34;),
        (&#34;DOUBLE&#34;, &#34;FLOAT16&#34;),
        (&#34;FLOAT&#34;, &#34;STRING&#34;),
        (&#34;STRING&#34;, &#34;FLOAT&#34;),
        (&#34;FLOAT&#34;, &#34;BFLOAT16&#34;),
        (&#34;BFLOAT16&#34;, &#34;FLOAT&#34;),
    ]

    for from_type, to_type in test_cases:
        input_type_proto = None
        output_type_proto = None
        if &#34;BFLOAT16&#34; == from_type or &#34;BFLOAT16&#34; == to_type:
            np_fp32 = np.array(
                [
                    &#34;0.47892547&#34;,
                    &#34;0.48033667&#34;,
                    &#34;0.49968487&#34;,
                    &#34;0.81910545&#34;,
                    &#34;0.47031248&#34;,
                    &#34;0.816468&#34;,
                    &#34;0.21087195&#34;,
                    &#34;0.7229038&#34;,
                    &#34;NaN&#34;,
                    &#34;INF&#34;,
                    &#34;+INF&#34;,
                    &#34;-INF&#34;,
                ],
                dtype=np.float32,
            )
            little_endisan = sys.byteorder == &#34;little&#34;
            np_uint16_view = np_fp32.view(dtype=np.uint16)
            np_bfp16 = (
                np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]
            )
            if &#34;BFLOAT16&#34; == to_type:
                assert from_type == &#34;FLOAT&#34;
                input = np_fp32.reshape([3, 4])
                output = np_bfp16.reshape([3, 4])
                input_type_proto = onnx.helper.make_tensor_type_proto(
                    int(TensorProto.FLOAT), input.shape
                )
                output_type_proto = onnx.helper.make_tensor_type_proto(
                    int(TensorProto.BFLOAT16), output.shape
                )
            else:
                assert to_type == &#34;FLOAT&#34;
                input = np_bfp16.reshape([3, 4])
                # convert bfloat to FLOAT
                np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)
                if little_endisan:
                    np_fp32_zeros[1::2] = np_bfp16
                else:
                    np_fp32_zeros[0::2] = np_bfp16
                np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)
                output = np_fp32_from_bfloat.reshape([3, 4])
                input_type_proto = onnx.helper.make_tensor_type_proto(
                    int(TensorProto.BFLOAT16), input.shape
                )
                output_type_proto = onnx.helper.make_tensor_type_proto(
                    int(TensorProto.FLOAT), output.shape
                )
        elif &#34;STRING&#34; != from_type:
            input = np.random.random_sample(shape).astype(
                TENSOR_TYPE_TO_NP_TYPE[getattr(TensorProto, from_type)]
            )
            if &#34;STRING&#34; == to_type:
                # Converting input to str, then give it object dtype for generating script
                ss = []
                for i in input.flatten():
                    s = str(i).encode(&#34;utf-8&#34;)
                    su = s.decode(&#34;utf-8&#34;)
                    ss.append(su)

                output = np.array(ss).astype(object).reshape([3, 4])
            else:
                output = input.astype(
                    TENSOR_TYPE_TO_NP_TYPE[getattr(TensorProto, to_type)]
                )
        else:
            input = np.array(
                [
                    &#34;0.47892547&#34;,
                    &#34;0.48033667&#34;,
                    &#34;0.49968487&#34;,
                    &#34;0.81910545&#34;,
                    &#34;0.47031248&#34;,
                    &#34;0.816468&#34;,
                    &#34;0.21087195&#34;,
                    &#34;0.7229038&#34;,
                    &#34;NaN&#34;,
                    &#34;INF&#34;,
                    &#34;+INF&#34;,
                    &#34;-INF&#34;,
                ],
                dtype=np.dtype(object),
            ).reshape([3, 4])
            output = input.astype(
                TENSOR_TYPE_TO_NP_TYPE[getattr(TensorProto, to_type)]
            )
        node = onnx.helper.make_node(
            &#34;Cast&#34;,
            inputs=[&#34;input&#34;],
            outputs=[&#34;output&#34;],
            to=getattr(TensorProto, to_type),
        )
        if input_type_proto and output_type_proto:
            expect(
                node,
                inputs=[input],
                outputs=[output],
                name=&#34;test_cast_&#34; + from_type + &#34;_to_&#34; + to_type,
                input_type_protos=[input_type_proto],
                output_type_protos=[output_type_proto],
            )
        else:
            expect(
                node,
                inputs=[input],
                outputs=[output],
                name=&#34;test_cast_&#34; + from_type + &#34;_to_&#34; + to_type,
            )

.. toctree::

    text_diff_Cast_9_13

.. _l-onnx-op-cast-9:

Cast - 9
========

**Version**

* **name**: `Cast (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast>`_
* **domain**: **main**
* **since_version**: **9**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 9**.

**Summary**

The operator casts the elements of a given input tensor to a data type
specified by the &#39;to&#39; argument and returns an output tensor of the same size in
the converted type. The &#39;to&#39; argument must be one of the data types specified
in the &#39;DataType&#39; enum field in the TensorProto message.

Casting from string tensor in plain (e.g., &#34;3.14&#34; and &#34;1000&#34;) and scientific numeric representations
(e.g., &#34;1e-5&#34; and &#34;1E8&#34;) to float types is supported. For example, converting string &#34;100.5&#34; to an integer may
result 100. There are some string literals reserved for special floating-point values;
&#34;+INF&#34; (and &#34;INF&#34;), &#34;-INF&#34;, and &#34;NaN&#34; are positive infinity, negative infinity, and not-a-number, respectively.
Any string which can exactly match &#34;+INF&#34; in a case-insensitive way would be mapped to positive infinite. Similarly,
this case-insensitive rule is applied to &#34;INF&#34; and &#34;NaN&#34;. When casting from numeric tensors
to string tensors, plain floating-point representation (such as &#34;314.15926&#34;) would be used.
Converting non-numerical-literal string such as &#34;Hello World!&#34; is an undefined behavior. Cases
of converting string representing floating-point arithmetic value, such as &#34;2.718&#34;, to INT is an undefined behavior.

Conversion from a numerical type to any numerical type is always allowed.
User must be aware of precision loss and value change caused by range difference between two types.
For example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting
an integer 36 to Boolean may produce 1 because we truncate bits which can&#39;t be stored in the targeted type.

**Attributes**

* **to** (required):
  The data type to which the elements of the input tensor are cast.
  Strictly must be one of the types from DataType enum in TensorProto

**Inputs**

* **input** (heterogeneous) - **T1**:
  Input tensor to be cast.

**Outputs**

* **output** (heterogeneous) - **T2**:
  Output tensor with the same shape as input with type specified by
  the &#39;to&#39; argument

**Type Constraints**

* **T1** in (
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input types. Casting from complex is not supported.
* **T2** in (
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain output types. Casting to complex is not supported.

.. toctree::

    text_diff_Cast_6_9

.. _l-onnx-op-cast-6:

Cast - 6
========

**Version**

* **name**: `Cast (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast>`_
* **domain**: **main**
* **since_version**: **6**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 6**.

**Summary**

The operator casts the elements of a given input tensor to a data type
specified by the &#39;to&#39; argument and returns an output tensor of the same size in
the converted type. The &#39;to&#39; argument must be one of the data types specified
in the &#39;DataType&#39; enum field in the TensorProto message.
NOTE: Casting to and from strings is not supported yet.

**Attributes**

* **to** (required):
  The data type to which the elements of the input tensor are cast.
  Strictly must be one of the types from DataType enum in TensorProto

**Inputs**

* **input** (heterogeneous) - **T1**:
  Input tensor to be cast.

**Outputs**

* **output** (heterogeneous) - **T2**:
  Output tensor with the same shape as input with type specified by
  the &#39;to&#39; argument

**Type Constraints**

* **T1** in (
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input types. Casting from strings and complex are not
  supported.
* **T2** in (
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain output types. Casting to strings and complex are not
  supported.

.. toctree::

    text_diff_Cast_1_6

.. _l-onnx-op-cast-1:

Cast - 1
========

**Version**

* **name**: `Cast (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

The operator casts the elements of a given input tensor to a data type
specified by the &#39;to&#39; argument and returns an output tensor of the same size in
the converted type. The &#39;to&#39; argument must be one of the data types specified
in the &#39;DataType&#39; enum field in the TensorProto message.
NOTE: Casting to and from strings is not supported yet.

**Attributes**

* **to** (required):
  The data type to which the elements of the input tensor are cast.
  Strictly must be one of the types from DataType enum in TensorProto

**Inputs**

* **input** (heterogeneous) - **T1**:
  Input tensor to be cast.

**Outputs**

* **output** (heterogeneous) - **T2**:
  Output tensor with the same shape as input with type specified by
  the &#39;to&#39; argument

**Type Constraints**

* **T1** in (
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input types. Casting from strings and complex are not
  supported.
* **T2** in (
  tensor(bool),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain output types. Casting to strings and complex are not
  supported.
