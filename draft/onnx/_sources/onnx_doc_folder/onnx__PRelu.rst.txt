
.. _l-onnx-doc-PRelu:

=====
PRelu
=====

.. contents::
    :local:


.. _l-onnx-op-prelu-16:

PRelu - 16
==========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **16**
* **function**: True
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 16**.

**Summary**

PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function `f(x) = slope * x for x &lt; 0`,
`f(x) = x for x &gt;= 0`., is applied to the data tensor elementwise.

**History**
- Version 16 adds bfloat16 to the types allowed.
This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX &lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;`_.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. The shape of slope can be smaller then first input X;
  if so, its shape must be unidirectional broadcastable to X

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor (same size as X)

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to float/int tensors.

**Examples**

**default**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        &#34;PRelu&#34;,
        inputs=[&#34;x&#34;, &#34;slope&#34;],
        outputs=[&#34;y&#34;],
    )

    x = np.random.randn(3, 4, 5).astype(np.float32)
    slope = np.random.randn(3, 4, 5).astype(np.float32)
    y = np.clip(x, 0, np.inf) + np.clip(x, -np.inf, 0) * slope

    expect(node, inputs=[x, slope], outputs=[y], name=&#34;test_prelu_example&#34;)

**_prelu_broadcast**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        &#34;PRelu&#34;,
        inputs=[&#34;x&#34;, &#34;slope&#34;],
        outputs=[&#34;y&#34;],
    )

    x = np.random.randn(3, 4, 5).astype(np.float32)
    slope = np.random.randn(5).astype(np.float32)
    y = np.clip(x, 0, np.inf) + np.clip(x, -np.inf, 0) * slope

    expect(node, inputs=[x, slope], outputs=[y], name=&#34;test_prelu_broadcast&#34;)

.. toctree::

    text_diff_PRelu_9_16

.. _l-onnx-op-prelu-9:

PRelu - 9
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **9**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 9**.

**Summary**

PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function `f(x) = slope * x for x &lt; 0`,
`f(x) = x for x &gt;= 0`., is applied to the data tensor elementwise.
This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX &lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;`_.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. The shape of slope can be smaller then first input X;
  if so, its shape must be unidirectional broadcastable to X

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor (same size as X)

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to float/int tensors.

.. toctree::

    text_diff_PRelu_7_9

.. _l-onnx-op-prelu-7:

PRelu - 7
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **7**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 7**.

**Summary**

PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function `f(x) = slope * x for x &lt; 0`,
`f(x) = x for x &gt;= 0`., is applied to the data tensor elementwise.
This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX &lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;`_.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. The shape of slope can be smaller then first input X;
  if so, its shape must be unidirectional broadcastable to X

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor (same size as X)

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

.. toctree::

    text_diff_PRelu_6_7

.. _l-onnx-op-prelu-6:

PRelu - 6
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **6**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 6**.

**Summary**

PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function `f(x) = slope * x for x &lt; 0`,
`f(x) = x for x &gt;= 0`., is applied to the data tensor elementwise.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. If `Slope` is of size 1, the value is sharedacross
  different channels

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

.. toctree::

    text_diff_PRelu_1_6

.. _l-onnx-op-prelu-1:

PRelu - 1
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function `f(x) = slope * x for x &lt; 0`,
`f(x) = x for x &gt;= 0`., is applied to the data tensor elementwise.

**Attributes**

* **consumed_inputs**:
  legacy optimization attribute.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. If `Slope` is of size 1, the value is sharedacross
  different channels

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
