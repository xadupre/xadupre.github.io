
.. _l-onnx-doc-PRelu:

=====
PRelu
=====

.. contents::
    :local:


.. _l-onnx-op-prelu-16:

PRelu - 16
==========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **16**
* **function**: True
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 16**.

**Summary**

PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one
output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,
`f(x) = x for x >= 0`., is applied to the data tensor elementwise.

**History**
- Version 16 adds bfloat16 to the types allowed.
This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. The shape of slope can be smaller then first input X;
  if so, its shape must be unidirectional broadcastable to X

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor (same size as X)

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to float/int tensors.

**Examples**

**default**

::

    node = onnx.helper.make_node(
        "PRelu",
        inputs=["x", "slope"],
        outputs=["y"],
    )

    x = np.random.randn(3, 4, 5).astype(np.float32)
    slope = np.random.randn(3, 4, 5).astype(np.float32)
    y = np.clip(x, 0, np.inf) + np.clip(x, -np.inf, 0) * slope

    expect(node, inputs=[x, slope], outputs=[y], name="test_prelu_example")

**_prelu_broadcast**

::

    node = onnx.helper.make_node(
        "PRelu",
        inputs=["x", "slope"],
        outputs=["y"],
    )

    x = np.random.randn(3, 4, 5).astype(np.float32)
    slope = np.random.randn(5).astype(np.float32)
    y = np.clip(x, 0, np.inf) + np.clip(x, -np.inf, 0) * slope

    expect(node, inputs=[x, slope], outputs=[y], name="test_prelu_broadcast")

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to146__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to146__0"><a href="#difflib_chg_to146__0">f</a></td><td class="diff_header" id="from146_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to146__0">f</a></td><td class="diff_header" id="to146_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to146_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to146_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to146__1">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to146__1">n</a></td><td class="diff_header" id="to146_4">4</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_5">5</td><td nowrap="nowrap"><span class="diff_add">**History**</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_6">6</td><td nowrap="nowrap"><span class="diff_add">-&nbsp;Version&nbsp;16&nbsp;adds&nbsp;bfloat16&nbsp;to&nbsp;the&nbsp;types&nbsp;allowed.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_4">4</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td><td class="diff_next"></td><td class="diff_header" id="to146_7">7</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_8">8</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_6">6</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to146_9">9</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_10">10</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to146_11">11</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to146_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to146_13">13</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td><td class="diff_next"></td><td class="diff_header" id="to146_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td><td class="diff_next"></td><td class="diff_header" id="to146_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_16">16</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_14">14</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to146_17">17</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_18">18</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to146_19">19</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to146__1"></td><td class="diff_header" id="from146_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td><td class="diff_next"></td><td class="diff_header" id="to146_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_21">21</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to146_22">22</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_20">20</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_23">23</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_21">21</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to146_24">24</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to146__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to146__top">t</a></td><td class="diff_header" id="to146_25">25</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to146_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to146_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to146_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to146_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to146_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to146_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to146_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to146_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from146_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to146_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-prelu-9:

PRelu - 9
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **9**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 9**.

**Summary**

PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one
output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,
`f(x) = x for x >= 0`., is applied to the data tensor elementwise.
This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. The shape of slope can be smaller then first input X;
  if so, its shape must be unidirectional broadcastable to X

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor (same size as X)

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to float/int tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to147__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to147__0">f</a></td><td class="diff_header" id="from147_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to147__0">f</a></td><td class="diff_header" id="to147_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to147_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to147_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_4">4</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td><td class="diff_next"></td><td class="diff_header" id="to147_4">4</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_5">5</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_6">6</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to147_6">6</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to147_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to147_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to147_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td><td class="diff_next"></td><td class="diff_header" id="to147_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td><td class="diff_next"></td><td class="diff_header" id="to147_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_13">13</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_14">14</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to147_14">14</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_15">15</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to147_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td><td class="diff_next"></td><td class="diff_header" id="to147_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_18">18</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to147__0"></td><td class="diff_header" id="from147_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to147_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_20">20</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_20">20</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_21">21</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to147_21">21</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to147_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to147_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to147__1">n</a></td><td class="diff_header" id="from147_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"><a href="#difflib_chg_to147__1">n</a></td><td class="diff_header" id="to147_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)<span class="diff_add">,</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to147__1"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_25">25</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(int32),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_26">26</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(int64),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_27">27</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(uint32),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_28">28</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(uint64)</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from147_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to147_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to147__top">t</a></td><td class="diff_header" id="from147_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"><a href="#difflib_chg_to147__top">t</a></td><td class="diff_header" id="to147_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float<span class="diff_add">/int</span>&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-prelu-7:

PRelu - 7
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **7**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 7**.

**Summary**

PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one
output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,
`f(x) = x for x >= 0`., is applied to the data tensor elementwise.
This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. The shape of slope can be smaller then first input X;
  if so, its shape must be unidirectional broadcastable to X

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor (same size as X)

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to148__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to148__0"><a href="#difflib_chg_to148__0">f</a></td><td class="diff_header" id="from148_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to148__0">f</a></td><td class="diff_header" id="to148_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to148_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to148_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to148__1">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to148__1">n</a></td><td class="diff_header" id="to148_4">4</td><td nowrap="nowrap"><span class="diff_add">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_5">5</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to148__1"></td><td class="diff_header" id="from148_5">5</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to148_6">6</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_6">6</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_7">7</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to148_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_8">8</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to148_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_9">9</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to148_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to148__2">n</a></td><td class="diff_header" id="from148_10">10</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;If&nbsp;Slope&nbsp;is&nbsp;of&nbsp;size&nbsp;1,&nbsp;the&nbsp;value&nbsp;is&nbsp;sharedacross</span></td><td class="diff_next"><a href="#difflib_chg_to148__2">n</a></td><td class="diff_header" id="to148_11">11</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to148__2"></td><td class="diff_header" id="from148_11">11</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;different&nbsp;channels</span></td><td class="diff_next"></td><td class="diff_header" id="to148_12">12</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_12">12</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_13">13</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_13">13</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to148_14">14</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_14">14</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_15">15</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_15">15</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to148_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to148__top">t</a></td><td class="diff_header" id="from148_16">16</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Output&nbsp;tensor</span></td><td class="diff_next"><a href="#difflib_chg_to148__top">t</a></td><td class="diff_header" id="to148_17">17</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_18">18</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_18">18</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to148_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_20">20</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_20">20</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to148_21">21</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to148_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to148_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to148_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to148_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from148_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to148_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-prelu-6:

PRelu - 6
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **6**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 6**.

**Summary**

PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one
output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,
`f(x) = x for x >= 0`., is applied to the data tensor elementwise.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. If `Slope` is of size 1, the value is sharedacross
  different channels

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to149__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to149__0"><a href="#difflib_chg_to149__0">f</a></td><td class="diff_header" id="from149_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to149__0">f</a></td><td class="diff_header" id="to149_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to149_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to149_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to149__top">t</a></td><td class="diff_header" id="from149_4">4</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;</span></td><td class="diff_next"><a href="#difflib_chg_to149__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_5">5</td><td nowrap="nowrap"><span class="diff_sub">**Attributes**</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_6">6</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_7">7</td><td nowrap="nowrap"><span class="diff_sub">*&nbsp;**consumed_inputs**:</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_8">8</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;legacy&nbsp;optimization&nbsp;attribute.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_10">10</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to149_5">5</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_11">11</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_6">6</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_12">12</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to149_7">7</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to149_8">8</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_14">14</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to149_9">9</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;If&nbsp;Slope&nbsp;is&nbsp;of&nbsp;size&nbsp;1,&nbsp;the&nbsp;value&nbsp;is&nbsp;sharedacross</td><td class="diff_next"></td><td class="diff_header" id="to149_10">10</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;If&nbsp;Slope&nbsp;is&nbsp;of&nbsp;size&nbsp;1,&nbsp;the&nbsp;value&nbsp;is&nbsp;sharedacross</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;different&nbsp;channels</td><td class="diff_next"></td><td class="diff_header" id="to149_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;different&nbsp;channels</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_12">12</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_18">18</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to149_13">13</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_14">14</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_20">20</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to149_15">15</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to149_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_23">23</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to149_18">18</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_25">25</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to149_20">20</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to149_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to149_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to149_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to149_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from149_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to149_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-prelu-1:

PRelu - 1
=========

**Version**

* **name**: `PRelu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one
output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,
`f(x) = x for x >= 0`., is applied to the data tensor elementwise.

**Attributes**

* **consumed_inputs**:
  legacy optimization attribute.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor
* **slope** (heterogeneous) - **T**:
  Slope tensor. If `Slope` is of size 1, the value is sharedacross
  different channels

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
