
.. _l-onnx-doc-Softmax:

=======
Softmax
=======

.. contents::
    :local:


.. _l-onnx-op-softmax-13:
Softmax - 13
============
**Version**
* **name**: `Softmax (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Softmax>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

The operator computes the normalized exponential values for the given input:

 Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1)

The "axis" attribute indicates the dimension along which Softmax
will be performed. The output tensor has the same shape
and contains the Softmax values of the corresponding input.

**Attributes**
* **axis**:
   Describes the dimension Softmax will be performed on. Negative
  value means counting dimensions from the back. Accepted range is
  [-r, r-1] where r = rank(input).

**Inputs**

* **input** (heterogeneous) - **T**:
  The input tensor of rank >= axis.

**Outputs**

* **output** (heterogeneous) - **T**:
  The output values with the same shape as the input tensor.

**Type Constraints**
* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Examples**

**default**
::
    node = onnx.helper.make_node(
        "Softmax",
        inputs=["x"],
        outputs=["y"],
    )
    x = np.array([[-1, 0, 1]]).astype(np.float32)
    # expected output [[0.09003058, 0.24472848, 0.66524094]]
    y = softmax(x, axis=1)
    expect(node, inputs=[x], outputs=[y], name="test_softmax_example")

**_softmax_axis**
::
    x = np.array([[0, 1, 2, 3], [10000, 10001, 10002, 10003]]).astype(np.float32)
    # expected output
    # [[0.032058604 0.08714432  0.23688284  0.6439143  ]
    # [0.032058604 0.08714432  0.23688284  0.6439143  ]]
    y = softmax(x)

    node = onnx.helper.make_node(
        "Softmax",
        inputs=["x"],
        outputs=["y"],
    )
    expect(node, inputs=[x], outputs=[y], name="test_softmax_large_number")

    x = np.abs(np.random.randn(3, 4, 5).astype(np.float32))
    node = onnx.helper.make_node(
        "Softmax",
        inputs=["x"],
        outputs=["y"],
        axis=0,
    )
    y = softmax(x, axis=0)
    expect(node, inputs=[x], outputs=[y], name="test_softmax_axis_0")

    node = onnx.helper.make_node(
        "Softmax",
        inputs=["x"],
        outputs=["y"],
        axis=1,
    )
    y = softmax(x, axis=1)
    expect(node, inputs=[x], outputs=[y], name="test_softmax_axis_1")

    node = onnx.helper.make_node(
        "Softmax",
        inputs=["x"],
        outputs=["y"],
        axis=2,
    )
    y = softmax(x, axis=2)
    expect(node, inputs=[x], outputs=[y], name="test_softmax_axis_2")

    node = onnx.helper.make_node(
        "Softmax",
        inputs=["x"],
        outputs=["y"],
        axis=-1,
    )
    y = softmax(x, axis=-1)
    expect(node, inputs=[x], outputs=[y], name="test_softmax_negative_axis")

    # default axis is -1
    node = onnx.helper.make_node(
        "Softmax",
        inputs=["x"],
        outputs=["y"],
    )
    expect(node, inputs=[x], outputs=[y], name="test_softmax_default_axis")

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to215__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to215__1"><a href="#difflib_chg_to215__1">n</a></td><td class="diff_header" id="from215_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;<span class="diff_sub">softmax&nbsp;(</span>normalized&nbsp;exponential<span class="diff_sub">)</span>&nbsp;values&nbsp;for&nbsp;<span class="diff_sub">each&nbsp;layer&nbsp;in&nbsp;</span>the&nbsp;<span class="diff_chg">ba</span>t<span class="diff_chg">ch</span></td><td class="diff_next"><a href="#difflib_chg_to215__1">n</a></td><td class="diff_header" id="to215_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;normalized&nbsp;exponential&nbsp;values&nbsp;for&nbsp;the&nbsp;<span class="diff_chg">given&nbsp;inpu</span>t<span class="diff_chg">:</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to215_2">2</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to215__2">n</a></td><td class="diff_header" id="from215_4">4</td><td nowrap="nowrap"><span class="diff_sub">The&nbsp;input&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</span></td><td class="diff_next"><a href="#difflib_chg_to215__2">n</a></td><td class="diff_header" id="to215_3">3</td><td nowrap="nowrap"><span class="diff_add">&nbsp;Softmax(input,&nbsp;axis)&nbsp;=&nbsp;Exp(input)&nbsp;/&nbsp;ReduceSum(Exp(input),&nbsp;axis=axis,&nbsp;keepdims=1)</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_5">5</td><td nowrap="nowrap"><span class="diff_sub">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header" id="to215_4">4</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_6">6</td><td nowrap="nowrap"><span class="diff_sub">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</span></td><td class="diff_next"></td><td class="diff_header" id="to215_5">5</td><td nowrap="nowrap"><span class="diff_add">The&nbsp;"axis"&nbsp;attribute&nbsp;indicates&nbsp;the&nbsp;dimension&nbsp;along&nbsp;which&nbsp;Softmax</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_7">7</td><td nowrap="nowrap"><span class="diff_sub">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_8">8</td><td nowrap="nowrap"><span class="diff_sub">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_9">9</td><td nowrap="nowrap"><span class="diff_sub">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_10">10</td><td nowrap="nowrap"><span class="diff_sub">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_11">11</td><td nowrap="nowrap"><span class="diff_sub">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_12">12</td><td nowrap="nowrap"><span class="diff_sub">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to215__2"></td><td class="diff_header" id="from215_13">13</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">throw&nbsp;</span>er<span class="diff_chg">r</span>or<span class="diff_chg">s</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td><td class="diff_next"></td><td class="diff_header" id="to215_6">6</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">be&nbsp;p</span>er<span class="diff_chg">f</span>or<span class="diff_chg">med</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_14">14</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">s</span>oftmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td><td class="diff_next"></td><td class="diff_header" id="to215_7">7</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">S</span>oftmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to215_8">8</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_16">16</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to215_9">9</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_17">17</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to215_10">10</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to215__3">n</a></td><td class="diff_header" id="from215_18">18</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</span></td><td class="diff_next"><a href="#difflib_chg_to215__3">n</a></td><td class="diff_header" id="to215_11">11</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;&nbsp;Describes&nbsp;the&nbsp;dimension&nbsp;Softmax&nbsp;will&nbsp;be&nbsp;performed&nbsp;on.&nbsp;Negative</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_19">19</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size.&nbsp;Negative</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to215_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to215__3"></td><td class="diff_header" id="from215_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td><td class="diff_next"></td><td class="diff_header" id="to215_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to215_14">14</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_23">23</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to215_15">15</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to215_16">16</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_25">25</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to215_17">17</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to215__4">n</a></td><td class="diff_header" id="from215_26">26</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</span></td><td class="diff_next"><a href="#difflib_chg_to215__4">n</a></td><td class="diff_header" id="to215_18">18</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;of&nbsp;rank&nbsp;&gt;=&nbsp;axis.</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to215__4"></td><td class="diff_header" id="from215_27">27</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;described&nbsp;above.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_28">28</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to215_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_29">29</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to215_20">20</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_30">30</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to215_21">21</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_31">31</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to215_22">22</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to215__5"><a href="#difflib_chg_to215__5">n</a></td><td class="diff_header" id="from215_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor<span class="diff_chg">&nbsp;(the&nbsp;original</span></td><td class="diff_next"><a href="#difflib_chg_to215__5">n</a></td><td class="diff_header" id="to215_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as<span class="diff_add">&nbsp;the</span>&nbsp;input&nbsp;tensor<span class="diff_chg">.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_33">33</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_34">34</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to215_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_35">35</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to215_25">25</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_36">36</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to215_26">26</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to215__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to215__top">t</a></td><td class="diff_header" id="to215_27">27</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to215_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to215_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to215_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to215_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from215_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to215_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-softmax-11:
Softmax - 11
============
**Version**
* **name**: `Softmax (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Softmax>`_
* **domain**: **main**
* **since_version**: **11**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 11**.

**Summary**

The operator computes the softmax (normalized exponential) values for each layer in the batch
 of the given input.

The input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input \in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * ... * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * ... * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors. The output tensor has the same shape
and contains the softmax values of the corresponding input.

**Attributes**
* **axis**:
  Describes the axis of the inputs when coerced to 2D; defaults to one
  because the 0th axis most likely describes the batch_size. Negative
  value means counting dimensions from the back. Accepted range is
  [-r, r-1] where r = rank(input).

**Inputs**

* **input** (heterogeneous) - **T**:
  The input tensor that's coerced into a 2D matrix of size (NxD) as
  described above.

**Outputs**

* **output** (heterogeneous) - **T**:
  The output values with the same shape as input tensor (the original
  size without coercion).

**Type Constraints**
* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to216__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to216__1"><a href="#difflib_chg_to216__0">f</a></td><td class="diff_header" id="from216_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;softmax&nbsp;(normalized&nbsp;exponential)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td><td class="diff_next"><a href="#difflib_chg_to216__0">f</a></td><td class="diff_header" id="to216_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;softmax&nbsp;(normalized&nbsp;exponential)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to216__1">n</a></td><td class="diff_header" id="from216_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.&nbsp;The&nbsp;input&nbsp;is&nbsp;a&nbsp;2-D&nbsp;tensor&nbsp;(Tensor&lt;float&gt;)&nbsp;of&nbsp;size</span></td><td class="diff_next"><a href="#difflib_chg_to216__1">n</a></td><td class="diff_header" id="to216_2">2</td><td nowrap="nowrap"><span class="diff_add">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_3">3</td><td nowrap="nowrap"><span class="diff_sub">(batch_size&nbsp;x&nbsp;input_feature_dimensions).&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_4">4</td><td nowrap="nowrap"><span class="diff_sub">and&nbsp;contains&nbsp;the&nbsp;softmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_3">3</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to216__2">n</a></td><td class="diff_header" id="from216_6">6</td><td nowrap="nowrap"><span class="diff_chg">I</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td><td class="diff_next"><a href="#difflib_chg_to216__2">n</a></td><td class="diff_header" id="to216_4">4</td><td nowrap="nowrap"><span class="diff_chg">The&nbsp;i</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_7">7</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to216_5">5</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_8">8</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to216_6">6</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_9">9</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td><td class="diff_next"></td><td class="diff_header" id="to216_7">7</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to216__2"></td><td class="diff_header" id="from216_10">10</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td><td class="diff_next"></td><td class="diff_header" id="to216_8">8</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_11">11</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to216_9">9</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_12">12</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td><td class="diff_next"></td><td class="diff_header" id="to216_10">10</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_13">13</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td><td class="diff_next"></td><td class="diff_header" id="to216_11">11</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_14">14</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td><td class="diff_next"></td><td class="diff_header" id="to216_12">12</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to216__3">n</a></td><td class="diff_header" id="from216_15">15</td><td nowrap="nowrap"><span class="diff_sub">will&nbsp;throw&nbsp;errors.</span></td><td class="diff_next"><a href="#difflib_chg_to216__3">n</a></td><td class="diff_header" id="to216_13">13</td><td nowrap="nowrap"><span class="diff_add">will&nbsp;throw&nbsp;errors.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to216__3"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_14">14</td><td nowrap="nowrap"><span class="diff_add">and&nbsp;contains&nbsp;the&nbsp;softmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_15">15</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_17">17</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to216_16">16</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_18">18</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to216_17">17</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td><td class="diff_next"></td><td class="diff_header" id="to216_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to216__top">t</a></td><td class="diff_header" id="from216_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size</td><td class="diff_next"><a href="#difflib_chg_to216__top">t</a></td><td class="diff_header" id="to216_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size<span class="diff_add">.&nbsp;Negative</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_20">20</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_21">21</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_22">22</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to216_23">23</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_24">24</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to216_25">25</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td><td class="diff_next"></td><td class="diff_header" id="to216_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td><td class="diff_next"></td><td class="diff_header" id="to216_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_28">28</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_28">28</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to216_29">29</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_30">30</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_30">30</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to216_31">31</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td><td class="diff_next"></td><td class="diff_header" id="to216_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td><td class="diff_next"></td><td class="diff_header" id="to216_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to216_34">34</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_34">34</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to216_35">35</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_35">35</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to216_36">36</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to216_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to216_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to216_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to216_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from216_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to216_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-softmax-1:
Softmax - 1
===========
**Version**
* **name**: `Softmax (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Softmax>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 1**.

**Summary**

The operator computes the softmax (normalized exponential) values for each layer in the batch
 of the given input. The input is a 2-D tensor (Tensor<float>) of size
(batch_size x input_feature_dimensions). The output tensor has the same shape
and contains the softmax values of the corresponding input.

Input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input \in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * ... * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * ... * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors.

**Attributes**
* **axis**:
  Describes the axis of the inputs when coerced to 2D; defaults to one
  because the 0th axis most likely describes the batch_size

**Inputs**

* **input** (heterogeneous) - **T**:
  The input tensor that's coerced into a 2D matrix of size (NxD) as
  described above.

**Outputs**

* **output** (heterogeneous) - **T**:
  The output values with the same shape as input tensor (the original
  size without coercion).

**Type Constraints**
* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
