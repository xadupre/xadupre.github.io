
.. _l-onnx-doc-ReduceLogSumExp:

===============
ReduceLogSumExp
===============

.. contents::
    :local:


.. _l-onnx-op-reducelogsumexp-13:

ReduceLogSumExp - 13
====================

**Version**

* **name**: `ReduceLogSumExp (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceLogSumExp>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

Computes the log sum exponent of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then
the resulting tensor has the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor. Accepted range is [-r,
  r-1] where r = rank(data).
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

**Examples**

**_do_not_keepdims**

::

    shape = [3, 2, 2]
    axes = [1]
    keepdims = 0
    node = onnx.helper.make_node(
        "ReduceLogSumExp",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.array(
        [[[5, 1], [20, 2]], [[30, 1], [40, 2]], [[55, 1], [60, 2]]], dtype=np.double
    )
    reduced = np.log(np.sum(np.exp(data), axis=tuple(axes), keepdims=keepdims == 1))
    # print(reduced)
    # [[20., 2.31326175]
    # [40.00004578, 2.31326175]
    # [60.00671387, 2.31326175]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_do_not_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.double)
    reduced = np.log(np.sum(np.exp(data), axis=tuple(axes), keepdims=keepdims == 1))

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_do_not_keepdims_random",
    )

**_keepdims**

::

    shape = [3, 2, 2]
    axes = [1]
    keepdims = 1
    node = onnx.helper.make_node(
        "ReduceLogSumExp",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.array(
        [[[5, 1], [20, 2]], [[30, 1], [40, 2]], [[55, 1], [60, 2]]], dtype=np.double
    )
    reduced = np.log(np.sum(np.exp(data), axis=tuple(axes), keepdims=keepdims == 1))
    # print(reduced)
    # [[[20., 2.31326175]]
    # [[40.00004578, 2.31326175]]
    # [[60.00671387, 2.31326175]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.double)
    reduced = np.log(np.sum(np.exp(data), axis=tuple(axes), keepdims=keepdims == 1))

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_keepdims_random",
    )

**_default_axes_keepdims**

::

    shape = [3, 2, 2]
    axes = None
    keepdims = 1

    node = onnx.helper.make_node(
        "ReduceLogSumExp", inputs=["data"], outputs=["reduced"], keepdims=keepdims
    )

    data = np.array(
        [[[5, 1], [20, 2]], [[30, 1], [40, 2]], [[55, 1], [60, 2]]], dtype=np.double
    )
    reduced = np.log(np.sum(np.exp(data), axis=axes, keepdims=keepdims == 1))
    # print(reduced)
    # [[[60.00671387]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_default_axes_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.double)
    reduced = np.log(np.sum(np.exp(data), axis=axes, keepdims=keepdims == 1))
    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_default_axes_keepdims_random",
    )

**_negative_axes_keepdims**

::

    shape = [3, 2, 2]
    axes = [-2]
    keepdims = 1
    node = onnx.helper.make_node(
        "ReduceLogSumExp",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.array(
        [[[5, 1], [20, 2]], [[30, 1], [40, 2]], [[55, 1], [60, 2]]], dtype=np.double
    )
    reduced = np.log(np.sum(np.exp(data), axis=tuple(axes), keepdims=keepdims == 1))
    # print(reduced)
    # [[[20., 2.31326175]]
    # [[40.00004578, 2.31326175]]
    # [[60.00671387, 2.31326175]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_negative_axes_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.double)
    reduced = np.log(np.sum(np.exp(data), axis=tuple(axes), keepdims=keepdims == 1))

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_log_sum_exp_negative_axes_keepdims_random",
    )

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to169__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to169__0"><a href="#difflib_chg_to169__0">f</a></td><td class="diff_header" id="from169_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;log&nbsp;sum&nbsp;exponent&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td><td class="diff_next"><a href="#difflib_chg_to169__0">f</a></td><td class="diff_header" id="to169_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;log&nbsp;sum&nbsp;exponent&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to169__1">n</a></td><td class="diff_header" id="from169_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td><td class="diff_next"><a href="#difflib_chg_to169__1">n</a></td><td class="diff_header" id="to169_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal<span class="diff_add">s</span>&nbsp;0,&nbsp;then</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_3">3</td><td nowrap="nowrap">the&nbsp;result<span class="diff_chg">ed</span>&nbsp;tensor&nbsp;ha<span class="diff_chg">ve</span>&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td><td class="diff_next"></td><td class="diff_header" id="to169_3">3</td><td nowrap="nowrap">the&nbsp;result<span class="diff_chg">ing</span>&nbsp;tensor&nbsp;ha<span class="diff_chg">s</span>&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to169_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td><td class="diff_next"></td><td class="diff_header" id="to169_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_8">8</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to169_8">8</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td><td class="diff_next"></td><td class="diff_header" id="to169_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td><td class="diff_next"></td><td class="diff_header" id="to169_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</td><td class="diff_next"></td><td class="diff_header" id="to169_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</td><td class="diff_next"></td><td class="diff_header" id="to169_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td><td class="diff_next"></td><td class="diff_header" id="to169_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td><td class="diff_next"></td><td class="diff_header" id="to169_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td><td class="diff_next"></td><td class="diff_header" id="to169_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_18">18</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to169_18">18</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to169_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to169_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_23">23</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to169_23">23</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to169_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to169__1"></td><td class="diff_header" id="from169_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to169_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to169_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to169_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to169_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to169__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to169__top">t</a></td><td class="diff_header" id="to169_31">31</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to169_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to169_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to169_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to169_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to169_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to169_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to169_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to169_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from169_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to169_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-reducelogsumexp-11:

ReduceLogSumExp - 11
====================

**Version**

* **name**: `ReduceLogSumExp (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceLogSumExp>`_
* **domain**: **main**
* **since_version**: **11**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 11**.

**Summary**

Computes the log sum exponent of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equal 0, then
the resulted tensor have the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor. Accepted range is [-r,
  r-1] where r = rank(data).
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to170__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to170__0">f</a></td><td class="diff_header" id="from170_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;log&nbsp;sum&nbsp;exponent&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td><td class="diff_next"><a href="#difflib_chg_to170__0">f</a></td><td class="diff_header" id="to170_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;log&nbsp;sum&nbsp;exponent&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td><td class="diff_next"></td><td class="diff_header" id="to170_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_3">3</td><td nowrap="nowrap">the&nbsp;resulted&nbsp;tensor&nbsp;have&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td><td class="diff_next"></td><td class="diff_header" id="to170_3">3</td><td nowrap="nowrap">the&nbsp;resulted&nbsp;tensor&nbsp;have&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to170_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td><td class="diff_next"></td><td class="diff_header" id="to170_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to170__0"></td><td class="diff_header" id="from170_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_8">8</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to170_8">8</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td><td class="diff_next"></td><td class="diff_header" id="to170_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td><td class="diff_next"></td><td class="diff_header" id="to170_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to170__top">t</a></td><td class="diff_header" id="from170_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.</td><td class="diff_next"><a href="#difflib_chg_to170__top">t</a></td><td class="diff_header" id="to170_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.<span class="diff_add">&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_13">13</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_13">13</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td><td class="diff_next"></td><td class="diff_header" id="to170_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td><td class="diff_next"></td><td class="diff_header" id="to170_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td><td class="diff_next"></td><td class="diff_header" id="to170_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_17">17</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to170_18">18</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_19">19</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to170_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to170_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_22">22</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to170_23">23</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_24">24</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to170_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to170_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_26">26</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_27">27</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to170_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_28">28</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to170_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_29">29</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to170_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to170_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to170_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to170_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to170_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to170_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to170_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to170_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to170_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from170_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to170_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-reducelogsumexp-1:

ReduceLogSumExp - 1
===================

**Version**

* **name**: `ReduceLogSumExp (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceLogSumExp>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 1**.

**Summary**

Computes the log sum exponent of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equal 0, then
the resulted tensor have the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor.
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.
