
.. _l-onnx-doc-Selu:

====
Selu
====

.. contents::
    :local:


.. _l-onnx-op-selu-6:

Selu - 6
========

**Version**

* **name**: `Selu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Selu>`_
* **domain**: **main**
* **since_version**: **6**
* **function**: True
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 6**.

**Summary**

Selu takes one input data (Tensor<T>) and produces one output data
(Tensor<T>) where the scaled exponential linear unit function,
`y = gamma * (alpha * e^x - alpha) for x <= 0`, `y = gamma * x for x > 0`,
is applied to the tensor elementwise.

**Attributes**

* **alpha**:
  Coefficient of SELU default to 1.67326319217681884765625 (i.e.,
  float32 approximation of 1.6732632423543772848170429916717).
* **gamma**:
  Coefficient of SELU default to 1.05070102214813232421875 (i.e.,
  float32 approximation of 1.0507009873554804934193349852946).

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Examples**

**default**

::

    node = onnx.helper.make_node(
        "Selu", inputs=["x"], outputs=["y"], alpha=2.0, gamma=3.0
    )

    x = np.array([-1, 0, 1]).astype(np.float32)
    # expected output [-3.79272318, 0., 3.]
    y = (
        np.clip(x, 0, np.inf) * 3.0
        + (np.exp(np.clip(x, -np.inf, 0)) - 1) * 2.0 * 3.0
    )
    expect(node, inputs=[x], outputs=[y], name="test_selu_example")

    x = np.random.randn(3, 4, 5).astype(np.float32)
    y = (
        np.clip(x, 0, np.inf) * 3.0
        + (np.exp(np.clip(x, -np.inf, 0)) - 1) * 2.0 * 3.0
    )
    expect(node, inputs=[x], outputs=[y], name="test_selu")

**_selu_default**

::

    default_alpha = 1.67326319217681884765625
    default_gamma = 1.05070102214813232421875
    node = onnx.helper.make_node(
        "Selu",
        inputs=["x"],
        outputs=["y"],
    )
    x = np.random.randn(3, 4, 5).astype(np.float32)
    y = (
        np.clip(x, 0, np.inf) * default_gamma
        + (np.exp(np.clip(x, -np.inf, 0)) - 1) * default_alpha * default_gamma
    )
    expect(node, inputs=[x], outputs=[y], name="test_selu_default")

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to205__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to205__0">f</a></td><td class="diff_header" id="from205_1">1</td><td nowrap="nowrap">Selu&nbsp;takes&nbsp;one&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;produces&nbsp;one&nbsp;output&nbsp;data</td><td class="diff_next"><a href="#difflib_chg_to205__0">f</a></td><td class="diff_header" id="to205_1">1</td><td nowrap="nowrap">Selu&nbsp;takes&nbsp;one&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;produces&nbsp;one&nbsp;output&nbsp;data</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_2">2</td><td nowrap="nowrap">(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;scaled&nbsp;exponential&nbsp;linear&nbsp;unit&nbsp;function,</td><td class="diff_next"></td><td class="diff_header" id="to205_2">2</td><td nowrap="nowrap">(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;scaled&nbsp;exponential&nbsp;linear&nbsp;unit&nbsp;function,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_3">3</td><td nowrap="nowrap">y&nbsp;=&nbsp;gamma&nbsp;*&nbsp;(alpha&nbsp;*&nbsp;e^x&nbsp;-&nbsp;alpha)&nbsp;for&nbsp;x&nbsp;&lt;=&nbsp;0,&nbsp;y&nbsp;=&nbsp;gamma&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to205_3">3</td><td nowrap="nowrap">y&nbsp;=&nbsp;gamma&nbsp;*&nbsp;(alpha&nbsp;*&nbsp;e^x&nbsp;-&nbsp;alpha)&nbsp;for&nbsp;x&nbsp;&lt;=&nbsp;0,&nbsp;y&nbsp;=&nbsp;gamma&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;&nbsp;0,</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to205__0"></td><td class="diff_header" id="from205_4">4</td><td nowrap="nowrap">is&nbsp;applied&nbsp;to&nbsp;the&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to205_4">4</td><td nowrap="nowrap">is&nbsp;applied&nbsp;to&nbsp;the&nbsp;tensor&nbsp;elementwise.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_5">5</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_6">6</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to205_6">6</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to205__1"></td><td class="diff_header" id="from205_8">8</td><td nowrap="nowrap">*&nbsp;**alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to205_8">8</td><td nowrap="nowrap">*&nbsp;**alpha**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to205__1">n</a></td><td class="diff_header" id="from205_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Coefficient&nbsp;of&nbsp;SELU&nbsp;default&nbsp;to&nbsp;1.6732.</td><td class="diff_next"><a href="#difflib_chg_to205__1">n</a></td><td class="diff_header" id="to205_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Coefficient&nbsp;of&nbsp;SELU&nbsp;default&nbsp;to&nbsp;1.6732<span class="diff_add">6319217681884765625&nbsp;(i</span>.<span class="diff_add">e.,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_10">10</td><td nowrap="nowrap"><span class="diff_sub">*&nbsp;**consumed_inputs**:</span></td><td class="diff_next"></td><td class="diff_header" id="to205_10">10</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;float32&nbsp;approximation&nbsp;of&nbsp;1.6732632423543772848170429916717).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_11">11</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;legacy&nbsp;optimization&nbsp;attribute.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_12">12</td><td nowrap="nowrap">*&nbsp;**gamma**:</td><td class="diff_next"></td><td class="diff_header" id="to205_11">11</td><td nowrap="nowrap">*&nbsp;**gamma**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to205__top">t</a></td><td class="diff_header" id="from205_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;Coefficient&nbsp;of&nbsp;SELU&nbsp;default&nbsp;to&nbsp;1.0507.</td><td class="diff_next"><a href="#difflib_chg_to205__top">t</a></td><td class="diff_header" id="to205_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Coefficient&nbsp;of&nbsp;SELU&nbsp;default&nbsp;to&nbsp;1.0507<span class="diff_add">0102214813232421875&nbsp;(i</span>.<span class="diff_add">e.,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_13">13</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;float32&nbsp;approximation&nbsp;of&nbsp;1.0507009873554804934193349852946).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_14">14</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_14">14</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_15">15</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to205_15">15</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_16">16</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_17">17</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to205_17">17</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to205_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_20">20</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to205_20">20</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_21">21</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_22">22</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to205_22">22</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to205_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_25">25</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to205_25">25</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_26">26</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to205_26">26</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_27">27</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to205_27">27</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to205_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to205_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to205_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to205_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from205_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to205_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-selu-1:

Selu - 1
========

**Version**

* **name**: `Selu (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Selu>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

Selu takes one input data (Tensor<T>) and produces one output data
(Tensor<T>) where the scaled exponential linear unit function,
`y = gamma * (alpha * e^x - alpha) for x <= 0`, `y = gamma * x for x > 0`,
is applied to the tensor elementwise.

**Attributes**

* **alpha**:
  Coefficient of SELU default to 1.6732.
* **consumed_inputs**:
  legacy optimization attribute.
* **gamma**:
  Coefficient of SELU default to 1.0507.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
