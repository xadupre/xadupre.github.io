
.. _l-onnx-doc-ReduceSumSquare:

===============
ReduceSumSquare
===============

.. contents::
    :local:


.. _l-onnx-op-reducesumsquare-13:

ReduceSumSquare - 13
====================

**Version**

* **name**: `ReduceSumSquare (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceSumSquare>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

Computes the sum square of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then
the resulting tensor has the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor. Accepted range is [-r,
  r-1] where r = rank(data).
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

**Examples**

**_do_not_keepdims**

::

    shape = [3, 2, 2]
    axes = [1]
    keepdims = 0

    node = onnx.helper.make_node(
        "ReduceSumSquare",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.array(
        [[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]], dtype=np.float32
    )
    reduced = np.sum(np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    # print(reduced)
    # [[10., 20.]
    # [74., 100.]
    # [202., 244.]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_do_not_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sum(np.square(data), axis=tuple(axes), keepdims=keepdims == 1)

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_do_not_keepdims_random",
    )

**_keepdims**

::

    shape = [3, 2, 2]
    axes = [1]
    keepdims = 1

    node = onnx.helper.make_node(
        "ReduceSumSquare",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.array(
        [[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]], dtype=np.float32
    )
    reduced = np.sum(np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    # print(reduced)
    # [[[10., 20.]]
    # [[74., 100.]]
    # [[202., 244.]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sum(np.square(data), axis=tuple(axes), keepdims=keepdims == 1)

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_keepdims_random",
    )

**_default_axes_keepdims**

::

    shape = [3, 2, 2]
    axes = None
    keepdims = 1

    node = onnx.helper.make_node(
        "ReduceSumSquare", inputs=["data"], outputs=["reduced"], keepdims=keepdims
    )

    data = np.array(
        [[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]], dtype=np.float32
    )
    reduced = np.sum(np.square(data), axis=axes, keepdims=keepdims == 1)
    # print(reduced)
    # [[[650.]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_default_axes_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sum(np.square(data), axis=axes, keepdims=keepdims == 1)

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_default_axes_keepdims_random",
    )

**_negative_axes_keepdims**

::

    shape = [3, 2, 2]
    axes = [-2]
    keepdims = 1

    node = onnx.helper.make_node(
        "ReduceSumSquare",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.array(
        [[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]], dtype=np.float32
    )
    reduced = np.sum(np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    # print(reduced)
    # [[[10., 20.s]]
    # [[74., 100.]]
    # [[202., 244.]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_negative_axes_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sum(np.square(data), axis=tuple(axes), keepdims=keepdims == 1)

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_sum_square_negative_axes_keepdims_random",
    )

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to183__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to183__0"><a href="#difflib_chg_to183__0">f</a></td><td class="diff_header" id="from183_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;sum&nbsp;square&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td><td class="diff_next"><a href="#difflib_chg_to183__0">f</a></td><td class="diff_header" id="to183_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;sum&nbsp;square&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to183__1">n</a></td><td class="diff_header" id="from183_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td><td class="diff_next"><a href="#difflib_chg_to183__1">n</a></td><td class="diff_header" id="to183_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal<span class="diff_add">s</span>&nbsp;0,&nbsp;then</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_3">3</td><td nowrap="nowrap">the&nbsp;result<span class="diff_chg">ed</span>&nbsp;tensor&nbsp;ha<span class="diff_chg">ve</span>&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td><td class="diff_next"></td><td class="diff_header" id="to183_3">3</td><td nowrap="nowrap">the&nbsp;result<span class="diff_chg">ing</span>&nbsp;tensor&nbsp;ha<span class="diff_chg">s</span>&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to183_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td><td class="diff_next"></td><td class="diff_header" id="to183_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_8">8</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to183_8">8</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td><td class="diff_next"></td><td class="diff_header" id="to183_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td><td class="diff_next"></td><td class="diff_header" id="to183_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</td><td class="diff_next"></td><td class="diff_header" id="to183_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</td><td class="diff_next"></td><td class="diff_header" id="to183_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td><td class="diff_next"></td><td class="diff_header" id="to183_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td><td class="diff_next"></td><td class="diff_header" id="to183_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td><td class="diff_next"></td><td class="diff_header" id="to183_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_18">18</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to183_18">18</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to183_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to183_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_23">23</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to183_23">23</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to183_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to183__1"></td><td class="diff_header" id="from183_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to183_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to183_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to183_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to183_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to183__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to183__top">t</a></td><td class="diff_header" id="to183_31">31</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to183_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to183_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to183_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to183_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to183_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to183_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to183_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to183_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from183_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to183_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-reducesumsquare-11:

ReduceSumSquare - 11
====================

**Version**

* **name**: `ReduceSumSquare (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceSumSquare>`_
* **domain**: **main**
* **since_version**: **11**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 11**.

**Summary**

Computes the sum square of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equal 0, then
the resulted tensor have the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor. Accepted range is [-r,
  r-1] where r = rank(data).
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to184__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to184__0">f</a></td><td class="diff_header" id="from184_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;sum&nbsp;square&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td><td class="diff_next"><a href="#difflib_chg_to184__0">f</a></td><td class="diff_header" id="to184_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;sum&nbsp;square&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td><td class="diff_next"></td><td class="diff_header" id="to184_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_3">3</td><td nowrap="nowrap">the&nbsp;resulted&nbsp;tensor&nbsp;have&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td><td class="diff_next"></td><td class="diff_header" id="to184_3">3</td><td nowrap="nowrap">the&nbsp;resulted&nbsp;tensor&nbsp;have&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to184_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td><td class="diff_next"></td><td class="diff_header" id="to184_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to184__0"></td><td class="diff_header" id="from184_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_8">8</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to184_8">8</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td><td class="diff_next"></td><td class="diff_header" id="to184_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td><td class="diff_next"></td><td class="diff_header" id="to184_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to184__top">t</a></td><td class="diff_header" id="from184_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.</td><td class="diff_next"><a href="#difflib_chg_to184__top">t</a></td><td class="diff_header" id="to184_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.<span class="diff_add">&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_13">13</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_13">13</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td><td class="diff_next"></td><td class="diff_header" id="to184_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td><td class="diff_next"></td><td class="diff_header" id="to184_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td><td class="diff_next"></td><td class="diff_header" id="to184_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_17">17</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to184_18">18</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_19">19</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to184_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to184_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_22">22</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to184_23">23</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_24">24</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to184_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to184_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_26">26</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_27">27</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to184_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_28">28</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to184_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_29">29</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to184_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to184_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to184_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to184_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to184_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to184_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to184_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to184_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to184_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from184_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to184_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-reducesumsquare-1:

ReduceSumSquare - 1
===================

**Version**

* **name**: `ReduceSumSquare (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceSumSquare>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 1**.

**Summary**

Computes the sum square of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equal 0, then
the resulted tensor have the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor.
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.
