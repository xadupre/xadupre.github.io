
.. _l-onnx-doc-GlobalLpPool:

============
GlobalLpPool
============

.. contents::
    :local:


.. _l-onnx-op-globallppool-2:
GlobalLpPool - 2
================
**Version**
* **name**: `GlobalLpPool (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#GlobalLpPool>`_
* **domain**: **main**
* **since_version**: **2**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 2**.

**Summary**

GlobalLpPool consumes an input tensor X and applies lp pool pooling across
the values in the same channel. This is equivalent to LpPool with kernel size
equal to the spatial dimension of input tensor.

**Attributes**
* **p**:
  p value of the Lp norm used to pool over the input data.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input data tensor from the previous operator; dimensions for image
  case are (N x C x H x W), where N is the batch size, C is the number
  of channels, and H and W are the height and the width of the data.
  For non image case, the dimensions are in the form of (N x C x D1 x
  D2 ... Dn), where N is the batch size.

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output data tensor from pooling across the input tensor. The output
  tensor has the same rank as the input. The first two dimensions of
  output shape are the same as the input (N x C), while the other
  dimensions are all 1.

**Type Constraints**
* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Examples**

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to79__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to79__0"><a href="#difflib_chg_to79__1">n</a></td><td class="diff_header" id="from79_1">1</td><td nowrap="nowrap">GlobalLpPool&nbsp;consumes&nbsp;an&nbsp;input&nbsp;tensor&nbsp;X&nbsp;and&nbsp;applies&nbsp;lp&nbsp;pool&nbsp;pooling&nbsp;across<span class="diff_sub">&nbsp;the</span></td><td class="diff_next"><a href="#difflib_chg_to79__1">n</a></td><td class="diff_header" id="to79_1">1</td><td nowrap="nowrap">GlobalLpPool&nbsp;consumes&nbsp;an&nbsp;input&nbsp;tensor&nbsp;X&nbsp;and&nbsp;applies&nbsp;lp&nbsp;pool&nbsp;pooling&nbsp;across</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to79__1"></td><td class="diff_header" id="from79_2">2</td><td nowrap="nowrap">the&nbsp;values&nbsp;in&nbsp;the&nbsp;same&nbsp;channel.&nbsp;This&nbsp;is&nbsp;equivalent&nbsp;to&nbsp;LpPool&nbsp;with&nbsp;kernel&nbsp;size</td><td class="diff_next"></td><td class="diff_header" id="to79_2">2</td><td nowrap="nowrap">the&nbsp;values&nbsp;in&nbsp;the&nbsp;same&nbsp;channel.&nbsp;This&nbsp;is&nbsp;equivalent&nbsp;to&nbsp;LpPool&nbsp;with&nbsp;kernel&nbsp;size</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_3">3</td><td nowrap="nowrap">equal&nbsp;to&nbsp;the&nbsp;spatial&nbsp;dimension&nbsp;of&nbsp;input&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to79_3">3</td><td nowrap="nowrap">equal&nbsp;to&nbsp;the&nbsp;spatial&nbsp;dimension&nbsp;of&nbsp;input&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_5">5</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to79_5">5</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_6">6</td><td nowrap="nowrap">*&nbsp;**p**:</td><td class="diff_next"></td><td class="diff_header" id="to79_6">6</td><td nowrap="nowrap">*&nbsp;**p**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to79__2">n</a></td><td class="diff_header" id="from79_7">7</td><td nowrap="nowrap">&nbsp;&nbsp;p&nbsp;value&nbsp;of&nbsp;the&nbsp;Lp&nbsp;norm&nbsp;used&nbsp;to&nbsp;pool&nbsp;over&nbsp;the&nbsp;input&nbsp;data<span class="diff_chg">,&nbsp;default&nbsp;is</span></td><td class="diff_next"><a href="#difflib_chg_to79__2">n</a></td><td class="diff_header" id="to79_7">7</td><td nowrap="nowrap">&nbsp;&nbsp;p&nbsp;value&nbsp;of&nbsp;the&nbsp;Lp&nbsp;norm&nbsp;used&nbsp;to&nbsp;pool&nbsp;over&nbsp;the&nbsp;input&nbsp;data<span class="diff_chg">.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_8">8</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;2.0.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_8">8</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_10">10</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to79_9">9</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to79__2"></td><td class="diff_header" id="from79_11">11</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_10">10</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_12">12</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to79_11">11</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;data&nbsp;tensor&nbsp;from&nbsp;the&nbsp;previous&nbsp;operator;&nbsp;dimensions&nbsp;for&nbsp;image</td><td class="diff_next"></td><td class="diff_header" id="to79_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;data&nbsp;tensor&nbsp;from&nbsp;the&nbsp;previous&nbsp;operator;&nbsp;dimensions&nbsp;for&nbsp;image</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;case&nbsp;are&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;H&nbsp;x&nbsp;W),&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size,&nbsp;C&nbsp;is&nbsp;the&nbsp;number</td><td class="diff_next"></td><td class="diff_header" id="to79_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;case&nbsp;are&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;H&nbsp;x&nbsp;W),&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size,&nbsp;C&nbsp;is&nbsp;the&nbsp;number</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;of&nbsp;channels,&nbsp;and&nbsp;H&nbsp;and&nbsp;W&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;the&nbsp;width&nbsp;of&nbsp;the&nbsp;data.</td><td class="diff_next"></td><td class="diff_header" id="to79_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;of&nbsp;channels,&nbsp;and&nbsp;H&nbsp;and&nbsp;W&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;the&nbsp;width&nbsp;of&nbsp;the&nbsp;data.</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to79__3">n</a></td><td class="diff_header" id="from79_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;For&nbsp;non&nbsp;image&nbsp;case,&nbsp;the&nbsp;dimension&nbsp;are&nbsp;in&nbsp;the&nbsp;form&nbsp;of&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;D1&nbsp;x</td><td class="diff_next"><a href="#difflib_chg_to79__3">n</a></td><td class="diff_header" id="to79_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;For&nbsp;non&nbsp;image&nbsp;case,&nbsp;the&nbsp;dimension<span class="diff_add">s</span>&nbsp;are&nbsp;in&nbsp;the&nbsp;form&nbsp;of&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;D1&nbsp;x</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to79__3"></td><td class="diff_header" id="from79_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;D2&nbsp;...&nbsp;Dn),&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size.</td><td class="diff_next"></td><td class="diff_header" id="to79_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;D2&nbsp;...&nbsp;Dn),&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_19">19</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to79_18">18</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_20">20</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_21">21</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to79_20">20</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to79__top">t</a></td><td class="diff_header" id="from79_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;data&nbsp;tensor&nbsp;from&nbsp;pooling&nbsp;across&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;<span class="diff_chg">Dim</span>e<span class="diff_chg">nsi</span>o<span class="diff_chg">ns</span></td><td class="diff_next"><a href="#difflib_chg_to79__top">t</a></td><td class="diff_header" id="to79_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;data&nbsp;tensor&nbsp;from&nbsp;pooling&nbsp;across&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;<span class="diff_chg">Th</span>e<span class="diff_chg">&nbsp;</span>o<span class="diff_chg">utput</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_23">23</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;will&nbsp;be&nbsp;N&nbsp;x&nbsp;C&nbsp;x&nbsp;1&nbsp;x&nbsp;1</span></td><td class="diff_next"></td><td class="diff_header" id="to79_22">22</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input.&nbsp;The&nbsp;first&nbsp;two&nbsp;dimensions&nbsp;of</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_23">23</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;output&nbsp;shape&nbsp;are&nbsp;the&nbsp;same&nbsp;as&nbsp;the&nbsp;input&nbsp;(N&nbsp;x&nbsp;C),&nbsp;while&nbsp;the&nbsp;other</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_24">24</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;dimensions&nbsp;are&nbsp;all&nbsp;1.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to79_25">25</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_25">25</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to79_26">26</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_26">26</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to79_27">27</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to79_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to79_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to79_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to79_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from79_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to79_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-globallppool-1:
GlobalLpPool - 1
================
**Version**
* **name**: `GlobalLpPool (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#GlobalLpPool>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

GlobalLpPool consumes an input tensor X and applies lp pool pooling across the
the values in the same channel. This is equivalent to LpPool with kernel size
equal to the spatial dimension of input tensor.

**Attributes**
* **p**:
  p value of the Lp norm used to pool over the input data, default is
  2.0.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input data tensor from the previous operator; dimensions for image
  case are (N x C x H x W), where N is the batch size, C is the number
  of channels, and H and W are the height and the width of the data.
  For non image case, the dimension are in the form of (N x C x D1 x
  D2 ... Dn), where N is the batch size.

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output data tensor from pooling across the input tensor. Dimensions
  will be N x C x 1 x 1

**Type Constraints**
* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
