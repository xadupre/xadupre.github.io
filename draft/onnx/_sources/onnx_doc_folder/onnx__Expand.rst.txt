
.. _l-onnx-doc-Expand:

======
Expand
======

.. contents::
    :local:


.. _l-onnx-op-expand-13:

Expand - 13
===========

**Version**

* **name**: `Expand (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Expand>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

Broadcast the input tensor following the given shape and the broadcast rule.
The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):
Dimensions are right alignment;
Two corresponding dimensions must have the same value, or one of them is equal to 1.
Also, this operator is similar to numpy.broadcast_to(input, shape),
but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().
It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,
or the shape.ndim &lt; input.shape.ndim.

**Inputs**

* **input** (heterogeneous) - **T**:
  Input tensor
* **shape** (heterogeneous) - **tensor(int64)**:
  A 1-D tensor indicates the shape you want to expand to, following
  the broadcast rule

**Outputs**

* **output** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(bool),
  tensor(complex128),
  tensor(complex64),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input and output types to all tensors.

**Examples**

**_dim_changed**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        &#34;Expand&#34;,
        inputs=[&#34;data&#34;, &#34;new_shape&#34;],
        outputs=[&#34;expanded&#34;],
    )
    shape = [3, 1]
    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[1.], [2.], [3.]]
    new_shape = [2, 1, 6]
    expanded = data * np.ones(new_shape, dtype=np.float32)
    # print(expanded)
    # [[[1., 1., 1., 1., 1., 1.],
    #  [2., 2., 2., 2., 2., 2.],
    #  [3., 3., 3., 3., 3., 3.]],
    #
    # [[1., 1., 1., 1., 1., 1.],
    #  [2., 2., 2., 2., 2., 2.],
    #  [3., 3., 3., 3., 3., 3.]]]
    new_shape = np.array(new_shape, dtype=np.int64)
    expect(
        node,
        inputs=[data, new_shape],
        outputs=[expanded],
        name=&#34;test_expand_dim_changed&#34;,
    )

**_dim_unchanged**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        &#34;Expand&#34;,
        inputs=[&#34;data&#34;, &#34;new_shape&#34;],
        outputs=[&#34;expanded&#34;],
    )
    shape = [3, 1]
    new_shape = [3, 4]
    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[1.], [2.], [3.]]
    expanded = np.tile(data, 4)
    # print(expanded)
    # [[1., 1., 1., 1.],
    # [2., 2., 2., 2.],
    # [3., 3., 3., 3.]]
    new_shape = np.array(new_shape, dtype=np.int64)
    expect(
        node,
        inputs=[data, new_shape],
        outputs=[expanded],
        name=&#34;test_expand_dim_unchanged&#34;,
    )

.. toctree::

    text_diff_Expand_8_13

.. _l-onnx-op-expand-8:

Expand - 8
==========

**Version**

* **name**: `Expand (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Expand>`_
* **domain**: **main**
* **since_version**: **8**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 8**.

**Summary**

Broadcast the input tensor following the given shape and the broadcast rule.
The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):
Dimensions are right alignment;
Two corresponding dimensions must have the same value, or one of them is equal to 1.
Also, this operator is similar to numpy.broadcast_to(input, shape),
but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().
It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,
or the shape.ndim &lt; input.shape.ndim.

**Inputs**

* **input** (heterogeneous) - **T**:
  Input tensor
* **shape** (heterogeneous) - **tensor(int64)**:
  A 1-D tensor indicates the shape you want to expand to, following
  the broadcast rule

**Outputs**

* **output** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(bool),
  tensor(complex128),
  tensor(complex64),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input and output types to all tensors.
