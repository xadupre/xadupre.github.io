
.. _l-onnx-doc-Expand:

======
Expand
======

.. contents::
    :local:


.. _l-onnx-op-expand-13:

Expand - 13
===========

**Version**

* **name**: `Expand (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Expand>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

Broadcast the input tensor following the given shape and the broadcast rule.
The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):
Dimensions are right alignment;
Two corresponding dimensions must have the same value, or one of them is equal to 1.
Also, this operator is similar to numpy.broadcast_to(input, shape),
but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().
It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,
or the shape.ndim < input.shape.ndim.

**Inputs**

* **input** (heterogeneous) - **T**:
  Input tensor
* **shape** (heterogeneous) - **tensor(int64)**:
  A 1-D tensor indicates the shape you want to expand to, following
  the broadcast rule

**Outputs**

* **output** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(bool),
  tensor(complex128),
  tensor(complex64),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input and output types to all tensors.

**Examples**

**_dim_changed**

::

    node = onnx.helper.make_node(
        "Expand",
        inputs=["data", "new_shape"],
        outputs=["expanded"],
    )
    shape = [3, 1]
    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[1.], [2.], [3.]]
    new_shape = [2, 1, 6]
    expanded = data * np.ones(new_shape, dtype=np.float32)
    # print(expanded)
    # [[[1., 1., 1., 1., 1., 1.],
    #  [2., 2., 2., 2., 2., 2.],
    #  [3., 3., 3., 3., 3., 3.]],
    #
    # [[1., 1., 1., 1., 1., 1.],
    #  [2., 2., 2., 2., 2., 2.],
    #  [3., 3., 3., 3., 3., 3.]]]
    new_shape = np.array(new_shape, dtype=np.int64)
    expect(
        node,
        inputs=[data, new_shape],
        outputs=[expanded],
        name="test_expand_dim_changed",
    )

**_dim_unchanged**

::

    node = onnx.helper.make_node(
        "Expand",
        inputs=["data", "new_shape"],
        outputs=["expanded"],
    )
    shape = [3, 1]
    new_shape = [3, 4]
    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[1.], [2.], [3.]]
    expanded = np.tile(data, 4)
    # print(expanded)
    # [[1., 1., 1., 1.],
    # [2., 2., 2., 2.],
    # [3., 3., 3., 3.]]
    new_shape = np.array(new_shape, dtype=np.int64)
    expect(
        node,
        inputs=[data, new_shape],
        outputs=[expanded],
        name="test_expand_dim_unchanged",
    )

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to60__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to60__0">f</a></td><td class="diff_header" id="from60_1">1</td><td nowrap="nowrap">Broadcast&nbsp;the&nbsp;input&nbsp;tensor&nbsp;following&nbsp;the&nbsp;given&nbsp;shape&nbsp;and&nbsp;the&nbsp;broadcast&nbsp;rule.</td><td class="diff_next"><a href="#difflib_chg_to60__0">f</a></td><td class="diff_header" id="to60_1">1</td><td nowrap="nowrap">Broadcast&nbsp;the&nbsp;input&nbsp;tensor&nbsp;following&nbsp;the&nbsp;given&nbsp;shape&nbsp;and&nbsp;the&nbsp;broadcast&nbsp;rule.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_2">2</td><td nowrap="nowrap">The&nbsp;broadcast&nbsp;rule&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.array(input)&nbsp;*&nbsp;numpy.ones(shape):</td><td class="diff_next"></td><td class="diff_header" id="to60_2">2</td><td nowrap="nowrap">The&nbsp;broadcast&nbsp;rule&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.array(input)&nbsp;*&nbsp;numpy.ones(shape):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_3">3</td><td nowrap="nowrap">Dimensions&nbsp;are&nbsp;right&nbsp;alignment;</td><td class="diff_next"></td><td class="diff_header" id="to60_3">3</td><td nowrap="nowrap">Dimensions&nbsp;are&nbsp;right&nbsp;alignment;</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_4">4</td><td nowrap="nowrap">Two&nbsp;corresponding&nbsp;dimensions&nbsp;must&nbsp;have&nbsp;the&nbsp;same&nbsp;value,&nbsp;or&nbsp;one&nbsp;of&nbsp;them&nbsp;is&nbsp;equal&nbsp;to&nbsp;1.</td><td class="diff_next"></td><td class="diff_header" id="to60_4">4</td><td nowrap="nowrap">Two&nbsp;corresponding&nbsp;dimensions&nbsp;must&nbsp;have&nbsp;the&nbsp;same&nbsp;value,&nbsp;or&nbsp;one&nbsp;of&nbsp;them&nbsp;is&nbsp;equal&nbsp;to&nbsp;1.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_5">5</td><td nowrap="nowrap">Also,&nbsp;this&nbsp;operator&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.broadcast_to(input,&nbsp;shape),</td><td class="diff_next"></td><td class="diff_header" id="to60_5">5</td><td nowrap="nowrap">Also,&nbsp;this&nbsp;operator&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.broadcast_to(input,&nbsp;shape),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_6">6</td><td nowrap="nowrap">but&nbsp;the&nbsp;major&nbsp;difference&nbsp;is&nbsp;numpy.broadcast_to()&nbsp;does&nbsp;not&nbsp;allow&nbsp;shape&nbsp;to&nbsp;be&nbsp;smaller&nbsp;than&nbsp;input.size().</td><td class="diff_next"></td><td class="diff_header" id="to60_6">6</td><td nowrap="nowrap">but&nbsp;the&nbsp;major&nbsp;difference&nbsp;is&nbsp;numpy.broadcast_to()&nbsp;does&nbsp;not&nbsp;allow&nbsp;shape&nbsp;to&nbsp;be&nbsp;smaller&nbsp;than&nbsp;input.size().</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_7">7</td><td nowrap="nowrap">It&nbsp;is&nbsp;possible&nbsp;that&nbsp;the&nbsp;output.shape&nbsp;is&nbsp;not&nbsp;equal&nbsp;to&nbsp;shape,&nbsp;when&nbsp;some&nbsp;dimensions&nbsp;in&nbsp;shape&nbsp;is&nbsp;equal&nbsp;to&nbsp;1,</td><td class="diff_next"></td><td class="diff_header" id="to60_7">7</td><td nowrap="nowrap">It&nbsp;is&nbsp;possible&nbsp;that&nbsp;the&nbsp;output.shape&nbsp;is&nbsp;not&nbsp;equal&nbsp;to&nbsp;shape,&nbsp;when&nbsp;some&nbsp;dimensions&nbsp;in&nbsp;shape&nbsp;is&nbsp;equal&nbsp;to&nbsp;1,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_8">8</td><td nowrap="nowrap">or&nbsp;the&nbsp;shape.ndim&nbsp;&lt;&nbsp;input.shape.ndim.</td><td class="diff_next"></td><td class="diff_header" id="to60_8">8</td><td nowrap="nowrap">or&nbsp;the&nbsp;shape.ndim&nbsp;&lt;&nbsp;input.shape.ndim.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_10">10</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to60_10">10</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_11">11</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_11">11</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_12">12</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to60_12">12</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to60_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_14">14</td><td nowrap="nowrap">*&nbsp;**shape**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(int64)**:</td><td class="diff_next"></td><td class="diff_header" id="to60_14">14</td><td nowrap="nowrap">*&nbsp;**shape**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(int64)**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;1-D&nbsp;tensor&nbsp;indicates&nbsp;the&nbsp;shape&nbsp;you&nbsp;want&nbsp;to&nbsp;expand&nbsp;to,&nbsp;following</td><td class="diff_next"></td><td class="diff_header" id="to60_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;1-D&nbsp;tensor&nbsp;indicates&nbsp;the&nbsp;shape&nbsp;you&nbsp;want&nbsp;to&nbsp;expand&nbsp;to,&nbsp;following</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;broadcast&nbsp;rule</td><td class="diff_next"></td><td class="diff_header" id="to60_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;broadcast&nbsp;rule</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_18">18</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to60_18">18</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_20">20</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to60_20">20</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to60__0"></td><td class="diff_header" id="from60_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to60_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_23">23</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to60_23">23</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_25">25</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to60_25">25</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to60__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to60__top">t</a></td><td class="diff_header" id="to60_26">26</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(bool),</td><td class="diff_next"></td><td class="diff_header" id="to60_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(bool),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex128),</td><td class="diff_next"></td><td class="diff_header" id="to60_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex128),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex64),</td><td class="diff_next"></td><td class="diff_header" id="to60_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to60_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to60_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to60_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int16),</td><td class="diff_next"></td><td class="diff_header" id="to60_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to60_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to60_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int8),</td><td class="diff_next"></td><td class="diff_header" id="to60_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int8),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(string),</td><td class="diff_next"></td><td class="diff_header" id="to60_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(string),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint16),</td><td class="diff_next"></td><td class="diff_header" id="to60_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to60_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64),</td><td class="diff_next"></td><td class="diff_header" id="to60_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint8)</td><td class="diff_next"></td><td class="diff_header" id="to60_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint8)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to60_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from60_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;all&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to60_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;all&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-expand-8:

Expand - 8
==========

**Version**

* **name**: `Expand (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Expand>`_
* **domain**: **main**
* **since_version**: **8**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 8**.

**Summary**

Broadcast the input tensor following the given shape and the broadcast rule.
The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):
Dimensions are right alignment;
Two corresponding dimensions must have the same value, or one of them is equal to 1.
Also, this operator is similar to numpy.broadcast_to(input, shape),
but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().
It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,
or the shape.ndim < input.shape.ndim.

**Inputs**

* **input** (heterogeneous) - **T**:
  Input tensor
* **shape** (heterogeneous) - **tensor(int64)**:
  A 1-D tensor indicates the shape you want to expand to, following
  the broadcast rule

**Outputs**

* **output** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(bool),
  tensor(complex128),
  tensor(complex64),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(string),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input and output types to all tensors.
