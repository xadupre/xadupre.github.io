
.. _l-onnx-doc-Hardmax:

=======
Hardmax
=======

.. contents::
    :local:


.. _l-onnx-op-hardmax-13:
Hardmax - 13
============
**Version**
* **name**: `Hardmax (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Hardmax>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

The operator computes the hardmax values for the given input:

 Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise

The "axis" attribute indicates the dimension along which Hardmax
will be performed. The output tensor has the same shape
and contains the Hardmax values of the corresponding input.

**Attributes**
* **axis**:
   Describes the dimension Hardmax will be performed on. Negative
  value means counting dimensions from the back. Accepted range is
  [-r, r-1] where r = rank(input).

**Inputs**

* **input** (heterogeneous) - **T**:
  The input tensor of rank >= axis.

**Outputs**

* **output** (heterogeneous) - **T**:
  The output values with the same shape as the input tensor.

**Type Constraints**
* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Examples**

**default**
::
    node = onnx.helper.make_node(
        "Hardmax",
        inputs=["x"],
        outputs=["y"],
    )

    x = np.array([[3, 0, 1, 2], [2, 5, 1, 0], [0, 1, 3, 2], [0, 1, 2, 3]]).astype(
        np.float32
    )
    # expect result:
    # [[1. 0. 0. 0.]
    # [0. 1. 0. 0.]
    # [0. 0. 1. 0.]
    # [0. 0. 0. 1.]]
    y = hardmax(x)
    expect(node, inputs=[x], outputs=[y], name="test_hardmax_example")

    # For multiple occurrences of the maximal values, the first occurrence is selected for one-hot output
    x = np.array([[3, 3, 3, 1]]).astype(np.float32)
    # expect result:
    # [[1, 0, 0, 0]]
    y = hardmax(x)
    expect(node, inputs=[x], outputs=[y], name="test_hardmax_one_hot")

**_hardmax_axis**
::
    x = np.random.randn(3, 4, 5).astype(np.float32)
    node = onnx.helper.make_node(
        "Hardmax",
        inputs=["x"],
        outputs=["y"],
        axis=0,
    )
    y = hardmax(x, axis=0)
    expect(node, inputs=[x], outputs=[y], name="test_hardmax_axis_0")

    node = onnx.helper.make_node(
        "Hardmax",
        inputs=["x"],
        outputs=["y"],
        axis=1,
    )
    y = hardmax(x, axis=1)
    expect(node, inputs=[x], outputs=[y], name="test_hardmax_axis_1")

    node = onnx.helper.make_node(
        "Hardmax",
        inputs=["x"],
        outputs=["y"],
        axis=2,
    )
    y = hardmax(x, axis=2)
    expect(node, inputs=[x], outputs=[y], name="test_hardmax_axis_2")

    node = onnx.helper.make_node(
        "Hardmax",
        inputs=["x"],
        outputs=["y"],
        axis=-1,
    )
    y = hardmax(x, axis=-1)
    expect(node, inputs=[x], outputs=[y], name="test_hardmax_negative_axis")

    # default axis is -1
    node = onnx.helper.make_node(
        "Hardmax",
        inputs=["x"],
        outputs=["y"],
    )
    expect(node, inputs=[x], outputs=[y], name="test_hardmax_default_axis")

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to85__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to85__1"><a href="#difflib_chg_to85__1">n</a></td><td class="diff_header" id="from85_1">1</td><td nowrap="nowrap"><span class="diff_sub">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;(1&nbsp;for&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value,&nbsp;and&nbsp;0&nbsp;for&nbsp;all&nbsp;others)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</span></td><td class="diff_next"><a href="#difflib_chg_to85__1">n</a></td><td class="diff_header" id="to85_1">1</td><td nowrap="nowrap"><span class="diff_add">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;values&nbsp;for&nbsp;the&nbsp;given&nbsp;input:</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_2">2</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to85__2">n</a></td><td class="diff_header" id="from85_4">4</td><td nowrap="nowrap"><span class="diff_sub">The&nbsp;input&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</span></td><td class="diff_next"><a href="#difflib_chg_to85__2">n</a></td><td class="diff_header" id="to85_3">3</td><td nowrap="nowrap"><span class="diff_add">&nbsp;Hardmax(element&nbsp;in&nbsp;input,&nbsp;axis)&nbsp;=&nbsp;1&nbsp;if&nbsp;the&nbsp;element&nbsp;is&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value&nbsp;along&nbsp;the&nbsp;specified&nbsp;axis,&nbsp;0&nbsp;otherwise</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_5">5</td><td nowrap="nowrap"><span class="diff_sub">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header" id="to85_4">4</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_6">6</td><td nowrap="nowrap"><span class="diff_sub">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</span></td><td class="diff_next"></td><td class="diff_header" id="to85_5">5</td><td nowrap="nowrap"><span class="diff_add">The&nbsp;"axis"&nbsp;attribute&nbsp;indicates&nbsp;the&nbsp;dimension&nbsp;along&nbsp;which&nbsp;Hardmax</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_7">7</td><td nowrap="nowrap"><span class="diff_sub">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_8">8</td><td nowrap="nowrap"><span class="diff_sub">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_9">9</td><td nowrap="nowrap"><span class="diff_sub">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_10">10</td><td nowrap="nowrap"><span class="diff_sub">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_11">11</td><td nowrap="nowrap"><span class="diff_sub">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_12">12</td><td nowrap="nowrap"><span class="diff_sub">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to85__2"></td><td class="diff_header" id="from85_13">13</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">throw&nbsp;</span>er<span class="diff_chg">r</span>or<span class="diff_chg">s</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td><td class="diff_next"></td><td class="diff_header" id="to85_6">6</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">be&nbsp;p</span>er<span class="diff_chg">f</span>or<span class="diff_chg">med</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_14">14</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">h</span>ardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td><td class="diff_next"></td><td class="diff_header" id="to85_7">7</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">H</span>ardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_8">8</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_16">16</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to85_9">9</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_17">17</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to85_10">10</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to85__3">n</a></td><td class="diff_header" id="from85_18">18</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</span></td><td class="diff_next"><a href="#difflib_chg_to85__3">n</a></td><td class="diff_header" id="to85_11">11</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;&nbsp;Describes&nbsp;the&nbsp;dimension&nbsp;Hardmax&nbsp;will&nbsp;be&nbsp;performed&nbsp;on.&nbsp;Negative</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_19">19</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size.&nbsp;Negative</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to85_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to85__3"></td><td class="diff_header" id="from85_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td><td class="diff_next"></td><td class="diff_header" id="to85_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_14">14</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_23">23</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to85_15">15</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_16">16</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_25">25</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to85_17">17</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to85__4">n</a></td><td class="diff_header" id="from85_26">26</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</span></td><td class="diff_next"><a href="#difflib_chg_to85__4">n</a></td><td class="diff_header" id="to85_18">18</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;of&nbsp;rank&nbsp;&gt;=&nbsp;axis.</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to85__4"></td><td class="diff_header" id="from85_27">27</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;described&nbsp;above.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_28">28</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_29">29</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to85_20">20</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_30">30</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_21">21</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_31">31</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to85_22">22</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to85__5"><a href="#difflib_chg_to85__5">n</a></td><td class="diff_header" id="from85_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor<span class="diff_chg">&nbsp;(the&nbsp;original</span></td><td class="diff_next"><a href="#difflib_chg_to85__5">n</a></td><td class="diff_header" id="to85_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as<span class="diff_add">&nbsp;the</span>&nbsp;input&nbsp;tensor<span class="diff_chg">.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_33">33</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_34">34</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_35">35</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to85_25">25</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_36">36</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to85_26">26</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to85__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to85__top">t</a></td><td class="diff_header" id="to85_27">27</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to85_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to85_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to85_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to85_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from85_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to85_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-hardmax-11:
Hardmax - 11
============
**Version**
* **name**: `Hardmax (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Hardmax>`_
* **domain**: **main**
* **since_version**: **11**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 11**.

**Summary**

The operator computes the hardmax (1 for the first maximum value, and 0 for all others) values for each layer in the batch
 of the given input.

The input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input \in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * ... * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * ... * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors. The output tensor has the same shape
and contains the hardmax values of the corresponding input.

**Attributes**
* **axis**:
  Describes the axis of the inputs when coerced to 2D; defaults to one
  because the 0th axis most likely describes the batch_size. Negative
  value means counting dimensions from the back. Accepted range is
  [-r, r-1] where r = rank(input).

**Inputs**

* **input** (heterogeneous) - **T**:
  The input tensor that's coerced into a 2D matrix of size (NxD) as
  described above.

**Outputs**

* **output** (heterogeneous) - **T**:
  The output values with the same shape as input tensor (the original
  size without coercion).

**Type Constraints**
* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to86__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to86__1"><a href="#difflib_chg_to86__0">f</a></td><td class="diff_header" id="from86_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;(1&nbsp;for&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value,&nbsp;and&nbsp;0&nbsp;for&nbsp;all&nbsp;others)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td><td class="diff_next"><a href="#difflib_chg_to86__0">f</a></td><td class="diff_header" id="to86_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;(1&nbsp;for&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value,&nbsp;and&nbsp;0&nbsp;for&nbsp;all&nbsp;others)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to86__1">n</a></td><td class="diff_header" id="from86_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.&nbsp;The&nbsp;input&nbsp;is&nbsp;a&nbsp;2-D&nbsp;tensor&nbsp;(Tensor&lt;float&gt;)&nbsp;of&nbsp;size</span></td><td class="diff_next"><a href="#difflib_chg_to86__1">n</a></td><td class="diff_header" id="to86_2">2</td><td nowrap="nowrap"><span class="diff_add">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_3">3</td><td nowrap="nowrap"><span class="diff_sub">(batch_size&nbsp;x&nbsp;input_feature_dimensions).&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_4">4</td><td nowrap="nowrap"><span class="diff_sub">and&nbsp;contains&nbsp;the&nbsp;hardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_3">3</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to86__2">n</a></td><td class="diff_header" id="from86_6">6</td><td nowrap="nowrap"><span class="diff_chg">I</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td><td class="diff_next"><a href="#difflib_chg_to86__2">n</a></td><td class="diff_header" id="to86_4">4</td><td nowrap="nowrap"><span class="diff_chg">The&nbsp;i</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_7">7</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to86_5">5</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_8">8</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to86_6">6</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_9">9</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td><td class="diff_next"></td><td class="diff_header" id="to86_7">7</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to86__2"></td><td class="diff_header" id="from86_10">10</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td><td class="diff_next"></td><td class="diff_header" id="to86_8">8</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_11">11</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to86_9">9</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_12">12</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td><td class="diff_next"></td><td class="diff_header" id="to86_10">10</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_13">13</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td><td class="diff_next"></td><td class="diff_header" id="to86_11">11</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_14">14</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td><td class="diff_next"></td><td class="diff_header" id="to86_12">12</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to86__3">n</a></td><td class="diff_header" id="from86_15">15</td><td nowrap="nowrap"><span class="diff_sub">will&nbsp;throw&nbsp;errors.</span></td><td class="diff_next"><a href="#difflib_chg_to86__3">n</a></td><td class="diff_header" id="to86_13">13</td><td nowrap="nowrap"><span class="diff_add">will&nbsp;throw&nbsp;errors.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td></tr>
                <tr><td class="diff_next" id="difflib_chg_to86__3"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_14">14</td><td nowrap="nowrap"><span class="diff_add">and&nbsp;contains&nbsp;the&nbsp;hardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_15">15</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_17">17</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to86_16">16</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_18">18</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to86_17">17</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td><td class="diff_next"></td><td class="diff_header" id="to86_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to86__top">t</a></td><td class="diff_header" id="from86_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size</td><td class="diff_next"><a href="#difflib_chg_to86__top">t</a></td><td class="diff_header" id="to86_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size<span class="diff_add">.&nbsp;Negative</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_20">20</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_21">21</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_22">22</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to86_23">23</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_24">24</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to86_25">25</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td><td class="diff_next"></td><td class="diff_header" id="to86_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td><td class="diff_next"></td><td class="diff_header" id="to86_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_28">28</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_28">28</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to86_29">29</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_30">30</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_30">30</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to86_31">31</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td><td class="diff_next"></td><td class="diff_header" id="to86_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td><td class="diff_next"></td><td class="diff_header" id="to86_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_34">34</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_34">34</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to86_35">35</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_35">35</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to86_36">36</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to86_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to86_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to86_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to86_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from86_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to86_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-hardmax-1:
Hardmax - 1
===========
**Version**
* **name**: `Hardmax (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Hardmax>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 1**.

**Summary**

The operator computes the hardmax (1 for the first maximum value, and 0 for all others) values for each layer in the batch
 of the given input. The input is a 2-D tensor (Tensor<float>) of size
(batch_size x input_feature_dimensions). The output tensor has the same shape
and contains the hardmax values of the corresponding input.

Input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input \in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * ... * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * ... * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors.

**Attributes**
* **axis**:
  Describes the axis of the inputs when coerced to 2D; defaults to one
  because the 0th axis most likely describes the batch_size

**Inputs**

* **input** (heterogeneous) - **T**:
  The input tensor that's coerced into a 2D matrix of size (NxD) as
  described above.

**Outputs**

* **output** (heterogeneous) - **T**:
  The output values with the same shape as input tensor (the original
  size without coercion).

**Type Constraints**
* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
