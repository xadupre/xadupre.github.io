
.. _l-onnx-doc-Mul:

===
Mul
===

.. contents::
    :local:


.. _l-onnx-op-mul-14:

Mul - 14
========

**Version**

* **name**: `Mul (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mul>`_
* **domain**: **main**
* **since_version**: **14**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 14**.

**Summary**

Performs element-wise binary multiplication (with Numpy-style broadcasting support).

This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX &lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;`_.

(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.

**Inputs**

* **A** (heterogeneous) - **T**:
  First operand.
* **B** (heterogeneous) - **T**:
  Second operand.

**Outputs**

* **C** (heterogeneous) - **T**:
  Result, has same element type as two inputs

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int16),
  tensor(int32),
  tensor(int64),
  tensor(int8),
  tensor(uint16),
  tensor(uint32),
  tensor(uint64),
  tensor(uint8)
  ):
  Constrain input and output types to all numeric tensors.

**Examples**

**default**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        &#34;Mul&#34;,
        inputs=[&#34;x&#34;, &#34;y&#34;],
        outputs=[&#34;z&#34;],
    )

    x = np.array([1, 2, 3]).astype(np.float32)
    y = np.array([4, 5, 6]).astype(np.float32)
    z = x * y  # expected output [4., 10., 18.]
    expect(node, inputs=[x, y], outputs=[z], name=&#34;test_mul_example&#34;)

    x = np.random.randn(3, 4, 5).astype(np.float32)
    y = np.random.randn(3, 4, 5).astype(np.float32)
    z = x * y
    expect(node, inputs=[x, y], outputs=[z], name=&#34;test_mul&#34;)

    x = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)
    y = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)
    z = x * y
    expect(node, inputs=[x, y], outputs=[z], name=&#34;test_mul_uint8&#34;)

**_mul_broadcast**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        &#34;Mul&#34;,
        inputs=[&#34;x&#34;, &#34;y&#34;],
        outputs=[&#34;z&#34;],
    )

    x = np.random.randn(3, 4, 5).astype(np.float32)
    y = np.random.randn(5).astype(np.float32)
    z = x * y
    expect(node, inputs=[x, y], outputs=[z], name=&#34;test_mul_bcast&#34;)

.. toctree::

    text_diff_Mul_13_14

.. _l-onnx-op-mul-13:

Mul - 13
========

**Version**

* **name**: `Mul (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mul>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

Performs element-wise binary multiplication (with Numpy-style broadcasting support).

This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX &lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;`_.

**Inputs**

* **A** (heterogeneous) - **T**:
  First operand.
* **B** (heterogeneous) - **T**:
  Second operand.

**Outputs**

* **C** (heterogeneous) - **T**:
  Result, has same element type as two inputs

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

.. toctree::

    text_diff_Mul_7_13

.. _l-onnx-op-mul-7:

Mul - 7
=======

**Version**

* **name**: `Mul (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mul>`_
* **domain**: **main**
* **since_version**: **7**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 7**.

**Summary**

Performs element-wise binary multiplication (with Numpy-style broadcasting support).

This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX &lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;`_.

**Inputs**

* **A** (heterogeneous) - **T**:
  First operand.
* **B** (heterogeneous) - **T**:
  Second operand.

**Outputs**

* **C** (heterogeneous) - **T**:
  Result, has same element type as two inputs

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

.. toctree::

    text_diff_Mul_6_7

.. _l-onnx-op-mul-6:

Mul - 6
=======

**Version**

* **name**: `Mul (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mul>`_
* **domain**: **main**
* **since_version**: **6**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 6**.

**Summary**

Performs element-wise binary multiplication (with limited broadcast support).

If necessary the right-hand-side argument will be broadcasted to match the
shape of left-hand-side argument. When broadcasting is specified, the second
tensor can either be of element size 1 (including a scalar tensor and any
tensor with rank equal to or smaller than the first tensor), or having its
shape as a contiguous subset of the first tensor&#39;s shape. The starting of the
mutually equal shape is specified by the argument &#34;axis&#34;, and if it is not set,
suffix matching is assumed. 1-dim expansion doesn&#39;t work yet.

For example, the following tensor shapes are supported (with broadcast=1):

  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0

Attribute `broadcast=1` needs to be passed to enable broadcasting.

**Attributes**

* **axis**:
  If set, defines the broadcast dimensions. See doc for details.
* **broadcast**:
  Pass 1 to enable broadcasting

**Inputs**

* **A** (heterogeneous) - **T**:
  First operand, should share the type with the second operand.
* **B** (heterogeneous) - **T**:
  Second operand. With broadcasting can be of smaller size than A. If
  broadcasting is disabled it should be of the same size.

**Outputs**

* **C** (heterogeneous) - **T**:
  Result, has same dimensions and type as A

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

.. toctree::

    text_diff_Mul_1_6

.. _l-onnx-op-mul-1:

Mul - 1
=======

**Version**

* **name**: `Mul (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mul>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

Performs element-wise binary multiplication (with limited broadcast support).

If necessary the right-hand-side argument will be broadcasted to match the
shape of left-hand-side argument. When broadcasting is specified, the second
tensor can either be of element size 1 (including a scalar tensor and any
tensor with rank equal to or smaller than the first tensor), or having its
shape as a contiguous subset of the first tensor&#39;s shape. The starting of the
mutually equal shape is specified by the argument &#34;axis&#34;, and if it is not set,
suffix matching is assumed. 1-dim expansion doesn&#39;t work yet.

For example, the following tensor shapes are supported (with broadcast=1):

  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0

Attribute `broadcast=1` needs to be passed to enable broadcasting.

**Attributes**

* **axis**:
  If set, defines the broadcast dimensions. See doc for details.
* **broadcast**:
  Pass 1 to enable broadcasting
* **consumed_inputs**:
  legacy optimization attribute.

**Inputs**

* **A** (heterogeneous) - **T**:
  First operand, should share the type with the second operand.
* **B** (heterogeneous) - **T**:
  Second operand. With broadcasting can be of smaller size than A. If
  broadcasting is disabled it should be of the same size.

**Outputs**

* **C** (heterogeneous) - **T**:
  Result, has same dimensions and type as A

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
