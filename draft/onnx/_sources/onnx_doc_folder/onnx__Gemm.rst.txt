
.. _l-onnx-doc-Gemm:

====
Gemm
====

.. contents::
    :local:


.. _l-onnx-op-gemm-13:

Gemm - 13
=========

**Version**

* **name**: `Gemm (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

General Matrix multiplication:
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3

A' = transpose(A) if transA else A

B' = transpose(B) if transB else B

Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports **unidirectional broadcasting** (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.
This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.

**Attributes**

* **alpha**:
  Scalar multiplier for the product of input tensors A * B.
* **beta**:
  Scalar multiplier for input tensor C.
* **transA**:
  Whether A should be transposed
* **transB**:
  Whether B should be transposed

**Inputs**

Between 2 and 3 inputs.

* **A** (heterogeneous) - **T**:
  Input tensor A. The shape of A should be (M, K) if transA is 0, or
  (K, M) if transA is non-zero.
* **B** (heterogeneous) - **T**:
  Input tensor B. The shape of B should be (K, N) if transB is 0, or
  (N, K) if transB is non-zero.
* **C** (optional, heterogeneous) - **T**:
  Optional input tensor C. If not specified, the computation is done
  as if C is a scalar 0. The shape of C should be unidirectional
  broadcastable to (M, N).

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor of shape (M, N).

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to float/int tensors.

**Examples**

**_default_zero_bias**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node("Gemm", inputs=["a", "b", "c"], outputs=["y"])
    a = np.random.ranf([3, 5]).astype(np.float32)
    b = np.random.ranf([5, 4]).astype(np.float32)
    c = np.zeros([1, 4]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c)
    expect(node, inputs=[a, b, c], outputs=[y], name="test_gemm_default_zero_bias")

**_default_no_bias**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node("Gemm", inputs=["a", "b"], outputs=["y"])
    a = np.random.ranf([2, 10]).astype(np.float32)
    b = np.random.ranf([10, 3]).astype(np.float32)
    y = gemm_reference_implementation(a, b)
    expect(node, inputs=[a, b], outputs=[y], name="test_gemm_default_no_bias")

**_default_scalar_bias**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node("Gemm", inputs=["a", "b", "c"], outputs=["y"])
    a = np.random.ranf([2, 3]).astype(np.float32)
    b = np.random.ranf([3, 4]).astype(np.float32)
    c = np.array(3.14).astype(np.float32)
    y = gemm_reference_implementation(a, b, c)
    expect(
        node, inputs=[a, b, c], outputs=[y], name="test_gemm_default_scalar_bias"
    )

**_default_single_elem_vector_bias**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node("Gemm", inputs=["a", "b", "c"], outputs=["y"])
    a = np.random.ranf([3, 7]).astype(np.float32)
    b = np.random.ranf([7, 3]).astype(np.float32)
    c = np.random.ranf([1]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c)
    expect(
        node,
        inputs=[a, b, c],
        outputs=[y],
        name="test_gemm_default_single_elem_vector_bias",
    )

**_default_vector_bias**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node("Gemm", inputs=["a", "b", "c"], outputs=["y"])
    a = np.random.ranf([2, 7]).astype(np.float32)
    b = np.random.ranf([7, 4]).astype(np.float32)
    c = np.random.ranf([1, 4]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c)
    expect(
        node, inputs=[a, b, c], outputs=[y], name="test_gemm_default_vector_bias"
    )

**_default_matrix_bias**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node("Gemm", inputs=["a", "b", "c"], outputs=["y"])
    a = np.random.ranf([3, 6]).astype(np.float32)
    b = np.random.ranf([6, 4]).astype(np.float32)
    c = np.random.ranf([3, 4]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c)
    expect(
        node, inputs=[a, b, c], outputs=[y], name="test_gemm_default_matrix_bias"
    )

**_transposeA**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        "Gemm", inputs=["a", "b", "c"], outputs=["y"], transA=1
    )
    a = np.random.ranf([6, 3]).astype(np.float32)
    b = np.random.ranf([6, 4]).astype(np.float32)
    c = np.zeros([1, 4]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c, transA=1)
    expect(node, inputs=[a, b, c], outputs=[y], name="test_gemm_transposeA")

**_transposeB**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        "Gemm", inputs=["a", "b", "c"], outputs=["y"], transB=1
    )
    a = np.random.ranf([3, 6]).astype(np.float32)
    b = np.random.ranf([4, 6]).astype(np.float32)
    c = np.zeros([1, 4]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c, transB=1)
    expect(node, inputs=[a, b, c], outputs=[y], name="test_gemm_transposeB")

**_alpha**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        "Gemm", inputs=["a", "b", "c"], outputs=["y"], alpha=0.5
    )
    a = np.random.ranf([3, 5]).astype(np.float32)
    b = np.random.ranf([5, 4]).astype(np.float32)
    c = np.zeros([1, 4]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c, alpha=0.5)
    expect(node, inputs=[a, b, c], outputs=[y], name="test_gemm_alpha")

**_beta**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        "Gemm", inputs=["a", "b", "c"], outputs=["y"], beta=0.5
    )
    a = np.random.ranf([2, 7]).astype(np.float32)
    b = np.random.ranf([7, 4]).astype(np.float32)
    c = np.random.ranf([1, 4]).astype(np.float32)
    y = gemm_reference_implementation(a, b, c, beta=0.5)
    expect(node, inputs=[a, b, c], outputs=[y], name="test_gemm_beta")

**_all_attributes**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        "Gemm",
        inputs=["a", "b", "c"],
        outputs=["y"],
        alpha=0.25,
        beta=0.35,
        transA=1,
        transB=1,
    )
    a = np.random.ranf([4, 3]).astype(np.float32)
    b = np.random.ranf([5, 4]).astype(np.float32)
    c = np.random.ranf([1, 5]).astype(np.float32)
    y = gemm_reference_implementation(
        a, b, c, transA=1, transB=1, alpha=0.25, beta=0.35
    )
    expect(node, inputs=[a, b, c], outputs=[y], name="test_gemm_all_attributes")

.. toctree::

    text_diff_Gemm_11_13

.. _l-onnx-op-gemm-11:

Gemm - 11
=========

**Version**

* **name**: `Gemm (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm>`_
* **domain**: **main**
* **since_version**: **11**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 11**.

**Summary**

General Matrix multiplication:
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3

A' = transpose(A) if transA else A

B' = transpose(B) if transB else B

Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports **unidirectional broadcasting** (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.
This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.

**Attributes**

* **alpha**:
  Scalar multiplier for the product of input tensors A * B.
* **beta**:
  Scalar multiplier for input tensor C.
* **transA**:
  Whether A should be transposed
* **transB**:
  Whether B should be transposed

**Inputs**

Between 2 and 3 inputs.

* **A** (heterogeneous) - **T**:
  Input tensor A. The shape of A should be (M, K) if transA is 0, or
  (K, M) if transA is non-zero.
* **B** (heterogeneous) - **T**:
  Input tensor B. The shape of B should be (K, N) if transB is 0, or
  (N, K) if transB is non-zero.
* **C** (optional, heterogeneous) - **T**:
  Optional input tensor C. If not specified, the computation is done
  as if C is a scalar 0. The shape of C should be unidirectional
  broadcastable to (M, N).

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor of shape (M, N).

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to float/int tensors.

.. toctree::

    text_diff_Gemm_9_13
    text_diff_Gemm_9_11

.. _l-onnx-op-gemm-9:

Gemm - 9
========

**Version**

* **name**: `Gemm (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm>`_
* **domain**: **main**
* **since_version**: **9**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 9**.

**Summary**

General Matrix multiplication:
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3

A' = transpose(A) if transA else A

B' = transpose(B) if transB else B

Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports **unidirectional broadcasting** (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.

**Attributes**

* **alpha**:
  Scalar multiplier for the product of input tensors A * B.
* **beta**:
  Scalar multiplier for input tensor C.
* **transA**:
  Whether A should be transposed
* **transB**:
  Whether B should be transposed

**Inputs**

* **A** (heterogeneous) - **T**:
  Input tensor A. The shape of A should be (M, K) if transA is 0, or
  (K, M) if transA is non-zero.
* **B** (heterogeneous) - **T**:
  Input tensor B. The shape of B should be (K, N) if transB is 0, or
  (N, K) if transB is non-zero.
* **C** (heterogeneous) - **T**:
  Input tensor C. The shape of C should be unidirectional
  broadcastable to (M, N).

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor of shape (M, N).

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to float/int tensors.

.. toctree::

    text_diff_Gemm_7_13
    text_diff_Gemm_7_11
    text_diff_Gemm_7_9

.. _l-onnx-op-gemm-7:

Gemm - 7
========

**Version**

* **name**: `Gemm (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm>`_
* **domain**: **main**
* **since_version**: **7**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 7**.

**Summary**

General Matrix multiplication:
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3

A' = transpose(A) if transA else A

B' = transpose(B) if transB else B

Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports **unidirectional broadcasting** (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.

**Attributes**

* **alpha**:
  Scalar multiplier for the product of input tensors A * B.
* **beta**:
  Scalar multiplier for input tensor C.
* **transA**:
  Whether A should be transposed
* **transB**:
  Whether B should be transposed

**Inputs**

* **A** (heterogeneous) - **T**:
  Input tensor A. The shape of A should be (M, K) if transA is 0, or
  (K, M) if transA is non-zero.
* **B** (heterogeneous) - **T**:
  Input tensor B. The shape of B should be (K, N) if transB is 0, or
  (N, K) if transB is non-zero.
* **C** (heterogeneous) - **T**:
  Input tensor C. The shape of C should be unidirectional
  broadcastable to (M, N).

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor of shape (M, N).

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

.. toctree::

    text_diff_Gemm_6_13
    text_diff_Gemm_6_11
    text_diff_Gemm_6_9
    text_diff_Gemm_6_7

.. _l-onnx-op-gemm-6:

Gemm - 6
========

**Version**

* **name**: `Gemm (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm>`_
* **domain**: **main**
* **since_version**: **6**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 6**.

**Summary**

General Matrix multiplication:
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3
Compute Y = alpha * A * B + beta * C, where input tensor A has
dimension (M X K), input tensor B has dimension (K X N), input tensor C and
output tensor Y have dimension (M X N).
If attribute broadcast is non-zero, input tensor C will be broadcasted to match
the dimension requirement. A will be transposed before doing the computation
if attribute transA is non-zero, same for B and transB.

**Attributes**

* **alpha**:
  Scalar multiplier for the product of input tensors A * B, the
  default value is 1.0.
* **beta**:
  Scalar multiplier for input tensor C, the default value is 1.0.
* **broadcast**:
  Whether C should be broadcasted
* **transA**:
  Whether A should be transposed
* **transB**:
  Whether B should be transposed

**Inputs**

* **A** (heterogeneous) - **T**:
  Input tensor A
* **B** (heterogeneous) - **T**:
  Input tensor B
* **C** (heterogeneous) - **T**:
  Input tensor C

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.

.. toctree::

    text_diff_Gemm_1_13
    text_diff_Gemm_1_11
    text_diff_Gemm_1_9
    text_diff_Gemm_1_7
    text_diff_Gemm_1_6

.. _l-onnx-op-gemm-1:

Gemm - 1
========

**Version**

* **name**: `Gemm (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 1**.

**Summary**

General Matrix multiplication:
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3
Compute Y = alpha * A * B + beta * C, where input tensor A has
dimension (M X K), input tensor B has dimension (K X N), input tensor C and
output tensor Y have dimension (M X N).
If attribute broadcast is non-zero, input tensor C will be broadcasted to match
the dimension requirement. A will be transposed before doing the computation
if attribute transA is non-zero, same for B and transB.

**Attributes**

* **alpha**:
  Scalar multiplier for the product of input tensors A * B, the
  default value is 1.0.
* **beta**:
  Scalar multiplier for input tensor C, the default value is 1.0.
* **broadcast**:
  Whether C should be broadcasted
* **transA**:
  Whether A should be transposed
* **transB**:
  Whether B should be transposed

**Inputs**

* **A** (heterogeneous) - **T**:
  Input tensor A
* **B** (heterogeneous) - **T**:
  Input tensor B
* **C** (heterogeneous) - **T**:
  Input tensor C, can be inplace.

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to float tensors.
