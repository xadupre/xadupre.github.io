
.. _l-onnx-docai.onnx.preview.training-Momentum:

===================================
ai.onnx.preview.training - Momentum
===================================

.. contents::
    :local:


.. _l-onnx-opai-onnx-preview-training-momentum-1:

Momentum - 1 (ai.onnx.preview.training)
=======================================

**Version**

* **name**: `Momentum (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ai.onnx.preview.training.Momentum>`_
* **domain**: **ai.onnx.preview.training**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 1 of domain ai.onnx.preview.training**.

**Summary**

Compute one iteration of stochastic gradient update with momentum.
This operator can conduct the optimization of multiple tensor variables.

Let&#39;s define the behavior of this operator. As you can imagine, SG with momentum requires
several parameters:

 - The learning-rate &#34;R&#34;.
 - The update count &#34;T&#34;. That is, the number of conducted training iterations. It should
   be zero in the first training iteration.
 - A L2-norm regularization coefficient &#34;norm_coefficient&#34;.
 - A decay coefficient of previous accumulated gradient (i.e., momentum) &#34;alpha&#34;.
 - The scaling coefficient of current gradient &#34;beta&#34;.
 - An attribute to choose either standard momentum or Nesterov&#39;s momentum &#34;mode&#34; should
   be used.

For the sake of simplicity, assume that there is only one tensor (called &#34;X&#34;) to be optimized.
Other necessary inputs are &#34;X&#34;&#39;s gradient (called &#34;G&#34;) and &#34;X&#34;&#39;s momentum (called &#34;V&#34;). This
Momentum operator maps all these inputs to the new value of &#34;X&#34; (called &#34;X_new&#34;) and its new
momentum (called &#34;V_new&#34;).

This operator supports two different momentum algorithms. Set the attribute &#34;mode&#34; to
&#34;nesterov&#34; if Nesterov&#39;s momentum is desired. Otherwise, set the attribute &#34;model&#34; to
&#34;standard&#34; to use standard momentum. Computation details are described subsequently.

Let &#34;+&#34;, &#34;-&#34;, &#34;*&#34;, and &#34;/&#34; are all element-wise operations with numpy-style broadcasting.

Pseudo code for SG with standard momentum:

  // Add gradient of 0.5 * norm_coefficient * ||X||^2, where ||X|| is the sum of squared
  // values of all elements in X.
  G_regularized = norm_coefficient * X + G

  // In the first training iteration, beta should always be 1.
  beta_adjusted = T &gt; 0 ? beta : 1

  // Compute the current momentum based on previous momentum and the current gradient.
  V_new = alpha * V + beta_adjusted * G_regularized

  // Update X.
  X_new = X - R * V_new

Pseudo code for SG with Nesterov&#39;s momentum:

  // Add gradient of 0.5 * norm_coefficient * ||X||^2, where ||X|| is the sum of squared
  // values of all elements in X.
  G_regularized = norm_coefficient * X + G;

  // In the first training iteration, beta should always be 1.
  beta_adjusted = T &gt; 0 ? beta : 1

  // Compute the current momentum based on previous momentum and the current gradient.
  V_new = alpha * V + beta_adjusted * G_regularized;

  // Compute final update direction and then update X.
  X_new = X - R * (G_regularized + alpha * V_new)

If one assign this operators to optimize multiple inputs, for example, &#34;X_1&#34; and &#34;X_2&#34;. The same
pseudo code would be extended to handle all tensors jointly. More specifically, we can view &#34;X&#34; as a
concatenation of &#34;X_1&#34; and &#34;X_2&#34; (of course, their gradient and accumulate gradient should
be concatenated too) and then our pseudo code becomes applicable.

**Attributes**

* **alpha** (required):
  The decay factor of momentum. It should be a scalar.
* **beta** (required):
  The coefficient of gradient in computing new momentum. It should be
  a scalar.
* **mode** (required):
  Its value should be either &#34;nesterov&#34; or &#34;standard&#34;. The value
  &#34;nesterov&#34; leads to the use of Nesterov&#39;s momentum while &#34;standard&#34;
  invokes stochastic gradient method using standard momentum
* **norm_coefficient** (required):
  Coefficient of 0.5 * norm_coefficient * ||X||^2.

**Inputs**

Between 3 and 2147483647 inputs.

* **R** (heterogeneous) - **T1**:
  The learning rate.
* **T** (heterogeneous) - **T2**:
  Update count of &#34;X&#34;. It should be a scalar.
* **inputs** (variadic) - **T3**:
  It sequentially contains the current values of optimized tensors,
  then their gradient tensors, and finally their momentum tensors. For
  example, if two tensors &#34;X_1&#34; and &#34;X_2&#34; are optimized, The expected
  input list would be [&#34;X_1&#34;, &#34;X_2&#34;, gradient of &#34;X_1&#34;, gradient of
  &#34;X_2&#34;, momentum of &#34;X_1&#34;, momentum of &#34;X_2&#34;].

**Outputs**

Between 1 and 2147483647 outputs.

* **outputs** (variadic) - **T3**:
  It sequentially contains the new values of optimized tensors and
  then the new values of their momentum tensors. For example, if two
  tensors &#34;X_1&#34; and &#34;X_2&#34; are optimized, the output list would be [new
  value of &#34;X_1,&#34; new value of &#34;X_2&#34; new momentum of &#34;X_1&#34;, new
  momentum of &#34;X_2&#34;].

**Type Constraints**

* **T1** in (
  tensor(double),
  tensor(float)
  ):
  Constrain input types to float scalars.
* **T2** in (
  tensor(int64)
  ):
  Constrain input types to 64-bit integer scalars.
* **T3** in (
  tensor(double),
  tensor(float)
  ):
  Constrain input types to float tensors.

**Examples**

**_momentum**

::

    import numpy as np
    import onnx

    # Define operator attributes.
    norm_coefficient = 0.001
    alpha = 0.95
    beta = 0.1

    # Create operator.
    node = onnx.helper.make_node(
        &#34;Momentum&#34;,
        inputs=[&#34;R&#34;, &#34;T&#34;, &#34;X&#34;, &#34;G&#34;, &#34;V&#34;],
        outputs=[&#34;X_new&#34;, &#34;V_new&#34;],
        norm_coefficient=norm_coefficient,
        alpha=alpha,
        beta=beta,
        mode=&#34;standard&#34;,
        domain=AI_ONNX_PREVIEW_TRAINING_DOMAIN,
    )

    # Define operator inputs.
    r = np.array(0.1, dtype=np.float32)  # scalar
    t = np.array(0, dtype=np.int64)  # scalar
    x = np.array([1.2, 2.8], dtype=np.float32)
    g = np.array([-0.94, -2.5], dtype=np.float32)
    v = np.array([1.7, 3.6], dtype=np.float32)

    # Compute expected outputs of Momentum.
    x_new, v_new = apply_momentum(r, t, x, g, v, norm_coefficient, alpha, beta)

    # Check results.
    expect(
        node,
        inputs=[r, t, x, g, v],
        outputs=[x_new, v_new],
        name=&#34;test_momentum&#34;,
        opset_imports=[
            onnx.helper.make_opsetid(AI_ONNX_PREVIEW_TRAINING_DOMAIN, 1)
        ],
    )

**_nesterov_momentum**

::

    import numpy as np
    import onnx

    # Define operator attributes.
    norm_coefficient = 0.01
    alpha = 0.95
    beta = 1.0

    # Create operator.
    node = onnx.helper.make_node(
        &#34;Momentum&#34;,
        inputs=[&#34;R&#34;, &#34;T&#34;, &#34;X&#34;, &#34;G&#34;, &#34;V&#34;],
        outputs=[&#34;X_new&#34;, &#34;V_new&#34;],
        norm_coefficient=norm_coefficient,
        alpha=alpha,
        beta=beta,
        mode=&#34;nesterov&#34;,
        domain=AI_ONNX_PREVIEW_TRAINING_DOMAIN,
    )

    # Define operator inputs.
    r = np.array(0.1, dtype=np.float32)  # scalar
    t = np.array(0, dtype=np.int64)  # scalar
    x = np.array([1.2, 2.8], dtype=np.float32)
    g = np.array([-0.94, -2.5], dtype=np.float32)
    v = np.array([1.7, 3.6], dtype=np.float32)

    # Compute expected outputs of Momentum.
    x_new, v_new = apply_nesterov(r, t, x, g, v, norm_coefficient, alpha, beta)

    # Check results.
    expect(
        node,
        inputs=[r, t, x, g, v],
        outputs=[x_new, v_new],
        name=&#34;test_nesterov_momentum&#34;,
        opset_imports=[
            onnx.helper.make_opsetid(AI_ONNX_PREVIEW_TRAINING_DOMAIN, 1)
        ],
    )

**_momentum_multiple**

::

    import numpy as np
    import onnx

    # Define operator attributes.
    norm_coefficient = 0.001
    alpha = 0.95
    beta = 0.85

    node = onnx.helper.make_node(
        &#34;Momentum&#34;,
        inputs=[&#34;R&#34;, &#34;T&#34;, &#34;X1&#34;, &#34;X2&#34;, &#34;G1&#34;, &#34;G2&#34;, &#34;H1&#34;, &#34;H2&#34;],
        outputs=[&#34;X1_new&#34;, &#34;X2_new&#34;, &#34;V1_new&#34;, &#34;V2_new&#34;],
        norm_coefficient=norm_coefficient,
        alpha=alpha,
        beta=beta,
        mode=&#34;standard&#34;,
        domain=AI_ONNX_PREVIEW_TRAINING_DOMAIN,
    )

    # Define operator inputs.
    r = np.array(0.1, dtype=np.float32)  # scalar
    t = np.array(0, dtype=np.int64)  # scalar

    x1 = np.array([1.0], dtype=np.float32)
    g1 = np.array([-1.0], dtype=np.float32)
    v1 = np.array([2.0], dtype=np.float32)

    x2 = np.array([1.0, 2.0], dtype=np.float32)
    g2 = np.array([-1.0, -3.0], dtype=np.float32)
    v2 = np.array([4.0, 1.0], dtype=np.float32)

    # Compute expected outputs of Momentum.
    x1_new, v1_new = apply_momentum(r, t, x1, g1, v1, norm_coefficient, alpha, beta)
    x2_new, v2_new = apply_momentum(r, t, x2, g2, v2, norm_coefficient, alpha, beta)

    # Check results.
    expect(
        node,
        inputs=[r, t, x1, x2, g1, g2, v1, v2],
        outputs=[x1_new, x2_new, v1_new, v2_new],
        name=&#34;test_momentum_multiple&#34;,
        opset_imports=[
            onnx.helper.make_opsetid(AI_ONNX_PREVIEW_TRAINING_DOMAIN, 1)
        ],
    )
