
.. _l-onnx-doc-ReduceL2:

========
ReduceL2
========

.. contents::
    :local:


.. _l-onnx-op-reducel2-13:

ReduceL2 - 13
=============

**Version**

* **name**: `ReduceL2 (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceL2>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

Computes the L2 norm of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then
the resulting tensor has the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor. Accepted range is [-r,
  r-1] where r = rank(data).
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

**Examples**

**_do_not_keepdims**

::

    shape = [3, 2, 2]
    axes = [2]
    keepdims = 0

    node = onnx.helper.make_node(
        "ReduceL2",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]], [[9., 10.], [11., 12.]]]

    reduced = np.sqrt(
        np.sum(a=np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    )
    # print(reduced)
    # [[2.23606798, 5.],
    # [7.81024968, 10.63014581],
    # [13.45362405, 16.2788206]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_do_not_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sqrt(
        np.sum(a=np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    )

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_do_not_keepdims_random",
    )

**_keepdims**

::

    shape = [3, 2, 2]
    axes = [2]
    keepdims = 1

    node = onnx.helper.make_node(
        "ReduceL2",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]], [[9., 10.], [11., 12.]]]

    reduced = np.sqrt(
        np.sum(a=np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    )
    # print(reduced)
    # [[[2.23606798], [5.]]
    # [[7.81024968], [10.63014581]]
    # [[13.45362405], [16.2788206 ]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_keep_dims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sqrt(
        np.sum(a=np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    )

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_keep_dims_random",
    )

**_default_axes_keepdims**

::

    shape = [3, 2, 2]
    axes = None
    keepdims = 1

    node = onnx.helper.make_node(
        "ReduceL2", inputs=["data"], outputs=["reduced"], keepdims=keepdims
    )

    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]], [[9., 10.], [11., 12.]]]

    reduced = np.sqrt(np.sum(a=np.square(data), axis=axes, keepdims=keepdims == 1))
    # print(reduced)
    # [[[25.49509757]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_default_axes_keepdims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sqrt(np.sum(a=np.square(data), axis=axes, keepdims=keepdims == 1))

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_default_axes_keepdims_random",
    )

**_negative_axes_keepdims**

::

    shape = [3, 2, 2]
    axes = [-1]
    keepdims = 1

    node = onnx.helper.make_node(
        "ReduceL2",
        inputs=["data"],
        outputs=["reduced"],
        axes=axes,
        keepdims=keepdims,
    )

    data = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)
    # print(data)
    # [[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]], [[9., 10.], [11., 12.]]]

    reduced = np.sqrt(
        np.sum(a=np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    )
    # print(reduced)
    # [[[2.23606798], [5.]]
    # [[7.81024968], [10.63014581]]
    # [[13.45362405], [16.2788206 ]]]

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_negative_axes_keep_dims_example",
    )

    np.random.seed(0)
    data = np.random.uniform(-10, 10, shape).astype(np.float32)
    reduced = np.sqrt(
        np.sum(a=np.square(data), axis=tuple(axes), keepdims=keepdims == 1)
    )

    expect(
        node,
        inputs=[data],
        outputs=[reduced],
        name="test_reduce_l2_negative_axes_keep_dims_random",
    )

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to165__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to165__0"><a href="#difflib_chg_to165__0">f</a></td><td class="diff_header" id="from165_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;L2&nbsp;norm&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td><td class="diff_next"><a href="#difflib_chg_to165__0">f</a></td><td class="diff_header" id="to165_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;L2&nbsp;norm&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to165__1">n</a></td><td class="diff_header" id="from165_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td><td class="diff_next"><a href="#difflib_chg_to165__1">n</a></td><td class="diff_header" id="to165_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal<span class="diff_add">s</span>&nbsp;0,&nbsp;then</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_3">3</td><td nowrap="nowrap">the&nbsp;result<span class="diff_chg">ed</span>&nbsp;tensor&nbsp;ha<span class="diff_chg">ve</span>&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td><td class="diff_next"></td><td class="diff_header" id="to165_3">3</td><td nowrap="nowrap">the&nbsp;result<span class="diff_chg">ing</span>&nbsp;tensor&nbsp;ha<span class="diff_chg">s</span>&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to165_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td><td class="diff_next"></td><td class="diff_header" id="to165_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_8">8</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to165_8">8</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td><td class="diff_next"></td><td class="diff_header" id="to165_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td><td class="diff_next"></td><td class="diff_header" id="to165_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</td><td class="diff_next"></td><td class="diff_header" id="to165_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</td><td class="diff_next"></td><td class="diff_header" id="to165_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td><td class="diff_next"></td><td class="diff_header" id="to165_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td><td class="diff_next"></td><td class="diff_header" id="to165_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td><td class="diff_next"></td><td class="diff_header" id="to165_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_18">18</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to165_18">18</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to165_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to165_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_23">23</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to165_23">23</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to165_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to165__1"></td><td class="diff_header" id="from165_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to165_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to165_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to165_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to165_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to165__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to165__top">t</a></td><td class="diff_header" id="to165_31">31</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to165_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to165_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to165_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to165_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to165_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to165_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to165_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to165_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from165_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to165_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-reducel2-11:

ReduceL2 - 11
=============

**Version**

* **name**: `ReduceL2 (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceL2>`_
* **domain**: **main**
* **since_version**: **11**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 11**.

**Summary**

Computes the L2 norm of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equal 0, then
the resulted tensor have the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor. Accepted range is [-r,
  r-1] where r = rank(data).
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to166__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next"><a href="#difflib_chg_to166__0">f</a></td><td class="diff_header" id="from166_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;L2&nbsp;norm&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td><td class="diff_next"><a href="#difflib_chg_to166__0">f</a></td><td class="diff_header" id="to166_1">1</td><td nowrap="nowrap">Computes&nbsp;the&nbsp;L2&nbsp;norm&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor's&nbsp;element&nbsp;along&nbsp;the&nbsp;provided&nbsp;axes.&nbsp;The&nbsp;resulting</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td><td class="diff_next"></td><td class="diff_header" id="to166_2">2</td><td nowrap="nowrap">tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;rank&nbsp;as&nbsp;the&nbsp;input&nbsp;if&nbsp;keepdims&nbsp;equals&nbsp;1.&nbsp;If&nbsp;keepdims&nbsp;equal&nbsp;0,&nbsp;then</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_3">3</td><td nowrap="nowrap">the&nbsp;resulted&nbsp;tensor&nbsp;have&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td><td class="diff_next"></td><td class="diff_header" id="to166_3">3</td><td nowrap="nowrap">the&nbsp;resulted&nbsp;tensor&nbsp;have&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;pruned.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_4">4</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to166_5">5</td><td nowrap="nowrap">The&nbsp;above&nbsp;behavior&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy,&nbsp;with&nbsp;the&nbsp;exception&nbsp;that&nbsp;numpy&nbsp;defaults&nbsp;keepdims&nbsp;to</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td><td class="diff_next"></td><td class="diff_header" id="to166_6">6</td><td nowrap="nowrap">False&nbsp;instead&nbsp;of&nbsp;True.</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to166__0"></td><td class="diff_header" id="from166_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_7">7</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_8">8</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to166_8">8</td><td nowrap="nowrap">**Attributes**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_9">9</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td><td class="diff_next"></td><td class="diff_header" id="to166_10">10</td><td nowrap="nowrap">*&nbsp;**axes**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td><td class="diff_next"></td><td class="diff_header" id="to166_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;integers,&nbsp;along&nbsp;which&nbsp;to&nbsp;reduce.&nbsp;The&nbsp;default&nbsp;is&nbsp;to&nbsp;reduce</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to166__top">t</a></td><td class="diff_header" id="from166_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.</td><td class="diff_next"><a href="#difflib_chg_to166__top">t</a></td><td class="diff_header" id="to166_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;over&nbsp;all&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the&nbsp;input&nbsp;tensor.<span class="diff_add">&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_13">13</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(data).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_13">13</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td><td class="diff_next"></td><td class="diff_header" id="to166_14">14</td><td nowrap="nowrap">*&nbsp;**keepdims**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td><td class="diff_next"></td><td class="diff_header" id="to166_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Keep&nbsp;the&nbsp;reduced&nbsp;dimension&nbsp;or&nbsp;not,&nbsp;default&nbsp;1&nbsp;means&nbsp;keep&nbsp;reduced</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td><td class="diff_next"></td><td class="diff_header" id="to166_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dimension.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_17">17</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_17">17</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to166_18">18</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_19">19</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_19">19</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to166_20">20</td><td nowrap="nowrap">*&nbsp;**data**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to166_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;An&nbsp;input&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_22">22</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_22">22</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to166_23">23</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_24">24</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_24">24</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to166_25">25</td><td nowrap="nowrap">*&nbsp;**reduced**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to166_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Reduced&nbsp;output&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_26">26</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_27">27</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_27">27</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to166_28">28</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_28">28</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to166_29">29</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_29">29</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to166_30">30</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to166_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to166_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to166_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to166_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to166_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to166_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to166_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to166_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from166_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to166_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;high-precision&nbsp;numeric&nbsp;tensors.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-reducel2-1:

ReduceL2 - 1
============

**Version**

* **name**: `ReduceL2 (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceL2>`_
* **domain**: **main**
* **since_version**: **1**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 1**.

**Summary**

Computes the L2 norm of the input tensor's element along the provided axes. The resulting
tensor has the same rank as the input if keepdims equals 1. If keepdims equal 0, then
the resulted tensor have the reduced dimension pruned.

The above behavior is similar to numpy, with the exception that numpy defaults keepdims to
False instead of True.

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to reduce
  over all the dimensions of the input tensor.
* **keepdims**:
  Keep the reduced dimension or not, default 1 means keep reduced
  dimension.

**Inputs**

* **data** (heterogeneous) - **T**:
  An input tensor.

**Outputs**

* **reduced** (heterogeneous) - **T**:
  Reduced output tensor.

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16),
  tensor(int32),
  tensor(int64),
  tensor(uint32),
  tensor(uint64)
  ):
  Constrain input and output types to high-precision numeric tensors.
