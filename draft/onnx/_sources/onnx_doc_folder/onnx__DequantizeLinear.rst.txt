
.. _l-onnx-doc-DequantizeLinear:

================
DequantizeLinear
================

.. contents::
    :local:


.. _l-onnx-op-dequantizelinear-13:
DequantizeLinear - 13
=====================
**Version**
* **name**: `DequantizeLinear (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#DequantizeLinear>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 13**.

**Summary**

The linear dequantization operator. It consumes a quantized tensor, a scale, and a zero point to compute the full precision tensor.
The dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' must have same shape, and can be either a scalar
for per-tensor / per layer quantization, or a 1-D tensor for per-axis quantization.
'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,
there's no zero point (zero point is supposed to be 0).

**Attributes**
* **axis**:
  (Optional) The axis of the dequantizing dimension of the input
  tensor. Ignored for per-tensor quantization. Negative value means
  counting dimensions from the back. Accepted range is [-r, r-1] where
  r = rank(input).

**Inputs**
Between 2 and 3 inputs.

* **x** (heterogeneous) - **T**:
  N-D quantized input tensor to be de-quantized.
* **x_scale** (heterogeneous) - **tensor(float)**:
  Scale for input 'x'. It can be a scalar, which means a per-
  tensor/layer dequantization, or a 1-D tensor for per-axis
  dequantization.
* **x_zero_point** (optional, heterogeneous) - **T**:
  Zero point for input 'x'. Shape must match x_scale. It's optional.
  Zero point is 0 when it's not specified.

**Outputs**

* **y** (heterogeneous) - **tensor(float)**:
  N-D full precision output tensor. It has same shape as input 'x'.

**Type Constraints**
* **T** in (
  tensor(int32),
  tensor(int8),
  tensor(uint8)
  ):
  Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.

**Examples**

**default**
::
    node = onnx.helper.make_node(
        "DequantizeLinear",
        inputs=["x", "x_scale", "x_zero_point"],
        outputs=["y"],
    )

    # scalar zero point and scale
    x = np.array([0, 3, 128, 255]).astype(np.uint8)
    x_scale = np.float32(2)
    x_zero_point = np.uint8(128)
    y = np.array([-256, -250, 0, 254], dtype=np.float32)

    expect(
        node,
        inputs=[x, x_scale, x_zero_point],
        outputs=[y],
        name="test_dequantizelinear",
    )

**_axis**
::
    node = onnx.helper.make_node(
        "DequantizeLinear",
        inputs=["x", "x_scale", "x_zero_point"],
        outputs=["y"],
    )

    # 1-D tensor zero point and scale of size equal to axis 1 of the input tensor
    x = np.array(
        [
            [
                [[3, 89], [34, 200], [74, 59]],
                [[5, 24], [24, 87], [32, 13]],
                [[245, 99], [4, 142], [121, 102]],
            ],
        ],
        dtype=np.uint8,
    )
    x_scale = np.array([2, 4, 5], dtype=np.float32)
    x_zero_point = np.array([84, 24, 196], dtype=np.uint8)
    y = (
        x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)
    ) * x_scale.reshape(1, 3, 1, 1)

    expect(
        node,
        inputs=[x, x_scale, x_zero_point],
        outputs=[y],
        name="test_dequantizelinear_axis",
    )

**Differences**

.. raw:: html

        <table class="diff" id="difflib_chg_to43__top"
               cellspacing="0" cellpadding="0" rules="groups" >
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
            <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

            <tbody>
                <tr><td class="diff_next" id="difflib_chg_to43__1"><a href="#difflib_chg_to43__1">n</a></td><td class="diff_header" id="from43_1">1</td><td nowrap="nowrap">The&nbsp;linear&nbsp;dequantization&nbsp;operator.&nbsp;It&nbsp;consumes&nbsp;a&nbsp;quantized&nbsp;tensor,&nbsp;a&nbsp;scale,&nbsp;a&nbsp;zero&nbsp;point&nbsp;to&nbsp;compute&nbsp;the&nbsp;full&nbsp;precision&nbsp;tensor.</td><td class="diff_next"><a href="#difflib_chg_to43__1">n</a></td><td class="diff_header" id="to43_1">1</td><td nowrap="nowrap">The&nbsp;linear&nbsp;dequantization&nbsp;operator.&nbsp;It&nbsp;consumes&nbsp;a&nbsp;quantized&nbsp;tensor,&nbsp;a&nbsp;scale,&nbsp;a<span class="diff_add">nd&nbsp;a</span>&nbsp;zero&nbsp;point&nbsp;to&nbsp;compute&nbsp;the&nbsp;full&nbsp;precision&nbsp;tensor.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_2">2</td><td nowrap="nowrap">The&nbsp;dequantization&nbsp;formula&nbsp;is&nbsp;y&nbsp;=&nbsp;(x&nbsp;-&nbsp;x_zero_point)&nbsp;*&nbsp;x_scale.&nbsp;'x_scale'&nbsp;and&nbsp;'x_zero_point'&nbsp;a<span class="diff_chg">r</span>e&nbsp;b<span class="diff_chg">o</span>th&nbsp;scalar<span class="diff_sub">s.</span></td><td class="diff_next"></td><td class="diff_header" id="to43_2">2</td><td nowrap="nowrap">The&nbsp;dequantization&nbsp;formula&nbsp;is&nbsp;y&nbsp;=&nbsp;(x&nbsp;-&nbsp;x_zero_point)&nbsp;*&nbsp;x_scale.&nbsp;'x_scale'&nbsp;and&nbsp;'x_zero_point'&nbsp;<span class="diff_add">must&nbsp;h</span>a<span class="diff_chg">v</span>e&nbsp;<span class="diff_add">same&nbsp;shape,&nbsp;and&nbsp;can&nbsp;</span>b<span class="diff_chg">e&nbsp;ei</span>th<span class="diff_add">er&nbsp;a</span>&nbsp;scalar</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_3">3</td><td nowrap="nowrap"><span class="diff_add">for&nbsp;per-tensor&nbsp;/&nbsp;per&nbsp;layer&nbsp;quantization,&nbsp;or&nbsp;a&nbsp;1-D&nbsp;tensor&nbsp;for&nbsp;per-axis&nbsp;quantization.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_3">3</td><td nowrap="nowrap">'x_zero_point'&nbsp;and&nbsp;'x'&nbsp;must&nbsp;have&nbsp;same&nbsp;type.&nbsp;'x'&nbsp;and&nbsp;'y'&nbsp;must&nbsp;have&nbsp;same&nbsp;shape.&nbsp;In&nbsp;the&nbsp;case&nbsp;of&nbsp;dequantizing&nbsp;int32,</td><td class="diff_next"></td><td class="diff_header" id="to43_4">4</td><td nowrap="nowrap">'x_zero_point'&nbsp;and&nbsp;'x'&nbsp;must&nbsp;have&nbsp;same&nbsp;type.&nbsp;'x'&nbsp;and&nbsp;'y'&nbsp;must&nbsp;have&nbsp;same&nbsp;shape.&nbsp;In&nbsp;the&nbsp;case&nbsp;of&nbsp;dequantizing&nbsp;int32,</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_4">4</td><td nowrap="nowrap">there's&nbsp;no&nbsp;zero&nbsp;point&nbsp;(zero&nbsp;point&nbsp;is&nbsp;supposed&nbsp;to&nbsp;be&nbsp;0).</td><td class="diff_next"></td><td class="diff_header" id="to43_5">5</td><td nowrap="nowrap">there's&nbsp;no&nbsp;zero&nbsp;point&nbsp;(zero&nbsp;point&nbsp;is&nbsp;supposed&nbsp;to&nbsp;be&nbsp;0).</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to43__2">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to43__2">n</a></td><td class="diff_header" id="to43_6">6</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_7">7</td><td nowrap="nowrap"><span class="diff_add">**Attributes**</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_8">8</td><td nowrap="nowrap"><span class="diff_add">*&nbsp;**axis**:</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_9">9</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;(Optional)&nbsp;The&nbsp;axis&nbsp;of&nbsp;the&nbsp;dequantizing&nbsp;dimension&nbsp;of&nbsp;the&nbsp;input</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_10">10</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor.&nbsp;Ignored&nbsp;for&nbsp;per-tensor&nbsp;quantization.&nbsp;Negative&nbsp;value&nbsp;means</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_11">11</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is&nbsp;[-r,&nbsp;r-1]&nbsp;where</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_12">12</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;r&nbsp;=&nbsp;rank(input).</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_13">13</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_6">6</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to43_14">14</td><td nowrap="nowrap">**Inputs**</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to43__2"></td><td class="diff_header" id="from43_7">7</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to43_15">15</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_8">8</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_16">16</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_9">9</td><td nowrap="nowrap">*&nbsp;**x**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to43_17">17</td><td nowrap="nowrap">*&nbsp;**x**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_10">10</td><td nowrap="nowrap">&nbsp;&nbsp;N-D&nbsp;quantized&nbsp;input&nbsp;tensor&nbsp;to&nbsp;be&nbsp;de-quantized.</td><td class="diff_next"></td><td class="diff_header" id="to43_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;N-D&nbsp;quantized&nbsp;input&nbsp;tensor&nbsp;to&nbsp;be&nbsp;de-quantized.</td></tr>
                <tr><td class="diff_next" id="difflib_chg_to43__3"></td><td class="diff_header" id="from43_11">11</td><td nowrap="nowrap">*&nbsp;**x_scale**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(float)**:</td><td class="diff_next"></td><td class="diff_header" id="to43_19">19</td><td nowrap="nowrap">*&nbsp;**x_scale**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(float)**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to43__3">n</a></td><td class="diff_header" id="from43_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Scale&nbsp;for&nbsp;input&nbsp;'x'.&nbsp;It<span class="diff_chg">'s&nbsp;</span>a&nbsp;scalar,&nbsp;which&nbsp;means&nbsp;a&nbsp;per-<span class="diff_sub">tensor/layer</span></td><td class="diff_next"><a href="#difflib_chg_to43__3">n</a></td><td class="diff_header" id="to43_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Scale&nbsp;for&nbsp;input&nbsp;'x'.&nbsp;It<span class="diff_chg">&nbsp;c</span>a<span class="diff_add">n&nbsp;be&nbsp;a</span>&nbsp;scalar,&nbsp;which&nbsp;means&nbsp;a&nbsp;per-</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_21">21</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor/layer&nbsp;dequantization,&nbsp;or&nbsp;a&nbsp;1-D&nbsp;tensor&nbsp;for&nbsp;per-axis</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;quantization.</td><td class="diff_next"></td><td class="diff_header" id="to43_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;<span class="diff_add">de</span>quantization.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_14">14</td><td nowrap="nowrap">*&nbsp;**x_zero_point**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to43_23">23</td><td nowrap="nowrap">*&nbsp;**x_zero_point**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
                <tr><td class="diff_next"><a href="#difflib_chg_to43__top">t</a></td><td class="diff_header" id="from43_15">15</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Zero&nbsp;point&nbsp;for&nbsp;input&nbsp;'x'.&nbsp;It's&nbsp;a&nbsp;scalar,&nbsp;which&nbsp;means&nbsp;a&nbsp;per-</span></td><td class="diff_next"><a href="#difflib_chg_to43__top">t</a></td><td class="diff_header" id="to43_24">24</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Zero&nbsp;point&nbsp;for&nbsp;input&nbsp;'x'.&nbsp;Shape&nbsp;must&nbsp;match&nbsp;x_scale.&nbsp;It's&nbsp;optional.</span></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_16">16</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;tensor/layer&nbsp;quantization.&nbsp;It's&nbsp;optional.&nbsp;0&nbsp;is&nbsp;the&nbsp;default&nbsp;value</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;when&nbsp;it's&nbsp;not&nbsp;specified.</td><td class="diff_next"></td><td class="diff_header" id="to43_25">25</td><td nowrap="nowrap">&nbsp;<span class="diff_add">&nbsp;Zero&nbsp;point&nbsp;is&nbsp;0</span>&nbsp;when&nbsp;it's&nbsp;not&nbsp;specified.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_26">26</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_19">19</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to43_27">27</td><td nowrap="nowrap">**Outputs**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_20">20</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_28">28</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_21">21</td><td nowrap="nowrap">*&nbsp;**y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(float)**:</td><td class="diff_next"></td><td class="diff_header" id="to43_29">29</td><td nowrap="nowrap">*&nbsp;**y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(float)**:</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;N-D&nbsp;full&nbsp;precision&nbsp;output&nbsp;tensor.&nbsp;It&nbsp;has&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;'x'.</td><td class="diff_next"></td><td class="diff_header" id="to43_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;N-D&nbsp;full&nbsp;precision&nbsp;output&nbsp;tensor.&nbsp;It&nbsp;has&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;'x'.</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to43_31">31</td><td nowrap="nowrap"></td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_24">24</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to43_32">32</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_25">25</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to43_33">33</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to43_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int8),</td><td class="diff_next"></td><td class="diff_header" id="to43_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int8),</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint8)</td><td class="diff_next"></td><td class="diff_header" id="to43_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint8)</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to43_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
                <tr><td class="diff_next"></td><td class="diff_header" id="from43_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;'x_zero_point'&nbsp;and&nbsp;'x'&nbsp;to&nbsp;8-bit/32-bit&nbsp;integer&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to43_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;'x_zero_point'&nbsp;and&nbsp;'x'&nbsp;to&nbsp;8-bit/32-bit&nbsp;integer&nbsp;tensor.</td></tr>
            </tbody>
        </table>

.. _l-onnx-op-dequantizelinear-10:
DequantizeLinear - 10
=====================
**Version**
* **name**: `DequantizeLinear (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#DequantizeLinear>`_
* **domain**: **main**
* **since_version**: **10**
* **function**: False
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 10**.

**Summary**

The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.
The dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.
'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,
there's no zero point (zero point is supposed to be 0).

**Inputs**
Between 2 and 3 inputs.

* **x** (heterogeneous) - **T**:
  N-D quantized input tensor to be de-quantized.
* **x_scale** (heterogeneous) - **tensor(float)**:
  Scale for input 'x'. It's a scalar, which means a per-tensor/layer
  quantization.
* **x_zero_point** (optional, heterogeneous) - **T**:
  Zero point for input 'x'. It's a scalar, which means a per-
  tensor/layer quantization. It's optional. 0 is the default value
  when it's not specified.

**Outputs**

* **y** (heterogeneous) - **tensor(float)**:
  N-D full precision output tensor. It has same shape as input 'x'.

**Type Constraints**
* **T** in (
  tensor(int32),
  tensor(int8),
  tensor(uint8)
  ):
  Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
