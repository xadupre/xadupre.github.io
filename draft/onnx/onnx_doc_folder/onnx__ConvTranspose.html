<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>ConvTranspose &#8212; ONNX 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cos" href="onnx__Cos.html" />
    <link rel="prev" title="ConvInteger" href="onnx__ConvInteger.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ONNX Docs</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../onnx-api/index.html">API Overview</a></li>
                <li><a href="../operators/index.html">Op Schemas</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">API Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.checker.html">onnx.checker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.compose.html">onnx.compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.external_data_helper.html">onnx.external_data_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.helper.html">onnx.helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.hub.html">onnx.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.numpy_helper.html">onnx.numpy_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.parser.html">onnx.parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.utils.html">onnx.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version.version.html">onnx.version.version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version_converter.html">onnx.version_converter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Operators + OpSchemas</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">ONNX operators</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">ConvTranspose</a><ul>
<li><a class="reference internal" href="#convtranspose-11">ConvTranspose - 11</a></li>
<li><a class="reference internal" href="#convtranspose-1">ConvTranspose - 1</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="onnx__ConvInteger.html" title="Previous Chapter: ConvInteger"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; ConvInteger</span>
    </a>
  </li>
  <li>
    <a href="onnx__Cos.html" title="Next Chapter: Cos"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Cos &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/onnx_doc_folder/onnx__ConvTranspose.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="convtranspose">
<span id="l-onnx-doc-convtranspose"></span><h1>ConvTranspose<a class="headerlink" href="#convtranspose" title="Permalink to this heading">¶</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#convtranspose-11" id="id2">ConvTranspose - 11</a></p></li>
<li><p><a class="reference internal" href="#convtranspose-1" id="id3">ConvTranspose - 1</a></p></li>
</ul>
</nav>
<section id="convtranspose-11">
<span id="l-onnx-op-convtranspose-11"></span><h2><a class="toc-backref" href="#id2" role="doc-backlink">ConvTranspose - 11</a><a class="headerlink" href="#convtranspose-11" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose">ConvTranspose (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>11</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 11</strong>.</p>
<p><strong>Summary</strong></p>
<p>The convolution transpose operator consumes an input tensor and a filter,
and computes the output.</p>
<p>If the pads parameter is provided the shape of the output is calculated via the following equation:</p>
<blockquote>
<div><p>output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]</p>
</div></blockquote>
<p>output_shape can also be explicitly specified in which case pads values are auto generated using these equations:</p>
<blockquote>
<div><p>total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]
If (auto_pads == SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).</p>
</div></blockquote>
<p><strong>Attributes</strong>
* <strong>auto_pad</strong>:</p>
<blockquote>
<div><p>auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
Where default value is NOTSET, which means explicit padding is used.
SAME_UPPER or SAME_LOWER mean pad the input so that <cite>output_shape[i]
= input_shape[i] * strides[i]</cite> for each axis <cite>i</cite>. The padding is
split between the two sides equally or almost equally (depending on
whether it is even or odd). In case the padding is an odd number,
the extra padding is added at the end for SAME_UPPER and at the
beginning for SAME_LOWER.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>dilations</strong>:
dilation value along each spatial axis of the filter. If not
present, the dilation defaults to 1 along each spatial axis.</p></li>
<li><p><strong>group</strong>:
number of groups input channels and output channels are divided
into.</p></li>
<li><p><strong>kernel_shape</strong>:
The shape of the convolution kernel. If not present, should be
inferred from input W.</p></li>
<li><p><strong>output_padding</strong>:
Additional elements added to the side with higher coordinate indices
in the output. Each padding value in “output_padding” must be less
than the corresponding stride/dilation dimension. By default, this
attribute is a zero vector. Note that this attribute doesn’t
directly affect the computed output values. It only controls the
selection of the computed values, so changing this attribute only
adds or removes output elements. If “output_shape” is explicitly
provided, “output_padding” does not contribute additional size to
“output_shape” but participates in the computation of the needed
padding amount. This is also called adjs or adjustment in some
frameworks.</p></li>
<li><p><strong>output_shape</strong>:
The shape of the output can be explicitly set which will cause pads
values to be auto generated. If output_shape is specified pads
values are ignored. See doc for details for equations to generate
pads</p></li>
<li><p><strong>pads</strong>:
Padding for the beginning and ending along each spatial axis, it can
take any value greater than or equal to 0. The value represent the
number of pixels added to the beginning and end part of the
corresponding axis. <cite>pads</cite> format should be as follow [x1_begin,
x2_begin…x1_end, x2_end,…], where xi_begin the number of pixels
added at the beginning of axis <cite>i</cite> and xi_end, the number of pixels
added at the end of axis <cite>i</cite>. This attribute cannot be used
simultaneously with auto_pad attribute. If not present, the padding
defaults to 0 along start and end of each spatial axis.</p></li>
<li><p><strong>strides</strong>:
Stride along each spatial axis. If not present, the stride defaults
to 1 along each spatial axis.</p></li>
</ul>
<p><strong>Inputs</strong>
Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from previous layer; has size (N x C x H x W),
where N is the batch size, C is the number of channels, and H and W
are the height and width. Note that this is for the 2D image.
Otherwise the size is (N x C x D1 x D2 … x Dn)</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor that will be used in the convolutions; has size (C
x M/group x kH x kW), where C is the number of channels, and kH and
kW are the height and width of the kernel, and M is the number of
feature maps. For more than 2 dimensions, the weight shape will be
(C x M/group x k1 x k2 x … x kn), where (k1 x k2 x … x kn) is
the dimension of the kernel. The number of channels in the output
should be equal to W.shape[1] * group (assuming zero based indices
of the shape array)</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional 1D bias to be added to the convolution, has size of M.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output data tensor that contains the result of the convolution. The
output dimensions are functions of the kernel size, stride size, pad
lengths and group count. The number of channels in the output should
be equal to W.shape[1] * group (assuming zero based indices of the
shape array)</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
<p><strong>Examples</strong></p>
<p><strong>default</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]]]]</span>  <span class="c1"># (1, 1, 3, 3)</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>  <span class="c1"># (1, 2, 3, 3)</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>  <span class="c1"># (1, 2, 5, 5)</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">36.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">],</span>
            <span class="p">],</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">36.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">],</span>
            <span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_convtranspose_1d</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (1, 1, 3)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># (1, 2, 3)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]]]</span>  <span class="c1"># (1, 2, 5)</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_1d&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_convtranspose_3d</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 4, 5)</span>
                    <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">14.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">17.0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">20.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">,</span> <span class="mf">23.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span> <span class="mf">26.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">28.0</span><span class="p">,</span> <span class="mf">29.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">30.0</span><span class="p">,</span> <span class="mf">31.0</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">34.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">35.0</span><span class="p">,</span> <span class="mf">36.0</span><span class="p">,</span> <span class="mf">37.0</span><span class="p">,</span> <span class="mf">38.0</span><span class="p">,</span> <span class="mf">39.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">40.0</span><span class="p">,</span> <span class="mf">41.0</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">,</span> <span class="mf">43.0</span><span class="p">,</span> <span class="mf">44.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">45.0</span><span class="p">,</span> <span class="mf">46.0</span><span class="p">,</span> <span class="mf">47.0</span><span class="p">,</span> <span class="mf">48.0</span><span class="p">,</span> <span class="mf">49.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">50.0</span><span class="p">,</span> <span class="mf">51.0</span><span class="p">,</span> <span class="mf">52.0</span><span class="p">,</span> <span class="mf">53.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">55.0</span><span class="p">,</span> <span class="mf">56.0</span><span class="p">,</span> <span class="mf">57.0</span><span class="p">,</span> <span class="mf">58.0</span><span class="p">,</span> <span class="mf">59.0</span><span class="p">],</span>
                <span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># (1, 2, 3, 3, 3)</span>
                    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
            <span class="p">],</span>
            <span class="p">[</span>
                <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
            <span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span>  <span class="c1"># (1, 2, 5, 6, 7)</span>
                    <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">,</span> <span class="mf">63.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">,</span> <span class="mf">51.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">30.0</span><span class="p">,</span> <span class="mf">63.0</span><span class="p">,</span> <span class="mf">99.0</span><span class="p">,</span> <span class="mf">108.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span> <span class="mf">52.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">,</span> <span class="mf">87.0</span><span class="p">,</span> <span class="mf">93.0</span><span class="p">,</span> <span class="mf">64.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">31.0</span><span class="p">,</span> <span class="mf">48.0</span><span class="p">,</span> <span class="mf">51.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">,</span> <span class="mf">37.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">20.0</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">,</span> <span class="mf">66.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">,</span> <span class="mf">78.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">,</span> <span class="mf">28.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">50.0</span><span class="p">,</span> <span class="mf">104.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">,</span> <span class="mf">174.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">,</span> <span class="mf">128.0</span><span class="p">,</span> <span class="mf">66.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">90.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">,</span> <span class="mf">288.0</span><span class="p">,</span> <span class="mf">306.0</span><span class="p">,</span> <span class="mf">324.0</span><span class="p">,</span> <span class="mf">222.0</span><span class="p">,</span> <span class="mf">114.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">120.0</span><span class="p">,</span> <span class="mf">246.0</span><span class="p">,</span> <span class="mf">378.0</span><span class="p">,</span> <span class="mf">396.0</span><span class="p">,</span> <span class="mf">414.0</span><span class="p">,</span> <span class="mf">282.0</span><span class="p">,</span> <span class="mf">144.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">90.0</span><span class="p">,</span> <span class="mf">184.0</span><span class="p">,</span> <span class="mf">282.0</span><span class="p">,</span> <span class="mf">294.0</span><span class="p">,</span> <span class="mf">306.0</span><span class="p">,</span> <span class="mf">208.0</span><span class="p">,</span> <span class="mf">106.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">50.0</span><span class="p">,</span> <span class="mf">102.0</span><span class="p">,</span> <span class="mf">156.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">,</span> <span class="mf">168.0</span><span class="p">,</span> <span class="mf">114.0</span><span class="p">,</span> <span class="mf">58.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">60.0</span><span class="p">,</span> <span class="mf">123.0</span><span class="p">,</span> <span class="mf">189.0</span><span class="p">,</span> <span class="mf">198.0</span><span class="p">,</span> <span class="mf">207.0</span><span class="p">,</span> <span class="mf">141.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">135.0</span><span class="p">,</span> <span class="mf">276.0</span><span class="p">,</span> <span class="mf">423.0</span><span class="p">,</span> <span class="mf">441.0</span><span class="p">,</span> <span class="mf">459.0</span><span class="p">,</span> <span class="mf">312.0</span><span class="p">,</span> <span class="mf">159.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">225.0</span><span class="p">,</span> <span class="mf">459.0</span><span class="p">,</span> <span class="mf">702.0</span><span class="p">,</span> <span class="mf">729.0</span><span class="p">,</span> <span class="mf">756.0</span><span class="p">,</span> <span class="mf">513.0</span><span class="p">,</span> <span class="mf">261.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">270.0</span><span class="p">,</span> <span class="mf">549.0</span><span class="p">,</span> <span class="mf">837.0</span><span class="p">,</span> <span class="mf">864.0</span><span class="p">,</span> <span class="mf">891.0</span><span class="p">,</span> <span class="mf">603.0</span><span class="p">,</span> <span class="mf">306.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">195.0</span><span class="p">,</span> <span class="mf">396.0</span><span class="p">,</span> <span class="mf">603.0</span><span class="p">,</span> <span class="mf">621.0</span><span class="p">,</span> <span class="mf">639.0</span><span class="p">,</span> <span class="mf">432.0</span><span class="p">,</span> <span class="mf">219.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">105.0</span><span class="p">,</span> <span class="mf">213.0</span><span class="p">,</span> <span class="mf">324.0</span><span class="p">,</span> <span class="mf">333.0</span><span class="p">,</span> <span class="mf">342.0</span><span class="p">,</span> <span class="mf">231.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">60.0</span><span class="p">,</span> <span class="mf">122.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">,</span> <span class="mf">192.0</span><span class="p">,</span> <span class="mf">198.0</span><span class="p">,</span> <span class="mf">134.0</span><span class="p">,</span> <span class="mf">68.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">130.0</span><span class="p">,</span> <span class="mf">264.0</span><span class="p">,</span> <span class="mf">402.0</span><span class="p">,</span> <span class="mf">414.0</span><span class="p">,</span> <span class="mf">426.0</span><span class="p">,</span> <span class="mf">288.0</span><span class="p">,</span> <span class="mf">146.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">210.0</span><span class="p">,</span> <span class="mf">426.0</span><span class="p">,</span> <span class="mf">648.0</span><span class="p">,</span> <span class="mf">666.0</span><span class="p">,</span> <span class="mf">684.0</span><span class="p">,</span> <span class="mf">462.0</span><span class="p">,</span> <span class="mf">234.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">240.0</span><span class="p">,</span> <span class="mf">486.0</span><span class="p">,</span> <span class="mf">738.0</span><span class="p">,</span> <span class="mf">756.0</span><span class="p">,</span> <span class="mf">774.0</span><span class="p">,</span> <span class="mf">522.0</span><span class="p">,</span> <span class="mf">264.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">170.0</span><span class="p">,</span> <span class="mf">344.0</span><span class="p">,</span> <span class="mf">522.0</span><span class="p">,</span> <span class="mf">534.0</span><span class="p">,</span> <span class="mf">546.0</span><span class="p">,</span> <span class="mf">368.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">90.0</span><span class="p">,</span> <span class="mf">182.0</span><span class="p">,</span> <span class="mf">276.0</span><span class="p">,</span> <span class="mf">282.0</span><span class="p">,</span> <span class="mf">288.0</span><span class="p">,</span> <span class="mf">194.0</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">40.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">,</span> <span class="mf">123.0</span><span class="p">,</span> <span class="mf">126.0</span><span class="p">,</span> <span class="mf">129.0</span><span class="p">,</span> <span class="mf">87.0</span><span class="p">,</span> <span class="mf">44.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">85.0</span><span class="p">,</span> <span class="mf">172.0</span><span class="p">,</span> <span class="mf">261.0</span><span class="p">,</span> <span class="mf">267.0</span><span class="p">,</span> <span class="mf">273.0</span><span class="p">,</span> <span class="mf">184.0</span><span class="p">,</span> <span class="mf">93.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">135.0</span><span class="p">,</span> <span class="mf">273.0</span><span class="p">,</span> <span class="mf">414.0</span><span class="p">,</span> <span class="mf">423.0</span><span class="p">,</span> <span class="mf">432.0</span><span class="p">,</span> <span class="mf">291.0</span><span class="p">,</span> <span class="mf">147.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">150.0</span><span class="p">,</span> <span class="mf">303.0</span><span class="p">,</span> <span class="mf">459.0</span><span class="p">,</span> <span class="mf">468.0</span><span class="p">,</span> <span class="mf">477.0</span><span class="p">,</span> <span class="mf">321.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">105.0</span><span class="p">,</span> <span class="mf">212.0</span><span class="p">,</span> <span class="mf">321.0</span><span class="p">,</span> <span class="mf">327.0</span><span class="p">,</span> <span class="mf">333.0</span><span class="p">,</span> <span class="mf">224.0</span><span class="p">,</span> <span class="mf">113.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">55.0</span><span class="p">,</span> <span class="mf">111.0</span><span class="p">,</span> <span class="mf">168.0</span><span class="p">,</span> <span class="mf">171.0</span><span class="p">,</span> <span class="mf">174.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">,</span> <span class="mf">59.0</span><span class="p">],</span>
                <span class="p">],</span>
            <span class="p">],</span>
            <span class="p">[</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">,</span> <span class="mf">63.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">,</span> <span class="mf">51.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">30.0</span><span class="p">,</span> <span class="mf">63.0</span><span class="p">,</span> <span class="mf">99.0</span><span class="p">,</span> <span class="mf">108.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span> <span class="mf">52.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">,</span> <span class="mf">87.0</span><span class="p">,</span> <span class="mf">93.0</span><span class="p">,</span> <span class="mf">64.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">31.0</span><span class="p">,</span> <span class="mf">48.0</span><span class="p">,</span> <span class="mf">51.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">,</span> <span class="mf">37.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">20.0</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">,</span> <span class="mf">66.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">,</span> <span class="mf">78.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">,</span> <span class="mf">28.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">50.0</span><span class="p">,</span> <span class="mf">104.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">,</span> <span class="mf">174.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">,</span> <span class="mf">128.0</span><span class="p">,</span> <span class="mf">66.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">90.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">,</span> <span class="mf">288.0</span><span class="p">,</span> <span class="mf">306.0</span><span class="p">,</span> <span class="mf">324.0</span><span class="p">,</span> <span class="mf">222.0</span><span class="p">,</span> <span class="mf">114.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">120.0</span><span class="p">,</span> <span class="mf">246.0</span><span class="p">,</span> <span class="mf">378.0</span><span class="p">,</span> <span class="mf">396.0</span><span class="p">,</span> <span class="mf">414.0</span><span class="p">,</span> <span class="mf">282.0</span><span class="p">,</span> <span class="mf">144.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">90.0</span><span class="p">,</span> <span class="mf">184.0</span><span class="p">,</span> <span class="mf">282.0</span><span class="p">,</span> <span class="mf">294.0</span><span class="p">,</span> <span class="mf">306.0</span><span class="p">,</span> <span class="mf">208.0</span><span class="p">,</span> <span class="mf">106.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">50.0</span><span class="p">,</span> <span class="mf">102.0</span><span class="p">,</span> <span class="mf">156.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">,</span> <span class="mf">168.0</span><span class="p">,</span> <span class="mf">114.0</span><span class="p">,</span> <span class="mf">58.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">60.0</span><span class="p">,</span> <span class="mf">123.0</span><span class="p">,</span> <span class="mf">189.0</span><span class="p">,</span> <span class="mf">198.0</span><span class="p">,</span> <span class="mf">207.0</span><span class="p">,</span> <span class="mf">141.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">135.0</span><span class="p">,</span> <span class="mf">276.0</span><span class="p">,</span> <span class="mf">423.0</span><span class="p">,</span> <span class="mf">441.0</span><span class="p">,</span> <span class="mf">459.0</span><span class="p">,</span> <span class="mf">312.0</span><span class="p">,</span> <span class="mf">159.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">225.0</span><span class="p">,</span> <span class="mf">459.0</span><span class="p">,</span> <span class="mf">702.0</span><span class="p">,</span> <span class="mf">729.0</span><span class="p">,</span> <span class="mf">756.0</span><span class="p">,</span> <span class="mf">513.0</span><span class="p">,</span> <span class="mf">261.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">270.0</span><span class="p">,</span> <span class="mf">549.0</span><span class="p">,</span> <span class="mf">837.0</span><span class="p">,</span> <span class="mf">864.0</span><span class="p">,</span> <span class="mf">891.0</span><span class="p">,</span> <span class="mf">603.0</span><span class="p">,</span> <span class="mf">306.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">195.0</span><span class="p">,</span> <span class="mf">396.0</span><span class="p">,</span> <span class="mf">603.0</span><span class="p">,</span> <span class="mf">621.0</span><span class="p">,</span> <span class="mf">639.0</span><span class="p">,</span> <span class="mf">432.0</span><span class="p">,</span> <span class="mf">219.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">105.0</span><span class="p">,</span> <span class="mf">213.0</span><span class="p">,</span> <span class="mf">324.0</span><span class="p">,</span> <span class="mf">333.0</span><span class="p">,</span> <span class="mf">342.0</span><span class="p">,</span> <span class="mf">231.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">60.0</span><span class="p">,</span> <span class="mf">122.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">,</span> <span class="mf">192.0</span><span class="p">,</span> <span class="mf">198.0</span><span class="p">,</span> <span class="mf">134.0</span><span class="p">,</span> <span class="mf">68.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">130.0</span><span class="p">,</span> <span class="mf">264.0</span><span class="p">,</span> <span class="mf">402.0</span><span class="p">,</span> <span class="mf">414.0</span><span class="p">,</span> <span class="mf">426.0</span><span class="p">,</span> <span class="mf">288.0</span><span class="p">,</span> <span class="mf">146.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">210.0</span><span class="p">,</span> <span class="mf">426.0</span><span class="p">,</span> <span class="mf">648.0</span><span class="p">,</span> <span class="mf">666.0</span><span class="p">,</span> <span class="mf">684.0</span><span class="p">,</span> <span class="mf">462.0</span><span class="p">,</span> <span class="mf">234.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">240.0</span><span class="p">,</span> <span class="mf">486.0</span><span class="p">,</span> <span class="mf">738.0</span><span class="p">,</span> <span class="mf">756.0</span><span class="p">,</span> <span class="mf">774.0</span><span class="p">,</span> <span class="mf">522.0</span><span class="p">,</span> <span class="mf">264.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">170.0</span><span class="p">,</span> <span class="mf">344.0</span><span class="p">,</span> <span class="mf">522.0</span><span class="p">,</span> <span class="mf">534.0</span><span class="p">,</span> <span class="mf">546.0</span><span class="p">,</span> <span class="mf">368.0</span><span class="p">,</span> <span class="mf">186.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">90.0</span><span class="p">,</span> <span class="mf">182.0</span><span class="p">,</span> <span class="mf">276.0</span><span class="p">,</span> <span class="mf">282.0</span><span class="p">,</span> <span class="mf">288.0</span><span class="p">,</span> <span class="mf">194.0</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="p">[</span><span class="mf">40.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">,</span> <span class="mf">123.0</span><span class="p">,</span> <span class="mf">126.0</span><span class="p">,</span> <span class="mf">129.0</span><span class="p">,</span> <span class="mf">87.0</span><span class="p">,</span> <span class="mf">44.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">85.0</span><span class="p">,</span> <span class="mf">172.0</span><span class="p">,</span> <span class="mf">261.0</span><span class="p">,</span> <span class="mf">267.0</span><span class="p">,</span> <span class="mf">273.0</span><span class="p">,</span> <span class="mf">184.0</span><span class="p">,</span> <span class="mf">93.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">135.0</span><span class="p">,</span> <span class="mf">273.0</span><span class="p">,</span> <span class="mf">414.0</span><span class="p">,</span> <span class="mf">423.0</span><span class="p">,</span> <span class="mf">432.0</span><span class="p">,</span> <span class="mf">291.0</span><span class="p">,</span> <span class="mf">147.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">150.0</span><span class="p">,</span> <span class="mf">303.0</span><span class="p">,</span> <span class="mf">459.0</span><span class="p">,</span> <span class="mf">468.0</span><span class="p">,</span> <span class="mf">477.0</span><span class="p">,</span> <span class="mf">321.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">105.0</span><span class="p">,</span> <span class="mf">212.0</span><span class="p">,</span> <span class="mf">321.0</span><span class="p">,</span> <span class="mf">327.0</span><span class="p">,</span> <span class="mf">333.0</span><span class="p">,</span> <span class="mf">224.0</span><span class="p">,</span> <span class="mf">113.0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">55.0</span><span class="p">,</span> <span class="mf">111.0</span><span class="p">,</span> <span class="mf">168.0</span><span class="p">,</span> <span class="mf">171.0</span><span class="p">,</span> <span class="mf">174.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">,</span> <span class="mf">59.0</span><span class="p">],</span>
                <span class="p">],</span>
            <span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_3d&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_convtranspose_attributes</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]]]]</span>  <span class="c1"># (1, 1, 3, 3)</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>  <span class="c1"># (1, 2, 3, 3)</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>  <span class="c1"># (1, 2, 10, 8)</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
            <span class="p">],</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
            <span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_output_shape&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">output_padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_pad&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span>
    <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="n">output_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">output_padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_kernel_shape&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_convtranspose_pads</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]]]]</span>  <span class="c1"># (1, 1, 3, 3)</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>  <span class="c1"># (1, 2, 3, 3)</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">pads</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span>  <span class="c1"># (1, 2, 7, 3)</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">],</span>
            <span class="p">],</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">],</span>
            <span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_pads&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_convtranspose_dilations</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[[[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]]]]</span>  <span class="c1"># (1, 1, 3, 3)</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (1, 1, 2, 2)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">dilations</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">21.0</span><span class="p">,</span> <span class="mf">56.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>  <span class="c1"># [1, 1, 5, 5]</span>
                <span class="p">[</span><span class="mf">63.0</span><span class="p">,</span> <span class="mf">35.0</span><span class="p">,</span> <span class="mf">67.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">14.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">,</span> <span class="mf">76.0</span><span class="p">,</span> <span class="mf">76.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">88.0</span><span class="p">,</span> <span class="mf">45.0</span><span class="p">,</span> <span class="mf">63.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_dilations&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_convtranspose_autopad_same</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]]]]</span>  <span class="c1"># (1, 1, 3, 3)</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>  <span class="c1"># (1, 2, 3, 3)</span>
            <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">auto_pad</span><span class="o">=</span><span class="s2">&quot;SAME_UPPER&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">],</span>
            <span class="p">],</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">],</span>
            <span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_convtranspose_autopad_same&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to39__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to39__0">f</a></td><td class="diff_header" id="from39_1">1</td><td nowrap="nowrap">The&nbsp;convolution&nbsp;transpose&nbsp;operator&nbsp;consumes&nbsp;an&nbsp;input&nbsp;tensor&nbsp;and&nbsp;a&nbsp;filter,</td><td class="diff_next"><a href="#difflib_chg_to39__0">f</a></td><td class="diff_header" id="to39_1">1</td><td nowrap="nowrap">The&nbsp;convolution&nbsp;transpose&nbsp;operator&nbsp;consumes&nbsp;an&nbsp;input&nbsp;tensor&nbsp;and&nbsp;a&nbsp;filter,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_2">2</td><td nowrap="nowrap">and&nbsp;computes&nbsp;the&nbsp;output.</td><td class="diff_next"></td><td class="diff_header" id="to39_2">2</td><td nowrap="nowrap">and&nbsp;computes&nbsp;the&nbsp;output.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_3">3</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_4">4</td><td nowrap="nowrap">If&nbsp;the&nbsp;pads&nbsp;parameter&nbsp;is&nbsp;provided&nbsp;the&nbsp;shape&nbsp;of&nbsp;the&nbsp;output&nbsp;is&nbsp;calculated&nbsp;via&nbsp;the&nbsp;following&nbsp;equation:</td><td class="diff_next"></td><td class="diff_header" id="to39_4">4</td><td nowrap="nowrap">If&nbsp;the&nbsp;pads&nbsp;parameter&nbsp;is&nbsp;provided&nbsp;the&nbsp;shape&nbsp;of&nbsp;the&nbsp;output&nbsp;is&nbsp;calculated&nbsp;via&nbsp;the&nbsp;following&nbsp;equation:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_5">5</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to39__0"></td><td class="diff_header" id="from39_6">6</td><td nowrap="nowrap">&nbsp;&nbsp;output_shape[i]&nbsp;=&nbsp;stride[i]&nbsp;*&nbsp;(input_size[i]&nbsp;-&nbsp;1)&nbsp;+&nbsp;output_padding[i]&nbsp;+&nbsp;((kernel_shape[i]&nbsp;-&nbsp;1)&nbsp;*&nbsp;dilations[i]&nbsp;+&nbsp;1)&nbsp;-&nbsp;pads[start_i]&nbsp;-&nbsp;pads[end_i]</td><td class="diff_next"></td><td class="diff_header" id="to39_6">6</td><td nowrap="nowrap">&nbsp;&nbsp;output_shape[i]&nbsp;=&nbsp;stride[i]&nbsp;*&nbsp;(input_size[i]&nbsp;-&nbsp;1)&nbsp;+&nbsp;output_padding[i]&nbsp;+&nbsp;((kernel_shape[i]&nbsp;-&nbsp;1)&nbsp;*&nbsp;dilations[i]&nbsp;+&nbsp;1)&nbsp;-&nbsp;pads[start_i]&nbsp;-&nbsp;pads[end_i]</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_7">7</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_8">8</td><td nowrap="nowrap">output_shape&nbsp;can&nbsp;also&nbsp;be&nbsp;explicitly&nbsp;specified&nbsp;in&nbsp;which&nbsp;case&nbsp;pads&nbsp;values&nbsp;are&nbsp;auto&nbsp;generated&nbsp;using&nbsp;these&nbsp;equations:</td><td class="diff_next"></td><td class="diff_header" id="to39_8">8</td><td nowrap="nowrap">output_shape&nbsp;can&nbsp;also&nbsp;be&nbsp;explicitly&nbsp;specified&nbsp;in&nbsp;which&nbsp;case&nbsp;pads&nbsp;values&nbsp;are&nbsp;auto&nbsp;generated&nbsp;using&nbsp;these&nbsp;equations:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_9">9</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_10">10</td><td nowrap="nowrap">&nbsp;&nbsp;total_padding[i]&nbsp;=&nbsp;stride[i]&nbsp;*&nbsp;(input_size[i]&nbsp;-&nbsp;1)&nbsp;+&nbsp;output_padding[i]&nbsp;+&nbsp;((kernel_shape[i]&nbsp;-&nbsp;1)&nbsp;*&nbsp;dilations[i]&nbsp;+&nbsp;1)&nbsp;-&nbsp;output_shape[i]</td><td class="diff_next"></td><td class="diff_header" id="to39_10">10</td><td nowrap="nowrap">&nbsp;&nbsp;total_padding[i]&nbsp;=&nbsp;stride[i]&nbsp;*&nbsp;(input_size[i]&nbsp;-&nbsp;1)&nbsp;+&nbsp;output_padding[i]&nbsp;+&nbsp;((kernel_shape[i]&nbsp;-&nbsp;1)&nbsp;*&nbsp;dilations[i]&nbsp;+&nbsp;1)&nbsp;-&nbsp;output_shape[i]</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to39__1">n</a></td><td class="diff_header" id="from39_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;(auto_pads&nbsp;<span class="diff_sub">!</span>=&nbsp;SAME_UPPER):&nbsp;pads[start_i]&nbsp;=&nbsp;total_padding[i]/2;&nbsp;pads[end_i]&nbsp;=&nbsp;total_padding[i]&nbsp;-&nbsp;(total_padding[i]/2)</td><td class="diff_next"><a href="#difflib_chg_to39__1">n</a></td><td class="diff_header" id="to39_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;If&nbsp;(auto_pads&nbsp;=<span class="diff_add">=</span>&nbsp;SAME_UPPER):&nbsp;pads[start_i]&nbsp;=&nbsp;total_padding[i]/2;&nbsp;pads[end_i]&nbsp;=&nbsp;total_padding[i]&nbsp;-&nbsp;(total_padding[i]/2)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Else:&nbsp;pads[start_i]&nbsp;=&nbsp;total_padding[i]&nbsp;-&nbsp;(total_padding[i]/2);&nbsp;pads[end_i]&nbsp;=&nbsp;(total_padding[i]/2).</td><td class="diff_next"></td><td class="diff_header" id="to39_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Else:&nbsp;pads[start_i]&nbsp;=&nbsp;total_padding[i]&nbsp;-&nbsp;(total_padding[i]/2);&nbsp;pads[end_i]&nbsp;=&nbsp;(total_padding[i]/2).</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to39__1"></td><td class="diff_header" id="from39_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_13">13</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_14">14</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to39_14">14</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_15">15</td><td nowrap="nowrap">*&nbsp;**auto_pad**:</td><td class="diff_next"></td><td class="diff_header" id="to39_15">15</td><td nowrap="nowrap">*&nbsp;**auto_pad**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;auto_pad&nbsp;must&nbsp;be&nbsp;either&nbsp;NOTSET,&nbsp;SAME_UPPER,&nbsp;SAME_LOWER&nbsp;or&nbsp;VALID.</td><td class="diff_next"></td><td class="diff_header" id="to39_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;auto_pad&nbsp;must&nbsp;be&nbsp;either&nbsp;NOTSET,&nbsp;SAME_UPPER,&nbsp;SAME_LOWER&nbsp;or&nbsp;VALID.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Where&nbsp;default&nbsp;value&nbsp;is&nbsp;NOTSET,&nbsp;which&nbsp;means&nbsp;explicit&nbsp;padding&nbsp;is&nbsp;used.</td><td class="diff_next"></td><td class="diff_header" id="to39_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Where&nbsp;default&nbsp;value&nbsp;is&nbsp;NOTSET,&nbsp;which&nbsp;means&nbsp;explicit&nbsp;padding&nbsp;is&nbsp;used.</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to39__2">n</a></td><td class="diff_header" id="from39_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;SAME_UPPER&nbsp;or&nbsp;SAME_LOWER&nbsp;mean&nbsp;pad&nbsp;the&nbsp;input&nbsp;so&nbsp;that<span class="diff_sub">&nbsp;the</span>&nbsp;output</td><td class="diff_next"><a href="#difflib_chg_to39__2">n</a></td><td class="diff_header" id="to39_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;SAME_UPPER&nbsp;or&nbsp;SAME_LOWER&nbsp;mean&nbsp;pad&nbsp;the&nbsp;input&nbsp;so&nbsp;that&nbsp;output<span class="diff_add">_shape[i]</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_19">19</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;spatial&nbsp;size&nbsp;match&nbsp;the&nbsp;input.In&nbsp;case&nbsp;of&nbsp;odd&nbsp;number&nbsp;add&nbsp;the&nbsp;extra</span></td><td class="diff_next"></td><td class="diff_header" id="to39_19">19</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;=&nbsp;input_shape[i]&nbsp;*&nbsp;strides[i]&nbsp;for&nbsp;each&nbsp;axis&nbsp;i.&nbsp;The&nbsp;padding&nbsp;is</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to39__2"></td><td class="diff_header" id="from39_20">20</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;padding&nbsp;at&nbsp;the&nbsp;end&nbsp;for&nbsp;SAME_UPPER&nbsp;and&nbsp;at&nbsp;the&nbsp;beginning&nbsp;for</span></td><td class="diff_next"></td><td class="diff_header" id="to39_20">20</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;split&nbsp;between&nbsp;the&nbsp;two&nbsp;sides&nbsp;equally&nbsp;or&nbsp;almost&nbsp;equally&nbsp;(depending&nbsp;on</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_21">21</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;SAME_LOWER.&nbsp;VALID&nbsp;mean&nbsp;no&nbsp;padding.</span></td><td class="diff_next"></td><td class="diff_header" id="to39_21">21</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;whether&nbsp;it&nbsp;is&nbsp;even&nbsp;or&nbsp;odd).&nbsp;In&nbsp;case&nbsp;the&nbsp;padding&nbsp;is&nbsp;an&nbsp;odd&nbsp;number,</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_22">22</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;the&nbsp;extra&nbsp;padding&nbsp;is&nbsp;added&nbsp;at&nbsp;the&nbsp;end&nbsp;for&nbsp;SAME_UPPER&nbsp;and&nbsp;at&nbsp;the</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_23">23</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;beginning&nbsp;for&nbsp;SAME_LOWER.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_22">22</td><td nowrap="nowrap">*&nbsp;**dilations**:</td><td class="diff_next"></td><td class="diff_header" id="to39_24">24</td><td nowrap="nowrap">*&nbsp;**dilations**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to39__3">n</a></td><td class="diff_header" id="from39_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;dilation&nbsp;value&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis&nbsp;of&nbsp;the&nbsp;filter.</td><td class="diff_next"><a href="#difflib_chg_to39__3">n</a></td><td class="diff_header" id="to39_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;dilation&nbsp;value&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis&nbsp;of&nbsp;the&nbsp;filter.<span class="diff_add">&nbsp;If&nbsp;not</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_26">26</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;present,&nbsp;the&nbsp;dilation&nbsp;defaults&nbsp;to&nbsp;1&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_24">24</td><td nowrap="nowrap">*&nbsp;**group**:</td><td class="diff_next"></td><td class="diff_header" id="to39_27">27</td><td nowrap="nowrap">*&nbsp;**group**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;groups&nbsp;input&nbsp;channels&nbsp;and&nbsp;output&nbsp;channels&nbsp;are&nbsp;divided</td><td class="diff_next"></td><td class="diff_header" id="to39_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;groups&nbsp;input&nbsp;channels&nbsp;and&nbsp;output&nbsp;channels&nbsp;are&nbsp;divided</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to39__3"></td><td class="diff_header" id="from39_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;into.</td><td class="diff_next"></td><td class="diff_header" id="to39_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;into.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_27">27</td><td nowrap="nowrap">*&nbsp;**kernel_shape**:</td><td class="diff_next"></td><td class="diff_header" id="to39_30">30</td><td nowrap="nowrap">*&nbsp;**kernel_shape**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;shape&nbsp;of&nbsp;the&nbsp;convolution&nbsp;kernel.&nbsp;If&nbsp;not&nbsp;present,&nbsp;should&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to39_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;shape&nbsp;of&nbsp;the&nbsp;convolution&nbsp;kernel.&nbsp;If&nbsp;not&nbsp;present,&nbsp;should&nbsp;be</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;inferred&nbsp;from&nbsp;input&nbsp;W.</td><td class="diff_next"></td><td class="diff_header" id="to39_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;inferred&nbsp;from&nbsp;input&nbsp;W.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_30">30</td><td nowrap="nowrap">*&nbsp;**output_padding**:</td><td class="diff_next"></td><td class="diff_header" id="to39_33">33</td><td nowrap="nowrap">*&nbsp;**output_padding**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to39__4">n</a></td><td class="diff_header" id="from39_31">31</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;The&nbsp;zero-padding&nbsp;added&nbsp;to&nbsp;one&nbsp;side&nbsp;of&nbsp;the&nbsp;output.&nbsp;This&nbsp;is&nbsp;also</span></td><td class="diff_next"><a href="#difflib_chg_to39__4">n</a></td><td class="diff_header" id="to39_34">34</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Additional&nbsp;elements&nbsp;added&nbsp;to&nbsp;the&nbsp;side&nbsp;with&nbsp;higher&nbsp;coordinate&nbsp;indices</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_32">32</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;called&nbsp;adjs/adjustment&nbsp;in&nbsp;some&nbsp;frameworks.</span></td><td class="diff_next"></td><td class="diff_header" id="to39_35">35</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;in&nbsp;the&nbsp;output.&nbsp;Each&nbsp;padding&nbsp;value&nbsp;in&nbsp;"output_padding"&nbsp;must&nbsp;be&nbsp;less</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_36">36</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;than&nbsp;the&nbsp;corresponding&nbsp;stride/dilation&nbsp;dimension.&nbsp;By&nbsp;default,&nbsp;this</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_37">37</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;attribute&nbsp;is&nbsp;a&nbsp;zero&nbsp;vector.&nbsp;Note&nbsp;that&nbsp;this&nbsp;attribute&nbsp;doesn't</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_38">38</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;directly&nbsp;affect&nbsp;the&nbsp;computed&nbsp;output&nbsp;values.&nbsp;It&nbsp;only&nbsp;controls&nbsp;the</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_39">39</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;selection&nbsp;of&nbsp;the&nbsp;computed&nbsp;values,&nbsp;so&nbsp;changing&nbsp;this&nbsp;attribute&nbsp;only</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_40">40</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;adds&nbsp;or&nbsp;removes&nbsp;output&nbsp;elements.&nbsp;If&nbsp;"output_shape"&nbsp;is&nbsp;explicitly</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_41">41</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;provided,&nbsp;"output_padding"&nbsp;does&nbsp;not&nbsp;contribute&nbsp;additional&nbsp;size&nbsp;to</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_42">42</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;"output_shape"&nbsp;but&nbsp;participates&nbsp;in&nbsp;the&nbsp;computation&nbsp;of&nbsp;the&nbsp;needed</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_43">43</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;padding&nbsp;amount.&nbsp;This&nbsp;is&nbsp;also&nbsp;called&nbsp;adjs&nbsp;or&nbsp;adjustment&nbsp;in&nbsp;some</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_44">44</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;frameworks.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_33">33</td><td nowrap="nowrap">*&nbsp;**output_shape**:</td><td class="diff_next"></td><td class="diff_header" id="to39_45">45</td><td nowrap="nowrap">*&nbsp;**output_shape**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;shape&nbsp;of&nbsp;the&nbsp;output&nbsp;can&nbsp;be&nbsp;explicitly&nbsp;set&nbsp;which&nbsp;will&nbsp;cause&nbsp;pads</td><td class="diff_next"></td><td class="diff_header" id="to39_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;shape&nbsp;of&nbsp;the&nbsp;output&nbsp;can&nbsp;be&nbsp;explicitly&nbsp;set&nbsp;which&nbsp;will&nbsp;cause&nbsp;pads</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;to&nbsp;be&nbsp;auto&nbsp;generated.&nbsp;If&nbsp;output_shape&nbsp;is&nbsp;specified&nbsp;pads</td><td class="diff_next"></td><td class="diff_header" id="to39_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;to&nbsp;be&nbsp;auto&nbsp;generated.&nbsp;If&nbsp;output_shape&nbsp;is&nbsp;specified&nbsp;pads</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;ignored.&nbsp;See&nbsp;doc&nbsp;for&nbsp;details&nbsp;for&nbsp;equations&nbsp;to&nbsp;generate</td><td class="diff_next"></td><td class="diff_header" id="to39_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;values&nbsp;are&nbsp;ignored.&nbsp;See&nbsp;doc&nbsp;for&nbsp;details&nbsp;for&nbsp;equations&nbsp;to&nbsp;generate</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;pads</td><td class="diff_next"></td><td class="diff_header" id="to39_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;pads</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_38">38</td><td nowrap="nowrap">*&nbsp;**pads**:</td><td class="diff_next"></td><td class="diff_header" id="to39_50">50</td><td nowrap="nowrap">*&nbsp;**pads**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Padding&nbsp;for&nbsp;the&nbsp;beginning&nbsp;and&nbsp;ending&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis,&nbsp;it&nbsp;can</td><td class="diff_next"></td><td class="diff_header" id="to39_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;Padding&nbsp;for&nbsp;the&nbsp;beginning&nbsp;and&nbsp;ending&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis,&nbsp;it&nbsp;can</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;take&nbsp;any&nbsp;value&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;0.&nbsp;The&nbsp;value&nbsp;represent&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to39_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;take&nbsp;any&nbsp;value&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;0.&nbsp;The&nbsp;value&nbsp;represent&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;pixels&nbsp;added&nbsp;to&nbsp;the&nbsp;beginning&nbsp;and&nbsp;end&nbsp;part&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to39_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;pixels&nbsp;added&nbsp;to&nbsp;the&nbsp;beginning&nbsp;and&nbsp;end&nbsp;part&nbsp;of&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;axis.&nbsp;pads&nbsp;format&nbsp;should&nbsp;be&nbsp;as&nbsp;follow&nbsp;[x1_begin,</td><td class="diff_next"></td><td class="diff_header" id="to39_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;axis.&nbsp;pads&nbsp;format&nbsp;should&nbsp;be&nbsp;as&nbsp;follow&nbsp;[x1_begin,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;x2_begin...x1_end,&nbsp;x2_end,...],&nbsp;where&nbsp;xi_begin&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td><td class="diff_next"></td><td class="diff_header" id="to39_55">55</td><td nowrap="nowrap">&nbsp;&nbsp;x2_begin...x1_end,&nbsp;x2_end,...],&nbsp;where&nbsp;xi_begin&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to39__4"></td><td class="diff_header" id="from39_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;beginning&nbsp;of&nbsp;axis&nbsp;i&nbsp;and&nbsp;xi_end,&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td><td class="diff_next"></td><td class="diff_header" id="to39_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;beginning&nbsp;of&nbsp;axis&nbsp;i&nbsp;and&nbsp;xi_end,&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_45">45</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;end&nbsp;of&nbsp;axis&nbsp;i.&nbsp;This&nbsp;attribute&nbsp;cannot&nbsp;be&nbsp;used</td><td class="diff_next"></td><td class="diff_header" id="to39_57">57</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;end&nbsp;of&nbsp;axis&nbsp;i.&nbsp;This&nbsp;attribute&nbsp;cannot&nbsp;be&nbsp;used</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;simultaneously&nbsp;with&nbsp;auto_pad&nbsp;attribute.&nbsp;If&nbsp;not&nbsp;present,&nbsp;the&nbsp;padding</td><td class="diff_next"></td><td class="diff_header" id="to39_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;simultaneously&nbsp;with&nbsp;auto_pad&nbsp;attribute.&nbsp;If&nbsp;not&nbsp;present,&nbsp;the&nbsp;padding</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;defaults&nbsp;to&nbsp;0&nbsp;along&nbsp;start&nbsp;and&nbsp;end&nbsp;of&nbsp;each&nbsp;spatial&nbsp;axis.</td><td class="diff_next"></td><td class="diff_header" id="to39_59">59</td><td nowrap="nowrap">&nbsp;&nbsp;defaults&nbsp;to&nbsp;0&nbsp;along&nbsp;start&nbsp;and&nbsp;end&nbsp;of&nbsp;each&nbsp;spatial&nbsp;axis.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_48">48</td><td nowrap="nowrap">*&nbsp;**strides**:</td><td class="diff_next"></td><td class="diff_header" id="to39_60">60</td><td nowrap="nowrap">*&nbsp;**strides**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to39__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to39__top">t</a></td><td class="diff_header" id="to39_61">61</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Stride&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.&nbsp;If&nbsp;not&nbsp;present,&nbsp;the&nbsp;stride&nbsp;defaults</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;<span class="diff_sub">S</span>t<span class="diff_chg">ride</span>&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.</td><td class="diff_next"></td><td class="diff_header" id="to39_62">62</td><td nowrap="nowrap">&nbsp;&nbsp;t<span class="diff_chg">o&nbsp;1</span>&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_50">50</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_63">63</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_51">51</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to39_64">64</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_52">52</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to39_65">65</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_53">53</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_66">66</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_54">54</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to39_67">67</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_55">55</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;data&nbsp;tensor&nbsp;from&nbsp;previous&nbsp;layer;&nbsp;has&nbsp;size&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;H&nbsp;x&nbsp;W),</td><td class="diff_next"></td><td class="diff_header" id="to39_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;data&nbsp;tensor&nbsp;from&nbsp;previous&nbsp;layer;&nbsp;has&nbsp;size&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;H&nbsp;x&nbsp;W),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size,&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;H&nbsp;and&nbsp;W</td><td class="diff_next"></td><td class="diff_header" id="to39_69">69</td><td nowrap="nowrap">&nbsp;&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size,&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;H&nbsp;and&nbsp;W</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_57">57</td><td nowrap="nowrap">&nbsp;&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width.&nbsp;Note&nbsp;that&nbsp;this&nbsp;is&nbsp;for&nbsp;the&nbsp;2D&nbsp;image.</td><td class="diff_next"></td><td class="diff_header" id="to39_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width.&nbsp;Note&nbsp;that&nbsp;this&nbsp;is&nbsp;for&nbsp;the&nbsp;2D&nbsp;image.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;Otherwise&nbsp;the&nbsp;size&nbsp;is&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;D1&nbsp;x&nbsp;D2&nbsp;...&nbsp;x&nbsp;Dn)</td><td class="diff_next"></td><td class="diff_header" id="to39_71">71</td><td nowrap="nowrap">&nbsp;&nbsp;Otherwise&nbsp;the&nbsp;size&nbsp;is&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;D1&nbsp;x&nbsp;D2&nbsp;...&nbsp;x&nbsp;Dn)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_59">59</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to39_72">72</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;convolutions;&nbsp;has&nbsp;size&nbsp;(C</td><td class="diff_next"></td><td class="diff_header" id="to39_73">73</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;convolutions;&nbsp;has&nbsp;size&nbsp;(C</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_61">61</td><td nowrap="nowrap">&nbsp;&nbsp;x&nbsp;M/group&nbsp;x&nbsp;kH&nbsp;x&nbsp;kW),&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;kH&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to39_74">74</td><td nowrap="nowrap">&nbsp;&nbsp;x&nbsp;M/group&nbsp;x&nbsp;kH&nbsp;x&nbsp;kW),&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;kH&nbsp;and</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_62">62</td><td nowrap="nowrap">&nbsp;&nbsp;kW&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width&nbsp;of&nbsp;the&nbsp;kernel,&nbsp;and&nbsp;M&nbsp;is&nbsp;the&nbsp;number&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to39_75">75</td><td nowrap="nowrap">&nbsp;&nbsp;kW&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width&nbsp;of&nbsp;the&nbsp;kernel,&nbsp;and&nbsp;M&nbsp;is&nbsp;the&nbsp;number&nbsp;of</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_63">63</td><td nowrap="nowrap">&nbsp;&nbsp;feature&nbsp;maps.&nbsp;For&nbsp;more&nbsp;than&nbsp;2&nbsp;dimensions,&nbsp;the&nbsp;weight&nbsp;shape&nbsp;will&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to39_76">76</td><td nowrap="nowrap">&nbsp;&nbsp;feature&nbsp;maps.&nbsp;For&nbsp;more&nbsp;than&nbsp;2&nbsp;dimensions,&nbsp;the&nbsp;weight&nbsp;shape&nbsp;will&nbsp;be</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;(C&nbsp;x&nbsp;M/group&nbsp;x&nbsp;k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;x&nbsp;kn),&nbsp;where&nbsp;(k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;x&nbsp;kn)&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to39_77">77</td><td nowrap="nowrap">&nbsp;&nbsp;(C&nbsp;x&nbsp;M/group&nbsp;x&nbsp;k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;x&nbsp;kn),&nbsp;where&nbsp;(k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;x&nbsp;kn)&nbsp;is</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_65">65</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;dimension&nbsp;of&nbsp;the&nbsp;kernel.&nbsp;The&nbsp;number&nbsp;of&nbsp;channels&nbsp;in&nbsp;the&nbsp;output</td><td class="diff_next"></td><td class="diff_header" id="to39_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;dimension&nbsp;of&nbsp;the&nbsp;kernel.&nbsp;The&nbsp;number&nbsp;of&nbsp;channels&nbsp;in&nbsp;the&nbsp;output</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;should&nbsp;be&nbsp;equal&nbsp;to&nbsp;W.shape[1]&nbsp;*&nbsp;group&nbsp;(assuming&nbsp;zero&nbsp;based&nbsp;indices</td><td class="diff_next"></td><td class="diff_header" id="to39_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;should&nbsp;be&nbsp;equal&nbsp;to&nbsp;W.shape[1]&nbsp;*&nbsp;group&nbsp;(assuming&nbsp;zero&nbsp;based&nbsp;indices</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_67">67</td><td nowrap="nowrap">&nbsp;&nbsp;of&nbsp;the&nbsp;shape&nbsp;array)</td><td class="diff_next"></td><td class="diff_header" id="to39_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;of&nbsp;the&nbsp;shape&nbsp;array)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_68">68</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to39_81">81</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_69">69</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;1D&nbsp;bias&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;convolution,&nbsp;has&nbsp;size&nbsp;of&nbsp;M.</td><td class="diff_next"></td><td class="diff_header" id="to39_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;1D&nbsp;bias&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;convolution,&nbsp;has&nbsp;size&nbsp;of&nbsp;M.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_70">70</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_83">83</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_71">71</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to39_84">84</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_72">72</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_85">85</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_73">73</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to39_86">86</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_74">74</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;data&nbsp;tensor&nbsp;that&nbsp;contains&nbsp;the&nbsp;result&nbsp;of&nbsp;the&nbsp;convolution.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to39_87">87</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;data&nbsp;tensor&nbsp;that&nbsp;contains&nbsp;the&nbsp;result&nbsp;of&nbsp;the&nbsp;convolution.&nbsp;The</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_75">75</td><td nowrap="nowrap">&nbsp;&nbsp;output&nbsp;dimensions&nbsp;are&nbsp;functions&nbsp;of&nbsp;the&nbsp;kernel&nbsp;size,&nbsp;stride&nbsp;size,&nbsp;pad</td><td class="diff_next"></td><td class="diff_header" id="to39_88">88</td><td nowrap="nowrap">&nbsp;&nbsp;output&nbsp;dimensions&nbsp;are&nbsp;functions&nbsp;of&nbsp;the&nbsp;kernel&nbsp;size,&nbsp;stride&nbsp;size,&nbsp;pad</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_76">76</td><td nowrap="nowrap">&nbsp;&nbsp;lengths&nbsp;and&nbsp;group&nbsp;count.&nbsp;The&nbsp;number&nbsp;of&nbsp;channels&nbsp;in&nbsp;the&nbsp;output&nbsp;should</td><td class="diff_next"></td><td class="diff_header" id="to39_89">89</td><td nowrap="nowrap">&nbsp;&nbsp;lengths&nbsp;and&nbsp;group&nbsp;count.&nbsp;The&nbsp;number&nbsp;of&nbsp;channels&nbsp;in&nbsp;the&nbsp;output&nbsp;should</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_77">77</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;equal&nbsp;to&nbsp;W.shape[1]&nbsp;*&nbsp;group&nbsp;(assuming&nbsp;zero&nbsp;based&nbsp;indices&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to39_90">90</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;equal&nbsp;to&nbsp;W.shape[1]&nbsp;*&nbsp;group&nbsp;(assuming&nbsp;zero&nbsp;based&nbsp;indices&nbsp;of&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;array)</td><td class="diff_next"></td><td class="diff_header" id="to39_91">91</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;array)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_79">79</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to39_92">92</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_80">80</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to39_93">93</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_81">81</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to39_94">94</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to39_95">95</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_83">83</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to39_96">96</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_84">84</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to39_97">97</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to39_98">98</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from39_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to39_99">99</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="convtranspose-1">
<span id="l-onnx-op-convtranspose-1"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">ConvTranspose - 1</a><a class="headerlink" href="#convtranspose-1" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose">ConvTranspose (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>1</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<p>The convolution transpose operator consumes an input tensor and a filter,
and computes the output.</p>
<p>If the pads parameter is provided the shape of the output is calculated via the following equation:</p>
<blockquote>
<div><p>output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]</p>
</div></blockquote>
<p>output_shape can also be explicitly specified in which case pads values are auto generated using these equations:</p>
<blockquote>
<div><p>total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]
If (auto_pads != SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).</p>
</div></blockquote>
<p><strong>Attributes</strong>
* <strong>auto_pad</strong>:</p>
<blockquote>
<div><p>auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
Where default value is NOTSET, which means explicit padding is used.
SAME_UPPER or SAME_LOWER mean pad the input so that the output
spatial size match the input.In case of odd number add the extra
padding at the end for SAME_UPPER and at the beginning for
SAME_LOWER. VALID mean no padding.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>dilations</strong>:
dilation value along each spatial axis of the filter.</p></li>
<li><p><strong>group</strong>:
number of groups input channels and output channels are divided
into.</p></li>
<li><p><strong>kernel_shape</strong>:
The shape of the convolution kernel. If not present, should be
inferred from input W.</p></li>
<li><p><strong>output_padding</strong>:
The zero-padding added to one side of the output. This is also
called adjs/adjustment in some frameworks.</p></li>
<li><p><strong>output_shape</strong>:
The shape of the output can be explicitly set which will cause pads
values to be auto generated. If output_shape is specified pads
values are ignored. See doc for details for equations to generate
pads</p></li>
<li><p><strong>pads</strong>:
Padding for the beginning and ending along each spatial axis, it can
take any value greater than or equal to 0. The value represent the
number of pixels added to the beginning and end part of the
corresponding axis. <cite>pads</cite> format should be as follow [x1_begin,
x2_begin…x1_end, x2_end,…], where xi_begin the number of pixels
added at the beginning of axis <cite>i</cite> and xi_end, the number of pixels
added at the end of axis <cite>i</cite>. This attribute cannot be used
simultaneously with auto_pad attribute. If not present, the padding
defaults to 0 along start and end of each spatial axis.</p></li>
<li><p><strong>strides</strong>:
Stride along each spatial axis.</p></li>
</ul>
<p><strong>Inputs</strong>
Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from previous layer; has size (N x C x H x W),
where N is the batch size, C is the number of channels, and H and W
are the height and width. Note that this is for the 2D image.
Otherwise the size is (N x C x D1 x D2 … x Dn)</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor that will be used in the convolutions; has size (C
x M/group x kH x kW), where C is the number of channels, and kH and
kW are the height and width of the kernel, and M is the number of
feature maps. For more than 2 dimensions, the weight shape will be
(C x M/group x k1 x k2 x … x kn), where (k1 x k2 x … x kn) is
the dimension of the kernel. The number of channels in the output
should be equal to W.shape[1] * group (assuming zero based indices
of the shape array)</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional 1D bias to be added to the convolution, has size of M.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output data tensor that contains the result of the convolution. The
output dimensions are functions of the kernel size, stride size, pad
lengths and group count. The number of channels in the output should
be equal to W.shape[1] * group (assuming zero based indices of the
shape array)</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>