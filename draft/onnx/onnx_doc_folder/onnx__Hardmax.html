<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Hardmax &#8212; ONNX 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Identity" href="onnx__Identity.html" />
    <link rel="prev" title="HardSwish" href="onnx__HardSwish.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ONNX Docs</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../onnx-api/index.html">API Overview</a></li>
                <li><a href="../operators/index.html">Op Schemas</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">API Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.checker.html">onnx.checker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.compose.html">onnx.compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.external_data_helper.html">onnx.external_data_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.helper.html">onnx.helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.hub.html">onnx.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.numpy_helper.html">onnx.numpy_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.parser.html">onnx.parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.utils.html">onnx.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version.version.html">onnx.version.version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version_converter.html">onnx.version_converter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Operators + OpSchemas</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">ONNX operators</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Hardmax</a><ul>
<li><a class="reference internal" href="#hardmax-13">Hardmax - 13</a></li>
<li><a class="reference internal" href="#hardmax-11">Hardmax - 11</a></li>
<li><a class="reference internal" href="#hardmax-1">Hardmax - 1</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="onnx__HardSwish.html" title="Previous Chapter: HardSwish"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; HardSwish</span>
    </a>
  </li>
  <li>
    <a href="onnx__Identity.html" title="Next Chapter: Identity"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Identity &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/onnx_doc_folder/onnx__Hardmax.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="hardmax">
<span id="l-onnx-doc-hardmax"></span><h1>Hardmax<a class="headerlink" href="#hardmax" title="Permalink to this heading">¶</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#hardmax-13" id="id3">Hardmax - 13</a></p></li>
<li><p><a class="reference internal" href="#hardmax-11" id="id4">Hardmax - 11</a></p></li>
<li><p><a class="reference internal" href="#hardmax-1" id="id5">Hardmax - 1</a></p></li>
</ul>
</nav>
<section id="hardmax-13">
<span id="l-onnx-op-hardmax-13"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">Hardmax - 13</a><a class="headerlink" href="#hardmax-13" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Hardmax">Hardmax (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>13</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 13</strong>.</p>
<p><strong>Summary</strong></p>
<p>The operator computes the hardmax values for the given input:</p>
<blockquote>
<div><p>Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise</p>
</div></blockquote>
<p>The “axis” attribute indicates the dimension along which Hardmax
will be performed. The output tensor has the same shape
and contains the Hardmax values of the corresponding input.</p>
<p><strong>Attributes</strong>
* <strong>axis</strong>:</p>
<blockquote>
<div><blockquote>
<div><p>Describes the dimension Hardmax will be performed on. Negative</p>
</div></blockquote>
<p>value means counting dimensions from the back. Accepted range is
[-r, r-1] where r = rank(input).</p>
</div></blockquote>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
The input tensor of rank &gt;= axis.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
The output values with the same shape as the input tensor.</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
<p><strong>Examples</strong></p>
<p><strong>default</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Hardmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>
<span class="c1"># expect result:</span>
<span class="c1"># [[1. 0. 0. 0.]</span>
<span class="c1"># [0. 1. 0. 0.]</span>
<span class="c1"># [0. 0. 1. 0.]</span>
<span class="c1"># [0. 0. 0. 1.]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">hardmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_hardmax_example&quot;</span><span class="p">)</span>

<span class="c1"># For multiple occurrences of the maximal values, the first occurrence is selected for one-hot output</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># expect result:</span>
<span class="c1"># [[1, 0, 0, 0]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">hardmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_hardmax_one_hot&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_hardmax_axis</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Hardmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">hardmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_hardmax_axis_0&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Hardmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">hardmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_hardmax_axis_1&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Hardmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">hardmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_hardmax_axis_2&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Hardmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">hardmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_hardmax_negative_axis&quot;</span><span class="p">)</span>

<span class="c1"># default axis is -1</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Hardmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_hardmax_default_axis&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to85__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to85__1"><a href="#difflib_chg_to85__1">n</a></td><td class="diff_header" id="from85_1">1</td><td nowrap="nowrap"><span class="diff_sub">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;(1&nbsp;for&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value,&nbsp;and&nbsp;0&nbsp;for&nbsp;all&nbsp;others)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</span></td><td class="diff_next"><a href="#difflib_chg_to85__1">n</a></td><td class="diff_header" id="to85_1">1</td><td nowrap="nowrap"><span class="diff_add">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;values&nbsp;for&nbsp;the&nbsp;given&nbsp;input:</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_2">2</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to85__2">n</a></td><td class="diff_header" id="from85_4">4</td><td nowrap="nowrap"><span class="diff_sub">The&nbsp;input&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</span></td><td class="diff_next"><a href="#difflib_chg_to85__2">n</a></td><td class="diff_header" id="to85_3">3</td><td nowrap="nowrap"><span class="diff_add">&nbsp;Hardmax(element&nbsp;in&nbsp;input,&nbsp;axis)&nbsp;=&nbsp;1&nbsp;if&nbsp;the&nbsp;element&nbsp;is&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value&nbsp;along&nbsp;the&nbsp;specified&nbsp;axis,&nbsp;0&nbsp;otherwise</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_5">5</td><td nowrap="nowrap"><span class="diff_sub">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header" id="to85_4">4</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_6">6</td><td nowrap="nowrap"><span class="diff_sub">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</span></td><td class="diff_next"></td><td class="diff_header" id="to85_5">5</td><td nowrap="nowrap"><span class="diff_add">The&nbsp;"axis"&nbsp;attribute&nbsp;indicates&nbsp;the&nbsp;dimension&nbsp;along&nbsp;which&nbsp;Hardmax</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_7">7</td><td nowrap="nowrap"><span class="diff_sub">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_8">8</td><td nowrap="nowrap"><span class="diff_sub">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_9">9</td><td nowrap="nowrap"><span class="diff_sub">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_10">10</td><td nowrap="nowrap"><span class="diff_sub">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_11">11</td><td nowrap="nowrap"><span class="diff_sub">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_12">12</td><td nowrap="nowrap"><span class="diff_sub">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to85__2"></td><td class="diff_header" id="from85_13">13</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">throw&nbsp;</span>er<span class="diff_chg">r</span>or<span class="diff_chg">s</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td><td class="diff_next"></td><td class="diff_header" id="to85_6">6</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">be&nbsp;p</span>er<span class="diff_chg">f</span>or<span class="diff_chg">med</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_14">14</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">h</span>ardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td><td class="diff_next"></td><td class="diff_header" id="to85_7">7</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">H</span>ardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_8">8</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_16">16</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to85_9">9</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_17">17</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to85_10">10</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to85__3">n</a></td><td class="diff_header" id="from85_18">18</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</span></td><td class="diff_next"><a href="#difflib_chg_to85__3">n</a></td><td class="diff_header" id="to85_11">11</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;&nbsp;Describes&nbsp;the&nbsp;dimension&nbsp;Hardmax&nbsp;will&nbsp;be&nbsp;performed&nbsp;on.&nbsp;Negative</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_19">19</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size.&nbsp;Negative</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to85_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to85__3"></td><td class="diff_header" id="from85_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td><td class="diff_next"></td><td class="diff_header" id="to85_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_14">14</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_23">23</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to85_15">15</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_16">16</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_25">25</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to85_17">17</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to85__4">n</a></td><td class="diff_header" id="from85_26">26</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</span></td><td class="diff_next"><a href="#difflib_chg_to85__4">n</a></td><td class="diff_header" id="to85_18">18</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;of&nbsp;rank&nbsp;&gt;=&nbsp;axis.</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to85__4"></td><td class="diff_header" id="from85_27">27</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;described&nbsp;above.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_28">28</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_19">19</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_29">29</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to85_20">20</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_30">30</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_21">21</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_31">31</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to85_22">22</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to85__5"><a href="#difflib_chg_to85__5">n</a></td><td class="diff_header" id="from85_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor<span class="diff_chg">&nbsp;(the&nbsp;original</span></td><td class="diff_next"><a href="#difflib_chg_to85__5">n</a></td><td class="diff_header" id="to85_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as<span class="diff_add">&nbsp;the</span>&nbsp;input&nbsp;tensor<span class="diff_chg">.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_33">33</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_34">34</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to85_24">24</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_35">35</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to85_25">25</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_36">36</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to85_26">26</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to85__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to85__top">t</a></td><td class="diff_header" id="to85_27">27</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to85_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to85_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to85_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to85_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from85_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to85_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="hardmax-11">
<span id="l-onnx-op-hardmax-11"></span><h2><a class="toc-backref" href="#id4" role="doc-backlink">Hardmax - 11</a><a class="headerlink" href="#hardmax-11" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Hardmax">Hardmax (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>11</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 11</strong>.</p>
<p><strong>Summary</strong></p>
<dl class="simple">
<dt>The operator computes the hardmax (1 for the first maximum value, and 0 for all others) values for each layer in the batch</dt><dd><p>of the given input.</p>
</dd>
</dl>
<p>The input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input in [a_0, a_1, …, a_{k-1}, a_k, …, a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * … * a_{k-1}, a_k * … * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * … * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * … * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors. The output tensor has the same shape
and contains the hardmax values of the corresponding input.</p>
<p><strong>Attributes</strong>
* <strong>axis</strong>:</p>
<blockquote>
<div><p>Describes the axis of the inputs when coerced to 2D; defaults to one
because the 0th axis most likely describes the batch_size. Negative
value means counting dimensions from the back. Accepted range is
[-r, r-1] where r = rank(input).</p>
</div></blockquote>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
The input tensor that’s coerced into a 2D matrix of size (NxD) as
described above.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
The output values with the same shape as input tensor (the original
size without coercion).</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to86__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to86__1"><a href="#difflib_chg_to86__0">f</a></td><td class="diff_header" id="from86_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;(1&nbsp;for&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value,&nbsp;and&nbsp;0&nbsp;for&nbsp;all&nbsp;others)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td><td class="diff_next"><a href="#difflib_chg_to86__0">f</a></td><td class="diff_header" id="to86_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;hardmax&nbsp;(1&nbsp;for&nbsp;the&nbsp;first&nbsp;maximum&nbsp;value,&nbsp;and&nbsp;0&nbsp;for&nbsp;all&nbsp;others)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to86__1">n</a></td><td class="diff_header" id="from86_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.&nbsp;The&nbsp;input&nbsp;is&nbsp;a&nbsp;2-D&nbsp;tensor&nbsp;(Tensor&lt;float&gt;)&nbsp;of&nbsp;size</span></td><td class="diff_next"><a href="#difflib_chg_to86__1">n</a></td><td class="diff_header" id="to86_2">2</td><td nowrap="nowrap"><span class="diff_add">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_3">3</td><td nowrap="nowrap"><span class="diff_sub">(batch_size&nbsp;x&nbsp;input_feature_dimensions).&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_4">4</td><td nowrap="nowrap"><span class="diff_sub">and&nbsp;contains&nbsp;the&nbsp;hardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_3">3</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to86__2">n</a></td><td class="diff_header" id="from86_6">6</td><td nowrap="nowrap"><span class="diff_chg">I</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td><td class="diff_next"><a href="#difflib_chg_to86__2">n</a></td><td class="diff_header" id="to86_4">4</td><td nowrap="nowrap"><span class="diff_chg">The&nbsp;i</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_7">7</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to86_5">5</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_8">8</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to86_6">6</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_9">9</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td><td class="diff_next"></td><td class="diff_header" id="to86_7">7</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to86__2"></td><td class="diff_header" id="from86_10">10</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td><td class="diff_next"></td><td class="diff_header" id="to86_8">8</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_11">11</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to86_9">9</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_12">12</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td><td class="diff_next"></td><td class="diff_header" id="to86_10">10</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_13">13</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td><td class="diff_next"></td><td class="diff_header" id="to86_11">11</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_14">14</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td><td class="diff_next"></td><td class="diff_header" id="to86_12">12</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to86__3">n</a></td><td class="diff_header" id="from86_15">15</td><td nowrap="nowrap"><span class="diff_sub">will&nbsp;throw&nbsp;errors.</span></td><td class="diff_next"><a href="#difflib_chg_to86__3">n</a></td><td class="diff_header" id="to86_13">13</td><td nowrap="nowrap"><span class="diff_add">will&nbsp;throw&nbsp;errors.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to86__3"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_14">14</td><td nowrap="nowrap"><span class="diff_add">and&nbsp;contains&nbsp;the&nbsp;hardmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_15">15</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_17">17</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to86_16">16</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_18">18</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to86_17">17</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td><td class="diff_next"></td><td class="diff_header" id="to86_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to86__top">t</a></td><td class="diff_header" id="from86_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size</td><td class="diff_next"><a href="#difflib_chg_to86__top">t</a></td><td class="diff_header" id="to86_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size<span class="diff_add">.&nbsp;Negative</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_20">20</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_21">21</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_22">22</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_22">22</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to86_23">23</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_24">24</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_24">24</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to86_25">25</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td><td class="diff_next"></td><td class="diff_header" id="to86_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td><td class="diff_next"></td><td class="diff_header" id="to86_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_28">28</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_28">28</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to86_29">29</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_30">30</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_30">30</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to86_31">31</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td><td class="diff_next"></td><td class="diff_header" id="to86_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td><td class="diff_next"></td><td class="diff_header" id="to86_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to86_34">34</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_34">34</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to86_35">35</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_35">35</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to86_36">36</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to86_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to86_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to86_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to86_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from86_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to86_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="hardmax-1">
<span id="l-onnx-op-hardmax-1"></span><h2><a class="toc-backref" href="#id5" role="doc-backlink">Hardmax - 1</a><a class="headerlink" href="#hardmax-1" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Hardmax">Hardmax (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>1</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<dl class="simple">
<dt>The operator computes the hardmax (1 for the first maximum value, and 0 for all others) values for each layer in the batch</dt><dd><p>of the given input. The input is a 2-D tensor (Tensor&lt;float&gt;) of size</p>
</dd>
</dl>
<p>(batch_size x input_feature_dimensions). The output tensor has the same shape
and contains the hardmax values of the corresponding input.</p>
<p>Input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input in [a_0, a_1, …, a_{k-1}, a_k, …, a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * … * a_{k-1}, a_k * … * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * … * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * … * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors.</p>
<p><strong>Attributes</strong>
* <strong>axis</strong>:</p>
<blockquote>
<div><p>Describes the axis of the inputs when coerced to 2D; defaults to one
because the 0th axis most likely describes the batch_size</p>
</div></blockquote>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
The input tensor that’s coerced into a 2D matrix of size (NxD) as
described above.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
The output values with the same shape as input tensor (the original
size without coercion).</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>