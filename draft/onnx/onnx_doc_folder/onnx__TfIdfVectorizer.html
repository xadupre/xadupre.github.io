
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>TfIdfVectorizer &#8212; ONNX 0.1 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'onnx_doc_folder/onnx__TfIdfVectorizer';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ThresholdedRelu" href="onnx__ThresholdedRelu.html" />
    <link rel="prev" title="Tanh" href="onnx__Tanh.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fas fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fas fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Abs.html">
   Abs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acos.html">
   Acos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acosh.html">
   Acosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Add.html">
   Add
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__And.html">
   And
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMax.html">
   ArgMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMin.html">
   ArgMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asin.html">
   Asin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asinh.html">
   Asinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atan.html">
   Atan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atanh.html">
   Atanh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__AveragePool.html">
   AveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BatchNormalization.html">
   BatchNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Bernoulli.html">
   Bernoulli
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BitShift.html">
   BitShift
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BlackmanWindow.html">
   BlackmanWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cast.html">
   Cast
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CastLike.html">
   CastLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Ceil.html">
   Ceil
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Celu.html">
   Celu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CenterCropPad.html">
   CenterCropPad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Clip.html">
   Clip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Col2Im.html">
   Col2Im
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Compress.html">
   Compress
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Concat.html">
   Concat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConcatFromSequence.html">
   ConcatFromSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Constant.html">
   Constant
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConstantOfShape.html">
   ConstantOfShape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Conv.html">
   Conv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvInteger.html">
   ConvInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvTranspose.html">
   ConvTranspose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cos.html">
   Cos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cosh.html">
   Cosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CumSum.html">
   CumSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DFT.html">
   DFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DepthToSpace.html">
   DepthToSpace
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DequantizeLinear.html">
   DequantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Det.html">
   Det
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Div.html">
   Div
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Dropout.html">
   Dropout
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
   DynamicQuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Einsum.html">
   Einsum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Elu.html">
   Elu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Equal.html">
   Equal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Erf.html">
   Erf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Exp.html">
   Exp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Expand.html">
   Expand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__EyeLike.html">
   EyeLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Flatten.html">
   Flatten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Floor.html">
   Floor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GRU.html">
   GRU
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gather.html">
   Gather
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherElements.html">
   GatherElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherND.html">
   GatherND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gemm.html">
   Gemm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalAveragePool.html">
   GlobalAveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalLpPool.html">
   GlobalLpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalMaxPool.html">
   GlobalMaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Greater.html">
   Greater
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GreaterOrEqual.html">
   GreaterOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GridSample.html">
   GridSample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HammingWindow.html">
   HammingWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HannWindow.html">
   HannWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSigmoid.html">
   HardSigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSwish.html">
   HardSwish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Hardmax.html">
   Hardmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Identity.html">
   Identity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__If.html">
   If
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__InstanceNormalization.html">
   InstanceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsInf.html">
   IsInf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsNaN.html">
   IsNaN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LRN.html">
   LRN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LSTM.html">
   LSTM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LayerNormalization.html">
   LayerNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LeakyRelu.html">
   LeakyRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Less.html">
   Less
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LessOrEqual.html">
   LessOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Log.html">
   Log
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LogSoftmax.html">
   LogSoftmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Loop.html">
   Loop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpNormalization.html">
   LpNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpPool.html">
   LpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMul.html">
   MatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMulInteger.html">
   MatMulInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Max.html">
   Max
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxPool.html">
   MaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxRoiPool.html">
   MaxRoiPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxUnpool.html">
   MaxUnpool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mean.html">
   Mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
   MeanVarianceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MelWeightMatrix.html">
   MelWeightMatrix
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Min.html">
   Min
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mish.html">
   Mish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mod.html">
   Mod
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mul.html">
   Mul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Multinomial.html">
   Multinomial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Neg.html">
   Neg
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
   NegativeLogLikelihoodLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonMaxSuppression.html">
   NonMaxSuppression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonZero.html">
   NonZero
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Not.html">
   Not
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OneHot.html">
   OneHot
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Optional.html">
   Optional
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalGetElement.html">
   OptionalGetElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalHasElement.html">
   OptionalHasElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Or.html">
   Or
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__PRelu.html">
   PRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pad.html">
   Pad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pow.html">
   Pow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearConv.html">
   QLinearConv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearMatMul.html">
   QLinearMatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QuantizeLinear.html">
   QuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RNN.html">
   RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormal.html">
   RandomNormal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormalLike.html">
   RandomNormalLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniform.html">
   RandomUniform
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniformLike.html">
   RandomUniformLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Range.html">
   Range
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reciprocal.html">
   Reciprocal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL1.html">
   ReduceL1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL2.html">
   ReduceL2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSum.html">
   ReduceLogSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSumExp.html">
   ReduceLogSumExp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMax.html">
   ReduceMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMean.html">
   ReduceMean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMin.html">
   ReduceMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceProd.html">
   ReduceProd
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSum.html">
   ReduceSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSumSquare.html">
   ReduceSumSquare
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Relu.html">
   Relu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reshape.html">
   Reshape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Resize.html">
   Resize
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReverseSequence.html">
   ReverseSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RoiAlign.html">
   RoiAlign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Round.html">
   Round
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__STFT.html">
   STFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scan.html">
   Scan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scatter.html">
   Scatter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterElements.html">
   ScatterElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterND.html">
   ScatterND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Selu.html">
   Selu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceAt.html">
   SequenceAt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceConstruct.html">
   SequenceConstruct
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceEmpty.html">
   SequenceEmpty
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceErase.html">
   SequenceErase
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceInsert.html">
   SequenceInsert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceLength.html">
   SequenceLength
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceMap.html">
   SequenceMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shape.html">
   Shape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shrink.html">
   Shrink
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sigmoid.html">
   Sigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sign.html">
   Sign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sin.html">
   Sin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sinh.html">
   Sinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Size.html">
   Size
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Slice.html">
   Slice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softmax.html">
   Softmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
   SoftmaxCrossEntropyLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softplus.html">
   Softplus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softsign.html">
   Softsign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SpaceToDepth.html">
   SpaceToDepth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Split.html">
   Split
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SplitToSequence.html">
   SplitToSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sqrt.html">
   Sqrt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Squeeze.html">
   Squeeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__StringNormalizer.html">
   StringNormalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sub.html">
   Sub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sum.html">
   Sum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tan.html">
   Tan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tanh.html">
   Tanh
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   TfIdfVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ThresholdedRelu.html">
   ThresholdedRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tile.html">
   Tile
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__TopK.html">
   TopK
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Transpose.html">
   Transpose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Trilu.html">
   Trilu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unique.html">
   Unique
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unsqueeze.html">
   Unsqueeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Upsample.html">
   Upsample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Where.html">
   Where
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Xor.html">
   Xor
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
   ai.onnx.ml - ArrayFeatureExtractor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
   ai.onnx.ml - Binarizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CastMap.html">
   ai.onnx.ml - CastMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
   ai.onnx.ml - CategoryMapper
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
   ai.onnx.ml - DictVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
   ai.onnx.ml - FeatureVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Imputer.html">
   ai.onnx.ml - Imputer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
   ai.onnx.ml - LabelEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
   ai.onnx.ml - LinearClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
   ai.onnx.ml - LinearRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
   ai.onnx.ml - Normalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
   ai.onnx.ml - OneHotEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
   ai.onnx.ml - SVMClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
   ai.onnx.ml - SVMRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Scaler.html">
   ai.onnx.ml - Scaler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
   ai.onnx.ml - TreeEnsembleClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
   ai.onnx.ml - TreeEnsembleRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
   ai.onnx.ml - ZipMap
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
   ai.onnx.preview.training - Adagrad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
   ai.onnx.preview.training - Adam
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
   ai.onnx.preview.training - Gradient
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
   ai.onnx.preview.training - Momentum
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="table_main.html">
   operator table for domain main
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_ml.html">
   operator table for domain ai.onnx.ml
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_preview_training.html">
   operator table for domain ai.onnx.preview.training
  </a>
 </li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="tfidfvectorizer">
<span id="l-onnx-doc-tfidfvectorizer"></span><h1>TfIdfVectorizer<a class="headerlink" href="#tfidfvectorizer" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#tfidfvectorizer-9" id="id1">TfIdfVectorizer - 9</a></p></li>
</ul>
</nav>
<section id="tfidfvectorizer-9">
<span id="l-onnx-op-tfidfvectorizer-9"></span><h2><a class="toc-backref" href="#id1" role="doc-backlink">TfIdfVectorizer - 9</a><a class="headerlink" href="#tfidfvectorizer-9" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#TfIdfVectorizer">TfIdfVectorizer (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>9</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 9</strong>.</p>
<p><strong>Summary</strong></p>
<p>This transform extracts n-grams from the input sequence and save them as a vector. Input can
be either a 1-D or 2-D tensor. For 1-D input, output is the n-gram representation of that input.
For 2-D input, the output is also a  2-D tensor whose i-th row is the n-gram representation of the i-th input row.
More specifically, if input shape is [C], the corresponding output shape would be [max(ngram_indexes) + 1].
If input shape is [N, C], this operator produces a [N, max(ngram_indexes) + 1]-tensor.</p>
<p>In contrast to standard n-gram extraction, here, the indexes of extracting an n-gram from the original
sequence are not necessarily consecutive numbers. The discontinuity between indexes are controlled by the number of skips.
If the number of skips is 2, we should skip two tokens when scanning through the original sequence.
Let’s consider an example. Assume that input sequence is [94, 17, 36, 12, 28] and the number of skips is 2.
The associated 2-grams are [94, 12] and [17, 28] respectively indexed by [0, 3] and [1, 4].
If the number of skips becomes 0, the 2-grams generated are [94, 17], [17, 36], [36, 12], [12, 28]
indexed by [0, 1], [1, 2], [2, 3], [3, 4], respectively.</p>
<p>The output vector (denoted by Y) stores the count of each n-gram;
Y[ngram_indexes[i]] indicates the times that the i-th n-gram is found. The attribute ngram_indexes is used to determine the mapping
between index i and the corresponding n-gram’s output coordinate. If pool_int64s is [94, 17, 17, 36], ngram_indexes is [1, 0],
ngram_counts=[0, 0], then the Y[0] (first element in Y) and Y[1] (second element in Y) are the counts of [17, 36] and [94, 17],
respectively. An n-gram which cannot be found in pool_strings/pool_int64s should be ignored and has no effect on the output.
Note that we may consider all skips up to S when generating the n-grams.</p>
<p>The examples used above are true if mode is “TF”. If mode is “IDF”, all the counts larger than 1 would be truncated to 1 and
the i-th element in weights would be used to scale (by multiplication) the count of the i-th n-gram in pool. If mode is “TFIDF”,
this operator first computes the counts of all n-grams and then scale them by the associated values in the weights attribute.</p>
<p>Only one of pool_strings and pool_int64s can be set. If pool_int64s is set, the input should be an integer tensor.
If pool_strings is set, the input must be a string tensor.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>max_gram_length</strong> (required):
Maximum n-gram length. If this value is 3, 3-grams will be used to
generate the output.</p></li>
<li><p><strong>max_skip_count</strong> (required):
Maximum number of items (integers/strings) to be skipped when
constructing an n-gram from X. If max_skip_count=1,
min_gram_length=2, max_gram_length=3, this operator may generate
2-grams with skip_count=0 and skip_count=1, and 3-grams with
skip_count=0 and skip_count=1</p></li>
<li><p><strong>min_gram_length</strong> (required):
Minimum n-gram length. If this value is 2 and max_gram_length is 3,
output may contain counts of 2-grams and 3-grams.</p></li>
<li><p><strong>mode</strong> (required):
The weighting criteria. It can be one of “TF” (term frequency),
“IDF” (inverse document frequency), and “TFIDF” (the combination of
TF and IDF)</p></li>
<li><p><strong>ngram_counts</strong> (required):
The starting indexes of 1-grams, 2-grams, and so on in pool. It is
useful when determining the boundary between two consecutive
collections of n-grams. For example, if ngram_counts is [0, 17, 36],
the first index (zero-based) of 1-gram/2-gram/3-gram in pool are
0/17/36. This format is essentially identical to CSR (or CSC) sparse
matrix format, and we choose to use this due to its popularity.</p></li>
<li><p><strong>ngram_indexes</strong> (required):
list of int64s (type: AttributeProto::INTS). This list is parallel
to the specified ‘pool_*’ attribute. The i-th element in
ngram_indexes indicate the coordinate of the i-th n-gram in the
output tensor.</p></li>
<li><p><strong>pool_int64s</strong>:
List of int64 n-grams learned from the training set. Either this or
pool_strings attributes must be present but not both. It’s an 1-D
tensor starting with the collections of all 1-grams and ending with
the collections of n-grams. The i-th element in pool stores the
n-gram that should be mapped to coordinate ngram_indexes[i] in the
output vector.</p></li>
<li><p><strong>pool_strings</strong>:
List of strings n-grams learned from the training set. Either this
or pool_int64s attributes must be present but not both. It’s an 1-D
tensor starting with the collections of all 1-grams and ending with
the collections of n-grams. The i-th element in pool stores the
n-gram that should be mapped to coordinate ngram_indexes[i] in the
output vector.</p></li>
<li><p><strong>weights</strong>:
list of floats. This attribute stores the weight of each n-gram in
pool. The i-th element in weights is the weight of the i-th n-gram
in pool. Its length equals to the size of ngram_indexes. By default,
weights is an all-one tensor.This attribute is used when mode is
“IDF” or “TFIDF” to scale the associated word counts.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input for n-gram extraction</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T1</strong>:
Ngram results</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(int32),
tensor(int64),
tensor(string)
):
Input is ether string UTF-8 or int32/int64</p></li>
<li><p><strong>T1</strong> in (
tensor(float)
):
1-D tensor of floats</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>_tf_only_bigrams_skip0</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">ngram_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">ngram_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">pool_int64s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># unigrams</span>
    <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="p">)</span>  <span class="c1"># bigrams</span>

<span class="n">helper</span> <span class="o">=</span> <span class="n">TfIdfVectorizerHelper</span><span class="p">(</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;TF&quot;</span><span class="p">,</span>
    <span class="n">min_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_skip_count</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">ngram_counts</span><span class="o">=</span><span class="n">ngram_counts</span><span class="p">,</span>
    <span class="n">ngram_indexes</span><span class="o">=</span><span class="n">ngram_indexes</span><span class="p">,</span>
    <span class="n">pool_int64s</span><span class="o">=</span><span class="n">pool_int64s</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node_noweights</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_tfidfvectorizer_tf_only_bigrams_skip0&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_tf_batch_onlybigrams_skip0</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">ngram_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">ngram_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">pool_int64s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># unigrams</span>
    <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="p">)</span>  <span class="c1"># bigrams</span>

<span class="n">helper</span> <span class="o">=</span> <span class="n">TfIdfVectorizerHelper</span><span class="p">(</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;TF&quot;</span><span class="p">,</span>
    <span class="n">min_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_skip_count</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">ngram_counts</span><span class="o">=</span><span class="n">ngram_counts</span><span class="p">,</span>
    <span class="n">ngram_indexes</span><span class="o">=</span><span class="n">ngram_indexes</span><span class="p">,</span>
    <span class="n">pool_int64s</span><span class="o">=</span><span class="n">pool_int64s</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node_noweights</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_tfidfvectorizer_tf_batch_onlybigrams_skip0&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_tf_onlybigrams_levelempty</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">ngram_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">ngram_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">pool_int64s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># unigrams none</span>
    <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="p">)</span>  <span class="c1"># bigrams</span>

<span class="n">helper</span> <span class="o">=</span> <span class="n">TfIdfVectorizerHelper</span><span class="p">(</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;TF&quot;</span><span class="p">,</span>
    <span class="n">min_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_skip_count</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">ngram_counts</span><span class="o">=</span><span class="n">ngram_counts</span><span class="p">,</span>
    <span class="n">ngram_indexes</span><span class="o">=</span><span class="n">ngram_indexes</span><span class="p">,</span>
    <span class="n">pool_int64s</span><span class="o">=</span><span class="n">pool_int64s</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node_noweights</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_tfidfvectorizer_tf_onlybigrams_levelempty&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_tf_onlybigrams_skip5</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">ngram_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">ngram_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">pool_int64s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># unigrams</span>
    <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="p">)</span>  <span class="c1"># bigrams</span>

<span class="n">helper</span> <span class="o">=</span> <span class="n">TfIdfVectorizerHelper</span><span class="p">(</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;TF&quot;</span><span class="p">,</span>
    <span class="n">min_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_skip_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">ngram_counts</span><span class="o">=</span><span class="n">ngram_counts</span><span class="p">,</span>
    <span class="n">ngram_indexes</span><span class="o">=</span><span class="n">ngram_indexes</span><span class="p">,</span>
    <span class="n">pool_int64s</span><span class="o">=</span><span class="n">pool_int64s</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node_noweights</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_tfidfvectorizer_tf_onlybigrams_skip5&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_tf_batch_onlybigrams_skip5</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">ngram_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">ngram_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">pool_int64s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># unigrams</span>
    <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="p">)</span>  <span class="c1"># bigrams</span>

<span class="n">helper</span> <span class="o">=</span> <span class="n">TfIdfVectorizerHelper</span><span class="p">(</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;TF&quot;</span><span class="p">,</span>
    <span class="n">min_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_skip_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">ngram_counts</span><span class="o">=</span><span class="n">ngram_counts</span><span class="p">,</span>
    <span class="n">ngram_indexes</span><span class="o">=</span><span class="n">ngram_indexes</span><span class="p">,</span>
    <span class="n">pool_int64s</span><span class="o">=</span><span class="n">pool_int64s</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node_noweights</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_tfidfvectorizer_tf_batch_onlybigrams_skip5&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_tf_uniandbigrams_skip5</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">ngram_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">ngram_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">pool_int64s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># unigrams</span>
    <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="p">)</span>  <span class="c1"># bigrams</span>

<span class="n">helper</span> <span class="o">=</span> <span class="n">TfIdfVectorizerHelper</span><span class="p">(</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;TF&quot;</span><span class="p">,</span>
    <span class="n">min_gram_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_skip_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">ngram_counts</span><span class="o">=</span><span class="n">ngram_counts</span><span class="p">,</span>
    <span class="n">ngram_indexes</span><span class="o">=</span><span class="n">ngram_indexes</span><span class="p">,</span>
    <span class="n">pool_int64s</span><span class="o">=</span><span class="n">pool_int64s</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node_noweights</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_tfidfvectorizer_tf_uniandbigrams_skip5&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_tf_batch_uniandbigrams_skip5</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">ngram_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">ngram_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">pool_int64s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>  <span class="c1"># unigrams</span>
    <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="p">)</span>  <span class="c1"># bigrams</span>

<span class="n">helper</span> <span class="o">=</span> <span class="n">TfIdfVectorizerHelper</span><span class="p">(</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;TF&quot;</span><span class="p">,</span>
    <span class="n">min_gram_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_gram_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">max_skip_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">ngram_counts</span><span class="o">=</span><span class="n">ngram_counts</span><span class="p">,</span>
    <span class="n">ngram_indexes</span><span class="o">=</span><span class="n">ngram_indexes</span><span class="p">,</span>
    <span class="n">pool_int64s</span><span class="o">=</span><span class="n">pool_int64s</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node_noweights</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_tfidfvectorizer_tf_batch_uniandbigrams_skip5&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="onnx__Tanh.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Tanh</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="onnx__ThresholdedRelu.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">ThresholdedRelu</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fas fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tfidfvectorizer-9">
   TfIdfVectorizer - 9
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="../_sources/onnx_doc_folder/onnx__TfIdfVectorizer.rst.txt">
        <i class="fas fa-file-alt"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>