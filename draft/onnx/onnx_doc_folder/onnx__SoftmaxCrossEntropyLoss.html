
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>SoftmaxCrossEntropyLoss &#8212; ONNX 0.1 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'onnx_doc_folder/onnx__SoftmaxCrossEntropyLoss';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Softplus" href="onnx__Softplus.html" />
    <link rel="prev" title="Softmax" href="onnx__Softmax.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fas fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fas fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Abs.html">
   Abs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acos.html">
   Acos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acosh.html">
   Acosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Add.html">
   Add
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__And.html">
   And
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMax.html">
   ArgMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMin.html">
   ArgMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asin.html">
   Asin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asinh.html">
   Asinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atan.html">
   Atan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atanh.html">
   Atanh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__AveragePool.html">
   AveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BatchNormalization.html">
   BatchNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Bernoulli.html">
   Bernoulli
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BitShift.html">
   BitShift
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BlackmanWindow.html">
   BlackmanWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cast.html">
   Cast
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CastLike.html">
   CastLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Ceil.html">
   Ceil
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Celu.html">
   Celu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CenterCropPad.html">
   CenterCropPad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Clip.html">
   Clip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Col2Im.html">
   Col2Im
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Compress.html">
   Compress
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Concat.html">
   Concat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConcatFromSequence.html">
   ConcatFromSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Constant.html">
   Constant
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConstantOfShape.html">
   ConstantOfShape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Conv.html">
   Conv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvInteger.html">
   ConvInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvTranspose.html">
   ConvTranspose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cos.html">
   Cos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cosh.html">
   Cosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CumSum.html">
   CumSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DFT.html">
   DFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DepthToSpace.html">
   DepthToSpace
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DequantizeLinear.html">
   DequantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Det.html">
   Det
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Div.html">
   Div
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Dropout.html">
   Dropout
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
   DynamicQuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Einsum.html">
   Einsum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Elu.html">
   Elu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Equal.html">
   Equal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Erf.html">
   Erf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Exp.html">
   Exp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Expand.html">
   Expand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__EyeLike.html">
   EyeLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Flatten.html">
   Flatten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Floor.html">
   Floor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GRU.html">
   GRU
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gather.html">
   Gather
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherElements.html">
   GatherElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherND.html">
   GatherND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gemm.html">
   Gemm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalAveragePool.html">
   GlobalAveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalLpPool.html">
   GlobalLpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalMaxPool.html">
   GlobalMaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Greater.html">
   Greater
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GreaterOrEqual.html">
   GreaterOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GridSample.html">
   GridSample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HammingWindow.html">
   HammingWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HannWindow.html">
   HannWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSigmoid.html">
   HardSigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSwish.html">
   HardSwish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Hardmax.html">
   Hardmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Identity.html">
   Identity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__If.html">
   If
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__InstanceNormalization.html">
   InstanceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsInf.html">
   IsInf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsNaN.html">
   IsNaN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LRN.html">
   LRN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LSTM.html">
   LSTM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LayerNormalization.html">
   LayerNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LeakyRelu.html">
   LeakyRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Less.html">
   Less
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LessOrEqual.html">
   LessOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Log.html">
   Log
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LogSoftmax.html">
   LogSoftmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Loop.html">
   Loop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpNormalization.html">
   LpNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpPool.html">
   LpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMul.html">
   MatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMulInteger.html">
   MatMulInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Max.html">
   Max
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxPool.html">
   MaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxRoiPool.html">
   MaxRoiPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxUnpool.html">
   MaxUnpool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mean.html">
   Mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
   MeanVarianceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MelWeightMatrix.html">
   MelWeightMatrix
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Min.html">
   Min
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mish.html">
   Mish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mod.html">
   Mod
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mul.html">
   Mul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Multinomial.html">
   Multinomial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Neg.html">
   Neg
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
   NegativeLogLikelihoodLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonMaxSuppression.html">
   NonMaxSuppression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonZero.html">
   NonZero
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Not.html">
   Not
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OneHot.html">
   OneHot
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Optional.html">
   Optional
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalGetElement.html">
   OptionalGetElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalHasElement.html">
   OptionalHasElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Or.html">
   Or
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__PRelu.html">
   PRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pad.html">
   Pad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pow.html">
   Pow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearConv.html">
   QLinearConv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearMatMul.html">
   QLinearMatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QuantizeLinear.html">
   QuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RNN.html">
   RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormal.html">
   RandomNormal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormalLike.html">
   RandomNormalLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniform.html">
   RandomUniform
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniformLike.html">
   RandomUniformLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Range.html">
   Range
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reciprocal.html">
   Reciprocal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL1.html">
   ReduceL1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL2.html">
   ReduceL2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSum.html">
   ReduceLogSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSumExp.html">
   ReduceLogSumExp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMax.html">
   ReduceMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMean.html">
   ReduceMean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMin.html">
   ReduceMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceProd.html">
   ReduceProd
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSum.html">
   ReduceSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSumSquare.html">
   ReduceSumSquare
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Relu.html">
   Relu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reshape.html">
   Reshape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Resize.html">
   Resize
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReverseSequence.html">
   ReverseSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RoiAlign.html">
   RoiAlign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Round.html">
   Round
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__STFT.html">
   STFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scan.html">
   Scan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scatter.html">
   Scatter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterElements.html">
   ScatterElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterND.html">
   ScatterND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Selu.html">
   Selu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceAt.html">
   SequenceAt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceConstruct.html">
   SequenceConstruct
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceEmpty.html">
   SequenceEmpty
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceErase.html">
   SequenceErase
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceInsert.html">
   SequenceInsert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceLength.html">
   SequenceLength
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceMap.html">
   SequenceMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shape.html">
   Shape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shrink.html">
   Shrink
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sigmoid.html">
   Sigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sign.html">
   Sign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sin.html">
   Sin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sinh.html">
   Sinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Size.html">
   Size
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Slice.html">
   Slice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softmax.html">
   Softmax
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   SoftmaxCrossEntropyLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softplus.html">
   Softplus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softsign.html">
   Softsign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SpaceToDepth.html">
   SpaceToDepth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Split.html">
   Split
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SplitToSequence.html">
   SplitToSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sqrt.html">
   Sqrt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Squeeze.html">
   Squeeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__StringNormalizer.html">
   StringNormalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sub.html">
   Sub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sum.html">
   Sum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tan.html">
   Tan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tanh.html">
   Tanh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__TfIdfVectorizer.html">
   TfIdfVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ThresholdedRelu.html">
   ThresholdedRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tile.html">
   Tile
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__TopK.html">
   TopK
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Transpose.html">
   Transpose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Trilu.html">
   Trilu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unique.html">
   Unique
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unsqueeze.html">
   Unsqueeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Upsample.html">
   Upsample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Where.html">
   Where
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Xor.html">
   Xor
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
   ai.onnx.ml - ArrayFeatureExtractor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
   ai.onnx.ml - Binarizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CastMap.html">
   ai.onnx.ml - CastMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
   ai.onnx.ml - CategoryMapper
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
   ai.onnx.ml - DictVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
   ai.onnx.ml - FeatureVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Imputer.html">
   ai.onnx.ml - Imputer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
   ai.onnx.ml - LabelEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
   ai.onnx.ml - LinearClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
   ai.onnx.ml - LinearRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
   ai.onnx.ml - Normalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
   ai.onnx.ml - OneHotEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
   ai.onnx.ml - SVMClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
   ai.onnx.ml - SVMRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Scaler.html">
   ai.onnx.ml - Scaler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
   ai.onnx.ml - TreeEnsembleClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
   ai.onnx.ml - TreeEnsembleRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
   ai.onnx.ml - ZipMap
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
   ai.onnx.preview.training - Adagrad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
   ai.onnx.preview.training - Adam
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
   ai.onnx.preview.training - Gradient
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
   ai.onnx.preview.training - Momentum
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="table_main.html">
   operator table for domain main
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_ml.html">
   operator table for domain ai.onnx.ml
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_preview_training.html">
   operator table for domain ai.onnx.preview.training
  </a>
 </li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="softmaxcrossentropyloss">
<span id="l-onnx-doc-softmaxcrossentropyloss"></span><h1>SoftmaxCrossEntropyLoss<a class="headerlink" href="#softmaxcrossentropyloss" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#softmaxcrossentropyloss-13" id="id2">SoftmaxCrossEntropyLoss - 13</a></p></li>
<li><p><a class="reference internal" href="#softmaxcrossentropyloss-12" id="id3">SoftmaxCrossEntropyLoss - 12</a></p></li>
</ul>
</nav>
<section id="softmaxcrossentropyloss-13">
<span id="l-onnx-op-softmaxcrossentropyloss-13"></span><h2><a class="toc-backref" href="#id2" role="doc-backlink">SoftmaxCrossEntropyLoss - 13</a><a class="headerlink" href="#softmaxcrossentropyloss-13" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#SoftmaxCrossEntropyLoss">SoftmaxCrossEntropyLoss (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>13</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 13</strong>.</p>
<p><strong>Summary</strong></p>
<p>Loss function that measures the softmax cross entropy
between ‘scores’ and ‘labels’.
This operator first computes a loss tensor whose shape is identical to the labels input.
If the input is 2-D with shape (N, C), the loss tensor may be a N-element vector L = (l_1, l_2, …, l_N).
If the input is N-D tensor with shape (N, C, D1, D2, …, Dk),
the loss tensor L may have (N, D1, D2, …, Dk) as its shape and L[i,][j_1][j_2]…[j_k] denotes a scalar element in L.
After L is available, this operator can optionally do a reduction operator.</p>
<dl class="simple">
<dt>shape(scores): (N, C) where C is the number of classes, or (N, C, D1, D2,…, Dk),</dt><dd><p>with K &gt;= 1 in case of K-dimensional loss.</p>
</dd>
<dt>shape(labels): (N) where each value is 0 &lt;= labels[i] &lt;= C-1, or (N, D1, D2,…, Dk),</dt><dd><p>with K &gt;= 1 in case of K-dimensional loss.</p>
</dd>
<dt>The loss for one sample, l_i, can caculated as follows:</dt><dd><p>l[i][d1][d2]…[dk] = -y[i][c][d1][d2]..[dk], where i is the index of classes.</p>
</dd>
<dt>or</dt><dd><p>l[i][d1][d2]…[dk] = -y[i][c][d1][d2]..[dk] * weights[c], if ‘weights’ is provided.</p>
</dd>
<dt>loss is zero for the case when label-value equals ignore_index.</dt><dd><p>l[i][d1][d2]…[dk]  = 0, when labels[n][d1][d2]…[dk] = ignore_index</p>
</dd>
<dt>where:</dt><dd><p>p = Softmax(scores)
y = Log(p)
c = labels[i][d1][d2]…[dk]</p>
</dd>
</dl>
<p>Finally, L is optionally reduced:
If reduction = ‘none’, the output is L with shape (N, D1, D2, …, Dk).
If reduction = ‘sum’, the output is scalar: Sum(L).
If reduction = ‘mean’, the output is scalar: ReduceMean(L), or if weight is provided: ReduceSum(L) / ReduceSum(W),
where tensor W is of shape (N, D1, D2, …, Dk) and W[n][d1][d2]…[dk] = weights[labels[i][d1][d2]…[dk]].</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>ignore_index</strong>:
Specifies a target value that is ignored and does not contribute to
the input gradient. It’s an optional value.</p></li>
<li><p><strong>reduction</strong>:
Type of reduction to apply to loss: none, sum, mean(default).
‘none’: no reduction will be applied, ‘sum’: the output will be
summed. ‘mean’: the sum of the output will be divided by the number
of elements in the output.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>scores</strong> (heterogeneous) - <strong>T</strong>:
The predicted outputs with shape [batch_size, class_size], or
[batch_size, class_size, D1, D2 , …, Dk], where K is the number of
dimensions.</p></li>
<li><p><strong>labels</strong> (heterogeneous) - <strong>Tind</strong>:
The ground truth output tensor, with shape [batch_size], or
[batch_size, D1, D2, …, Dk], where K is the number of dimensions.
Labels element value shall be in range of [0, C). If ignore_index is
specified, it may have a value outside [0, C) and the label values
should either be in the range [0, C) or have the value ignore_index.</p></li>
<li><p><strong>weights</strong> (optional, heterogeneous) - <strong>T</strong>:
A manual rescaling weight given to each class. If given, it has to
be a 1D Tensor assigning weight to each of the classes. Otherwise,
it is treated as if having all ones.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 2 outputs.</p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
Weighted loss float Tensor. If reduction is ‘none’, this has the
shape of [batch_size], or [batch_size, D1, D2, …, Dk] in case of
K-dimensional loss. Otherwise, it is a scalar.</p></li>
<li><p><strong>log_prob</strong> (optional, heterogeneous) - <strong>T</strong>:
Log probability tensor. If the output of softmax is prob, its value
is log(prob).</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>Tind</strong> in (
tensor(int32),
tensor(int64)
):
Constrain target to integer types</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to217__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to217__0">f</a></td><td class="diff_header" id="from217_1">1</td><td nowrap="nowrap">Loss&nbsp;function&nbsp;that&nbsp;measures&nbsp;the&nbsp;softmax&nbsp;cross&nbsp;entropy</td><td class="diff_next"><a href="#difflib_chg_to217__0">f</a></td><td class="diff_header" id="to217_1">1</td><td nowrap="nowrap">Loss&nbsp;function&nbsp;that&nbsp;measures&nbsp;the&nbsp;softmax&nbsp;cross&nbsp;entropy</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_2">2</td><td nowrap="nowrap">between&nbsp;'scores'&nbsp;and&nbsp;'labels'.</td><td class="diff_next"></td><td class="diff_header" id="to217_2">2</td><td nowrap="nowrap">between&nbsp;'scores'&nbsp;and&nbsp;'labels'.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_3">3</td><td nowrap="nowrap">This&nbsp;operator&nbsp;first&nbsp;computes&nbsp;a&nbsp;loss&nbsp;tensor&nbsp;whose&nbsp;shape&nbsp;is&nbsp;identical&nbsp;to&nbsp;the&nbsp;labels&nbsp;input.</td><td class="diff_next"></td><td class="diff_header" id="to217_3">3</td><td nowrap="nowrap">This&nbsp;operator&nbsp;first&nbsp;computes&nbsp;a&nbsp;loss&nbsp;tensor&nbsp;whose&nbsp;shape&nbsp;is&nbsp;identical&nbsp;to&nbsp;the&nbsp;labels&nbsp;input.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_4">4</td><td nowrap="nowrap">If&nbsp;the&nbsp;input&nbsp;is&nbsp;2-D&nbsp;with&nbsp;shape&nbsp;(N,&nbsp;C),&nbsp;the&nbsp;loss&nbsp;tensor&nbsp;may&nbsp;be&nbsp;a&nbsp;N-element&nbsp;vector&nbsp;L&nbsp;=&nbsp;(l_1,&nbsp;l_2,&nbsp;...,&nbsp;l_N).</td><td class="diff_next"></td><td class="diff_header" id="to217_4">4</td><td nowrap="nowrap">If&nbsp;the&nbsp;input&nbsp;is&nbsp;2-D&nbsp;with&nbsp;shape&nbsp;(N,&nbsp;C),&nbsp;the&nbsp;loss&nbsp;tensor&nbsp;may&nbsp;be&nbsp;a&nbsp;N-element&nbsp;vector&nbsp;L&nbsp;=&nbsp;(l_1,&nbsp;l_2,&nbsp;...,&nbsp;l_N).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_5">5</td><td nowrap="nowrap">If&nbsp;the&nbsp;input&nbsp;is&nbsp;N-D&nbsp;tensor&nbsp;with&nbsp;shape&nbsp;(N,&nbsp;C,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk),</td><td class="diff_next"></td><td class="diff_header" id="to217_5">5</td><td nowrap="nowrap">If&nbsp;the&nbsp;input&nbsp;is&nbsp;N-D&nbsp;tensor&nbsp;with&nbsp;shape&nbsp;(N,&nbsp;C,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_6">6</td><td nowrap="nowrap">the&nbsp;loss&nbsp;tensor&nbsp;L&nbsp;may&nbsp;have&nbsp;(N,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk)&nbsp;as&nbsp;its&nbsp;shape&nbsp;and&nbsp;L[i,][j_1][j_2]...[j_k]&nbsp;denotes&nbsp;a&nbsp;scalar&nbsp;element&nbsp;in&nbsp;L.</td><td class="diff_next"></td><td class="diff_header" id="to217_6">6</td><td nowrap="nowrap">the&nbsp;loss&nbsp;tensor&nbsp;L&nbsp;may&nbsp;have&nbsp;(N,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk)&nbsp;as&nbsp;its&nbsp;shape&nbsp;and&nbsp;L[i,][j_1][j_2]...[j_k]&nbsp;denotes&nbsp;a&nbsp;scalar&nbsp;element&nbsp;in&nbsp;L.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_7">7</td><td nowrap="nowrap">After&nbsp;L&nbsp;is&nbsp;available,&nbsp;this&nbsp;operator&nbsp;can&nbsp;optionally&nbsp;do&nbsp;a&nbsp;reduction&nbsp;operator.</td><td class="diff_next"></td><td class="diff_header" id="to217_7">7</td><td nowrap="nowrap">After&nbsp;L&nbsp;is&nbsp;available,&nbsp;this&nbsp;operator&nbsp;can&nbsp;optionally&nbsp;do&nbsp;a&nbsp;reduction&nbsp;operator.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_8">8</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_8">8</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_9">9</td><td nowrap="nowrap">shape(scores):&nbsp;(N,&nbsp;C)&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;classes,&nbsp;or&nbsp;(N,&nbsp;C,&nbsp;D1,&nbsp;D2,...,&nbsp;Dk),</td><td class="diff_next"></td><td class="diff_header" id="to217_9">9</td><td nowrap="nowrap">shape(scores):&nbsp;(N,&nbsp;C)&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;classes,&nbsp;or&nbsp;(N,&nbsp;C,&nbsp;D1,&nbsp;D2,...,&nbsp;Dk),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_10">10</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;K&nbsp;&gt;=&nbsp;1&nbsp;in&nbsp;case&nbsp;of&nbsp;K-dimensional&nbsp;loss.</td><td class="diff_next"></td><td class="diff_header" id="to217_10">10</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;K&nbsp;&gt;=&nbsp;1&nbsp;in&nbsp;case&nbsp;of&nbsp;K-dimensional&nbsp;loss.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_11">11</td><td nowrap="nowrap">shape(labels):&nbsp;(N)&nbsp;where&nbsp;each&nbsp;value&nbsp;is&nbsp;0&nbsp;&lt;=&nbsp;labels[i]&nbsp;&lt;=&nbsp;C-1,&nbsp;or&nbsp;(N,&nbsp;D1,&nbsp;D2,...,&nbsp;Dk),</td><td class="diff_next"></td><td class="diff_header" id="to217_11">11</td><td nowrap="nowrap">shape(labels):&nbsp;(N)&nbsp;where&nbsp;each&nbsp;value&nbsp;is&nbsp;0&nbsp;&lt;=&nbsp;labels[i]&nbsp;&lt;=&nbsp;C-1,&nbsp;or&nbsp;(N,&nbsp;D1,&nbsp;D2,...,&nbsp;Dk),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;K&nbsp;&gt;=&nbsp;1&nbsp;in&nbsp;case&nbsp;of&nbsp;K-dimensional&nbsp;loss.</td><td class="diff_next"></td><td class="diff_header" id="to217_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;K&nbsp;&gt;=&nbsp;1&nbsp;in&nbsp;case&nbsp;of&nbsp;K-dimensional&nbsp;loss.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_13">13</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_14">14</td><td nowrap="nowrap">The&nbsp;loss&nbsp;for&nbsp;one&nbsp;sample,&nbsp;l_i,&nbsp;can&nbsp;caculated&nbsp;as&nbsp;follows:</td><td class="diff_next"></td><td class="diff_header" id="to217_14">14</td><td nowrap="nowrap">The&nbsp;loss&nbsp;for&nbsp;one&nbsp;sample,&nbsp;l_i,&nbsp;can&nbsp;caculated&nbsp;as&nbsp;follows:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;l[i][d1][d2]...[dk]&nbsp;=&nbsp;-y[i][c][d1][d2]..[dk],&nbsp;where&nbsp;i&nbsp;is&nbsp;the&nbsp;index&nbsp;of&nbsp;classes.</td><td class="diff_next"></td><td class="diff_header" id="to217_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;l[i][d1][d2]...[dk]&nbsp;=&nbsp;-y[i][c][d1][d2]..[dk],&nbsp;where&nbsp;i&nbsp;is&nbsp;the&nbsp;index&nbsp;of&nbsp;classes.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_16">16</td><td nowrap="nowrap">or</td><td class="diff_next"></td><td class="diff_header" id="to217_16">16</td><td nowrap="nowrap">or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;l[i][d1][d2]...[dk]&nbsp;=&nbsp;-y[i][c][d1][d2]..[dk]&nbsp;*&nbsp;weights[c],&nbsp;if&nbsp;'weights'&nbsp;is&nbsp;provided.</td><td class="diff_next"></td><td class="diff_header" id="to217_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;l[i][d1][d2]...[dk]&nbsp;=&nbsp;-y[i][c][d1][d2]..[dk]&nbsp;*&nbsp;weights[c],&nbsp;if&nbsp;'weights'&nbsp;is&nbsp;provided.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_18">18</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_19">19</td><td nowrap="nowrap">loss&nbsp;is&nbsp;zero&nbsp;for&nbsp;the&nbsp;case&nbsp;when&nbsp;label-value&nbsp;equals&nbsp;ignore_index.</td><td class="diff_next"></td><td class="diff_header" id="to217_19">19</td><td nowrap="nowrap">loss&nbsp;is&nbsp;zero&nbsp;for&nbsp;the&nbsp;case&nbsp;when&nbsp;label-value&nbsp;equals&nbsp;ignore_index.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;l[i][d1][d2]...[dk]&nbsp;&nbsp;=&nbsp;0,&nbsp;when&nbsp;labels[n][d1][d2]...[dk]&nbsp;=&nbsp;ignore_index</td><td class="diff_next"></td><td class="diff_header" id="to217_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;l[i][d1][d2]...[dk]&nbsp;&nbsp;=&nbsp;0,&nbsp;when&nbsp;labels[n][d1][d2]...[dk]&nbsp;=&nbsp;ignore_index</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_21">21</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_22">22</td><td nowrap="nowrap">where:</td><td class="diff_next"></td><td class="diff_header" id="to217_22">22</td><td nowrap="nowrap">where:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;p&nbsp;=&nbsp;Softmax(scores)</td><td class="diff_next"></td><td class="diff_header" id="to217_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;p&nbsp;=&nbsp;Softmax(scores)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;=&nbsp;Log(p)</td><td class="diff_next"></td><td class="diff_header" id="to217_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;=&nbsp;Log(p)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;c&nbsp;=&nbsp;labels[i][d1][d2]...[dk]</td><td class="diff_next"></td><td class="diff_header" id="to217_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;&nbsp;&nbsp;c&nbsp;=&nbsp;labels[i][d1][d2]...[dk]</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_26">26</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_26">26</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_27">27</td><td nowrap="nowrap">Finally,&nbsp;L&nbsp;is&nbsp;optionally&nbsp;reduced:</td><td class="diff_next"></td><td class="diff_header" id="to217_27">27</td><td nowrap="nowrap">Finally,&nbsp;L&nbsp;is&nbsp;optionally&nbsp;reduced:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_28">28</td><td nowrap="nowrap">If&nbsp;reduction&nbsp;=&nbsp;'none',&nbsp;the&nbsp;output&nbsp;is&nbsp;L&nbsp;with&nbsp;shape&nbsp;(N,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk).</td><td class="diff_next"></td><td class="diff_header" id="to217_28">28</td><td nowrap="nowrap">If&nbsp;reduction&nbsp;=&nbsp;'none',&nbsp;the&nbsp;output&nbsp;is&nbsp;L&nbsp;with&nbsp;shape&nbsp;(N,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_29">29</td><td nowrap="nowrap">If&nbsp;reduction&nbsp;=&nbsp;'sum',&nbsp;the&nbsp;output&nbsp;is&nbsp;scalar:&nbsp;Sum(L).</td><td class="diff_next"></td><td class="diff_header" id="to217_29">29</td><td nowrap="nowrap">If&nbsp;reduction&nbsp;=&nbsp;'sum',&nbsp;the&nbsp;output&nbsp;is&nbsp;scalar:&nbsp;Sum(L).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_30">30</td><td nowrap="nowrap">If&nbsp;reduction&nbsp;=&nbsp;'mean',&nbsp;the&nbsp;output&nbsp;is&nbsp;scalar:&nbsp;ReduceMean(L),&nbsp;or&nbsp;if&nbsp;weight&nbsp;is&nbsp;provided:&nbsp;ReduceSum(L)&nbsp;/&nbsp;ReduceSum(W),</td><td class="diff_next"></td><td class="diff_header" id="to217_30">30</td><td nowrap="nowrap">If&nbsp;reduction&nbsp;=&nbsp;'mean',&nbsp;the&nbsp;output&nbsp;is&nbsp;scalar:&nbsp;ReduceMean(L),&nbsp;or&nbsp;if&nbsp;weight&nbsp;is&nbsp;provided:&nbsp;ReduceSum(L)&nbsp;/&nbsp;ReduceSum(W),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_31">31</td><td nowrap="nowrap">where&nbsp;tensor&nbsp;W&nbsp;is&nbsp;of&nbsp;shape&nbsp;(N,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk)&nbsp;and&nbsp;W[n][d1][d2]...[dk]&nbsp;=&nbsp;weights[labels[i][d1][d2]...[dk]].</td><td class="diff_next"></td><td class="diff_header" id="to217_31">31</td><td nowrap="nowrap">where&nbsp;tensor&nbsp;W&nbsp;is&nbsp;of&nbsp;shape&nbsp;(N,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk)&nbsp;and&nbsp;W[n][d1][d2]...[dk]&nbsp;=&nbsp;weights[labels[i][d1][d2]...[dk]].</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_32">32</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_32">32</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_33">33</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to217_33">33</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_34">34</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_34">34</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_35">35</td><td nowrap="nowrap">*&nbsp;**ignore_index**:</td><td class="diff_next"></td><td class="diff_header" id="to217_35">35</td><td nowrap="nowrap">*&nbsp;**ignore_index**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;Specifies&nbsp;a&nbsp;target&nbsp;value&nbsp;that&nbsp;is&nbsp;ignored&nbsp;and&nbsp;does&nbsp;not&nbsp;contribute&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to217_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;Specifies&nbsp;a&nbsp;target&nbsp;value&nbsp;that&nbsp;is&nbsp;ignored&nbsp;and&nbsp;does&nbsp;not&nbsp;contribute&nbsp;to</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;input&nbsp;gradient.&nbsp;It's&nbsp;an&nbsp;optional&nbsp;value.</td><td class="diff_next"></td><td class="diff_header" id="to217_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;input&nbsp;gradient.&nbsp;It's&nbsp;an&nbsp;optional&nbsp;value.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_38">38</td><td nowrap="nowrap">*&nbsp;**reduction**:</td><td class="diff_next"></td><td class="diff_header" id="to217_38">38</td><td nowrap="nowrap">*&nbsp;**reduction**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Type&nbsp;of&nbsp;reduction&nbsp;to&nbsp;apply&nbsp;to&nbsp;loss:&nbsp;none,&nbsp;sum,&nbsp;mean(default).</td><td class="diff_next"></td><td class="diff_header" id="to217_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Type&nbsp;of&nbsp;reduction&nbsp;to&nbsp;apply&nbsp;to&nbsp;loss:&nbsp;none,&nbsp;sum,&nbsp;mean(default).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;'none':&nbsp;no&nbsp;reduction&nbsp;will&nbsp;be&nbsp;applied,&nbsp;'sum':&nbsp;the&nbsp;output&nbsp;will&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to217_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;'none':&nbsp;no&nbsp;reduction&nbsp;will&nbsp;be&nbsp;applied,&nbsp;'sum':&nbsp;the&nbsp;output&nbsp;will&nbsp;be</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;summed.&nbsp;'mean':&nbsp;the&nbsp;sum&nbsp;of&nbsp;the&nbsp;output&nbsp;will&nbsp;be&nbsp;divided&nbsp;by&nbsp;the&nbsp;number</td><td class="diff_next"></td><td class="diff_header" id="to217_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;summed.&nbsp;'mean':&nbsp;the&nbsp;sum&nbsp;of&nbsp;the&nbsp;output&nbsp;will&nbsp;be&nbsp;divided&nbsp;by&nbsp;the&nbsp;number</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;of&nbsp;elements&nbsp;in&nbsp;the&nbsp;output.</td><td class="diff_next"></td><td class="diff_header" id="to217_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;of&nbsp;elements&nbsp;in&nbsp;the&nbsp;output.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_43">43</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_43">43</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_44">44</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to217_44">44</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_45">45</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_45">45</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_46">46</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to217_46">46</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_47">47</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_47">47</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_48">48</td><td nowrap="nowrap">*&nbsp;**scores**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to217_48">48</td><td nowrap="nowrap">*&nbsp;**scores**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;predicted&nbsp;outputs&nbsp;with&nbsp;shape&nbsp;[batch_size,&nbsp;class_size],&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to217_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;predicted&nbsp;outputs&nbsp;with&nbsp;shape&nbsp;[batch_size,&nbsp;class_size],&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;[batch_size,&nbsp;class_size,&nbsp;D1,&nbsp;D2&nbsp;,&nbsp;...,&nbsp;Dk],&nbsp;where&nbsp;K&nbsp;is&nbsp;the&nbsp;number&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to217_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;[batch_size,&nbsp;class_size,&nbsp;D1,&nbsp;D2&nbsp;,&nbsp;...,&nbsp;Dk],&nbsp;where&nbsp;K&nbsp;is&nbsp;the&nbsp;number&nbsp;of</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;dimensions.</td><td class="diff_next"></td><td class="diff_header" id="to217_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;dimensions.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_52">52</td><td nowrap="nowrap">*&nbsp;**labels**&nbsp;(heterogeneous)&nbsp;-&nbsp;**Tind**:</td><td class="diff_next"></td><td class="diff_header" id="to217_52">52</td><td nowrap="nowrap">*&nbsp;**labels**&nbsp;(heterogeneous)&nbsp;-&nbsp;**Tind**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;ground&nbsp;truth&nbsp;output&nbsp;tensor,&nbsp;with&nbsp;shape&nbsp;[batch_size],&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to217_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;ground&nbsp;truth&nbsp;output&nbsp;tensor,&nbsp;with&nbsp;shape&nbsp;[batch_size],&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;[batch_size,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk],&nbsp;where&nbsp;K&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;dimensions.</td><td class="diff_next"></td><td class="diff_header" id="to217_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;[batch_size,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk],&nbsp;where&nbsp;K&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;dimensions.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_55">55</td><td nowrap="nowrap">&nbsp;&nbsp;Labels&nbsp;element&nbsp;value&nbsp;shall&nbsp;be&nbsp;in&nbsp;range&nbsp;of&nbsp;[0,&nbsp;C).&nbsp;If&nbsp;ignore_index&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to217_55">55</td><td nowrap="nowrap">&nbsp;&nbsp;Labels&nbsp;element&nbsp;value&nbsp;shall&nbsp;be&nbsp;in&nbsp;range&nbsp;of&nbsp;[0,&nbsp;C).&nbsp;If&nbsp;ignore_index&nbsp;is</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;specified,&nbsp;it&nbsp;may&nbsp;have&nbsp;a&nbsp;value&nbsp;outside&nbsp;[0,&nbsp;C)&nbsp;and&nbsp;the&nbsp;label&nbsp;values</td><td class="diff_next"></td><td class="diff_header" id="to217_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;specified,&nbsp;it&nbsp;may&nbsp;have&nbsp;a&nbsp;value&nbsp;outside&nbsp;[0,&nbsp;C)&nbsp;and&nbsp;the&nbsp;label&nbsp;values</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_57">57</td><td nowrap="nowrap">&nbsp;&nbsp;should&nbsp;either&nbsp;be&nbsp;in&nbsp;the&nbsp;range&nbsp;[0,&nbsp;C)&nbsp;or&nbsp;have&nbsp;the&nbsp;value&nbsp;ignore_index.</td><td class="diff_next"></td><td class="diff_header" id="to217_57">57</td><td nowrap="nowrap">&nbsp;&nbsp;should&nbsp;either&nbsp;be&nbsp;in&nbsp;the&nbsp;range&nbsp;[0,&nbsp;C)&nbsp;or&nbsp;have&nbsp;the&nbsp;value&nbsp;ignore_index.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_58">58</td><td nowrap="nowrap">*&nbsp;**weights**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to217_58">58</td><td nowrap="nowrap">*&nbsp;**weights**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_59">59</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;manual&nbsp;rescaling&nbsp;weight&nbsp;given&nbsp;to&nbsp;each&nbsp;class.&nbsp;If&nbsp;given,&nbsp;it&nbsp;has&nbsp;to</td><td class="diff_next"></td><td class="diff_header" id="to217_59">59</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;manual&nbsp;rescaling&nbsp;weight&nbsp;given&nbsp;to&nbsp;each&nbsp;class.&nbsp;If&nbsp;given,&nbsp;it&nbsp;has&nbsp;to</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;a&nbsp;1D&nbsp;Tensor&nbsp;assigning&nbsp;weight&nbsp;to&nbsp;each&nbsp;of&nbsp;the&nbsp;classes.&nbsp;Otherwise,</td><td class="diff_next"></td><td class="diff_header" id="to217_60">60</td><td nowrap="nowrap">&nbsp;&nbsp;be&nbsp;a&nbsp;1D&nbsp;Tensor&nbsp;assigning&nbsp;weight&nbsp;to&nbsp;each&nbsp;of&nbsp;the&nbsp;classes.&nbsp;Otherwise,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_61">61</td><td nowrap="nowrap">&nbsp;&nbsp;it&nbsp;is&nbsp;treated&nbsp;as&nbsp;if&nbsp;having&nbsp;all&nbsp;ones.</td><td class="diff_next"></td><td class="diff_header" id="to217_61">61</td><td nowrap="nowrap">&nbsp;&nbsp;it&nbsp;is&nbsp;treated&nbsp;as&nbsp;if&nbsp;having&nbsp;all&nbsp;ones.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_62">62</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_62">62</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_63">63</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to217_63">63</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_64">64</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_64">64</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_65">65</td><td nowrap="nowrap">Between&nbsp;1&nbsp;and&nbsp;2&nbsp;outputs.</td><td class="diff_next"></td><td class="diff_header" id="to217_65">65</td><td nowrap="nowrap">Between&nbsp;1&nbsp;and&nbsp;2&nbsp;outputs.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_66">66</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_66">66</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_67">67</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to217_67">67</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;Weighted&nbsp;loss&nbsp;float&nbsp;Tensor.&nbsp;If&nbsp;reduction&nbsp;is&nbsp;'none',&nbsp;this&nbsp;has&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to217_68">68</td><td nowrap="nowrap">&nbsp;&nbsp;Weighted&nbsp;loss&nbsp;float&nbsp;Tensor.&nbsp;If&nbsp;reduction&nbsp;is&nbsp;'none',&nbsp;this&nbsp;has&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_69">69</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;of&nbsp;[batch_size],&nbsp;or&nbsp;[batch_size,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk]&nbsp;in&nbsp;case&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to217_69">69</td><td nowrap="nowrap">&nbsp;&nbsp;shape&nbsp;of&nbsp;[batch_size],&nbsp;or&nbsp;[batch_size,&nbsp;D1,&nbsp;D2,&nbsp;...,&nbsp;Dk]&nbsp;in&nbsp;case&nbsp;of</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;K-dimensional&nbsp;loss.&nbsp;Otherwise,&nbsp;it&nbsp;is&nbsp;a&nbsp;scalar.</td><td class="diff_next"></td><td class="diff_header" id="to217_70">70</td><td nowrap="nowrap">&nbsp;&nbsp;K-dimensional&nbsp;loss.&nbsp;Otherwise,&nbsp;it&nbsp;is&nbsp;a&nbsp;scalar.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_71">71</td><td nowrap="nowrap">*&nbsp;**log_prob**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to217_71">71</td><td nowrap="nowrap">*&nbsp;**log_prob**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;Log&nbsp;probability&nbsp;tensor.&nbsp;If&nbsp;the&nbsp;output&nbsp;of&nbsp;softmax&nbsp;is&nbsp;prob,&nbsp;its&nbsp;value</td><td class="diff_next"></td><td class="diff_header" id="to217_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;Log&nbsp;probability&nbsp;tensor.&nbsp;If&nbsp;the&nbsp;output&nbsp;of&nbsp;softmax&nbsp;is&nbsp;prob,&nbsp;its&nbsp;value</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to217__0"></td><td class="diff_header" id="from217_73">73</td><td nowrap="nowrap">&nbsp;&nbsp;is&nbsp;log(prob).</td><td class="diff_next"></td><td class="diff_header" id="to217_73">73</td><td nowrap="nowrap">&nbsp;&nbsp;is&nbsp;log(prob).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_74">74</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_74">74</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_75">75</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to217_75">75</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_76">76</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to217_76">76</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_77">77</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to217_77">77</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to217__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to217__top">t</a></td><td class="diff_header" id="to217_78">78</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to217_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to217_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to217_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to217_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to217_83">83</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_83">83</td><td nowrap="nowrap">*&nbsp;**Tind**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to217_84">84</td><td nowrap="nowrap">*&nbsp;**Tind**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_84">84</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to217_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_85">85</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64)</td><td class="diff_next"></td><td class="diff_header" id="to217_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_86">86</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to217_87">87</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from217_87">87</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;target&nbsp;to&nbsp;integer&nbsp;types</td><td class="diff_next"></td><td class="diff_header" id="to217_88">88</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;target&nbsp;to&nbsp;integer&nbsp;types</td></tr>
    </tbody>
</table></section>
<section id="softmaxcrossentropyloss-12">
<span id="l-onnx-op-softmaxcrossentropyloss-12"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">SoftmaxCrossEntropyLoss - 12</a><a class="headerlink" href="#softmaxcrossentropyloss-12" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#SoftmaxCrossEntropyLoss">SoftmaxCrossEntropyLoss (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>12</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 12</strong>.</p>
<p><strong>Summary</strong></p>
<p>Loss function that measures the softmax cross entropy
between ‘scores’ and ‘labels’.
This operator first computes a loss tensor whose shape is identical to the labels input.
If the input is 2-D with shape (N, C), the loss tensor may be a N-element vector L = (l_1, l_2, …, l_N).
If the input is N-D tensor with shape (N, C, D1, D2, …, Dk),
the loss tensor L may have (N, D1, D2, …, Dk) as its shape and L[i,][j_1][j_2]…[j_k] denotes a scalar element in L.
After L is available, this operator can optionally do a reduction operator.</p>
<dl class="simple">
<dt>shape(scores): (N, C) where C is the number of classes, or (N, C, D1, D2,…, Dk),</dt><dd><p>with K &gt;= 1 in case of K-dimensional loss.</p>
</dd>
<dt>shape(labels): (N) where each value is 0 &lt;= labels[i] &lt;= C-1, or (N, D1, D2,…, Dk),</dt><dd><p>with K &gt;= 1 in case of K-dimensional loss.</p>
</dd>
<dt>The loss for one sample, l_i, can caculated as follows:</dt><dd><p>l[i][d1][d2]…[dk] = -y[i][c][d1][d2]..[dk], where i is the index of classes.</p>
</dd>
<dt>or</dt><dd><p>l[i][d1][d2]…[dk] = -y[i][c][d1][d2]..[dk] * weights[c], if ‘weights’ is provided.</p>
</dd>
<dt>loss is zero for the case when label-value equals ignore_index.</dt><dd><p>l[i][d1][d2]…[dk]  = 0, when labels[n][d1][d2]…[dk] = ignore_index</p>
</dd>
<dt>where:</dt><dd><p>p = Softmax(scores)
y = Log(p)
c = labels[i][d1][d2]…[dk]</p>
</dd>
</dl>
<p>Finally, L is optionally reduced:
If reduction = ‘none’, the output is L with shape (N, D1, D2, …, Dk).
If reduction = ‘sum’, the output is scalar: Sum(L).
If reduction = ‘mean’, the output is scalar: ReduceMean(L), or if weight is provided: ReduceSum(L) / ReduceSum(W),
where tensor W is of shape (N, D1, D2, …, Dk) and W[n][d1][d2]…[dk] = weights[labels[i][d1][d2]…[dk]].</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>ignore_index</strong>:
Specifies a target value that is ignored and does not contribute to
the input gradient. It’s an optional value.</p></li>
<li><p><strong>reduction</strong>:
Type of reduction to apply to loss: none, sum, mean(default).
‘none’: no reduction will be applied, ‘sum’: the output will be
summed. ‘mean’: the sum of the output will be divided by the number
of elements in the output.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>scores</strong> (heterogeneous) - <strong>T</strong>:
The predicted outputs with shape [batch_size, class_size], or
[batch_size, class_size, D1, D2 , …, Dk], where K is the number of
dimensions.</p></li>
<li><p><strong>labels</strong> (heterogeneous) - <strong>Tind</strong>:
The ground truth output tensor, with shape [batch_size], or
[batch_size, D1, D2, …, Dk], where K is the number of dimensions.
Labels element value shall be in range of [0, C). If ignore_index is
specified, it may have a value outside [0, C) and the label values
should either be in the range [0, C) or have the value ignore_index.</p></li>
<li><p><strong>weights</strong> (optional, heterogeneous) - <strong>T</strong>:
A manual rescaling weight given to each class. If given, it has to
be a 1D Tensor assigning weight to each of the classes. Otherwise,
it is treated as if having all ones.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 2 outputs.</p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
Weighted loss float Tensor. If reduction is ‘none’, this has the
shape of [batch_size], or [batch_size, D1, D2, …, Dk] in case of
K-dimensional loss. Otherwise, it is a scalar.</p></li>
<li><p><strong>log_prob</strong> (optional, heterogeneous) - <strong>T</strong>:
Log probability tensor. If the output of softmax is prob, its value
is log(prob).</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>Tind</strong> in (
tensor(int32),
tensor(int64)
):
Constrain target to integer types</p></li>
</ul>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="onnx__Softmax.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Softmax</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="onnx__Softplus.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Softplus</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fas fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#softmaxcrossentropyloss-13">
   SoftmaxCrossEntropyLoss - 13
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#softmaxcrossentropyloss-12">
   SoftmaxCrossEntropyLoss - 12
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="../_sources/onnx_doc_folder/onnx__SoftmaxCrossEntropyLoss.rst.txt">
        <i class="fas fa-file-alt"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>