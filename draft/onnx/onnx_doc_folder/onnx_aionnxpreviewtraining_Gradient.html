<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>ai.onnx.preview.training - Gradient &#8212; ONNX 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ai.onnx.preview.training - Momentum" href="onnx_aionnxpreviewtraining_Momentum.html" />
    <link rel="prev" title="ai.onnx.preview.training - Adam" href="onnx_aionnxpreviewtraining_Adam.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ONNX Docs</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../onnx-api/index.html">API Overview</a></li>
                <li><a href="../operators/index.html">Op Schemas</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">API Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.checker.html">onnx.checker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.compose.html">onnx.compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.external_data_helper.html">onnx.external_data_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.helper.html">onnx.helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.hub.html">onnx.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.numpy_helper.html">onnx.numpy_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.parser.html">onnx.parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.utils.html">onnx.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version.version.html">onnx.version.version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version_converter.html">onnx.version_converter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Operators + OpSchemas</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">ONNX operators</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">ai.onnx.preview.training - Gradient</a><ul>
<li><a class="reference internal" href="#gradient-1-ai-onnx-preview-training">Gradient - 1 (ai.onnx.preview.training)</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="onnx_aionnxpreviewtraining_Adam.html" title="Previous Chapter: ai.onnx.preview.training - Adam"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; ai.onnx.previ...</span>
    </a>
  </li>
  <li>
    <a href="onnx_aionnxpreviewtraining_Momentum.html" title="Next Chapter: ai.onnx.preview.training - Momentum"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">ai.onnx.previ... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/onnx_doc_folder/onnx_aionnxpreviewtraining_Gradient.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="ai-onnx-preview-training-gradient">
<span id="l-onnx-docai-onnx-preview-training-gradient"></span><h1>ai.onnx.preview.training - Gradient<a class="headerlink" href="#ai-onnx-preview-training-gradient" title="Permalink to this heading">¶</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#gradient-1-ai-onnx-preview-training" id="id1">Gradient - 1 (ai.onnx.preview.training)</a></p></li>
</ul>
</nav>
<section id="gradient-1-ai-onnx-preview-training">
<span id="l-onnx-opai-onnx-preview-training-gradient-1"></span><h2><a class="toc-backref" href="#id1" role="doc-backlink">Gradient - 1 (ai.onnx.preview.training)</a><a class="headerlink" href="#gradient-1-ai-onnx-preview-training" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ai.onnx.preview.training.Gradient">Gradient (GitHub)</a>
* <strong>domain</strong>: <strong>ai.onnx.preview.training</strong>
* <strong>since_version</strong>: <strong>1</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: False</p>
<p>This version of the operator has been available
<strong>since version 1 of domain ai.onnx.preview.training</strong>.</p>
<p><strong>Summary</strong></p>
<p>Gradient operator computes the partial derivatives of a specific tensor w.r.t.
some other tensors. This operator is widely used in gradient-based training
algorithms. To illustrate its use, let’s consider a computation graph,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">-----.</span>
       <span class="o">|</span>
       <span class="n">v</span>
<span class="n">W</span> <span class="o">--&gt;</span> <span class="n">Conv</span> <span class="o">--&gt;</span> <span class="n">H</span> <span class="o">--&gt;</span> <span class="n">Gemm</span> <span class="o">--&gt;</span> <span class="n">Y</span>
                      <span class="o">^</span>
                      <span class="o">|</span>
                      <span class="n">Z</span>
</pre></div>
</div>
<p>, where W and Z are trainable tensors. Note that operators’ attributes are
omitted for the sake of simplicity. Let dY/dW (dY/dZ) be the gradient of
Y with respect to W (Z). The user can compute gradient by inserting Gradient
operator to form another graph shown below.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">--&gt;</span> <span class="n">Conv</span> <span class="o">--&gt;</span> <span class="n">H</span> <span class="o">--&gt;</span> <span class="n">Gemm</span> <span class="o">--&gt;</span> <span class="n">Y</span>
<span class="o">|</span>      <span class="o">^</span>              <span class="o">^</span>
<span class="o">|</span>      <span class="o">|</span>              <span class="o">|</span>
<span class="o">|</span>      <span class="n">X</span>              <span class="n">Z</span>
<span class="o">|</span>      <span class="o">|</span>              <span class="o">|</span>
<span class="o">|</span>      <span class="o">|</span>   <span class="o">.----------</span><span class="s1">&#39;</span>
<span class="o">|</span>      <span class="o">|</span>   <span class="o">|</span>  <span class="p">(</span><span class="n">W</span><span class="o">/</span><span class="n">Z</span><span class="o">/</span><span class="n">X</span> <span class="ow">is</span> <span class="n">the</span> <span class="mi">1</span><span class="n">st</span><span class="o">/</span><span class="mi">2</span><span class="n">nd</span><span class="o">/</span><span class="mi">3</span><span class="n">rd</span> <span class="nb">input</span> <span class="n">of</span> <span class="n">Gradient</span> <span class="k">as</span> <span class="n">shown</span> <span class="ow">in</span>
<span class="o">|</span>      <span class="o">|</span>   <span class="o">|</span>   <span class="s2">&quot;xs&quot;</span> <span class="n">followed</span> <span class="n">by</span> <span class="s2">&quot;zs&quot;</span><span class="p">)</span>
<span class="o">|</span>      <span class="n">v</span>   <span class="n">v</span>
<span class="s1">&#39;---&gt; Gradient(xs=[&quot;W&quot;, &quot;Z&quot;], zs=[&quot;X&quot;], y=&quot;Y&quot;)</span>
       <span class="o">|</span>   <span class="o">|</span>
       <span class="o">|</span>   <span class="s1">&#39;-----------------------------------&gt; dY/dW (1st output of Gradient)</span>
       <span class="o">|</span>
       <span class="s1">&#39;---------------------------------------&gt; dY/dZ (2nd output of Gradient)</span>
</pre></div>
</div>
<p>By definition, the tensor “y” is a function of independent variables in “xs”
and “zs”. Since we only compute the gradient of “y” w.r.t. the differentiable
variables in “xs”, this Gradient only outputs dY/dW and dY/dZ. Note that “H”
cannot appear in “xs” and “zs”. The reason is that “H” can be determined by
tensors “W” and “X” and therefore “H” is not an independent variable.</p>
<p>All outputs are optional. If needed, for example, user can assign an empty
string to the 1st output name of that Gradient to skip the generation of dY/dW.
Note that the concept of optional outputs can also be found in ONNX’s RNN, GRU,
and LSTM.</p>
<p>Gradient operator can compute derivative against intermediate tensors. For
example, the gradient of Y with respect to H can be done via</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">--&gt;</span> <span class="n">Conv</span> <span class="o">--&gt;</span> <span class="n">H</span> <span class="o">--&gt;</span> <span class="n">Gemm</span> <span class="o">--&gt;</span> <span class="n">Y</span>
       <span class="o">^</span>       <span class="o">|</span>      <span class="o">^</span>
       <span class="o">|</span>       <span class="o">|</span>      <span class="o">|</span>
       <span class="n">X</span>       <span class="o">|</span>      <span class="n">Z</span>
       <span class="o">.-------</span><span class="s1">&#39;      |</span>
       <span class="o">|</span>   <span class="o">.----------</span><span class="s1">&#39;</span>
       <span class="o">|</span>   <span class="o">|</span> <span class="p">(</span><span class="n">H</span><span class="o">/</span><span class="n">Z</span> <span class="ow">is</span> <span class="n">the</span> <span class="mi">1</span><span class="n">st</span><span class="o">/</span><span class="mi">2</span><span class="n">nd</span> <span class="nb">input</span> <span class="n">of</span> <span class="n">Gradient</span> <span class="k">as</span> <span class="n">shown</span> <span class="ow">in</span> <span class="s2">&quot;xs&quot;</span><span class="p">)</span>
       <span class="n">v</span>   <span class="n">v</span>
      <span class="n">Gradient</span><span class="p">(</span><span class="n">xs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;H&quot;</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
       <span class="o">|</span>   <span class="o">|</span>
       <span class="o">|</span>   <span class="s1">&#39;-----------------------------------&gt; dY/dH (1st output of Gradient)</span>
       <span class="o">|</span>
       <span class="s1">&#39;---------------------------------------&gt; dY/dZ (2nd output of Gradient)</span>
</pre></div>
</div>
<p>It is possible to represent high-order differentiation using Gradient operators.
For example, given the following linear model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">--&gt;</span> <span class="n">Gemm</span> <span class="o">--&gt;</span> <span class="n">Y</span> <span class="o">--&gt;</span> <span class="n">Loss</span> <span class="o">--&gt;</span> <span class="n">O</span>
       <span class="o">^</span>              <span class="o">^</span>
       <span class="o">|</span>              <span class="o">|</span>
       <span class="n">X</span>              <span class="n">L</span>
</pre></div>
</div>
<p>To compute the 2nd order derivative of O with respect to W (denoted by
d^2O/dW^2), one can do</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">--&gt;</span> <span class="n">Gemm</span> <span class="o">--&gt;</span> <span class="n">Y</span> <span class="o">--&gt;</span> <span class="n">Loss</span> <span class="o">--&gt;</span> <span class="n">O</span>
<span class="o">|</span>      <span class="o">^</span>              <span class="o">^</span>
<span class="o">|</span>      <span class="o">|</span>              <span class="o">|</span>
<span class="o">|</span>      <span class="n">X</span> <span class="o">.------------</span><span class="n">L</span>
<span class="o">|</span>      <span class="o">|</span> <span class="o">|</span>            <span class="o">|</span>
<span class="o">|</span>      <span class="o">|</span> <span class="o">|</span>            <span class="n">v</span>
<span class="o">+------+-+&gt;</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">xs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="n">zs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;L&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;O&quot;</span><span class="p">)</span> <span class="o">---&gt;</span> <span class="n">dO</span><span class="o">/</span><span class="n">dX</span> <span class="p">(</span><span class="mi">1</span><span class="n">st</span> <span class="n">output</span> <span class="n">of</span> <span class="n">Gradient</span><span class="p">)</span>
<span class="o">|</span>      <span class="o">|</span> <span class="o">|</span>    <span class="o">|</span>
<span class="o">|</span>      <span class="o">|</span> <span class="o">|</span>    <span class="s1">&#39;---&gt; dO/dW (2nd output of Gradient)</span>
<span class="o">|</span>      <span class="n">v</span> <span class="n">v</span>
<span class="s1">&#39;---&gt; Gradient(xs=[&quot;X&quot;, &quot;W&quot;], zs=[&quot;L&quot;], y=&quot;dO/dW&quot;) ---&gt; d(dO/dW)dX (1st output of</span>
       <span class="o">|</span>                                                  <span class="n">Gradient</span><span class="p">)</span>
       <span class="o">|</span>
       <span class="o">|</span>
       <span class="s1">&#39;---&gt; d^2O/dW^2 (2nd output of Gradient)</span>
</pre></div>
</div>
<p>The tensors named in attributes “xs”, “zs”, and “y” define the differentiated
computation graph, and the inputs to Gradient node define the values at
which the gradient is computed. We can feed different tensors to the identified
graph. For example, one can compute the gradient of Y with respect to H at
a specific value of H, H_1, by providing that value as an input to the Gradient
node.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">--&gt;</span> <span class="n">Conv</span> <span class="o">--&gt;</span> <span class="n">H</span> <span class="o">--&gt;</span> <span class="n">Gemm</span> <span class="o">--&gt;</span> <span class="n">Y</span>
       <span class="o">^</span>              <span class="o">^</span>
       <span class="o">|</span>              <span class="o">|</span>
       <span class="n">X</span>              <span class="n">Z</span>

          <span class="n">Z_1</span> <span class="p">(</span><span class="mi">2</span><span class="n">nd</span> <span class="nb">input</span> <span class="n">of</span> <span class="n">Gradient</span><span class="p">)</span>
           <span class="o">|</span>
           <span class="n">v</span>
<span class="n">H_1</span> <span class="o">--&gt;</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">xs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;H&quot;</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span> <span class="o">---&gt;</span> <span class="n">dY</span><span class="o">/</span><span class="n">dH</span> <span class="n">when</span> <span class="n">H</span> <span class="o">=</span> <span class="n">H_1</span> <span class="ow">and</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">Y_1</span><span class="o">.</span>
           <span class="o">|</span>
           <span class="s1">&#39;------------------------------&gt; dY/dZ (2nd output of Gradient)</span>
</pre></div>
</div>
<p>When the inputs of Gradient are the tensors named in “xs” and “zs”, the
computation can be optimized. More specifically, intermediate variables in
forward pass can be reused if the gradient is computed via reverse-mode
auto-differentiation.</p>
<p><strong>Attributes</strong>
* <strong>xs</strong> (required):</p>
<blockquote>
<div><p>Input tensor names of the differentiated sub-graph. It contains only
the necessary differentiated inputs of a (sub-)graph. Variables
(usually called intermediate variables) that can be generated from
inputs cannot be included in this attribute.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>y</strong> (required):
The targeted tensor. It can be viewed as the output of the
differentiated function. The attribute “xs” and attribute “zs” are
the minimal independent variable set that determines the value of
“y”.</p></li>
<li><p><strong>zs</strong>:
Input tensor names of the differentiated sub-graph. It contains only
the necessary non-differentiated inputs of a (sub-)graph. Variables
(usually called intermediate variables) that can be generated from
inputs cannot be included in this attribute.</p></li>
</ul>
<p><strong>Inputs</strong>
Between 1 and 2147483647 inputs.</p>
<ul class="simple">
<li><p><strong>Inputs</strong> (variadic) - <strong>T1</strong>:
The values fed into graph identified by the attributes. The i-th
input is the value of the i-th tensor specified in the concatenated
list of the attribute “xs” and the attribute  “zs”. For example, if
xs=[“A”, “B”] and zs=[“C”], the first input is used as the value of
symbol “A” and the 3rd input is substituted for all the occurrences
of “C”.</p></li>
</ul>
<p><strong>Outputs</strong>
Between 1 and 2147483647 outputs.</p>
<ul class="simple">
<li><p><strong>Outputs</strong> (variadic) - <strong>T2</strong>:
The gradient of the tensor specified by the attribute “y” with
respect to each of tensors specified in the attribute “xs”. The i-th
output is the gradient of “y” with respect to the i-th tensor
specified in the attribute “xs”.</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T1</strong> in (</p>
<blockquote>
<div><p>tensor(bool),
tensor(complex128),
tensor(complex64),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(string),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Allow outputs to be any kind of tensor.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>T2</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Allow inputs to be any kind of floating-point tensor.</p></li>
</ul>
<p><strong>Examples</strong></p>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>