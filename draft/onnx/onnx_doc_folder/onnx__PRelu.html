<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>PRelu &#8212; ONNX 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pad" href="onnx__Pad.html" />
    <link rel="prev" title="Or" href="onnx__Or.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ONNX Docs</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../onnx-api/index.html">API Overview</a></li>
                <li><a href="../operators/index.html">Op Schemas</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">API Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.checker.html">onnx.checker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.compose.html">onnx.compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.external_data_helper.html">onnx.external_data_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.helper.html">onnx.helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.hub.html">onnx.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.numpy_helper.html">onnx.numpy_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.parser.html">onnx.parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.utils.html">onnx.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version.version.html">onnx.version.version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version_converter.html">onnx.version_converter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Operators + OpSchemas</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">ONNX operators</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">PRelu</a><ul>
<li><a class="reference internal" href="#prelu-16">PRelu - 16</a></li>
<li><a class="reference internal" href="#prelu-9">PRelu - 9</a></li>
<li><a class="reference internal" href="#prelu-7">PRelu - 7</a></li>
<li><a class="reference internal" href="#prelu-6">PRelu - 6</a></li>
<li><a class="reference internal" href="#prelu-1">PRelu - 1</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="onnx__Or.html" title="Previous Chapter: Or"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Or</span>
    </a>
  </li>
  <li>
    <a href="onnx__Pad.html" title="Next Chapter: Pad"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Pad &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/onnx_doc_folder/onnx__PRelu.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="prelu">
<span id="l-onnx-doc-prelu"></span><h1>PRelu<a class="headerlink" href="#prelu" title="Permalink to this heading">¶</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#prelu-16" id="id7">PRelu - 16</a></p></li>
<li><p><a class="reference internal" href="#prelu-9" id="id8">PRelu - 9</a></p></li>
<li><p><a class="reference internal" href="#prelu-7" id="id9">PRelu - 7</a></p></li>
<li><p><a class="reference internal" href="#prelu-6" id="id10">PRelu - 6</a></p></li>
<li><p><a class="reference internal" href="#prelu-1" id="id11">PRelu - 1</a></p></li>
</ul>
</nav>
<section id="prelu-16">
<span id="l-onnx-op-prelu-16"></span><h2><a class="toc-backref" href="#id7" role="doc-backlink">PRelu - 16</a><a class="headerlink" href="#prelu-16" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu">PRelu (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>16</strong>
* <strong>function</strong>: True
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 16</strong>.</p>
<p><strong>Summary</strong></p>
<p>PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function <cite>f(x) = slope * x for x &lt; 0</cite>,
<cite>f(x) = x for x &gt;= 0</cite>., is applied to the data tensor elementwise.</p>
<p><strong>History</strong>
- Version 16 adds bfloat16 to the types allowed.
This operator supports <strong>unidirectional broadcasting</strong> (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md">Broadcasting in ONNX</a>.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input tensor</p></li>
<li><p><strong>slope</strong> (heterogeneous) - <strong>T</strong>:
Slope tensor. The shape of slope can be smaller then first input X;
if so, its shape must be unidirectional broadcastable to X</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor (same size as X)</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16),
tensor(int32),
tensor(int64),
tensor(uint32),
tensor(uint64)
):
Constrain input and output types to float/int tensors.</p>
</div></blockquote>
<p><strong>Examples</strong></p>
<p><strong>default</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;PRelu&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;slope&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">slope</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">slope</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_prelu_example&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_prelu_broadcast</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;PRelu&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;slope&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">slope</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">slope</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_prelu_broadcast&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to146__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to146__0"><a href="#difflib_chg_to146__0">f</a></td><td class="diff_header" id="from146_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to146__0">f</a></td><td class="diff_header" id="to146_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to146_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to146_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to146__1">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to146__1">n</a></td><td class="diff_header" id="to146_4">4</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_5">5</td><td nowrap="nowrap"><span class="diff_add">**History**</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_6">6</td><td nowrap="nowrap"><span class="diff_add">-&nbsp;Version&nbsp;16&nbsp;adds&nbsp;bfloat16&nbsp;to&nbsp;the&nbsp;types&nbsp;allowed.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_4">4</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td><td class="diff_next"></td><td class="diff_header" id="to146_7">7</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_8">8</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_6">6</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to146_9">9</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_10">10</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to146_11">11</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to146_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to146_13">13</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td><td class="diff_next"></td><td class="diff_header" id="to146_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td><td class="diff_next"></td><td class="diff_header" id="to146_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_16">16</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_14">14</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to146_17">17</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_18">18</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to146__1"></td><td class="diff_header" id="from146_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to146_19">19</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td><td class="diff_next"></td><td class="diff_header" id="to146_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to146_21">21</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to146_22">22</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_20">20</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to146_23">23</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to146__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to146__top">t</a></td><td class="diff_header" id="to146_24">24</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to146_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to146_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to146_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to146_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to146_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to146_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to146_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to146_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from146_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to146_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="prelu-9">
<span id="l-onnx-op-prelu-9"></span><h2><a class="toc-backref" href="#id8" role="doc-backlink">PRelu - 9</a><a class="headerlink" href="#prelu-9" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu">PRelu (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>9</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 9</strong>.</p>
<p><strong>Summary</strong></p>
<p>PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function <cite>f(x) = slope * x for x &lt; 0</cite>,
<cite>f(x) = x for x &gt;= 0</cite>., is applied to the data tensor elementwise.
This operator supports <strong>unidirectional broadcasting</strong> (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md">Broadcasting in ONNX</a>.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input tensor</p></li>
<li><p><strong>slope</strong> (heterogeneous) - <strong>T</strong>:
Slope tensor. The shape of slope can be smaller then first input X;
if so, its shape must be unidirectional broadcastable to X</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor (same size as X)</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16),
tensor(int32),
tensor(int64),
tensor(uint32),
tensor(uint64)
):
Constrain input and output types to float/int tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to147__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to147__0">f</a></td><td class="diff_header" id="from147_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to147__0">f</a></td><td class="diff_header" id="to147_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to147_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to147_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_4">4</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td><td class="diff_next"></td><td class="diff_header" id="to147_4">4</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_5">5</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_6">6</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to147_6">6</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_7">7</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to147_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to147_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to147_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td><td class="diff_next"></td><td class="diff_header" id="to147_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td><td class="diff_next"></td><td class="diff_header" id="to147_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_13">13</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_14">14</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to147_14">14</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_15">15</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to147_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td><td class="diff_next"></td><td class="diff_header" id="to147_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to147__0"></td><td class="diff_header" id="from147_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_18">18</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to147_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_20">20</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to147_20">20</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to147_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to147_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to147__1">n</a></td><td class="diff_header" id="from147_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"><a href="#difflib_chg_to147__1">n</a></td><td class="diff_header" id="to147_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)<span class="diff_add">,</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to147__1"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_24">24</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(int32),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_25">25</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(int64),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_26">26</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(uint32),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to147_27">27</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(uint64)</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from147_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to147_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to147__top">t</a></td><td class="diff_header" id="from147_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"><a href="#difflib_chg_to147__top">t</a></td><td class="diff_header" id="to147_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float<span class="diff_add">/int</span>&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="prelu-7">
<span id="l-onnx-op-prelu-7"></span><h2><a class="toc-backref" href="#id9" role="doc-backlink">PRelu - 7</a><a class="headerlink" href="#prelu-7" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu">PRelu (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>7</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 7</strong>.</p>
<p><strong>Summary</strong></p>
<p>PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function <cite>f(x) = slope * x for x &lt; 0</cite>,
<cite>f(x) = x for x &gt;= 0</cite>., is applied to the data tensor elementwise.
This operator supports <strong>unidirectional broadcasting</strong> (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md">Broadcasting in ONNX</a>.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input tensor</p></li>
<li><p><strong>slope</strong> (heterogeneous) - <strong>T</strong>:
Slope tensor. The shape of slope can be smaller then first input X;
if so, its shape must be unidirectional broadcastable to X</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor (same size as X)</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to148__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to148__0"><a href="#difflib_chg_to148__0">f</a></td><td class="diff_header" id="from148_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to148__0">f</a></td><td class="diff_header" id="to148_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to148_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to148_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to148__1">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to148__1">n</a></td><td class="diff_header" id="to148_4">4</td><td nowrap="nowrap"><span class="diff_add">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;slope&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;input&nbsp;tensor&nbsp;X);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_4">4</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_5">5</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to148__1"></td><td class="diff_header" id="from148_5">5</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to148_6">6</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_6">6</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_7">7</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_7">7</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to148_8">8</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_8">8</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to148_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_9">9</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to148_10">10</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to148__2">n</a></td><td class="diff_header" id="from148_10">10</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;If&nbsp;Slope&nbsp;is&nbsp;of&nbsp;size&nbsp;1,&nbsp;the&nbsp;value&nbsp;is&nbsp;sharedacross</span></td><td class="diff_next"><a href="#difflib_chg_to148__2">n</a></td><td class="diff_header" id="to148_11">11</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;The&nbsp;shape&nbsp;of&nbsp;slope&nbsp;can&nbsp;be&nbsp;smaller&nbsp;then&nbsp;first&nbsp;input&nbsp;X;</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to148__2"></td><td class="diff_header" id="from148_11">11</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;different&nbsp;channels</span></td><td class="diff_next"></td><td class="diff_header" id="to148_12">12</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;if&nbsp;so,&nbsp;its&nbsp;shape&nbsp;must&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;X</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_12">12</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_13">13</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_13">13</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to148_14">14</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_14">14</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_15">15</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_15">15</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to148_16">16</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to148__top">t</a></td><td class="diff_header" id="from148_16">16</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Output&nbsp;tensor</span></td><td class="diff_next"><a href="#difflib_chg_to148__top">t</a></td><td class="diff_header" id="to148_17">17</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;(same&nbsp;size&nbsp;as&nbsp;X)</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to148_18">18</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_18">18</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to148_19">19</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_19">19</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to148_20">20</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to148_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to148_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to148_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to148_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from148_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to148_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="prelu-6">
<span id="l-onnx-op-prelu-6"></span><h2><a class="toc-backref" href="#id10" role="doc-backlink">PRelu - 6</a><a class="headerlink" href="#prelu-6" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu">PRelu (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>6</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 6</strong>.</p>
<p><strong>Summary</strong></p>
<p>PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function <cite>f(x) = slope * x for x &lt; 0</cite>,
<cite>f(x) = x for x &gt;= 0</cite>., is applied to the data tensor elementwise.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input tensor</p></li>
<li><p><strong>slope</strong> (heterogeneous) - <strong>T</strong>:
Slope tensor. If <cite>Slope</cite> is of size 1, the value is sharedacross
different channels</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to149__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to149__0"><a href="#difflib_chg_to149__0">f</a></td><td class="diff_header" id="from149_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td><td class="diff_next"><a href="#difflib_chg_to149__0">f</a></td><td class="diff_header" id="to149_1">1</td><td nowrap="nowrap">PRelu&nbsp;takes&nbsp;input&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;and&nbsp;slope&nbsp;tensor&nbsp;as&nbsp;input,&nbsp;and&nbsp;produces&nbsp;one</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td><td class="diff_next"></td><td class="diff_header" id="to149_2">2</td><td nowrap="nowrap">output&nbsp;data&nbsp;(Tensor&lt;T&gt;)&nbsp;where&nbsp;the&nbsp;function&nbsp;f(x)&nbsp;=&nbsp;slope&nbsp;*&nbsp;x&nbsp;for&nbsp;x&nbsp;&lt;&nbsp;0,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td><td class="diff_next"></td><td class="diff_header" id="to149_3">3</td><td nowrap="nowrap">f(x)&nbsp;=&nbsp;x&nbsp;for&nbsp;x&nbsp;&gt;=&nbsp;0.,&nbsp;is&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;tensor&nbsp;elementwise.</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to149__top">t</a></td><td class="diff_header" id="from149_4">4</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;</span></td><td class="diff_next"><a href="#difflib_chg_to149__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_5">5</td><td nowrap="nowrap"><span class="diff_sub">**Attributes**</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_6">6</td><td nowrap="nowrap"><span class="diff_sub">*&nbsp;**consumed_inputs**:</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_7">7</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;legacy&nbsp;optimization&nbsp;attribute.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_8">8</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_4">4</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_9">9</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to149_5">5</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_10">10</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_6">6</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_11">11</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to149_7">7</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to149_8">8</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_13">13</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to149_9">9</td><td nowrap="nowrap">*&nbsp;**slope**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;If&nbsp;Slope&nbsp;is&nbsp;of&nbsp;size&nbsp;1,&nbsp;the&nbsp;value&nbsp;is&nbsp;sharedacross</td><td class="diff_next"></td><td class="diff_header" id="to149_10">10</td><td nowrap="nowrap">&nbsp;&nbsp;Slope&nbsp;tensor.&nbsp;If&nbsp;Slope&nbsp;is&nbsp;of&nbsp;size&nbsp;1,&nbsp;the&nbsp;value&nbsp;is&nbsp;sharedacross</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;different&nbsp;channels</td><td class="diff_next"></td><td class="diff_header" id="to149_11">11</td><td nowrap="nowrap">&nbsp;&nbsp;different&nbsp;channels</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_12">12</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_17">17</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to149_13">13</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_14">14</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_19">19</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to149_15">15</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to149_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_21">21</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to149_17">17</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_22">22</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to149_18">18</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_23">23</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to149_19">19</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to149_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to149_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to149_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to149_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from149_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to149_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="prelu-1">
<span id="l-onnx-op-prelu-1"></span><h2><a class="toc-backref" href="#id11" role="doc-backlink">PRelu - 1</a><a class="headerlink" href="#prelu-1" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#PRelu">PRelu (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>1</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: False</p>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<p>PRelu takes input data (Tensor&lt;T&gt;) and slope tensor as input, and produces one
output data (Tensor&lt;T&gt;) where the function <cite>f(x) = slope * x for x &lt; 0</cite>,
<cite>f(x) = x for x &gt;= 0</cite>., is applied to the data tensor elementwise.</p>
<p><strong>Attributes</strong>
* <strong>consumed_inputs</strong>:</p>
<blockquote>
<div><p>legacy optimization attribute.</p>
</div></blockquote>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input tensor</p></li>
<li><p><strong>slope</strong> (heterogeneous) - <strong>T</strong>:
Slope tensor. If <cite>Slope</cite> is of size 1, the value is sharedacross
different channels</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>