<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Gemm &#8212; ONNX 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GlobalAveragePool" href="onnx__GlobalAveragePool.html" />
    <link rel="prev" title="GatherND" href="onnx__GatherND.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ONNX Docs</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../onnx-api/index.html">API Overview</a></li>
                <li><a href="../operators/index.html">Op Schemas</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">API Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.checker.html">onnx.checker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.compose.html">onnx.compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.external_data_helper.html">onnx.external_data_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.helper.html">onnx.helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.hub.html">onnx.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.numpy_helper.html">onnx.numpy_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.parser.html">onnx.parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.utils.html">onnx.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version.version.html">onnx.version.version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version_converter.html">onnx.version_converter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Operators + OpSchemas</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">ONNX operators</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Gemm</a><ul>
<li><a class="reference internal" href="#gemm-13">Gemm - 13</a></li>
<li><a class="reference internal" href="#gemm-11">Gemm - 11</a></li>
<li><a class="reference internal" href="#gemm-9">Gemm - 9</a></li>
<li><a class="reference internal" href="#gemm-7">Gemm - 7</a></li>
<li><a class="reference internal" href="#gemm-6">Gemm - 6</a></li>
<li><a class="reference internal" href="#gemm-1">Gemm - 1</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="onnx__GatherND.html" title="Previous Chapter: GatherND"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; GatherND</span>
    </a>
  </li>
  <li>
    <a href="onnx__GlobalAveragePool.html" title="Next Chapter: GlobalAveragePool"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">GlobalAveragePool &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/onnx_doc_folder/onnx__Gemm.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="gemm">
<span id="l-onnx-doc-gemm"></span><h1>Gemm<a class="headerlink" href="#gemm" title="Permalink to this heading">¶</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#gemm-13" id="id10">Gemm - 13</a></p></li>
<li><p><a class="reference internal" href="#gemm-11" id="id11">Gemm - 11</a></p></li>
<li><p><a class="reference internal" href="#gemm-9" id="id12">Gemm - 9</a></p></li>
<li><p><a class="reference internal" href="#gemm-7" id="id13">Gemm - 7</a></p></li>
<li><p><a class="reference internal" href="#gemm-6" id="id14">Gemm - 6</a></p></li>
<li><p><a class="reference internal" href="#gemm-1" id="id15">Gemm - 1</a></p></li>
</ul>
</nav>
<section id="gemm-13">
<span id="l-onnx-op-gemm-13"></span><h2><a class="toc-backref" href="#id10" role="doc-backlink">Gemm - 13</a><a class="headerlink" href="#gemm-13" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm">Gemm (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>13</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 13</strong>.</p>
<p><strong>Summary</strong>
General Matrix multiplication:
<a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</a></p>
<p>A’ = transpose(A) if transA else A</p>
<p>B’ = transpose(B) if transB else B</p>
<p>Compute Y = alpha * A’ * B’ + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports <strong>unidirectional broadcasting</strong> (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md">Broadcasting in ONNX</a>.
This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument’s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
<p><strong>Attributes</strong>
* <strong>alpha</strong>:</p>
<blockquote>
<div><p>Scalar multiplier for the product of input tensors A * B.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>beta</strong>:
Scalar multiplier for input tensor C.</p></li>
<li><p><strong>transA</strong>:
Whether A should be transposed</p></li>
<li><p><strong>transB</strong>:
Whether B should be transposed</p></li>
</ul>
<p><strong>Inputs</strong>
Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>A</strong> (heterogeneous) - <strong>T</strong>:
Input tensor A. The shape of A should be (M, K) if transA is 0, or
(K, M) if transA is non-zero.</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Input tensor B. The shape of B should be (K, N) if transB is 0, or
(N, K) if transB is non-zero.</p></li>
<li><p><strong>C</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional input tensor C. If not specified, the computation is done
as if C is a scalar 0. The shape of C should be unidirectional
broadcastable to (M, N).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor of shape (M, N).</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16),
tensor(int32),
tensor(int64),
tensor(uint32),
tensor(uint64)
):
Constrain input and output types to float/int tensors.</p>
</div></blockquote>
<p><strong>Examples</strong></p>
<p><strong>_default_zero_bias</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_default_zero_bias&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_default_no_bias</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_default_no_bias&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_default_scalar_bias</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">3.14</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_default_scalar_bias&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_default_single_elem_vector_bias</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_default_single_elem_vector_bias&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_default_vector_bias</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_default_vector_bias&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_default_matrix_bias</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_default_matrix_bias&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_transposeA</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">transA</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">transA</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_transposeA&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_transposeB</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">transB</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">transB</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_transposeB&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_alpha</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_alpha&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_beta</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Gemm&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_beta&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_all_attributes</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Gemm&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
    <span class="n">beta</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span>
    <span class="n">transA</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">transB</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">ranf</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gemm_reference_implementation</span><span class="p">(</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">transA</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">transB</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.35</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_gemm_all_attributes&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to74__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to74__0">f</a></td><td class="diff_header" id="from74_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td><td class="diff_next"><a href="#difflib_chg_to74__0">f</a></td><td class="diff_header" id="to74_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td><td class="diff_next"></td><td class="diff_header" id="to74_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_3">3</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_4">4</td><td nowrap="nowrap">A'&nbsp;=&nbsp;transpose(A)&nbsp;if&nbsp;transA&nbsp;else&nbsp;A</td><td class="diff_next"></td><td class="diff_header" id="to74_4">4</td><td nowrap="nowrap">A'&nbsp;=&nbsp;transpose(A)&nbsp;if&nbsp;transA&nbsp;else&nbsp;A</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_5">5</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_6">6</td><td nowrap="nowrap">B'&nbsp;=&nbsp;transpose(B)&nbsp;if&nbsp;transB&nbsp;else&nbsp;B</td><td class="diff_next"></td><td class="diff_header" id="to74_6">6</td><td nowrap="nowrap">B'&nbsp;=&nbsp;transpose(B)&nbsp;if&nbsp;transB&nbsp;else&nbsp;B</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_7">7</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_8">8</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A'&nbsp;*&nbsp;B'&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;K)&nbsp;or&nbsp;(K,&nbsp;M),</td><td class="diff_next"></td><td class="diff_header" id="to74_8">8</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A'&nbsp;*&nbsp;B'&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;K)&nbsp;or&nbsp;(K,&nbsp;M),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_9">9</td><td nowrap="nowrap">input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;shape&nbsp;(K,&nbsp;N)&nbsp;or&nbsp;(N,&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;is&nbsp;broadcastable&nbsp;to&nbsp;shape&nbsp;(M,&nbsp;N),</td><td class="diff_next"></td><td class="diff_header" id="to74_9">9</td><td nowrap="nowrap">input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;shape&nbsp;(K,&nbsp;N)&nbsp;or&nbsp;(N,&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;is&nbsp;broadcastable&nbsp;to&nbsp;shape&nbsp;(M,&nbsp;N),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_10">10</td><td nowrap="nowrap">and&nbsp;output&nbsp;tensor&nbsp;Y&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;N).&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to74_10">10</td><td nowrap="nowrap">and&nbsp;output&nbsp;tensor&nbsp;Y&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;N).&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_11">11</td><td nowrap="nowrap">computation&nbsp;if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td><td class="diff_next"></td><td class="diff_header" id="to74_11">11</td><td nowrap="nowrap">computation&nbsp;if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_12">12</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;tensor&nbsp;A&nbsp;*&nbsp;B);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td><td class="diff_next"></td><td class="diff_header" id="to74_12">12</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;tensor&nbsp;A&nbsp;*&nbsp;B);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_13">13</td><td nowrap="nowrap">This&nbsp;operator&nbsp;has&nbsp;**optional**&nbsp;inputs/outputs.&nbsp;See&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/IR.md&gt;_&nbsp;for&nbsp;more&nbsp;details&nbsp;about&nbsp;the&nbsp;representation&nbsp;of&nbsp;optional&nbsp;arguments.&nbsp;An&nbsp;empty&nbsp;string&nbsp;may&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;place&nbsp;of&nbsp;an&nbsp;actual&nbsp;argument's&nbsp;name&nbsp;to&nbsp;indicate&nbsp;a&nbsp;missing&nbsp;argument.&nbsp;Trailing&nbsp;optional&nbsp;arguments&nbsp;(those&nbsp;not&nbsp;followed&nbsp;by&nbsp;an&nbsp;argument&nbsp;that&nbsp;is&nbsp;present)&nbsp;may&nbsp;also&nbsp;be&nbsp;simply&nbsp;omitted.</td><td class="diff_next"></td><td class="diff_header" id="to74_13">13</td><td nowrap="nowrap">This&nbsp;operator&nbsp;has&nbsp;**optional**&nbsp;inputs/outputs.&nbsp;See&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/IR.md&gt;_&nbsp;for&nbsp;more&nbsp;details&nbsp;about&nbsp;the&nbsp;representation&nbsp;of&nbsp;optional&nbsp;arguments.&nbsp;An&nbsp;empty&nbsp;string&nbsp;may&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;place&nbsp;of&nbsp;an&nbsp;actual&nbsp;argument's&nbsp;name&nbsp;to&nbsp;indicate&nbsp;a&nbsp;missing&nbsp;argument.&nbsp;Trailing&nbsp;optional&nbsp;arguments&nbsp;(those&nbsp;not&nbsp;followed&nbsp;by&nbsp;an&nbsp;argument&nbsp;that&nbsp;is&nbsp;present)&nbsp;may&nbsp;also&nbsp;be&nbsp;simply&nbsp;omitted.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_14">14</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_14">14</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_15">15</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to74_15">15</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_16">16</td><td nowrap="nowrap">*&nbsp;**alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to74_16">16</td><td nowrap="nowrap">*&nbsp;**alpha**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B.</td><td class="diff_next"></td><td class="diff_header" id="to74_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_18">18</td><td nowrap="nowrap">*&nbsp;**beta**:</td><td class="diff_next"></td><td class="diff_header" id="to74_18">18</td><td nowrap="nowrap">*&nbsp;**beta**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C.</td><td class="diff_next"></td><td class="diff_header" id="to74_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_20">20</td><td nowrap="nowrap">*&nbsp;**transA**:</td><td class="diff_next"></td><td class="diff_header" id="to74_20">20</td><td nowrap="nowrap">*&nbsp;**transA**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to74_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_22">22</td><td nowrap="nowrap">*&nbsp;**transB**:</td><td class="diff_next"></td><td class="diff_header" id="to74_22">22</td><td nowrap="nowrap">*&nbsp;**transB**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to74_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_24">24</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_25">25</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to74_25">25</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_26">26</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to74_26">26</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_27">27</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_27">27</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_28">28</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to74_28">28</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A.&nbsp;The&nbsp;shape&nbsp;of&nbsp;A&nbsp;should&nbsp;be&nbsp;(M,&nbsp;K)&nbsp;if&nbsp;transA&nbsp;is&nbsp;0,&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to74_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A.&nbsp;The&nbsp;shape&nbsp;of&nbsp;A&nbsp;should&nbsp;be&nbsp;(M,&nbsp;K)&nbsp;if&nbsp;transA&nbsp;is&nbsp;0,&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;(K,&nbsp;M)&nbsp;if&nbsp;transA&nbsp;is&nbsp;non-zero.</td><td class="diff_next"></td><td class="diff_header" id="to74_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;(K,&nbsp;M)&nbsp;if&nbsp;transA&nbsp;is&nbsp;non-zero.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_31">31</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to74_31">31</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B.&nbsp;The&nbsp;shape&nbsp;of&nbsp;B&nbsp;should&nbsp;be&nbsp;(K,&nbsp;N)&nbsp;if&nbsp;transB&nbsp;is&nbsp;0,&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to74_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B.&nbsp;The&nbsp;shape&nbsp;of&nbsp;B&nbsp;should&nbsp;be&nbsp;(K,&nbsp;N)&nbsp;if&nbsp;transB&nbsp;is&nbsp;0,&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;(N,&nbsp;K)&nbsp;if&nbsp;transB&nbsp;is&nbsp;non-zero.</td><td class="diff_next"></td><td class="diff_header" id="to74_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;(N,&nbsp;K)&nbsp;if&nbsp;transB&nbsp;is&nbsp;non-zero.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_34">34</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to74_34">34</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;input&nbsp;tensor&nbsp;C.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;the&nbsp;computation&nbsp;is&nbsp;done</td><td class="diff_next"></td><td class="diff_header" id="to74_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;input&nbsp;tensor&nbsp;C.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;the&nbsp;computation&nbsp;is&nbsp;done</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;as&nbsp;if&nbsp;C&nbsp;is&nbsp;a&nbsp;scalar&nbsp;0.&nbsp;The&nbsp;shape&nbsp;of&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional</td><td class="diff_next"></td><td class="diff_header" id="to74_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;as&nbsp;if&nbsp;C&nbsp;is&nbsp;a&nbsp;scalar&nbsp;0.&nbsp;The&nbsp;shape&nbsp;of&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;broadcastable&nbsp;to&nbsp;(M,&nbsp;N).</td><td class="diff_next"></td><td class="diff_header" id="to74_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;broadcastable&nbsp;to&nbsp;(M,&nbsp;N).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_38">38</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_38">38</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_39">39</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to74_39">39</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_40">40</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_40">40</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to74__0"></td><td class="diff_header" id="from74_41">41</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to74_41">41</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(M,&nbsp;N).</td><td class="diff_next"></td><td class="diff_header" id="to74_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(M,&nbsp;N).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_43">43</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to74_43">43</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_44">44</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to74_44">44</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_45">45</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to74_45">45</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to74__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to74__top">t</a></td><td class="diff_header" id="to74_46">46</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to74_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to74_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to74_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to74_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to74_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to74_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to74_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to74_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from74_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to74_55">55</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="gemm-11">
<span id="l-onnx-op-gemm-11"></span><h2><a class="toc-backref" href="#id11" role="doc-backlink">Gemm - 11</a><a class="headerlink" href="#gemm-11" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm">Gemm (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>11</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 11</strong>.</p>
<p><strong>Summary</strong>
General Matrix multiplication:
<a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</a></p>
<p>A’ = transpose(A) if transA else A</p>
<p>B’ = transpose(B) if transB else B</p>
<p>Compute Y = alpha * A’ * B’ + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports <strong>unidirectional broadcasting</strong> (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md">Broadcasting in ONNX</a>.
This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument’s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
<p><strong>Attributes</strong>
* <strong>alpha</strong>:</p>
<blockquote>
<div><p>Scalar multiplier for the product of input tensors A * B.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>beta</strong>:
Scalar multiplier for input tensor C.</p></li>
<li><p><strong>transA</strong>:
Whether A should be transposed</p></li>
<li><p><strong>transB</strong>:
Whether B should be transposed</p></li>
</ul>
<p><strong>Inputs</strong>
Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>A</strong> (heterogeneous) - <strong>T</strong>:
Input tensor A. The shape of A should be (M, K) if transA is 0, or
(K, M) if transA is non-zero.</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Input tensor B. The shape of B should be (K, N) if transB is 0, or
(N, K) if transB is non-zero.</p></li>
<li><p><strong>C</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional input tensor C. If not specified, the computation is done
as if C is a scalar 0. The shape of C should be unidirectional
broadcastable to (M, N).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor of shape (M, N).</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16),
tensor(int32),
tensor(int64),
tensor(uint32),
tensor(uint64)
):
Constrain input and output types to float/int tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to75__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to75__0">f</a></td><td class="diff_header" id="from75_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td><td class="diff_next"><a href="#difflib_chg_to75__0">f</a></td><td class="diff_header" id="to75_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td><td class="diff_next"></td><td class="diff_header" id="to75_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_3">3</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_4">4</td><td nowrap="nowrap">A'&nbsp;=&nbsp;transpose(A)&nbsp;if&nbsp;transA&nbsp;else&nbsp;A</td><td class="diff_next"></td><td class="diff_header" id="to75_4">4</td><td nowrap="nowrap">A'&nbsp;=&nbsp;transpose(A)&nbsp;if&nbsp;transA&nbsp;else&nbsp;A</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_5">5</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_6">6</td><td nowrap="nowrap">B'&nbsp;=&nbsp;transpose(B)&nbsp;if&nbsp;transB&nbsp;else&nbsp;B</td><td class="diff_next"></td><td class="diff_header" id="to75_6">6</td><td nowrap="nowrap">B'&nbsp;=&nbsp;transpose(B)&nbsp;if&nbsp;transB&nbsp;else&nbsp;B</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_7">7</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to75__0"></td><td class="diff_header" id="from75_8">8</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A'&nbsp;*&nbsp;B'&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;K)&nbsp;or&nbsp;(K,&nbsp;M),</td><td class="diff_next"></td><td class="diff_header" id="to75_8">8</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A'&nbsp;*&nbsp;B'&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;K)&nbsp;or&nbsp;(K,&nbsp;M),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_9">9</td><td nowrap="nowrap">input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;shape&nbsp;(K,&nbsp;N)&nbsp;or&nbsp;(N,&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;is&nbsp;broadcastable&nbsp;to&nbsp;shape&nbsp;(M,&nbsp;N),</td><td class="diff_next"></td><td class="diff_header" id="to75_9">9</td><td nowrap="nowrap">input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;shape&nbsp;(K,&nbsp;N)&nbsp;or&nbsp;(N,&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;is&nbsp;broadcastable&nbsp;to&nbsp;shape&nbsp;(M,&nbsp;N),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_10">10</td><td nowrap="nowrap">and&nbsp;output&nbsp;tensor&nbsp;Y&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;N).&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to75_10">10</td><td nowrap="nowrap">and&nbsp;output&nbsp;tensor&nbsp;Y&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;N).&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_11">11</td><td nowrap="nowrap">computation&nbsp;if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td><td class="diff_next"></td><td class="diff_header" id="to75_11">11</td><td nowrap="nowrap">computation&nbsp;if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_12">12</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;tensor&nbsp;A&nbsp;*&nbsp;B);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td><td class="diff_next"></td><td class="diff_header" id="to75_12">12</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;tensor&nbsp;A&nbsp;*&nbsp;B);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to75__1">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to75__1">n</a></td><td class="diff_header" id="to75_13">13</td><td nowrap="nowrap"><span class="diff_add">This&nbsp;operator&nbsp;has&nbsp;**optional**&nbsp;inputs/outputs.&nbsp;See&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/IR.md&gt;_&nbsp;for&nbsp;more&nbsp;details&nbsp;about&nbsp;the&nbsp;representation&nbsp;of&nbsp;optional&nbsp;arguments.&nbsp;An&nbsp;empty&nbsp;string&nbsp;may&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;place&nbsp;of&nbsp;an&nbsp;actual&nbsp;argument's&nbsp;name&nbsp;to&nbsp;indicate&nbsp;a&nbsp;missing&nbsp;argument.&nbsp;Trailing&nbsp;optional&nbsp;arguments&nbsp;(those&nbsp;not&nbsp;followed&nbsp;by&nbsp;an&nbsp;argument&nbsp;that&nbsp;is&nbsp;present)&nbsp;may&nbsp;also&nbsp;be&nbsp;simply&nbsp;omitted.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_14">14</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_14">14</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to75_15">15</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_15">15</td><td nowrap="nowrap">*&nbsp;**alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to75_16">16</td><td nowrap="nowrap">*&nbsp;**alpha**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B.</td><td class="diff_next"></td><td class="diff_header" id="to75_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_17">17</td><td nowrap="nowrap">*&nbsp;**beta**:</td><td class="diff_next"></td><td class="diff_header" id="to75_18">18</td><td nowrap="nowrap">*&nbsp;**beta**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C.</td><td class="diff_next"></td><td class="diff_header" id="to75_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_19">19</td><td nowrap="nowrap">*&nbsp;**transA**:</td><td class="diff_next"></td><td class="diff_header" id="to75_20">20</td><td nowrap="nowrap">*&nbsp;**transA**:</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to75__1"></td><td class="diff_header" id="from75_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to75_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_21">21</td><td nowrap="nowrap">*&nbsp;**transB**:</td><td class="diff_next"></td><td class="diff_header" id="to75_22">22</td><td nowrap="nowrap">*&nbsp;**transB**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to75_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_24">24</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_24">24</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to75_25">25</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to75__2">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to75__2">n</a></td><td class="diff_header" id="to75_26">26</td><td nowrap="nowrap"><span class="diff_add">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_25">25</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_27">27</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_26">26</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to75_28">28</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to75__2"></td><td class="diff_header" id="from75_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A.&nbsp;The&nbsp;shape&nbsp;of&nbsp;A&nbsp;should&nbsp;be&nbsp;(M,&nbsp;K)&nbsp;if&nbsp;transA&nbsp;is&nbsp;0,&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to75_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A.&nbsp;The&nbsp;shape&nbsp;of&nbsp;A&nbsp;should&nbsp;be&nbsp;(M,&nbsp;K)&nbsp;if&nbsp;transA&nbsp;is&nbsp;0,&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;(K,&nbsp;M)&nbsp;if&nbsp;transA&nbsp;is&nbsp;non-zero.</td><td class="diff_next"></td><td class="diff_header" id="to75_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;(K,&nbsp;M)&nbsp;if&nbsp;transA&nbsp;is&nbsp;non-zero.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_29">29</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to75_31">31</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B.&nbsp;The&nbsp;shape&nbsp;of&nbsp;B&nbsp;should&nbsp;be&nbsp;(K,&nbsp;N)&nbsp;if&nbsp;transB&nbsp;is&nbsp;0,&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to75_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B.&nbsp;The&nbsp;shape&nbsp;of&nbsp;B&nbsp;should&nbsp;be&nbsp;(K,&nbsp;N)&nbsp;if&nbsp;transB&nbsp;is&nbsp;0,&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;(N,&nbsp;K)&nbsp;if&nbsp;transB&nbsp;is&nbsp;non-zero.</td><td class="diff_next"></td><td class="diff_header" id="to75_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;(N,&nbsp;K)&nbsp;if&nbsp;transB&nbsp;is&nbsp;non-zero.</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to75__top">t</a></td><td class="diff_header" id="from75_32">32</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"><a href="#difflib_chg_to75__top">t</a></td><td class="diff_header" id="to75_34">34</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(<span class="diff_add">optional,&nbsp;</span>heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_35">35</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Optional&nbsp;input&nbsp;tensor&nbsp;C.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;the&nbsp;computation&nbsp;is&nbsp;done</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;<span class="diff_chg">Input&nbsp;ten</span>s<span class="diff_chg">o</span>r&nbsp;<span class="diff_chg">C</span>.&nbsp;The&nbsp;shape&nbsp;of&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional</td><td class="diff_next"></td><td class="diff_header" id="to75_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;<span class="diff_chg">a</span>s<span class="diff_chg">&nbsp;if&nbsp;C&nbsp;is&nbsp;a&nbsp;scala</span>r&nbsp;<span class="diff_chg">0</span>.&nbsp;The&nbsp;shape&nbsp;of&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;broadcastable&nbsp;to&nbsp;(M,&nbsp;N).</td><td class="diff_next"></td><td class="diff_header" id="to75_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;broadcastable&nbsp;to&nbsp;(M,&nbsp;N).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_35">35</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_38">38</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_36">36</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to75_39">39</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_37">37</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_40">40</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_38">38</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to75_41">41</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(M,&nbsp;N).</td><td class="diff_next"></td><td class="diff_header" id="to75_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(M,&nbsp;N).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_40">40</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to75_43">43</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_41">41</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to75_44">44</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_42">42</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to75_45">45</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to75_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to75_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_45">45</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to75_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to75_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to75_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to75_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td><td class="diff_next"></td><td class="diff_header" id="to75_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to75_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from75_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to75_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float/int&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="gemm-9">
<span id="l-onnx-op-gemm-9"></span><h2><a class="toc-backref" href="#id12" role="doc-backlink">Gemm - 9</a><a class="headerlink" href="#gemm-9" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm">Gemm (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>9</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 9</strong>.</p>
<p><strong>Summary</strong>
General Matrix multiplication:
<a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</a></p>
<p>A’ = transpose(A) if transA else A</p>
<p>B’ = transpose(B) if transB else B</p>
<p>Compute Y = alpha * A’ * B’ + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports <strong>unidirectional broadcasting</strong> (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md">Broadcasting in ONNX</a>.</p>
<p><strong>Attributes</strong>
* <strong>alpha</strong>:</p>
<blockquote>
<div><p>Scalar multiplier for the product of input tensors A * B.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>beta</strong>:
Scalar multiplier for input tensor C.</p></li>
<li><p><strong>transA</strong>:
Whether A should be transposed</p></li>
<li><p><strong>transB</strong>:
Whether B should be transposed</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>A</strong> (heterogeneous) - <strong>T</strong>:
Input tensor A. The shape of A should be (M, K) if transA is 0, or
(K, M) if transA is non-zero.</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Input tensor B. The shape of B should be (K, N) if transB is 0, or
(N, K) if transB is non-zero.</p></li>
<li><p><strong>C</strong> (heterogeneous) - <strong>T</strong>:
Input tensor C. The shape of C should be unidirectional
broadcastable to (M, N).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor of shape (M, N).</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16),
tensor(int32),
tensor(int64),
tensor(uint32),
tensor(uint64)
):
Constrain input and output types to float/int tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to76__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to76__0">f</a></td><td class="diff_header" id="from76_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td><td class="diff_next"><a href="#difflib_chg_to76__0">f</a></td><td class="diff_header" id="to76_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td><td class="diff_next"></td><td class="diff_header" id="to76_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_3">3</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_4">4</td><td nowrap="nowrap">A'&nbsp;=&nbsp;transpose(A)&nbsp;if&nbsp;transA&nbsp;else&nbsp;A</td><td class="diff_next"></td><td class="diff_header" id="to76_4">4</td><td nowrap="nowrap">A'&nbsp;=&nbsp;transpose(A)&nbsp;if&nbsp;transA&nbsp;else&nbsp;A</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_5">5</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_6">6</td><td nowrap="nowrap">B'&nbsp;=&nbsp;transpose(B)&nbsp;if&nbsp;transB&nbsp;else&nbsp;B</td><td class="diff_next"></td><td class="diff_header" id="to76_6">6</td><td nowrap="nowrap">B'&nbsp;=&nbsp;transpose(B)&nbsp;if&nbsp;transB&nbsp;else&nbsp;B</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_7">7</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_7">7</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_8">8</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A'&nbsp;*&nbsp;B'&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;K)&nbsp;or&nbsp;(K,&nbsp;M),</td><td class="diff_next"></td><td class="diff_header" id="to76_8">8</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A'&nbsp;*&nbsp;B'&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;K)&nbsp;or&nbsp;(K,&nbsp;M),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_9">9</td><td nowrap="nowrap">input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;shape&nbsp;(K,&nbsp;N)&nbsp;or&nbsp;(N,&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;is&nbsp;broadcastable&nbsp;to&nbsp;shape&nbsp;(M,&nbsp;N),</td><td class="diff_next"></td><td class="diff_header" id="to76_9">9</td><td nowrap="nowrap">input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;shape&nbsp;(K,&nbsp;N)&nbsp;or&nbsp;(N,&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;is&nbsp;broadcastable&nbsp;to&nbsp;shape&nbsp;(M,&nbsp;N),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_10">10</td><td nowrap="nowrap">and&nbsp;output&nbsp;tensor&nbsp;Y&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;N).&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to76_10">10</td><td nowrap="nowrap">and&nbsp;output&nbsp;tensor&nbsp;Y&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;N).&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_11">11</td><td nowrap="nowrap">computation&nbsp;if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td><td class="diff_next"></td><td class="diff_header" id="to76_11">11</td><td nowrap="nowrap">computation&nbsp;if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_12">12</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;tensor&nbsp;A&nbsp;*&nbsp;B);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td><td class="diff_next"></td><td class="diff_header" id="to76_12">12</td><td nowrap="nowrap">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;tensor&nbsp;A&nbsp;*&nbsp;B);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_13">13</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_13">13</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_14">14</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to76_14">14</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_15">15</td><td nowrap="nowrap">*&nbsp;**alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to76_15">15</td><td nowrap="nowrap">*&nbsp;**alpha**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B.</td><td class="diff_next"></td><td class="diff_header" id="to76_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_17">17</td><td nowrap="nowrap">*&nbsp;**beta**:</td><td class="diff_next"></td><td class="diff_header" id="to76_17">17</td><td nowrap="nowrap">*&nbsp;**beta**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C.</td><td class="diff_next"></td><td class="diff_header" id="to76_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_19">19</td><td nowrap="nowrap">*&nbsp;**transA**:</td><td class="diff_next"></td><td class="diff_header" id="to76_19">19</td><td nowrap="nowrap">*&nbsp;**transA**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to76_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_21">21</td><td nowrap="nowrap">*&nbsp;**transB**:</td><td class="diff_next"></td><td class="diff_header" id="to76_21">21</td><td nowrap="nowrap">*&nbsp;**transB**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to76_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_23">23</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_24">24</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to76_24">24</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_25">25</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_25">25</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_26">26</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to76_26">26</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A.&nbsp;The&nbsp;shape&nbsp;of&nbsp;A&nbsp;should&nbsp;be&nbsp;(M,&nbsp;K)&nbsp;if&nbsp;transA&nbsp;is&nbsp;0,&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to76_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A.&nbsp;The&nbsp;shape&nbsp;of&nbsp;A&nbsp;should&nbsp;be&nbsp;(M,&nbsp;K)&nbsp;if&nbsp;transA&nbsp;is&nbsp;0,&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;(K,&nbsp;M)&nbsp;if&nbsp;transA&nbsp;is&nbsp;non-zero.</td><td class="diff_next"></td><td class="diff_header" id="to76_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;(K,&nbsp;M)&nbsp;if&nbsp;transA&nbsp;is&nbsp;non-zero.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_29">29</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to76_29">29</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B.&nbsp;The&nbsp;shape&nbsp;of&nbsp;B&nbsp;should&nbsp;be&nbsp;(K,&nbsp;N)&nbsp;if&nbsp;transB&nbsp;is&nbsp;0,&nbsp;or</td><td class="diff_next"></td><td class="diff_header" id="to76_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B.&nbsp;The&nbsp;shape&nbsp;of&nbsp;B&nbsp;should&nbsp;be&nbsp;(K,&nbsp;N)&nbsp;if&nbsp;transB&nbsp;is&nbsp;0,&nbsp;or</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;(N,&nbsp;K)&nbsp;if&nbsp;transB&nbsp;is&nbsp;non-zero.</td><td class="diff_next"></td><td class="diff_header" id="to76_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;(N,&nbsp;K)&nbsp;if&nbsp;transB&nbsp;is&nbsp;non-zero.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_32">32</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to76_32">32</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;C.&nbsp;The&nbsp;shape&nbsp;of&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional</td><td class="diff_next"></td><td class="diff_header" id="to76_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;C.&nbsp;The&nbsp;shape&nbsp;of&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;broadcastable&nbsp;to&nbsp;(M,&nbsp;N).</td><td class="diff_next"></td><td class="diff_header" id="to76_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;broadcastable&nbsp;to&nbsp;(M,&nbsp;N).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_35">35</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_35">35</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_36">36</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to76_36">36</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_37">37</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_37">37</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_38">38</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to76_38">38</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(M,&nbsp;N).</td><td class="diff_next"></td><td class="diff_header" id="to76_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(M,&nbsp;N).</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to76__0"></td><td class="diff_header" id="from76_40">40</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_40">40</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_41">41</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to76_41">41</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_42">42</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to76_42">42</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to76_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to76_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to76__1">n</a></td><td class="diff_header" id="from76_45">45</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"><a href="#difflib_chg_to76__1">n</a></td><td class="diff_header" id="to76_45">45</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)<span class="diff_add">,</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to76__1"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_46">46</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(int32),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_47">47</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(int64),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_48">48</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(uint32),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to76_49">49</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(uint64)</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from76_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to76_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to76__top">t</a></td><td class="diff_header" id="from76_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"><a href="#difflib_chg_to76__top">t</a></td><td class="diff_header" id="to76_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float<span class="diff_add">/int</span>&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="gemm-7">
<span id="l-onnx-op-gemm-7"></span><h2><a class="toc-backref" href="#id13" role="doc-backlink">Gemm - 7</a><a class="headerlink" href="#gemm-7" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm">Gemm (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>7</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 7</strong>.</p>
<p><strong>Summary</strong>
General Matrix multiplication:
<a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</a></p>
<p>A’ = transpose(A) if transA else A</p>
<p>B’ = transpose(B) if transB else B</p>
<p>Compute Y = alpha * A’ * B’ + beta * C, where input tensor A has shape (M, K) or (K, M),
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
and output tensor Y has shape (M, N). A will be transposed before doing the
computation if attribute transA is non-zero, same for B and transB.
This operator supports <strong>unidirectional broadcasting</strong> (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md">Broadcasting in ONNX</a>.</p>
<p><strong>Attributes</strong>
* <strong>alpha</strong>:</p>
<blockquote>
<div><p>Scalar multiplier for the product of input tensors A * B.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>beta</strong>:
Scalar multiplier for input tensor C.</p></li>
<li><p><strong>transA</strong>:
Whether A should be transposed</p></li>
<li><p><strong>transB</strong>:
Whether B should be transposed</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>A</strong> (heterogeneous) - <strong>T</strong>:
Input tensor A. The shape of A should be (M, K) if transA is 0, or
(K, M) if transA is non-zero.</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Input tensor B. The shape of B should be (K, N) if transB is 0, or
(N, K) if transB is non-zero.</p></li>
<li><p><strong>C</strong> (heterogeneous) - <strong>T</strong>:
Input tensor C. The shape of C should be unidirectional
broadcastable to (M, N).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor of shape (M, N).</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to77__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to77__0"><a href="#difflib_chg_to77__0">f</a></td><td class="diff_header" id="from77_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td><td class="diff_next"><a href="#difflib_chg_to77__0">f</a></td><td class="diff_header" id="to77_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td><td class="diff_next"></td><td class="diff_header" id="to77_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to77__1">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to77__1">n</a></td><td class="diff_header" id="to77_3">3</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_4">4</td><td nowrap="nowrap"><span class="diff_add">A'&nbsp;=&nbsp;transpose(A)&nbsp;if&nbsp;transA&nbsp;else&nbsp;A</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_5">5</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_6">6</td><td nowrap="nowrap"><span class="diff_add">B'&nbsp;=&nbsp;transpose(B)&nbsp;if&nbsp;transB&nbsp;else&nbsp;B</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_7">7</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_3">3</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A&nbsp;*&nbsp;B&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to77_8">8</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A<span class="diff_add">'</span>&nbsp;*&nbsp;B<span class="diff_add">'</span>&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has<span class="diff_add">&nbsp;shape&nbsp;(M,&nbsp;K)&nbsp;or&nbsp;(K,&nbsp;M),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_4">4</td><td nowrap="nowrap"><span class="diff_sub">dimension&nbsp;(M&nbsp;X&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;dimension&nbsp;(K&nbsp;X&nbsp;N),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;and</span></td><td class="diff_next"></td><td class="diff_header" id="to77_9">9</td><td nowrap="nowrap"><span class="diff_add">input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;shape&nbsp;(K,&nbsp;N)&nbsp;or&nbsp;(N,&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;is&nbsp;broadcastable&nbsp;to&nbsp;shape&nbsp;(M,&nbsp;N),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_5">5</td><td nowrap="nowrap"><span class="diff_sub">output&nbsp;tensor&nbsp;Y&nbsp;have&nbsp;dimension&nbsp;(M&nbsp;X&nbsp;N).</span></td><td class="diff_next"></td><td class="diff_header" id="to77_10">10</td><td nowrap="nowrap"><span class="diff_add">and&nbsp;output&nbsp;tensor&nbsp;Y&nbsp;has&nbsp;shape&nbsp;(M,&nbsp;N).&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_6">6</td><td nowrap="nowrap"><span class="diff_sub">If&nbsp;attribute&nbsp;broadcast&nbsp;is&nbsp;non-zero,&nbsp;input&nbsp;tensor&nbsp;C&nbsp;will&nbsp;be&nbsp;broadcasted&nbsp;to&nbsp;match</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_7">7</td><td nowrap="nowrap"><span class="diff_sub">the&nbsp;dimension&nbsp;requirement.&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the&nbsp;computation</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to77__1"></td><td class="diff_header" id="from77_8">8</td><td nowrap="nowrap">if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td><td class="diff_next"></td><td class="diff_header" id="to77_11">11</td><td nowrap="nowrap"><span class="diff_add">computation&nbsp;</span>if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_12">12</td><td nowrap="nowrap"><span class="diff_add">This&nbsp;operator&nbsp;supports&nbsp;**unidirectional&nbsp;broadcasting**&nbsp;(tensor&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional&nbsp;broadcastable&nbsp;to&nbsp;tensor&nbsp;A&nbsp;*&nbsp;B);&nbsp;for&nbsp;more&nbsp;details&nbsp;please&nbsp;check&nbsp;Broadcasting&nbsp;in&nbsp;ONNX&nbsp;&lt;https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md&gt;_.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_13">13</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to77__2"></td><td class="diff_header" id="from77_10">10</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to77_14">14</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_11">11</td><td nowrap="nowrap">*&nbsp;**alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to77_15">15</td><td nowrap="nowrap">*&nbsp;**alpha**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to77__2">n</a></td><td class="diff_header" id="from77_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B<span class="diff_chg">,&nbsp;the</span></td><td class="diff_next"><a href="#difflib_chg_to77__2">n</a></td><td class="diff_header" id="to77_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B<span class="diff_chg">.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_13">13</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;default&nbsp;value&nbsp;is&nbsp;1.0.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_14">14</td><td nowrap="nowrap">*&nbsp;**beta**:</td><td class="diff_next"></td><td class="diff_header" id="to77_17">17</td><td nowrap="nowrap">*&nbsp;**beta**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to77__3">n</a></td><td class="diff_header" id="from77_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C<span class="diff_sub">,&nbsp;the&nbsp;default&nbsp;value&nbsp;is&nbsp;1</span>.<span class="diff_sub">0.</span></td><td class="diff_next"><a href="#difflib_chg_to77__3">n</a></td><td class="diff_header" id="to77_18">18</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_16">16</td><td nowrap="nowrap"><span class="diff_sub">*&nbsp;**broadcast**:</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_17">17</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Whether&nbsp;C&nbsp;should&nbsp;be&nbsp;broadcasted</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_18">18</td><td nowrap="nowrap">*&nbsp;**transA**:</td><td class="diff_next"></td><td class="diff_header" id="to77_19">19</td><td nowrap="nowrap">*&nbsp;**transA**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to77_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_20">20</td><td nowrap="nowrap">*&nbsp;**transB**:</td><td class="diff_next"></td><td class="diff_header" id="to77_21">21</td><td nowrap="nowrap">*&nbsp;**transB**:</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to77__3"></td><td class="diff_header" id="from77_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to77_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_23">23</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_23">23</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to77_24">24</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to77__4"></td><td class="diff_header" id="from77_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_25">25</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_25">25</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to77_26">26</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to77__4">n</a></td><td class="diff_header" id="from77_26">26</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A</span></td><td class="diff_next"><a href="#difflib_chg_to77__4">n</a></td><td class="diff_header" id="to77_27">27</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A.&nbsp;The&nbsp;shape&nbsp;of&nbsp;A&nbsp;should&nbsp;be&nbsp;(M,&nbsp;K)&nbsp;if&nbsp;transA&nbsp;is&nbsp;0,&nbsp;or</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to77__5"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_28">28</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;(K,&nbsp;M)&nbsp;if&nbsp;transA&nbsp;is&nbsp;non-zero.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_27">27</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to77_29">29</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to77__5">n</a></td><td class="diff_header" id="from77_28">28</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B</span></td><td class="diff_next"><a href="#difflib_chg_to77__5">n</a></td><td class="diff_header" id="to77_30">30</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B.&nbsp;The&nbsp;shape&nbsp;of&nbsp;B&nbsp;should&nbsp;be&nbsp;(K,&nbsp;N)&nbsp;if&nbsp;transB&nbsp;is&nbsp;0,&nbsp;or</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_31">31</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;(N,&nbsp;K)&nbsp;if&nbsp;transB&nbsp;is&nbsp;non-zero.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_29">29</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to77_32">32</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to77__6">n</a></td><td class="diff_header" id="from77_30">30</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;C</span></td><td class="diff_next"><a href="#difflib_chg_to77__6">n</a></td><td class="diff_header" id="to77_33">33</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;C.&nbsp;The&nbsp;shape&nbsp;of&nbsp;C&nbsp;should&nbsp;be&nbsp;unidirectional</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to77__6"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_34">34</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;broadcastable&nbsp;to&nbsp;(M,&nbsp;N).</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_31">31</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_35">35</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_32">32</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to77_36">36</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_37">37</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_34">34</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to77_38">38</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to77__top">t</a></td><td class="diff_header" id="from77_35">35</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Output&nbsp;tensor.</span></td><td class="diff_next"><a href="#difflib_chg_to77__top">t</a></td><td class="diff_header" id="to77_39">39</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Output&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(M,&nbsp;N).</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_36">36</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to77_40">40</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_37">37</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to77_41">41</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_38">38</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to77_42">42</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to77_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to77_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to77_45">45</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to77_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from77_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to77_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="gemm-6">
<span id="l-onnx-op-gemm-6"></span><h2><a class="toc-backref" href="#id14" role="doc-backlink">Gemm - 6</a><a class="headerlink" href="#gemm-6" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm">Gemm (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>6</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 6</strong>.</p>
<p><strong>Summary</strong>
General Matrix multiplication:
<a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</a>
Compute Y = alpha * A * B + beta * C, where input tensor A has
dimension (M X K), input tensor B has dimension (K X N), input tensor C and
output tensor Y have dimension (M X N).
If attribute broadcast is non-zero, input tensor C will be broadcasted to match
the dimension requirement. A will be transposed before doing the computation
if attribute transA is non-zero, same for B and transB.</p>
<p><strong>Attributes</strong>
* <strong>alpha</strong>:</p>
<blockquote>
<div><p>Scalar multiplier for the product of input tensors A * B, the
default value is 1.0.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>beta</strong>:
Scalar multiplier for input tensor C, the default value is 1.0.</p></li>
<li><p><strong>broadcast</strong>:
Whether C should be broadcasted</p></li>
<li><p><strong>transA</strong>:
Whether A should be transposed</p></li>
<li><p><strong>transB</strong>:
Whether B should be transposed</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>A</strong> (heterogeneous) - <strong>T</strong>:
Input tensor A</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Input tensor B</p></li>
<li><p><strong>C</strong> (heterogeneous) - <strong>T</strong>:
Input tensor C</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor.</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to78__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to78__0">f</a></td><td class="diff_header" id="from78_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td><td class="diff_next"><a href="#difflib_chg_to78__0">f</a></td><td class="diff_header" id="to78_1">1</td><td nowrap="nowrap">General&nbsp;Matrix&nbsp;multiplication:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td><td class="diff_next"></td><td class="diff_header" id="to78_2">2</td><td nowrap="nowrap">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_3">3</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A&nbsp;*&nbsp;B&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has</td><td class="diff_next"></td><td class="diff_header" id="to78_3">3</td><td nowrap="nowrap">Compute&nbsp;Y&nbsp;=&nbsp;alpha&nbsp;*&nbsp;A&nbsp;*&nbsp;B&nbsp;+&nbsp;beta&nbsp;*&nbsp;C,&nbsp;where&nbsp;input&nbsp;tensor&nbsp;A&nbsp;has</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_4">4</td><td nowrap="nowrap">dimension&nbsp;(M&nbsp;X&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;dimension&nbsp;(K&nbsp;X&nbsp;N),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to78_4">4</td><td nowrap="nowrap">dimension&nbsp;(M&nbsp;X&nbsp;K),&nbsp;input&nbsp;tensor&nbsp;B&nbsp;has&nbsp;dimension&nbsp;(K&nbsp;X&nbsp;N),&nbsp;input&nbsp;tensor&nbsp;C&nbsp;and</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_5">5</td><td nowrap="nowrap">output&nbsp;tensor&nbsp;Y&nbsp;have&nbsp;dimension&nbsp;(M&nbsp;X&nbsp;N).</td><td class="diff_next"></td><td class="diff_header" id="to78_5">5</td><td nowrap="nowrap">output&nbsp;tensor&nbsp;Y&nbsp;have&nbsp;dimension&nbsp;(M&nbsp;X&nbsp;N).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_6">6</td><td nowrap="nowrap">If&nbsp;attribute&nbsp;broadcast&nbsp;is&nbsp;non-zero,&nbsp;input&nbsp;tensor&nbsp;C&nbsp;will&nbsp;be&nbsp;broadcasted&nbsp;to&nbsp;match</td><td class="diff_next"></td><td class="diff_header" id="to78_6">6</td><td nowrap="nowrap">If&nbsp;attribute&nbsp;broadcast&nbsp;is&nbsp;non-zero,&nbsp;input&nbsp;tensor&nbsp;C&nbsp;will&nbsp;be&nbsp;broadcasted&nbsp;to&nbsp;match</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_7">7</td><td nowrap="nowrap">the&nbsp;dimension&nbsp;requirement.&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the&nbsp;computation</td><td class="diff_next"></td><td class="diff_header" id="to78_7">7</td><td nowrap="nowrap">the&nbsp;dimension&nbsp;requirement.&nbsp;A&nbsp;will&nbsp;be&nbsp;transposed&nbsp;before&nbsp;doing&nbsp;the&nbsp;computation</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_8">8</td><td nowrap="nowrap">if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td><td class="diff_next"></td><td class="diff_header" id="to78_8">8</td><td nowrap="nowrap">if&nbsp;attribute&nbsp;transA&nbsp;is&nbsp;non-zero,&nbsp;same&nbsp;for&nbsp;B&nbsp;and&nbsp;transB.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to78_9">9</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_10">10</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to78_10">10</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_11">11</td><td nowrap="nowrap">*&nbsp;**alpha**:</td><td class="diff_next"></td><td class="diff_header" id="to78_11">11</td><td nowrap="nowrap">*&nbsp;**alpha**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B,&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to78_12">12</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;the&nbsp;product&nbsp;of&nbsp;input&nbsp;tensors&nbsp;A&nbsp;*&nbsp;B,&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;default&nbsp;value&nbsp;is&nbsp;1.0.</td><td class="diff_next"></td><td class="diff_header" id="to78_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;default&nbsp;value&nbsp;is&nbsp;1.0.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_14">14</td><td nowrap="nowrap">*&nbsp;**beta**:</td><td class="diff_next"></td><td class="diff_header" id="to78_14">14</td><td nowrap="nowrap">*&nbsp;**beta**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C,&nbsp;the&nbsp;default&nbsp;value&nbsp;is&nbsp;1.0.</td><td class="diff_next"></td><td class="diff_header" id="to78_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;Scalar&nbsp;multiplier&nbsp;for&nbsp;input&nbsp;tensor&nbsp;C,&nbsp;the&nbsp;default&nbsp;value&nbsp;is&nbsp;1.0.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_16">16</td><td nowrap="nowrap">*&nbsp;**broadcast**:</td><td class="diff_next"></td><td class="diff_header" id="to78_16">16</td><td nowrap="nowrap">*&nbsp;**broadcast**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;C&nbsp;should&nbsp;be&nbsp;broadcasted</td><td class="diff_next"></td><td class="diff_header" id="to78_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;C&nbsp;should&nbsp;be&nbsp;broadcasted</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_18">18</td><td nowrap="nowrap">*&nbsp;**transA**:</td><td class="diff_next"></td><td class="diff_header" id="to78_18">18</td><td nowrap="nowrap">*&nbsp;**transA**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to78_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;A&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_20">20</td><td nowrap="nowrap">*&nbsp;**transB**:</td><td class="diff_next"></td><td class="diff_header" id="to78_20">20</td><td nowrap="nowrap">*&nbsp;**transB**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td><td class="diff_next"></td><td class="diff_header" id="to78_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Whether&nbsp;B&nbsp;should&nbsp;be&nbsp;transposed</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to78_22">22</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_23">23</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to78_23">23</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to78_24">24</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to78__0"></td><td class="diff_header" id="from78_25">25</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to78_25">25</td><td nowrap="nowrap">*&nbsp;**A**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A</td><td class="diff_next"></td><td class="diff_header" id="to78_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;A</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_27">27</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to78_27">27</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B</td><td class="diff_next"></td><td class="diff_header" id="to78_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;B</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_29">29</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to78_29">29</td><td nowrap="nowrap">*&nbsp;**C**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to78__top">t</a></td><td class="diff_header" id="from78_30">30</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;C,&nbsp;can&nbsp;be&nbsp;inplace.</span></td><td class="diff_next"><a href="#difflib_chg_to78__top">t</a></td><td class="diff_header" id="to78_30">30</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Input&nbsp;tensor&nbsp;C</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_31">31</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to78_31">31</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_32">32</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to78_32">32</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to78_33">33</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_34">34</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to78_34">34</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor.</td><td class="diff_next"></td><td class="diff_header" id="to78_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_36">36</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to78_36">36</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_37">37</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to78_37">37</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_38">38</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to78_38">38</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to78_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to78_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to78_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to78_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from78_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to78_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="gemm-1">
<span id="l-onnx-op-gemm-1"></span><h2><a class="toc-backref" href="#id15" role="doc-backlink">Gemm - 1</a><a class="headerlink" href="#gemm-1" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Gemm">Gemm (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>1</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: False</p>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong>
General Matrix multiplication:
<a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3">https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3</a>
Compute Y = alpha * A * B + beta * C, where input tensor A has
dimension (M X K), input tensor B has dimension (K X N), input tensor C and
output tensor Y have dimension (M X N).
If attribute broadcast is non-zero, input tensor C will be broadcasted to match
the dimension requirement. A will be transposed before doing the computation
if attribute transA is non-zero, same for B and transB.</p>
<p><strong>Attributes</strong>
* <strong>alpha</strong>:</p>
<blockquote>
<div><p>Scalar multiplier for the product of input tensors A * B, the
default value is 1.0.</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>beta</strong>:
Scalar multiplier for input tensor C, the default value is 1.0.</p></li>
<li><p><strong>broadcast</strong>:
Whether C should be broadcasted</p></li>
<li><p><strong>transA</strong>:
Whether A should be transposed</p></li>
<li><p><strong>transB</strong>:
Whether B should be transposed</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>A</strong> (heterogeneous) - <strong>T</strong>:
Input tensor A</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Input tensor B</p></li>
<li><p><strong>C</strong> (heterogeneous) - <strong>T</strong>:
Input tensor C, can be inplace.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output tensor.</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p>
</div></blockquote>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>