
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Conv &#8212; ONNX 0.1 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'onnx_doc_folder/onnx__Conv';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ConvInteger" href="onnx__ConvInteger.html" />
    <link rel="prev" title="ConstantOfShape" href="onnx__ConstantOfShape.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fas fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fas fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Abs.html">
   Abs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acos.html">
   Acos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acosh.html">
   Acosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Add.html">
   Add
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__And.html">
   And
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMax.html">
   ArgMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMin.html">
   ArgMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asin.html">
   Asin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asinh.html">
   Asinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atan.html">
   Atan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atanh.html">
   Atanh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__AveragePool.html">
   AveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BatchNormalization.html">
   BatchNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Bernoulli.html">
   Bernoulli
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BitShift.html">
   BitShift
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BlackmanWindow.html">
   BlackmanWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cast.html">
   Cast
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CastLike.html">
   CastLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Ceil.html">
   Ceil
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Celu.html">
   Celu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CenterCropPad.html">
   CenterCropPad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Clip.html">
   Clip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Col2Im.html">
   Col2Im
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Compress.html">
   Compress
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Concat.html">
   Concat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConcatFromSequence.html">
   ConcatFromSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Constant.html">
   Constant
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConstantOfShape.html">
   ConstantOfShape
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Conv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvInteger.html">
   ConvInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvTranspose.html">
   ConvTranspose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cos.html">
   Cos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cosh.html">
   Cosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CumSum.html">
   CumSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DFT.html">
   DFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DepthToSpace.html">
   DepthToSpace
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DequantizeLinear.html">
   DequantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Det.html">
   Det
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Div.html">
   Div
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Dropout.html">
   Dropout
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
   DynamicQuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Einsum.html">
   Einsum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Elu.html">
   Elu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Equal.html">
   Equal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Erf.html">
   Erf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Exp.html">
   Exp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Expand.html">
   Expand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__EyeLike.html">
   EyeLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Flatten.html">
   Flatten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Floor.html">
   Floor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GRU.html">
   GRU
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gather.html">
   Gather
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherElements.html">
   GatherElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherND.html">
   GatherND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gemm.html">
   Gemm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalAveragePool.html">
   GlobalAveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalLpPool.html">
   GlobalLpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalMaxPool.html">
   GlobalMaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Greater.html">
   Greater
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GreaterOrEqual.html">
   GreaterOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GridSample.html">
   GridSample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HammingWindow.html">
   HammingWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HannWindow.html">
   HannWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSigmoid.html">
   HardSigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSwish.html">
   HardSwish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Hardmax.html">
   Hardmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Identity.html">
   Identity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__If.html">
   If
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__InstanceNormalization.html">
   InstanceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsInf.html">
   IsInf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsNaN.html">
   IsNaN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LRN.html">
   LRN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LSTM.html">
   LSTM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LayerNormalization.html">
   LayerNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LeakyRelu.html">
   LeakyRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Less.html">
   Less
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LessOrEqual.html">
   LessOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Log.html">
   Log
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LogSoftmax.html">
   LogSoftmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Loop.html">
   Loop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpNormalization.html">
   LpNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpPool.html">
   LpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMul.html">
   MatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMulInteger.html">
   MatMulInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Max.html">
   Max
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxPool.html">
   MaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxRoiPool.html">
   MaxRoiPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxUnpool.html">
   MaxUnpool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mean.html">
   Mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
   MeanVarianceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MelWeightMatrix.html">
   MelWeightMatrix
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Min.html">
   Min
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mish.html">
   Mish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mod.html">
   Mod
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mul.html">
   Mul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Multinomial.html">
   Multinomial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Neg.html">
   Neg
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
   NegativeLogLikelihoodLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonMaxSuppression.html">
   NonMaxSuppression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonZero.html">
   NonZero
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Not.html">
   Not
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OneHot.html">
   OneHot
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Optional.html">
   Optional
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalGetElement.html">
   OptionalGetElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalHasElement.html">
   OptionalHasElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Or.html">
   Or
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__PRelu.html">
   PRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pad.html">
   Pad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pow.html">
   Pow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearConv.html">
   QLinearConv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearMatMul.html">
   QLinearMatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QuantizeLinear.html">
   QuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RNN.html">
   RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormal.html">
   RandomNormal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormalLike.html">
   RandomNormalLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniform.html">
   RandomUniform
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniformLike.html">
   RandomUniformLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Range.html">
   Range
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reciprocal.html">
   Reciprocal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL1.html">
   ReduceL1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL2.html">
   ReduceL2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSum.html">
   ReduceLogSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSumExp.html">
   ReduceLogSumExp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMax.html">
   ReduceMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMean.html">
   ReduceMean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMin.html">
   ReduceMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceProd.html">
   ReduceProd
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSum.html">
   ReduceSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSumSquare.html">
   ReduceSumSquare
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Relu.html">
   Relu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reshape.html">
   Reshape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Resize.html">
   Resize
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReverseSequence.html">
   ReverseSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RoiAlign.html">
   RoiAlign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Round.html">
   Round
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__STFT.html">
   STFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scan.html">
   Scan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scatter.html">
   Scatter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterElements.html">
   ScatterElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterND.html">
   ScatterND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Selu.html">
   Selu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceAt.html">
   SequenceAt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceConstruct.html">
   SequenceConstruct
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceEmpty.html">
   SequenceEmpty
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceErase.html">
   SequenceErase
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceInsert.html">
   SequenceInsert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceLength.html">
   SequenceLength
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceMap.html">
   SequenceMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shape.html">
   Shape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shrink.html">
   Shrink
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sigmoid.html">
   Sigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sign.html">
   Sign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sin.html">
   Sin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sinh.html">
   Sinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Size.html">
   Size
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Slice.html">
   Slice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softmax.html">
   Softmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
   SoftmaxCrossEntropyLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softplus.html">
   Softplus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softsign.html">
   Softsign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SpaceToDepth.html">
   SpaceToDepth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Split.html">
   Split
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SplitToSequence.html">
   SplitToSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sqrt.html">
   Sqrt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Squeeze.html">
   Squeeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__StringNormalizer.html">
   StringNormalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sub.html">
   Sub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sum.html">
   Sum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tan.html">
   Tan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tanh.html">
   Tanh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__TfIdfVectorizer.html">
   TfIdfVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ThresholdedRelu.html">
   ThresholdedRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tile.html">
   Tile
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__TopK.html">
   TopK
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Transpose.html">
   Transpose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Trilu.html">
   Trilu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unique.html">
   Unique
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unsqueeze.html">
   Unsqueeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Upsample.html">
   Upsample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Where.html">
   Where
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Xor.html">
   Xor
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
   ai.onnx.ml - ArrayFeatureExtractor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
   ai.onnx.ml - Binarizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CastMap.html">
   ai.onnx.ml - CastMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
   ai.onnx.ml - CategoryMapper
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
   ai.onnx.ml - DictVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
   ai.onnx.ml - FeatureVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Imputer.html">
   ai.onnx.ml - Imputer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
   ai.onnx.ml - LabelEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
   ai.onnx.ml - LinearClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
   ai.onnx.ml - LinearRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
   ai.onnx.ml - Normalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
   ai.onnx.ml - OneHotEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
   ai.onnx.ml - SVMClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
   ai.onnx.ml - SVMRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Scaler.html">
   ai.onnx.ml - Scaler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
   ai.onnx.ml - TreeEnsembleClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
   ai.onnx.ml - TreeEnsembleRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
   ai.onnx.ml - ZipMap
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
   ai.onnx.preview.training - Adagrad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
   ai.onnx.preview.training - Adam
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
   ai.onnx.preview.training - Gradient
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
   ai.onnx.preview.training - Momentum
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="table_main.html">
   operator table for domain main
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_ml.html">
   operator table for domain ai.onnx.ml
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_preview_training.html">
   operator table for domain ai.onnx.preview.training
  </a>
 </li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="conv">
<span id="l-onnx-doc-conv"></span><h1>Conv<a class="headerlink" href="#conv" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#conv-11" id="id2">Conv - 11</a></p></li>
<li><p><a class="reference internal" href="#conv-1" id="id3">Conv - 1</a></p></li>
</ul>
</nav>
<section id="conv-11">
<span id="l-onnx-op-conv-11"></span><h2><a class="toc-backref" href="#id2" role="doc-backlink">Conv - 11</a><a class="headerlink" href="#conv-11" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Conv">Conv (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>11</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 11</strong>.</p>
<p><strong>Summary</strong></p>
<p>The convolution operator consumes an input tensor and a filter, and
computes the output.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>auto_pad</strong>:
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
Where default value is NOTSET, which means explicit padding is used.
SAME_UPPER or SAME_LOWER mean pad the input so that <cite>output_shape[i]
= ceil(input_shape[i] / strides[i])</cite> for each axis <cite>i</cite>. The padding
is split between the two sides equally or almost equally (depending
on whether it is even or odd). In case the padding is an odd number,
the extra padding is added at the end for SAME_UPPER and at the
beginning for SAME_LOWER.</p></li>
<li><p><strong>dilations</strong>:
dilation value along each spatial axis of the filter. If not
present, the dilation defaults is 1 along each spatial axis.</p></li>
<li><p><strong>group</strong>:
number of groups input channels and output channels are divided
into.</p></li>
<li><p><strong>kernel_shape</strong>:
The shape of the convolution kernel. If not present, should be
inferred from input W.</p></li>
<li><p><strong>pads</strong>:
Padding for the beginning and ending along each spatial axis, it can
take any value greater than or equal to 0. The value represent the
number of pixels added to the beginning and end part of the
corresponding axis. <cite>pads</cite> format should be as follow [x1_begin,
x2_begin…x1_end, x2_end,…], where xi_begin the number of pixels
added at the beginning of axis <cite>i</cite> and xi_end, the number of pixels
added at the end of axis <cite>i</cite>. This attribute cannot be used
simultaneously with auto_pad attribute. If not present, the padding
defaults to 0 along start and end of each spatial axis.</p></li>
<li><p><strong>strides</strong>:
Stride along each spatial axis. If not present, the stride defaults
is 1 along each spatial axis.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from previous layer; has size (N x C x H x W),
where N is the batch size, C is the number of channels, and H and W
are the height and width. Note that this is for the 2D image.
Otherwise the size is (N x C x D1 x D2 … x Dn). Optionally, if
dimension denotation is in effect, the operation expects input data
tensor to arrive with the dimension denotation of [DATA_BATCH,
DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE …].</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor that will be used in the convolutions; has size (M
x C/group x kH x kW), where C is the number of channels, and kH and
kW are the height and width of the kernel, and M is the number of
feature maps. For more than 2 dimensions, the kernel shape will be
(M x C/group x k1 x k2 x … x kn), where (k1 x k2 x … kn) is the
dimension of the kernel. Optionally, if dimension denotation is in
effect, the operation expects the weight tensor to arrive with the
dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL,
FILTER_SPATIAL, FILTER_SPATIAL …]. Assuming zero based indices for
the shape array, X.shape[1] == (W.shape[1] * group) == C and
W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL
multiplied by the number of groups should be equal to DATA_CHANNEL
and the number of feature maps M should be a multiple of the number
of groups G.</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional 1D bias to be added to the convolution, has size of M.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output data tensor that contains the result of the convolution. The
output dimensions are functions of the kernel size, stride size, and
pad lengths.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>default</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 5, 5) input tensor</span>
                <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">14.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">17.0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">20.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">,</span> <span class="mf">23.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3) tensor for convolution weights</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Convolution with padding</span>
<span class="n">node_with_padding</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Conv&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="c1"># Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1</span>
    <span class="n">pads</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">y_with_padding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">12.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 5, 5) output tensor</span>
                <span class="p">[</span><span class="mf">33.0</span><span class="p">,</span> <span class="mf">54.0</span><span class="p">,</span> <span class="mf">63.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">,</span> <span class="mf">51.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">63.0</span><span class="p">,</span> <span class="mf">99.0</span><span class="p">,</span> <span class="mf">108.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">93.0</span><span class="p">,</span> <span class="mf">144.0</span><span class="p">,</span> <span class="mf">153.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">,</span> <span class="mf">111.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">72.0</span><span class="p">,</span> <span class="mf">111.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">,</span> <span class="mf">123.0</span><span class="p">,</span> <span class="mf">84.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node_with_padding</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y_with_padding</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_basic_conv_with_padding&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Convolution without padding</span>
<span class="n">node_without_padding</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Conv&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="c1"># Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1</span>
    <span class="n">pads</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">y_without_padding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">54.0</span><span class="p">,</span> <span class="mf">63.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3) output tensor</span>
                <span class="p">[</span><span class="mf">99.0</span><span class="p">,</span> <span class="mf">108.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">144.0</span><span class="p">,</span> <span class="mf">153.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node_without_padding</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y_without_padding</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_basic_conv_without_padding&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_conv_with_strides</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 7, 5) input tensor</span>
                <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">14.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">17.0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">20.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">,</span> <span class="mf">23.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span> <span class="mf">26.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">28.0</span><span class="p">,</span> <span class="mf">29.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">30.0</span><span class="p">,</span> <span class="mf">31.0</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">34.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3) tensor for convolution weights</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Convolution with strides=2 and padding</span>
<span class="n">node_with_padding</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Conv&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">pads</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">strides</span><span class="o">=</span><span class="p">[</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
    <span class="p">],</span>  <span class="c1"># Default values for other attributes: dilations=[1, 1], groups=1</span>
<span class="p">)</span>
<span class="n">y_with_padding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">12.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 4, 3) output tensor</span>
                <span class="p">[</span><span class="mf">63.0</span><span class="p">,</span> <span class="mf">108.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">123.0</span><span class="p">,</span> <span class="mf">198.0</span><span class="p">,</span> <span class="mf">141.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">112.0</span><span class="p">,</span> <span class="mf">177.0</span><span class="p">,</span> <span class="mf">124.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node_with_padding</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y_with_padding</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_conv_with_strides_padding&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Convolution with strides=2 and no padding</span>
<span class="n">node_without_padding</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Conv&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">pads</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">strides</span><span class="o">=</span><span class="p">[</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
    <span class="p">],</span>  <span class="c1"># Default values for other attributes: dilations=[1, 1], groups=1</span>
<span class="p">)</span>
<span class="n">y_without_padding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">54.0</span><span class="p">,</span> <span class="mf">72.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 2) output tensor</span>
                <span class="p">[</span><span class="mf">144.0</span><span class="p">,</span> <span class="mf">162.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">234.0</span><span class="p">,</span> <span class="mf">252.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node_without_padding</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y_without_padding</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_conv_with_strides_no_padding&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)</span>
<span class="n">node_with_asymmetric_padding</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Conv&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">pads</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">strides</span><span class="o">=</span><span class="p">[</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
    <span class="p">],</span>  <span class="c1"># Default values for other attributes: dilations=[1, 1], groups=1</span>
<span class="p">)</span>
<span class="n">y_with_asymmetric_padding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">21.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 4, 2) output tensor</span>
                <span class="p">[</span><span class="mf">99.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">189.0</span><span class="p">,</span> <span class="mf">207.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">171.0</span><span class="p">,</span> <span class="mf">183.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node_with_asymmetric_padding</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y_with_asymmetric_padding</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_conv_with_strides_and_asymmetric_padding&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_conv_with_autopad_same</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 5, 5) input tensor</span>
                <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">14.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">15.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">17.0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">20.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">,</span> <span class="mf">23.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3) tensor for convolution weights</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Convolution with auto_pad=&#39;SAME_LOWER&#39; and strides=2</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Conv&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">auto_pad</span><span class="o">=</span><span class="s2">&quot;SAME_LOWER&quot;</span><span class="p">,</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[[[</span><span class="mf">12.0</span><span class="p">,</span> <span class="mf">27.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">63.0</span><span class="p">,</span> <span class="mf">108.0</span><span class="p">,</span> <span class="mf">81.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">72.0</span><span class="p">,</span> <span class="mf">117.0</span><span class="p">,</span> <span class="mf">84.0</span><span class="p">]]]]</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_conv_with_autopad_same&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to38__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to38__0">f</a></td><td class="diff_header" id="from38_1">1</td><td nowrap="nowrap">The&nbsp;convolution&nbsp;operator&nbsp;consumes&nbsp;an&nbsp;input&nbsp;tensor&nbsp;and&nbsp;a&nbsp;filter,&nbsp;and</td><td class="diff_next"><a href="#difflib_chg_to38__0">f</a></td><td class="diff_header" id="to38_1">1</td><td nowrap="nowrap">The&nbsp;convolution&nbsp;operator&nbsp;consumes&nbsp;an&nbsp;input&nbsp;tensor&nbsp;and&nbsp;a&nbsp;filter,&nbsp;and</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_2">2</td><td nowrap="nowrap">computes&nbsp;the&nbsp;output.</td><td class="diff_next"></td><td class="diff_header" id="to38_2">2</td><td nowrap="nowrap">computes&nbsp;the&nbsp;output.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_3">3</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to38__0"></td><td class="diff_header" id="from38_4">4</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to38_4">4</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_5">5</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_6">6</td><td nowrap="nowrap">*&nbsp;**auto_pad**:</td><td class="diff_next"></td><td class="diff_header" id="to38_6">6</td><td nowrap="nowrap">*&nbsp;**auto_pad**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_7">7</td><td nowrap="nowrap">&nbsp;&nbsp;auto_pad&nbsp;must&nbsp;be&nbsp;either&nbsp;NOTSET,&nbsp;SAME_UPPER,&nbsp;SAME_LOWER&nbsp;or&nbsp;VALID.</td><td class="diff_next"></td><td class="diff_header" id="to38_7">7</td><td nowrap="nowrap">&nbsp;&nbsp;auto_pad&nbsp;must&nbsp;be&nbsp;either&nbsp;NOTSET,&nbsp;SAME_UPPER,&nbsp;SAME_LOWER&nbsp;or&nbsp;VALID.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_8">8</td><td nowrap="nowrap">&nbsp;&nbsp;Where&nbsp;default&nbsp;value&nbsp;is&nbsp;NOTSET,&nbsp;which&nbsp;means&nbsp;explicit&nbsp;padding&nbsp;is&nbsp;used.</td><td class="diff_next"></td><td class="diff_header" id="to38_8">8</td><td nowrap="nowrap">&nbsp;&nbsp;Where&nbsp;default&nbsp;value&nbsp;is&nbsp;NOTSET,&nbsp;which&nbsp;means&nbsp;explicit&nbsp;padding&nbsp;is&nbsp;used.</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to38__1">n</a></td><td class="diff_header" id="from38_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;SAME_UPPER&nbsp;or&nbsp;SAME_LOWER&nbsp;mean&nbsp;pad&nbsp;the&nbsp;input&nbsp;so&nbsp;that<span class="diff_sub">&nbsp;the</span>&nbsp;output</td><td class="diff_next"><a href="#difflib_chg_to38__1">n</a></td><td class="diff_header" id="to38_9">9</td><td nowrap="nowrap">&nbsp;&nbsp;SAME_UPPER&nbsp;or&nbsp;SAME_LOWER&nbsp;mean&nbsp;pad&nbsp;the&nbsp;input&nbsp;so&nbsp;that&nbsp;output<span class="diff_add">_shape[i]</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_10">10</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;spatial&nbsp;size&nbsp;match&nbsp;the&nbsp;input.In&nbsp;case&nbsp;of&nbsp;odd&nbsp;number&nbsp;add&nbsp;the&nbsp;extra</span></td><td class="diff_next"></td><td class="diff_header" id="to38_10">10</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;=&nbsp;ceil(input_shape[i]&nbsp;/&nbsp;strides[i])&nbsp;for&nbsp;each&nbsp;axis&nbsp;i.&nbsp;The&nbsp;padding</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to38__1"></td><td class="diff_header" id="from38_11">11</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;padding&nbsp;at&nbsp;the&nbsp;end&nbsp;for&nbsp;SAME_UPPER&nbsp;and&nbsp;at&nbsp;the&nbsp;beginning&nbsp;for</span></td><td class="diff_next"></td><td class="diff_header" id="to38_11">11</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;is&nbsp;split&nbsp;between&nbsp;the&nbsp;two&nbsp;sides&nbsp;equally&nbsp;or&nbsp;almost&nbsp;equally&nbsp;(depending</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_12">12</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;SAME_LOWER.&nbsp;VALID&nbsp;mean&nbsp;no&nbsp;padding.</span></td><td class="diff_next"></td><td class="diff_header" id="to38_12">12</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;on&nbsp;whether&nbsp;it&nbsp;is&nbsp;even&nbsp;or&nbsp;odd).&nbsp;In&nbsp;case&nbsp;the&nbsp;padding&nbsp;is&nbsp;an&nbsp;odd&nbsp;number,</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_13">13</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;the&nbsp;extra&nbsp;padding&nbsp;is&nbsp;added&nbsp;at&nbsp;the&nbsp;end&nbsp;for&nbsp;SAME_UPPER&nbsp;and&nbsp;at&nbsp;the</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_14">14</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;beginning&nbsp;for&nbsp;SAME_LOWER.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_13">13</td><td nowrap="nowrap">*&nbsp;**dilations**:</td><td class="diff_next"></td><td class="diff_header" id="to38_15">15</td><td nowrap="nowrap">*&nbsp;**dilations**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to38__2">n</a></td><td class="diff_header" id="from38_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;dilation&nbsp;value&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis&nbsp;of&nbsp;the&nbsp;filter.</td><td class="diff_next"><a href="#difflib_chg_to38__2">n</a></td><td class="diff_header" id="to38_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;dilation&nbsp;value&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis&nbsp;of&nbsp;the&nbsp;filter.<span class="diff_add">&nbsp;If&nbsp;not</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_17">17</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;present,&nbsp;the&nbsp;dilation&nbsp;defaults&nbsp;is&nbsp;1&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_15">15</td><td nowrap="nowrap">*&nbsp;**group**:</td><td class="diff_next"></td><td class="diff_header" id="to38_18">18</td><td nowrap="nowrap">*&nbsp;**group**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;groups&nbsp;input&nbsp;channels&nbsp;and&nbsp;output&nbsp;channels&nbsp;are&nbsp;divided</td><td class="diff_next"></td><td class="diff_header" id="to38_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;groups&nbsp;input&nbsp;channels&nbsp;and&nbsp;output&nbsp;channels&nbsp;are&nbsp;divided</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_17">17</td><td nowrap="nowrap">&nbsp;&nbsp;into.</td><td class="diff_next"></td><td class="diff_header" id="to38_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;into.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_18">18</td><td nowrap="nowrap">*&nbsp;**kernel_shape**:</td><td class="diff_next"></td><td class="diff_header" id="to38_21">21</td><td nowrap="nowrap">*&nbsp;**kernel_shape**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;shape&nbsp;of&nbsp;the&nbsp;convolution&nbsp;kernel.&nbsp;If&nbsp;not&nbsp;present,&nbsp;should&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to38_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;shape&nbsp;of&nbsp;the&nbsp;convolution&nbsp;kernel.&nbsp;If&nbsp;not&nbsp;present,&nbsp;should&nbsp;be</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;inferred&nbsp;from&nbsp;input&nbsp;W.</td><td class="diff_next"></td><td class="diff_header" id="to38_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;inferred&nbsp;from&nbsp;input&nbsp;W.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_21">21</td><td nowrap="nowrap">*&nbsp;**pads**:</td><td class="diff_next"></td><td class="diff_header" id="to38_24">24</td><td nowrap="nowrap">*&nbsp;**pads**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;Padding&nbsp;for&nbsp;the&nbsp;beginning&nbsp;and&nbsp;ending&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis,&nbsp;it&nbsp;can</td><td class="diff_next"></td><td class="diff_header" id="to38_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;Padding&nbsp;for&nbsp;the&nbsp;beginning&nbsp;and&nbsp;ending&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis,&nbsp;it&nbsp;can</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_23">23</td><td nowrap="nowrap">&nbsp;&nbsp;take&nbsp;any&nbsp;value&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;0.&nbsp;The&nbsp;value&nbsp;represent&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to38_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;take&nbsp;any&nbsp;value&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;0.&nbsp;The&nbsp;value&nbsp;represent&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;pixels&nbsp;added&nbsp;to&nbsp;the&nbsp;beginning&nbsp;and&nbsp;end&nbsp;part&nbsp;of&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to38_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;number&nbsp;of&nbsp;pixels&nbsp;added&nbsp;to&nbsp;the&nbsp;beginning&nbsp;and&nbsp;end&nbsp;part&nbsp;of&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;axis.&nbsp;pads&nbsp;format&nbsp;should&nbsp;be&nbsp;as&nbsp;follow&nbsp;[x1_begin,</td><td class="diff_next"></td><td class="diff_header" id="to38_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;corresponding&nbsp;axis.&nbsp;pads&nbsp;format&nbsp;should&nbsp;be&nbsp;as&nbsp;follow&nbsp;[x1_begin,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;x2_begin...x1_end,&nbsp;x2_end,...],&nbsp;where&nbsp;xi_begin&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td><td class="diff_next"></td><td class="diff_header" id="to38_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;x2_begin...x1_end,&nbsp;x2_end,...],&nbsp;where&nbsp;xi_begin&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to38__2"></td><td class="diff_header" id="from38_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;beginning&nbsp;of&nbsp;axis&nbsp;i&nbsp;and&nbsp;xi_end,&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td><td class="diff_next"></td><td class="diff_header" id="to38_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;beginning&nbsp;of&nbsp;axis&nbsp;i&nbsp;and&nbsp;xi_end,&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;end&nbsp;of&nbsp;axis&nbsp;i.&nbsp;This&nbsp;attribute&nbsp;cannot&nbsp;be&nbsp;used</td><td class="diff_next"></td><td class="diff_header" id="to38_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;added&nbsp;at&nbsp;the&nbsp;end&nbsp;of&nbsp;axis&nbsp;i.&nbsp;This&nbsp;attribute&nbsp;cannot&nbsp;be&nbsp;used</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;simultaneously&nbsp;with&nbsp;auto_pad&nbsp;attribute.&nbsp;If&nbsp;not&nbsp;present,&nbsp;the&nbsp;padding</td><td class="diff_next"></td><td class="diff_header" id="to38_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;simultaneously&nbsp;with&nbsp;auto_pad&nbsp;attribute.&nbsp;If&nbsp;not&nbsp;present,&nbsp;the&nbsp;padding</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;defaults&nbsp;to&nbsp;0&nbsp;along&nbsp;start&nbsp;and&nbsp;end&nbsp;of&nbsp;each&nbsp;spatial&nbsp;axis.</td><td class="diff_next"></td><td class="diff_header" id="to38_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;defaults&nbsp;to&nbsp;0&nbsp;along&nbsp;start&nbsp;and&nbsp;end&nbsp;of&nbsp;each&nbsp;spatial&nbsp;axis.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_31">31</td><td nowrap="nowrap">*&nbsp;**strides**:</td><td class="diff_next"></td><td class="diff_header" id="to38_34">34</td><td nowrap="nowrap">*&nbsp;**strides**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to38__3">n</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to38__3">n</a></td><td class="diff_header" id="to38_35">35</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;Stride&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.&nbsp;If&nbsp;not&nbsp;present,&nbsp;the&nbsp;stride&nbsp;defaults</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;<span class="diff_sub">Str</span>i<span class="diff_chg">de</span>&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.</td><td class="diff_next"></td><td class="diff_header" id="to38_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;i<span class="diff_chg">s&nbsp;1</span>&nbsp;along&nbsp;each&nbsp;spatial&nbsp;axis.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_33">33</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_37">37</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_34">34</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to38_38">38</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_35">35</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_39">39</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_36">36</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td><td class="diff_next"></td><td class="diff_header" id="to38_40">40</td><td nowrap="nowrap">Between&nbsp;2&nbsp;and&nbsp;3&nbsp;inputs.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_37">37</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_41">41</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_38">38</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to38_42">42</td><td nowrap="nowrap">*&nbsp;**X**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;data&nbsp;tensor&nbsp;from&nbsp;previous&nbsp;layer;&nbsp;has&nbsp;size&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;H&nbsp;x&nbsp;W),</td><td class="diff_next"></td><td class="diff_header" id="to38_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;data&nbsp;tensor&nbsp;from&nbsp;previous&nbsp;layer;&nbsp;has&nbsp;size&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;H&nbsp;x&nbsp;W),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size,&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;H&nbsp;and&nbsp;W</td><td class="diff_next"></td><td class="diff_header" id="to38_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;where&nbsp;N&nbsp;is&nbsp;the&nbsp;batch&nbsp;size,&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;H&nbsp;and&nbsp;W</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width.&nbsp;Note&nbsp;that&nbsp;this&nbsp;is&nbsp;for&nbsp;the&nbsp;2D&nbsp;image.</td><td class="diff_next"></td><td class="diff_header" id="to38_45">45</td><td nowrap="nowrap">&nbsp;&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width.&nbsp;Note&nbsp;that&nbsp;this&nbsp;is&nbsp;for&nbsp;the&nbsp;2D&nbsp;image.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Otherwise&nbsp;the&nbsp;size&nbsp;is&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;D1&nbsp;x&nbsp;D2&nbsp;...&nbsp;x&nbsp;Dn).&nbsp;Optionally,&nbsp;if</td><td class="diff_next"></td><td class="diff_header" id="to38_46">46</td><td nowrap="nowrap">&nbsp;&nbsp;Otherwise&nbsp;the&nbsp;size&nbsp;is&nbsp;(N&nbsp;x&nbsp;C&nbsp;x&nbsp;D1&nbsp;x&nbsp;D2&nbsp;...&nbsp;x&nbsp;Dn).&nbsp;Optionally,&nbsp;if</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;dimension&nbsp;denotation&nbsp;is&nbsp;in&nbsp;effect,&nbsp;the&nbsp;operation&nbsp;expects&nbsp;input&nbsp;data</td><td class="diff_next"></td><td class="diff_header" id="to38_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;dimension&nbsp;denotation&nbsp;is&nbsp;in&nbsp;effect,&nbsp;the&nbsp;operation&nbsp;expects&nbsp;input&nbsp;data</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_44">44</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;to&nbsp;arrive&nbsp;with&nbsp;the&nbsp;dimension&nbsp;denotation&nbsp;of&nbsp;[DATA_BATCH,</td><td class="diff_next"></td><td class="diff_header" id="to38_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;tensor&nbsp;to&nbsp;arrive&nbsp;with&nbsp;the&nbsp;dimension&nbsp;denotation&nbsp;of&nbsp;[DATA_BATCH,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_45">45</td><td nowrap="nowrap">&nbsp;&nbsp;DATA_CHANNEL,&nbsp;DATA_FEATURE,&nbsp;DATA_FEATURE&nbsp;...].</td><td class="diff_next"></td><td class="diff_header" id="to38_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;DATA_CHANNEL,&nbsp;DATA_FEATURE,&nbsp;DATA_FEATURE&nbsp;...].</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_46">46</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to38_50">50</td><td nowrap="nowrap">*&nbsp;**W**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_47">47</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;convolutions;&nbsp;has&nbsp;size&nbsp;(M</td><td class="diff_next"></td><td class="diff_header" id="to38_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;weight&nbsp;tensor&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;convolutions;&nbsp;has&nbsp;size&nbsp;(M</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_48">48</td><td nowrap="nowrap">&nbsp;&nbsp;x&nbsp;C/group&nbsp;x&nbsp;kH&nbsp;x&nbsp;kW),&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;kH&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to38_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;x&nbsp;C/group&nbsp;x&nbsp;kH&nbsp;x&nbsp;kW),&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;channels,&nbsp;and&nbsp;kH&nbsp;and</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_49">49</td><td nowrap="nowrap">&nbsp;&nbsp;kW&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width&nbsp;of&nbsp;the&nbsp;kernel,&nbsp;and&nbsp;M&nbsp;is&nbsp;the&nbsp;number&nbsp;of</td><td class="diff_next"></td><td class="diff_header" id="to38_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;kW&nbsp;are&nbsp;the&nbsp;height&nbsp;and&nbsp;width&nbsp;of&nbsp;the&nbsp;kernel,&nbsp;and&nbsp;M&nbsp;is&nbsp;the&nbsp;number&nbsp;of</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to38__3"></td><td class="diff_header" id="from38_50">50</td><td nowrap="nowrap">&nbsp;&nbsp;feature&nbsp;maps.&nbsp;For&nbsp;more&nbsp;than&nbsp;2&nbsp;dimensions,&nbsp;the&nbsp;kernel&nbsp;shape&nbsp;will&nbsp;be</td><td class="diff_next"></td><td class="diff_header" id="to38_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;feature&nbsp;maps.&nbsp;For&nbsp;more&nbsp;than&nbsp;2&nbsp;dimensions,&nbsp;the&nbsp;kernel&nbsp;shape&nbsp;will&nbsp;be</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_51">51</td><td nowrap="nowrap">&nbsp;&nbsp;(M&nbsp;x&nbsp;C/group&nbsp;x&nbsp;k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;x&nbsp;kn),&nbsp;where&nbsp;(k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;kn)&nbsp;is&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to38_55">55</td><td nowrap="nowrap">&nbsp;&nbsp;(M&nbsp;x&nbsp;C/group&nbsp;x&nbsp;k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;x&nbsp;kn),&nbsp;where&nbsp;(k1&nbsp;x&nbsp;k2&nbsp;x&nbsp;...&nbsp;kn)&nbsp;is&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_52">52</td><td nowrap="nowrap">&nbsp;&nbsp;dimension&nbsp;of&nbsp;the&nbsp;kernel.&nbsp;Optionally,&nbsp;if&nbsp;dimension&nbsp;denotation&nbsp;is&nbsp;in</td><td class="diff_next"></td><td class="diff_header" id="to38_56">56</td><td nowrap="nowrap">&nbsp;&nbsp;dimension&nbsp;of&nbsp;the&nbsp;kernel.&nbsp;Optionally,&nbsp;if&nbsp;dimension&nbsp;denotation&nbsp;is&nbsp;in</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_53">53</td><td nowrap="nowrap">&nbsp;&nbsp;effect,&nbsp;the&nbsp;operation&nbsp;expects&nbsp;the&nbsp;weight&nbsp;tensor&nbsp;to&nbsp;arrive&nbsp;with&nbsp;the</td><td class="diff_next"></td><td class="diff_header" id="to38_57">57</td><td nowrap="nowrap">&nbsp;&nbsp;effect,&nbsp;the&nbsp;operation&nbsp;expects&nbsp;the&nbsp;weight&nbsp;tensor&nbsp;to&nbsp;arrive&nbsp;with&nbsp;the</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_54">54</td><td nowrap="nowrap">&nbsp;&nbsp;dimension&nbsp;denotation&nbsp;of&nbsp;[FILTER_OUT_CHANNEL,&nbsp;FILTER_IN_CHANNEL,</td><td class="diff_next"></td><td class="diff_header" id="to38_58">58</td><td nowrap="nowrap">&nbsp;&nbsp;dimension&nbsp;denotation&nbsp;of&nbsp;[FILTER_OUT_CHANNEL,&nbsp;FILTER_IN_CHANNEL,</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to38__top">t</a></td><td class="diff_header" id="from38_55">55</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;FILTER_SPATIAL,&nbsp;FILTER_SPATIAL&nbsp;...].&nbsp;X.shape[1]&nbsp;==&nbsp;(W.shape[1]&nbsp;*</span></td><td class="diff_next"><a href="#difflib_chg_to38__top">t</a></td><td class="diff_header" id="to38_59">59</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;FILTER_SPATIAL,&nbsp;FILTER_SPATIAL&nbsp;...].&nbsp;Assuming&nbsp;zero&nbsp;based&nbsp;indices&nbsp;for</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_56">56</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;group)&nbsp;==&nbsp;C&nbsp;(assuming&nbsp;zero&nbsp;based&nbsp;indices&nbsp;for&nbsp;the&nbsp;shape&nbsp;array).&nbsp;Or&nbsp;in</span></td><td class="diff_next"></td><td class="diff_header" id="to38_60">60</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;the&nbsp;shape&nbsp;array,&nbsp;X.shape[1]&nbsp;==&nbsp;(W.shape[1]&nbsp;*&nbsp;group)&nbsp;==&nbsp;C&nbsp;and</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_57">57</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;other&nbsp;words&nbsp;FILTER_IN_CHANNEL&nbsp;should&nbsp;be&nbsp;equal&nbsp;to&nbsp;DATA_CHANNEL.</span></td><td class="diff_next"></td><td class="diff_header" id="to38_61">61</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;W.shape[0]&nbsp;mod&nbsp;G&nbsp;==&nbsp;0.&nbsp;Or&nbsp;in&nbsp;other&nbsp;words&nbsp;FILTER_IN_CHANNEL</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_62">62</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;multiplied&nbsp;by&nbsp;the&nbsp;number&nbsp;of&nbsp;groups&nbsp;should&nbsp;be&nbsp;equal&nbsp;to&nbsp;DATA_CHANNEL</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_63">63</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;and&nbsp;the&nbsp;number&nbsp;of&nbsp;feature&nbsp;maps&nbsp;M&nbsp;should&nbsp;be&nbsp;a&nbsp;multiple&nbsp;of&nbsp;the&nbsp;number</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_64">64</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;of&nbsp;groups&nbsp;G.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_58">58</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to38_65">65</td><td nowrap="nowrap">*&nbsp;**B**&nbsp;(optional,&nbsp;heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_59">59</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;1D&nbsp;bias&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;convolution,&nbsp;has&nbsp;size&nbsp;of&nbsp;M.</td><td class="diff_next"></td><td class="diff_header" id="to38_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;Optional&nbsp;1D&nbsp;bias&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;convolution,&nbsp;has&nbsp;size&nbsp;of&nbsp;M.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_60">60</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_67">67</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_61">61</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to38_68">68</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_62">62</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_69">69</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_63">63</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to38_70">70</td><td nowrap="nowrap">*&nbsp;**Y**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_64">64</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;data&nbsp;tensor&nbsp;that&nbsp;contains&nbsp;the&nbsp;result&nbsp;of&nbsp;the&nbsp;convolution.&nbsp;The</td><td class="diff_next"></td><td class="diff_header" id="to38_71">71</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;data&nbsp;tensor&nbsp;that&nbsp;contains&nbsp;the&nbsp;result&nbsp;of&nbsp;the&nbsp;convolution.&nbsp;The</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_65">65</td><td nowrap="nowrap">&nbsp;&nbsp;output&nbsp;dimensions&nbsp;are&nbsp;functions&nbsp;of&nbsp;the&nbsp;kernel&nbsp;size,&nbsp;stride&nbsp;size,&nbsp;and</td><td class="diff_next"></td><td class="diff_header" id="to38_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;output&nbsp;dimensions&nbsp;are&nbsp;functions&nbsp;of&nbsp;the&nbsp;kernel&nbsp;size,&nbsp;stride&nbsp;size,&nbsp;and</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_66">66</td><td nowrap="nowrap">&nbsp;&nbsp;pad&nbsp;lengths.</td><td class="diff_next"></td><td class="diff_header" id="to38_73">73</td><td nowrap="nowrap">&nbsp;&nbsp;pad&nbsp;lengths.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_67">67</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_74">74</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_68">68</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to38_75">75</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_69">69</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to38_76">76</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_70">70</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to38_77">77</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_71">71</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to38_78">78</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_72">72</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to38_79">79</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_73">73</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to38_80">80</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_74">74</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to38_81">81</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from38_75">75</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to38_82">82</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="conv-1">
<span id="l-onnx-op-conv-1"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">Conv - 1</a><a class="headerlink" href="#conv-1" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Conv">Conv (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>1</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<p>The convolution operator consumes an input tensor and a filter, and
computes the output.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>auto_pad</strong>:
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
Where default value is NOTSET, which means explicit padding is used.
SAME_UPPER or SAME_LOWER mean pad the input so that the output
spatial size match the input.In case of odd number add the extra
padding at the end for SAME_UPPER and at the beginning for
SAME_LOWER. VALID mean no padding.</p></li>
<li><p><strong>dilations</strong>:
dilation value along each spatial axis of the filter.</p></li>
<li><p><strong>group</strong>:
number of groups input channels and output channels are divided
into.</p></li>
<li><p><strong>kernel_shape</strong>:
The shape of the convolution kernel. If not present, should be
inferred from input W.</p></li>
<li><p><strong>pads</strong>:
Padding for the beginning and ending along each spatial axis, it can
take any value greater than or equal to 0. The value represent the
number of pixels added to the beginning and end part of the
corresponding axis. <cite>pads</cite> format should be as follow [x1_begin,
x2_begin…x1_end, x2_end,…], where xi_begin the number of pixels
added at the beginning of axis <cite>i</cite> and xi_end, the number of pixels
added at the end of axis <cite>i</cite>. This attribute cannot be used
simultaneously with auto_pad attribute. If not present, the padding
defaults to 0 along start and end of each spatial axis.</p></li>
<li><p><strong>strides</strong>:
Stride along each spatial axis.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from previous layer; has size (N x C x H x W),
where N is the batch size, C is the number of channels, and H and W
are the height and width. Note that this is for the 2D image.
Otherwise the size is (N x C x D1 x D2 … x Dn). Optionally, if
dimension denotation is in effect, the operation expects input data
tensor to arrive with the dimension denotation of [DATA_BATCH,
DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE …].</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor that will be used in the convolutions; has size (M
x C/group x kH x kW), where C is the number of channels, and kH and
kW are the height and width of the kernel, and M is the number of
feature maps. For more than 2 dimensions, the kernel shape will be
(M x C/group x k1 x k2 x … x kn), where (k1 x k2 x … kn) is the
dimension of the kernel. Optionally, if dimension denotation is in
effect, the operation expects the weight tensor to arrive with the
dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL,
FILTER_SPATIAL, FILTER_SPATIAL …]. X.shape[1] == (W.shape[1] *
group) == C (assuming zero based indices for the shape array). Or in
other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL.</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional 1D bias to be added to the convolution, has size of M.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output data tensor that contains the result of the convolution. The
output dimensions are functions of the kernel size, stride size, and
pad lengths.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="onnx__ConstantOfShape.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">ConstantOfShape</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="onnx__ConvInteger.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">ConvInteger</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fas fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conv-11">
   Conv - 11
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conv-1">
   Conv - 1
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="../_sources/onnx_doc_folder/onnx__Conv.rst.txt">
        <i class="fas fa-file-alt"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>