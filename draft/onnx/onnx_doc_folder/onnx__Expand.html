<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Expand &#8212; ONNX 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="EyeLike" href="onnx__EyeLike.html" />
    <link rel="prev" title="Exp" href="onnx__Exp.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ONNX Docs</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../onnx-api/index.html">API Overview</a></li>
                <li><a href="../operators/index.html">Op Schemas</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">API Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.checker.html">onnx.checker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.compose.html">onnx.compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.external_data_helper.html">onnx.external_data_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.helper.html">onnx.helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.hub.html">onnx.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.numpy_helper.html">onnx.numpy_helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.parser.html">onnx.parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.utils.html">onnx.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version.version.html">onnx.version.version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx-api/modules/onnx.version_converter.html">onnx.version_converter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Operators + OpSchemas</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">ONNX operators</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Expand</a><ul>
<li><a class="reference internal" href="#expand-13">Expand - 13</a></li>
<li><a class="reference internal" href="#expand-8">Expand - 8</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="onnx__Exp.html" title="Previous Chapter: Exp"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Exp</span>
    </a>
  </li>
  <li>
    <a href="onnx__EyeLike.html" title="Next Chapter: EyeLike"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">EyeLike &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/onnx_doc_folder/onnx__Expand.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="expand">
<span id="l-onnx-doc-expand"></span><h1>Expand<a class="headerlink" href="#expand" title="Permalink to this heading">¶</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#expand-13" id="id2">Expand - 13</a></p></li>
<li><p><a class="reference internal" href="#expand-8" id="id3">Expand - 8</a></p></li>
</ul>
</nav>
<section id="expand-13">
<span id="l-onnx-op-expand-13"></span><h2><a class="toc-backref" href="#id2" role="doc-backlink">Expand - 13</a><a class="headerlink" href="#expand-13" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Expand">Expand (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>13</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 13</strong>.</p>
<p><strong>Summary</strong></p>
<p>Broadcast the input tensor following the given shape and the broadcast rule.
The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):
Dimensions are right alignment;
Two corresponding dimensions must have the same value, or one of them is equal to 1.
Also, this operator is similar to numpy.broadcast_to(input, shape),
but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().
It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,
or the shape.ndim &lt; input.shape.ndim.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
Input tensor</p></li>
<li><p><strong>shape</strong> (heterogeneous) - <strong>tensor(int64)</strong>:
A 1-D tensor indicates the shape you want to expand to, following
the broadcast rule</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
Output tensor</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(bfloat16),
tensor(bool),
tensor(complex128),
tensor(complex64),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(string),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain input and output types to all tensors.</p>
</div></blockquote>
<p><strong>Examples</strong></p>
<p><strong>_dim_changed</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Expand&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;new_shape&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;expanded&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">shape</span><span class="p">)</span>
<span class="c1"># print(data)</span>
<span class="c1"># [[1.], [2.], [3.]]</span>
<span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">expanded</span> <span class="o">=</span> <span class="n">data</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># print(expanded)</span>
<span class="c1"># [[[1., 1., 1., 1., 1., 1.],</span>
<span class="c1">#  [2., 2., 2., 2., 2., 2.],</span>
<span class="c1">#  [3., 3., 3., 3., 3., 3.]],</span>
<span class="c1">#</span>
<span class="c1"># [[1., 1., 1., 1., 1., 1.],</span>
<span class="c1">#  [2., 2., 2., 2., 2., 2.],</span>
<span class="c1">#  [3., 3., 3., 3., 3., 3.]]]</span>
<span class="n">new_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">expanded</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_expand_dim_changed&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>_dim_unchanged</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;Expand&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;new_shape&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;expanded&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">shape</span><span class="p">)</span>
<span class="c1"># print(data)</span>
<span class="c1"># [[1.], [2.], [3.]]</span>
<span class="n">expanded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="c1"># print(expanded)</span>
<span class="c1"># [[1., 1., 1., 1.],</span>
<span class="c1"># [2., 2., 2., 2.],</span>
<span class="c1"># [3., 3., 3., 3.]]</span>
<span class="n">new_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span>
    <span class="n">node</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">expanded</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_expand_dim_unchanged&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to60__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next"><a href="#difflib_chg_to60__0">f</a></td><td class="diff_header" id="from60_1">1</td><td nowrap="nowrap">Broadcast&nbsp;the&nbsp;input&nbsp;tensor&nbsp;following&nbsp;the&nbsp;given&nbsp;shape&nbsp;and&nbsp;the&nbsp;broadcast&nbsp;rule.</td><td class="diff_next"><a href="#difflib_chg_to60__0">f</a></td><td class="diff_header" id="to60_1">1</td><td nowrap="nowrap">Broadcast&nbsp;the&nbsp;input&nbsp;tensor&nbsp;following&nbsp;the&nbsp;given&nbsp;shape&nbsp;and&nbsp;the&nbsp;broadcast&nbsp;rule.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_2">2</td><td nowrap="nowrap">The&nbsp;broadcast&nbsp;rule&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.array(input)&nbsp;*&nbsp;numpy.ones(shape):</td><td class="diff_next"></td><td class="diff_header" id="to60_2">2</td><td nowrap="nowrap">The&nbsp;broadcast&nbsp;rule&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.array(input)&nbsp;*&nbsp;numpy.ones(shape):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_3">3</td><td nowrap="nowrap">Dimensions&nbsp;are&nbsp;right&nbsp;alignment;</td><td class="diff_next"></td><td class="diff_header" id="to60_3">3</td><td nowrap="nowrap">Dimensions&nbsp;are&nbsp;right&nbsp;alignment;</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_4">4</td><td nowrap="nowrap">Two&nbsp;corresponding&nbsp;dimensions&nbsp;must&nbsp;have&nbsp;the&nbsp;same&nbsp;value,&nbsp;or&nbsp;one&nbsp;of&nbsp;them&nbsp;is&nbsp;equal&nbsp;to&nbsp;1.</td><td class="diff_next"></td><td class="diff_header" id="to60_4">4</td><td nowrap="nowrap">Two&nbsp;corresponding&nbsp;dimensions&nbsp;must&nbsp;have&nbsp;the&nbsp;same&nbsp;value,&nbsp;or&nbsp;one&nbsp;of&nbsp;them&nbsp;is&nbsp;equal&nbsp;to&nbsp;1.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_5">5</td><td nowrap="nowrap">Also,&nbsp;this&nbsp;operator&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.broadcast_to(input,&nbsp;shape),</td><td class="diff_next"></td><td class="diff_header" id="to60_5">5</td><td nowrap="nowrap">Also,&nbsp;this&nbsp;operator&nbsp;is&nbsp;similar&nbsp;to&nbsp;numpy.broadcast_to(input,&nbsp;shape),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_6">6</td><td nowrap="nowrap">but&nbsp;the&nbsp;major&nbsp;difference&nbsp;is&nbsp;numpy.broadcast_to()&nbsp;does&nbsp;not&nbsp;allow&nbsp;shape&nbsp;to&nbsp;be&nbsp;smaller&nbsp;than&nbsp;input.size().</td><td class="diff_next"></td><td class="diff_header" id="to60_6">6</td><td nowrap="nowrap">but&nbsp;the&nbsp;major&nbsp;difference&nbsp;is&nbsp;numpy.broadcast_to()&nbsp;does&nbsp;not&nbsp;allow&nbsp;shape&nbsp;to&nbsp;be&nbsp;smaller&nbsp;than&nbsp;input.size().</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_7">7</td><td nowrap="nowrap">It&nbsp;is&nbsp;possible&nbsp;that&nbsp;the&nbsp;output.shape&nbsp;is&nbsp;not&nbsp;equal&nbsp;to&nbsp;shape,&nbsp;when&nbsp;some&nbsp;dimensions&nbsp;in&nbsp;shape&nbsp;is&nbsp;equal&nbsp;to&nbsp;1,</td><td class="diff_next"></td><td class="diff_header" id="to60_7">7</td><td nowrap="nowrap">It&nbsp;is&nbsp;possible&nbsp;that&nbsp;the&nbsp;output.shape&nbsp;is&nbsp;not&nbsp;equal&nbsp;to&nbsp;shape,&nbsp;when&nbsp;some&nbsp;dimensions&nbsp;in&nbsp;shape&nbsp;is&nbsp;equal&nbsp;to&nbsp;1,</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_8">8</td><td nowrap="nowrap">or&nbsp;the&nbsp;shape.ndim&nbsp;&lt;&nbsp;input.shape.ndim.</td><td class="diff_next"></td><td class="diff_header" id="to60_8">8</td><td nowrap="nowrap">or&nbsp;the&nbsp;shape.ndim&nbsp;&lt;&nbsp;input.shape.ndim.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_9">9</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_9">9</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_10">10</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to60_10">10</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_11">11</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_11">11</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_12">12</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to60_12">12</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to60_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;Input&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_14">14</td><td nowrap="nowrap">*&nbsp;**shape**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(int64)**:</td><td class="diff_next"></td><td class="diff_header" id="to60_14">14</td><td nowrap="nowrap">*&nbsp;**shape**&nbsp;(heterogeneous)&nbsp;-&nbsp;**tensor(int64)**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;1-D&nbsp;tensor&nbsp;indicates&nbsp;the&nbsp;shape&nbsp;you&nbsp;want&nbsp;to&nbsp;expand&nbsp;to,&nbsp;following</td><td class="diff_next"></td><td class="diff_header" id="to60_15">15</td><td nowrap="nowrap">&nbsp;&nbsp;A&nbsp;1-D&nbsp;tensor&nbsp;indicates&nbsp;the&nbsp;shape&nbsp;you&nbsp;want&nbsp;to&nbsp;expand&nbsp;to,&nbsp;following</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;broadcast&nbsp;rule</td><td class="diff_next"></td><td class="diff_header" id="to60_16">16</td><td nowrap="nowrap">&nbsp;&nbsp;the&nbsp;broadcast&nbsp;rule</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_17">17</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_18">18</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to60_18">18</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_19">19</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_19">19</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to60__0"></td><td class="diff_header" id="from60_20">20</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to60_20">20</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to60_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;Output&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to60_22">22</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_23">23</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to60_23">23</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_24">24</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to60_24">24</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to60__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to60__top">t</a></td><td class="diff_header" id="to60_25">25</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_25">25</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(bool),</td><td class="diff_next"></td><td class="diff_header" id="to60_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(bool),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex128),</td><td class="diff_next"></td><td class="diff_header" id="to60_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex128),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex64),</td><td class="diff_next"></td><td class="diff_header" id="to60_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(complex64),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to60_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_29">29</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to60_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td><td class="diff_next"></td><td class="diff_header" id="to60_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int16),</td><td class="diff_next"></td><td class="diff_header" id="to60_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int16),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td><td class="diff_next"></td><td class="diff_header" id="to60_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td><td class="diff_next"></td><td class="diff_header" id="to60_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int64),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int8),</td><td class="diff_next"></td><td class="diff_header" id="to60_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(int8),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_35">35</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(string),</td><td class="diff_next"></td><td class="diff_header" id="to60_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(string),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_36">36</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint16),</td><td class="diff_next"></td><td class="diff_header" id="to60_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint16),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_37">37</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td><td class="diff_next"></td><td class="diff_header" id="to60_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint32),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64),</td><td class="diff_next"></td><td class="diff_header" id="to60_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint64),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint8)</td><td class="diff_next"></td><td class="diff_header" id="to60_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(uint8)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to60_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from60_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;all&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to60_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;all&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="expand-8">
<span id="l-onnx-op-expand-8"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">Expand - 8</a><a class="headerlink" href="#expand-8" title="Permalink to this heading">¶</a></h2>
<p><strong>Version</strong>
* <strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Expand">Expand (GitHub)</a>
* <strong>domain</strong>: <strong>main</strong>
* <strong>since_version</strong>: <strong>8</strong>
* <strong>function</strong>: False
* <strong>support_level</strong>: SupportType.COMMON
* <strong>shape inference</strong>: True</p>
<p>This version of the operator has been available
<strong>since version 8</strong>.</p>
<p><strong>Summary</strong></p>
<p>Broadcast the input tensor following the given shape and the broadcast rule.
The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):
Dimensions are right alignment;
Two corresponding dimensions must have the same value, or one of them is equal to 1.
Also, this operator is similar to numpy.broadcast_to(input, shape),
but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().
It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,
or the shape.ndim &lt; input.shape.ndim.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
Input tensor</p></li>
<li><p><strong>shape</strong> (heterogeneous) - <strong>tensor(int64)</strong>:
A 1-D tensor indicates the shape you want to expand to, following
the broadcast rule</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
Output tensor</p></li>
</ul>
<p><strong>Type Constraints</strong>
* <strong>T</strong> in (</p>
<blockquote>
<div><p>tensor(bool),
tensor(complex128),
tensor(complex64),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(string),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain input and output types to all tensors.</p>
</div></blockquote>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>