
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Cast &#8212; ONNX 1.12.0 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <link rel="shortcut icon" href="../_static/onnx-favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cast - 9 vs 13" href="text_diff_Cast_9_13.html" />
    <link rel="prev" title="BlackmanWindow" href="onnx__BlackmanWindow.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="auto">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fas fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/onnx-horizontal-color.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/onnx-horizontal-white.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://github.com/onnx/onnx" title="GitHub" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://github.com/onnx/onnx" title="GitHub" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
<nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
  </p><div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_python/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_python/index.html">
   API Reference
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   ONNX Operators
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label class="toctree-toggle" for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../expect_onnxruntime.html">
     Sample operator test code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Abs.html">
     Abs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acos.html">
     Acos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acosh.html">
     Acosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Add.html">
     Add
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__And.html">
     And
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMax.html">
     ArgMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMin.html">
     ArgMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asin.html">
     Asin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asinh.html">
     Asinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atan.html">
     Atan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atanh.html">
     Atanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__AttributeHasValue.html">
     AttributeHasValue
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__AveragePool.html">
     AveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BatchNormalization.html">
     BatchNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Bernoulli.html">
     Bernoulli
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BitShift.html">
     BitShift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BlackmanWindow.html">
     BlackmanWindow
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="current reference internal" href="#">
     Cast
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label class="toctree-toggle" for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="text_diff_Cast_9_13.html">
       Cast - 9 vs 13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="text_diff_Cast_6_13.html">
       Cast - 6 vs 13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="text_diff_Cast_6_9.html">
       Cast - 6 vs 9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="text_diff_Cast_1_13.html">
       Cast - 1 vs 13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="text_diff_Cast_1_9.html">
       Cast - 1 vs 9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="text_diff_Cast_1_6.html">
       Cast - 1 vs 6
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CastLike.html">
     CastLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Ceil.html">
     Ceil
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Celu.html">
     Celu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CenterCropPad.html">
     CenterCropPad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Clip.html">
     Clip
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Col2Im.html">
     Col2Im
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Compress.html">
     Compress
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Concat.html">
     Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConcatFromSequence.html">
     ConcatFromSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Constant.html">
     Constant
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConstantOfShape.html">
     ConstantOfShape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Conv.html">
     Conv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvInteger.html">
     ConvInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvTranspose.html">
     ConvTranspose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cos.html">
     Cos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cosh.html">
     Cosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CumSum.html">
     CumSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DFT.html">
     DFT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DepthToSpace.html">
     DepthToSpace
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DequantizeLinear.html">
     DequantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Det.html">
     Det
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Div.html">
     Div
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Dropout.html">
     Dropout
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
     DynamicQuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Einsum.html">
     Einsum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Elu.html">
     Elu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Equal.html">
     Equal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Erf.html">
     Erf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Exp.html">
     Exp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Expand.html">
     Expand
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__EyeLike.html">
     EyeLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Flatten.html">
     Flatten
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Floor.html">
     Floor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GRU.html">
     GRU
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gather.html">
     Gather
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherElements.html">
     GatherElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherND.html">
     GatherND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gemm.html">
     Gemm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalAveragePool.html">
     GlobalAveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalLpPool.html">
     GlobalLpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalMaxPool.html">
     GlobalMaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Greater.html">
     Greater
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GreaterOrEqual.html">
     GreaterOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GridSample.html">
     GridSample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HammingWindow.html">
     HammingWindow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HannWindow.html">
     HannWindow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSigmoid.html">
     HardSigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSwish.html">
     HardSwish
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Hardmax.html">
     Hardmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Identity.html">
     Identity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__If.html">
     If
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__InstanceNormalization.html">
     InstanceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsInf.html">
     IsInf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsNaN.html">
     IsNaN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LRN.html">
     LRN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LSTM.html">
     LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LayerNormalization.html">
     LayerNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LeakyRelu.html">
     LeakyRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Less.html">
     Less
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LessOrEqual.html">
     LessOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Log.html">
     Log
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LogSoftmax.html">
     LogSoftmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Loop.html">
     Loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpNormalization.html">
     LpNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpPool.html">
     LpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMul.html">
     MatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMulInteger.html">
     MatMulInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Max.html">
     Max
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxPool.html">
     MaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxRoiPool.html">
     MaxRoiPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxUnpool.html">
     MaxUnpool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mean.html">
     Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
     MeanVarianceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MelWeightMatrix.html">
     MelWeightMatrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Min.html">
     Min
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mish.html">
     Mish
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mod.html">
     Mod
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mul.html">
     Mul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Multinomial.html">
     Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Neg.html">
     Neg
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
     NegativeLogLikelihoodLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonMaxSuppression.html">
     NonMaxSuppression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonZero.html">
     NonZero
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Not.html">
     Not
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OneHot.html">
     OneHot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Optional.html">
     Optional
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalGetElement.html">
     OptionalGetElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalHasElement.html">
     OptionalHasElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Or.html">
     Or
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__PRelu.html">
     PRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pad.html">
     Pad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pow.html">
     Pow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearConv.html">
     QLinearConv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearMatMul.html">
     QLinearMatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QuantizeLinear.html">
     QuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RNN.html">
     RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormal.html">
     RandomNormal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormalLike.html">
     RandomNormalLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniform.html">
     RandomUniform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniformLike.html">
     RandomUniformLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Range.html">
     Range
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reciprocal.html">
     Reciprocal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL1.html">
     ReduceL1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL2.html">
     ReduceL2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSum.html">
     ReduceLogSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSumExp.html">
     ReduceLogSumExp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMax.html">
     ReduceMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMean.html">
     ReduceMean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMin.html">
     ReduceMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceProd.html">
     ReduceProd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSum.html">
     ReduceSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSumSquare.html">
     ReduceSumSquare
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Relu.html">
     Relu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reshape.html">
     Reshape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Resize.html">
     Resize
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReverseSequence.html">
     ReverseSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RoiAlign.html">
     RoiAlign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Round.html">
     Round
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__STFT.html">
     STFT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scan.html">
     Scan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scatter.html">
     Scatter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterElements.html">
     ScatterElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterND.html">
     ScatterND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Selu.html">
     Selu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceAt.html">
     SequenceAt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceConstruct.html">
     SequenceConstruct
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceEmpty.html">
     SequenceEmpty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceErase.html">
     SequenceErase
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceInsert.html">
     SequenceInsert
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceLength.html">
     SequenceLength
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceMap.html">
     SequenceMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shape.html">
     Shape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shrink.html">
     Shrink
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sigmoid.html">
     Sigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sign.html">
     Sign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sin.html">
     Sin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sinh.html">
     Sinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Size.html">
     Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Slice.html">
     Slice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softmax.html">
     Softmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
     SoftmaxCrossEntropyLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softplus.html">
     Softplus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softsign.html">
     Softsign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SpaceToDepth.html">
     SpaceToDepth
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Split.html">
     Split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SplitToSequence.html">
     SplitToSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sqrt.html">
     Sqrt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Squeeze.html">
     Squeeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__StringNormalizer.html">
     StringNormalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sub.html">
     Sub
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sum.html">
     Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tan.html">
     Tan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tanh.html">
     Tanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TfIdfVectorizer.html">
     TfIdfVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ThresholdedRelu.html">
     ThresholdedRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tile.html">
     Tile
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TopK.html">
     TopK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Transpose.html">
     Transpose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Trilu.html">
     Trilu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unique.html">
     Unique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unsqueeze.html">
     Unsqueeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Upsample.html">
     Upsample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Where.html">
     Where
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Xor.html">
     Xor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
     ai.onnx.ml - ArrayFeatureExtractor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
     ai.onnx.ml - Binarizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CastMap.html">
     ai.onnx.ml - CastMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
     ai.onnx.ml - CategoryMapper
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
     ai.onnx.ml - DictVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
     ai.onnx.ml - FeatureVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Imputer.html">
     ai.onnx.ml - Imputer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
     ai.onnx.ml - LabelEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
     ai.onnx.ml - LinearClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
     ai.onnx.ml - LinearRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
     ai.onnx.ml - Normalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
     ai.onnx.ml - OneHotEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
     ai.onnx.ml - SVMClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
     ai.onnx.ml - SVMRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Scaler.html">
     ai.onnx.ml - Scaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
     ai.onnx.ml - TreeEnsembleClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
     ai.onnx.ml - TreeEnsembleRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
     ai.onnx.ml - ZipMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
     ai.onnx.preview.training - Adagrad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
     ai.onnx.preview.training - Adam
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
     ai.onnx.preview.training - Gradient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
     ai.onnx.preview.training - Momentum
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="cast">
<span id="l-onnx-doc-cast"></span><h1>Cast<a class="headerlink" href="#cast" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#cast-13" id="id4">Cast - 13</a></p></li>
<li><p><a class="reference internal" href="#cast-9" id="id5">Cast - 9</a></p></li>
<li><p><a class="reference internal" href="#cast-6" id="id6">Cast - 6</a></p></li>
<li><p><a class="reference internal" href="#cast-1" id="id7">Cast - 1</a></p></li>
</ul>
</nav>
<section id="cast-13">
<span id="l-onnx-op-cast-13"></span><h2><a class="toc-backref" href="#id4" role="doc-backlink">Cast - 13</a><a class="headerlink" href="#cast-13" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast">Cast (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>13</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 13</strong>.</p>
<p><strong>Summary</strong></p>
<p>The operator casts the elements of a given input tensor to a data type
specified by the ‘to’ argument and returns an output tensor of the same size in
the converted type. The ‘to’ argument must be one of the data types specified
in the ‘DataType’ enum field in the TensorProto message.</p>
<p>Casting from string tensor in plain (e.g., “3.14” and “1000”) and scientific numeric representations
(e.g., “1e-5” and “1E8”) to float types is supported. For example, converting string “100.5” to an integer may
result 100. There are some string literals reserved for special floating-point values;
“+INF” (and “INF”), “-INF”, and “NaN” are positive infinity, negative infinity, and not-a-number, respectively.
Any string which can exactly match “+INF” in a case-insensitive way would be mapped to positive infinite. Similarly,
this case-insensitive rule is applied to “INF” and “NaN”. When casting from numeric tensors
to string tensors, plain floating-point representation (such as “314.15926”) would be used.
Converting non-numerical-literal string such as “Hello World!” is an undefined behavior. Cases
of converting string representing floating-point arithmetic value, such as “2.718”, to INT is an undefined behavior.</p>
<p>Conversion from a numerical type to any numerical type is always allowed.
User must be aware of precision loss and value change caused by range difference between two types.
For example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting
an integer 36 to Boolean may produce 1 because we truncate bits which can’t be stored in the targeted type.</p>
<p>In more detail, the conversion among numerical types should follow these rules:</p>
<ul class="simple">
<li><p>Casting from floating point to:
* floating point: +/- infinity if OOR (out of range).
* fixed point: undefined if OOR.
* bool: +/- 0.0 to False; all else to True.</p></li>
<li><p>Casting from fixed point to:
* floating point: +/- infinity if OOR. (+ infinity in the case of uint)
* fixed point: when OOR, discard higher bits and reinterpret (with respect to two’s complement representation for</p></li>
</ul>
<dl class="simple">
<dt>signed types). For example, 200 (int16) -&gt; -56 (int8).</dt><dd><ul class="simple">
<li><p>bool: zero to False; nonzero to True.</p></li>
</ul>
</dd>
</dl>
<ul class="simple">
<li><p>Casting from bool to:
* floating point: <cite>{1.0, 0.0}</cite>.
* fixed point: <cite>{1, 0}</cite>.
* bool: no change.</p></li>
</ul>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>to</strong> (required):
The data type to which the elements of the input tensor are cast.
Strictly must be one of the types from DataType enum in TensorProto</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T1</strong>:
Input tensor to be cast.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T2</strong>:
Output tensor with the same shape as input with type specified by
the ‘to’ argument</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T1</strong> in (
tensor(bfloat16),
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(string),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain input types. Casting from complex is not supported.</p></li>
<li><p><strong>T2</strong> in (
tensor(bfloat16),
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(string),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain output types. Casting to complex is not supported.</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>default</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>

<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">test_cases</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;FLOAT&quot;</span><span class="p">,</span> <span class="s2">&quot;FLOAT16&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;FLOAT&quot;</span><span class="p">,</span> <span class="s2">&quot;DOUBLE&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;FLOAT16&quot;</span><span class="p">,</span> <span class="s2">&quot;FLOAT&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;FLOAT16&quot;</span><span class="p">,</span> <span class="s2">&quot;DOUBLE&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;DOUBLE&quot;</span><span class="p">,</span> <span class="s2">&quot;FLOAT&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;DOUBLE&quot;</span><span class="p">,</span> <span class="s2">&quot;FLOAT16&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;FLOAT&quot;</span><span class="p">,</span> <span class="s2">&quot;STRING&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;STRING&quot;</span><span class="p">,</span> <span class="s2">&quot;FLOAT&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;FLOAT&quot;</span><span class="p">,</span> <span class="s2">&quot;BFLOAT16&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;BFLOAT16&quot;</span><span class="p">,</span> <span class="s2">&quot;FLOAT&quot;</span><span class="p">),</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">from_type</span><span class="p">,</span> <span class="n">to_type</span> <span class="ow">in</span> <span class="n">test_cases</span><span class="p">:</span>
    <span class="n">input_type_proto</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">output_type_proto</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="s2">&quot;BFLOAT16&quot;</span> <span class="o">==</span> <span class="n">from_type</span> <span class="ow">or</span> <span class="s2">&quot;BFLOAT16&quot;</span> <span class="o">==</span> <span class="n">to_type</span><span class="p">:</span>
        <span class="n">np_fp32</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="s2">&quot;0.47892547&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.48033667&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.49968487&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.81910545&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.47031248&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.816468&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.21087195&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.7229038&quot;</span><span class="p">,</span>
                <span class="s2">&quot;NaN&quot;</span><span class="p">,</span>
                <span class="s2">&quot;INF&quot;</span><span class="p">,</span>
                <span class="s2">&quot;+INF&quot;</span><span class="p">,</span>
                <span class="s2">&quot;-INF&quot;</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">little_endisan</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">byteorder</span> <span class="o">==</span> <span class="s2">&quot;little&quot;</span>
        <span class="n">np_uint16_view</span> <span class="o">=</span> <span class="n">np_fp32</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>
        <span class="n">np_bfp16</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np_uint16_view</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">little_endisan</span> <span class="k">else</span> <span class="n">np_uint16_view</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;BFLOAT16&quot;</span> <span class="o">==</span> <span class="n">to_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">from_type</span> <span class="o">==</span> <span class="s2">&quot;FLOAT&quot;</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">np_fp32</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">np_bfp16</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
            <span class="n">input_type_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_type_proto</span><span class="p">(</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">),</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
            <span class="p">)</span>
            <span class="n">output_type_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_type_proto</span><span class="p">(</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">BFLOAT16</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">to_type</span> <span class="o">==</span> <span class="s2">&quot;FLOAT&quot;</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">np_bfp16</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
            <span class="c1"># convert bfloat to FLOAT</span>
            <span class="n">np_fp32_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">np_bfp16</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">little_endisan</span><span class="p">:</span>
                <span class="n">np_fp32_zeros</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np_bfp16</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">np_fp32_zeros</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np_bfp16</span>
            <span class="n">np_fp32_from_bfloat</span> <span class="o">=</span> <span class="n">np_fp32_zeros</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">np_fp32_from_bfloat</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
            <span class="n">input_type_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_type_proto</span><span class="p">(</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">BFLOAT16</span><span class="p">),</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
            <span class="p">)</span>
            <span class="n">output_type_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_type_proto</span><span class="p">(</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="s2">&quot;STRING&quot;</span> <span class="o">!=</span> <span class="n">from_type</span><span class="p">:</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
            <span class="n">helper</span><span class="o">.</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">TensorProto</span><span class="p">,</span> <span class="n">from_type</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;STRING&quot;</span> <span class="o">==</span> <span class="n">to_type</span><span class="p">:</span>
            <span class="c1"># Converting input to str, then give it object dtype for generating script</span>
            <span class="n">ss</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">input</span><span class="o">.</span><span class="n">flatten</span><span class="p">():</span>
                <span class="n">s</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
                <span class="n">su</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
                <span class="n">ss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">su</span><span class="p">)</span>

            <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ss</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
                <span class="n">helper</span><span class="o">.</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">TensorProto</span><span class="p">,</span> <span class="n">to_type</span><span class="p">))</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="s2">&quot;0.47892547&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.48033667&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.49968487&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.81910545&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.47031248&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.816468&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.21087195&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0.7229038&quot;</span><span class="p">,</span>
                <span class="s2">&quot;NaN&quot;</span><span class="p">,</span>
                <span class="s2">&quot;INF&quot;</span><span class="p">,</span>
                <span class="s2">&quot;+INF&quot;</span><span class="p">,</span>
                <span class="s2">&quot;-INF&quot;</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="nb">object</span><span class="p">),</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
        <span class="n">output</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
            <span class="n">helper</span><span class="o">.</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">TensorProto</span><span class="p">,</span> <span class="n">to_type</span><span class="p">))</span>
        <span class="p">)</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
        <span class="s2">&quot;Cast&quot;</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">],</span>
        <span class="n">to</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">TensorProto</span><span class="p">,</span> <span class="n">to_type</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">input_type_proto</span> <span class="ow">and</span> <span class="n">output_type_proto</span><span class="p">:</span>
        <span class="n">expect</span><span class="p">(</span>
            <span class="n">node</span><span class="p">,</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_cast_&quot;</span> <span class="o">+</span> <span class="n">from_type</span> <span class="o">+</span> <span class="s2">&quot;_to_&quot;</span> <span class="o">+</span> <span class="n">to_type</span><span class="p">,</span>
            <span class="n">input_type_protos</span><span class="o">=</span><span class="p">[</span><span class="n">input_type_proto</span><span class="p">],</span>
            <span class="n">output_type_protos</span><span class="o">=</span><span class="p">[</span><span class="n">output_type_proto</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">expect</span><span class="p">(</span>
            <span class="n">node</span><span class="p">,</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">],</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">],</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_cast_&quot;</span> <span class="o">+</span> <span class="n">from_type</span> <span class="o">+</span> <span class="s2">&quot;_to_&quot;</span> <span class="o">+</span> <span class="n">to_type</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>
</div>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="text_diff_Cast_9_13.html">Cast - 9 vs 13</a></li>
</ul>
</div>
</section>
<section id="cast-9">
<span id="l-onnx-op-cast-9"></span><h2><a class="toc-backref" href="#id5" role="doc-backlink">Cast - 9</a><a class="headerlink" href="#cast-9" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast">Cast (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>9</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 9</strong>.</p>
<p><strong>Summary</strong></p>
<p>The operator casts the elements of a given input tensor to a data type
specified by the ‘to’ argument and returns an output tensor of the same size in
the converted type. The ‘to’ argument must be one of the data types specified
in the ‘DataType’ enum field in the TensorProto message.</p>
<p>Casting from string tensor in plain (e.g., “3.14” and “1000”) and scientific numeric representations
(e.g., “1e-5” and “1E8”) to float types is supported. For example, converting string “100.5” to an integer may
result 100. There are some string literals reserved for special floating-point values;
“+INF” (and “INF”), “-INF”, and “NaN” are positive infinity, negative infinity, and not-a-number, respectively.
Any string which can exactly match “+INF” in a case-insensitive way would be mapped to positive infinite. Similarly,
this case-insensitive rule is applied to “INF” and “NaN”. When casting from numeric tensors
to string tensors, plain floating-point representation (such as “314.15926”) would be used.
Converting non-numerical-literal string such as “Hello World!” is an undefined behavior. Cases
of converting string representing floating-point arithmetic value, such as “2.718”, to INT is an undefined behavior.</p>
<p>Conversion from a numerical type to any numerical type is always allowed.
User must be aware of precision loss and value change caused by range difference between two types.
For example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting
an integer 36 to Boolean may produce 1 because we truncate bits which can’t be stored in the targeted type.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>to</strong> (required):
The data type to which the elements of the input tensor are cast.
Strictly must be one of the types from DataType enum in TensorProto</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T1</strong>:
Input tensor to be cast.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T2</strong>:
Output tensor with the same shape as input with type specified by
the ‘to’ argument</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T1</strong> in (
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(string),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain input types. Casting from complex is not supported.</p></li>
<li><p><strong>T2</strong> in (
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(string),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain output types. Casting to complex is not supported.</p></li>
</ul>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="text_diff_Cast_6_13.html">Cast - 6 vs 13</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_diff_Cast_6_9.html">Cast - 6 vs 9</a></li>
</ul>
</div>
</section>
<section id="cast-6">
<span id="l-onnx-op-cast-6"></span><h2><a class="toc-backref" href="#id6" role="doc-backlink">Cast - 6</a><a class="headerlink" href="#cast-6" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast">Cast (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>6</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 6</strong>.</p>
<p><strong>Summary</strong></p>
<p>The operator casts the elements of a given input tensor to a data type
specified by the ‘to’ argument and returns an output tensor of the same size in
the converted type. The ‘to’ argument must be one of the data types specified
in the ‘DataType’ enum field in the TensorProto message.
NOTE: Casting to and from strings is not supported yet.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>to</strong> (required):
The data type to which the elements of the input tensor are cast.
Strictly must be one of the types from DataType enum in TensorProto</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T1</strong>:
Input tensor to be cast.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T2</strong>:
Output tensor with the same shape as input with type specified by
the ‘to’ argument</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T1</strong> in (
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain input types. Casting from strings and complex are not
supported.</p></li>
<li><p><strong>T2</strong> in (
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain output types. Casting to strings and complex are not
supported.</p></li>
</ul>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="text_diff_Cast_1_13.html">Cast - 1 vs 13</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_diff_Cast_1_9.html">Cast - 1 vs 9</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_diff_Cast_1_6.html">Cast - 1 vs 6</a></li>
</ul>
</div>
</section>
<section id="cast-1">
<span id="l-onnx-op-cast-1"></span><h2><a class="toc-backref" href="#id7" role="doc-backlink">Cast - 1</a><a class="headerlink" href="#cast-1" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Cast">Cast (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>1</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: False</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<p>The operator casts the elements of a given input tensor to a data type
specified by the ‘to’ argument and returns an output tensor of the same size in
the converted type. The ‘to’ argument must be one of the data types specified
in the ‘DataType’ enum field in the TensorProto message.
NOTE: Casting to and from strings is not supported yet.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>to</strong> (required):
The data type to which the elements of the input tensor are cast.
Strictly must be one of the types from DataType enum in TensorProto</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T1</strong>:
Input tensor to be cast.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T2</strong>:
Output tensor with the same shape as input with type specified by
the ‘to’ argument</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T1</strong> in (
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain input types. Casting from strings and complex are not
supported.</p></li>
<li><p><strong>T2</strong> in (
tensor(bool),
tensor(double),
tensor(float),
tensor(float16),
tensor(int16),
tensor(int32),
tensor(int64),
tensor(int8),
tensor(uint16),
tensor(uint32),
tensor(uint64),
tensor(uint8)
):
Constrain output types. Casting to strings and complex are not
supported.</p></li>
</ul>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="onnx__BlackmanWindow.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">BlackmanWindow</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="text_diff_Cast_9_13.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Cast - 9 vs 13</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.2.1.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>