
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>LogSoftmax &#8212; ONNX 0.1 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=9b1a4fa89bdd0e95b23b" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sample.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'onnx_doc_folder/onnx__LogSoftmax';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Loop" href="onnx__Loop.html" />
    <link rel="prev" title="Log" href="onnx__Log.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fas fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/ONNX_logo_main.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fas fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/index.html">
                        Modules
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.checker.html">
                        onnx.checker
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.compose.html">
                        onnx.compose
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.external_data_helper.html">
                        onnx.external_data_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.helper.html">
                        onnx.helper
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.hub.html">
                        onnx.hub
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.numpy_helper.html">
                        onnx.numpy_helper
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.parser.html">
                        onnx.parser
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.utils.html">
                        onnx.utils
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version.version.html">
                        onnx.version.version
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx-api/modules/onnx.version_converter.html">
                        onnx.version_converter
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../onnx_python/index.html">
                        Summary of onnx API
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="index.html">
                        ONNX operators
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Abs.html">
   Abs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acos.html">
   Acos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Acosh.html">
   Acosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Add.html">
   Add
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__And.html">
   And
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMax.html">
   ArgMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ArgMin.html">
   ArgMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asin.html">
   Asin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Asinh.html">
   Asinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atan.html">
   Atan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Atanh.html">
   Atanh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__AveragePool.html">
   AveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BatchNormalization.html">
   BatchNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Bernoulli.html">
   Bernoulli
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BitShift.html">
   BitShift
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__BlackmanWindow.html">
   BlackmanWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cast.html">
   Cast
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CastLike.html">
   CastLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Ceil.html">
   Ceil
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Celu.html">
   Celu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CenterCropPad.html">
   CenterCropPad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Clip.html">
   Clip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Col2Im.html">
   Col2Im
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Compress.html">
   Compress
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Concat.html">
   Concat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConcatFromSequence.html">
   ConcatFromSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Constant.html">
   Constant
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConstantOfShape.html">
   ConstantOfShape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Conv.html">
   Conv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvInteger.html">
   ConvInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ConvTranspose.html">
   ConvTranspose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cos.html">
   Cos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Cosh.html">
   Cosh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__CumSum.html">
   CumSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DFT.html">
   DFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DepthToSpace.html">
   DepthToSpace
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DequantizeLinear.html">
   DequantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Det.html">
   Det
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Div.html">
   Div
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Dropout.html">
   Dropout
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
   DynamicQuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Einsum.html">
   Einsum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Elu.html">
   Elu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Equal.html">
   Equal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Erf.html">
   Erf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Exp.html">
   Exp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Expand.html">
   Expand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__EyeLike.html">
   EyeLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Flatten.html">
   Flatten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Floor.html">
   Floor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GRU.html">
   GRU
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gather.html">
   Gather
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherElements.html">
   GatherElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GatherND.html">
   GatherND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Gemm.html">
   Gemm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalAveragePool.html">
   GlobalAveragePool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalLpPool.html">
   GlobalLpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GlobalMaxPool.html">
   GlobalMaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Greater.html">
   Greater
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GreaterOrEqual.html">
   GreaterOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__GridSample.html">
   GridSample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HammingWindow.html">
   HammingWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HannWindow.html">
   HannWindow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSigmoid.html">
   HardSigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__HardSwish.html">
   HardSwish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Hardmax.html">
   Hardmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Identity.html">
   Identity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__If.html">
   If
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__InstanceNormalization.html">
   InstanceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsInf.html">
   IsInf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__IsNaN.html">
   IsNaN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LRN.html">
   LRN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LSTM.html">
   LSTM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LayerNormalization.html">
   LayerNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LeakyRelu.html">
   LeakyRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Less.html">
   Less
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LessOrEqual.html">
   LessOrEqual
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Log.html">
   Log
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   LogSoftmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Loop.html">
   Loop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpNormalization.html">
   LpNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__LpPool.html">
   LpPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMul.html">
   MatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MatMulInteger.html">
   MatMulInteger
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Max.html">
   Max
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxPool.html">
   MaxPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxRoiPool.html">
   MaxRoiPool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MaxUnpool.html">
   MaxUnpool
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mean.html">
   Mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
   MeanVarianceNormalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__MelWeightMatrix.html">
   MelWeightMatrix
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Min.html">
   Min
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mish.html">
   Mish
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mod.html">
   Mod
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Mul.html">
   Mul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Multinomial.html">
   Multinomial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Neg.html">
   Neg
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
   NegativeLogLikelihoodLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonMaxSuppression.html">
   NonMaxSuppression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__NonZero.html">
   NonZero
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Not.html">
   Not
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OneHot.html">
   OneHot
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Optional.html">
   Optional
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalGetElement.html">
   OptionalGetElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__OptionalHasElement.html">
   OptionalHasElement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Or.html">
   Or
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__PRelu.html">
   PRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pad.html">
   Pad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Pow.html">
   Pow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearConv.html">
   QLinearConv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QLinearMatMul.html">
   QLinearMatMul
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__QuantizeLinear.html">
   QuantizeLinear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RNN.html">
   RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormal.html">
   RandomNormal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomNormalLike.html">
   RandomNormalLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniform.html">
   RandomUniform
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RandomUniformLike.html">
   RandomUniformLike
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Range.html">
   Range
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reciprocal.html">
   Reciprocal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL1.html">
   ReduceL1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceL2.html">
   ReduceL2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSum.html">
   ReduceLogSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceLogSumExp.html">
   ReduceLogSumExp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMax.html">
   ReduceMax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMean.html">
   ReduceMean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceMin.html">
   ReduceMin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceProd.html">
   ReduceProd
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSum.html">
   ReduceSum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReduceSumSquare.html">
   ReduceSumSquare
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Relu.html">
   Relu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Reshape.html">
   Reshape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Resize.html">
   Resize
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ReverseSequence.html">
   ReverseSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__RoiAlign.html">
   RoiAlign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Round.html">
   Round
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__STFT.html">
   STFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scan.html">
   Scan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Scatter.html">
   Scatter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterElements.html">
   ScatterElements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ScatterND.html">
   ScatterND
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Selu.html">
   Selu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceAt.html">
   SequenceAt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceConstruct.html">
   SequenceConstruct
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceEmpty.html">
   SequenceEmpty
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceErase.html">
   SequenceErase
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceInsert.html">
   SequenceInsert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceLength.html">
   SequenceLength
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SequenceMap.html">
   SequenceMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shape.html">
   Shape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Shrink.html">
   Shrink
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sigmoid.html">
   Sigmoid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sign.html">
   Sign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sin.html">
   Sin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sinh.html">
   Sinh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Size.html">
   Size
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Slice.html">
   Slice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softmax.html">
   Softmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
   SoftmaxCrossEntropyLoss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softplus.html">
   Softplus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Softsign.html">
   Softsign
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SpaceToDepth.html">
   SpaceToDepth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Split.html">
   Split
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__SplitToSequence.html">
   SplitToSequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sqrt.html">
   Sqrt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Squeeze.html">
   Squeeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__StringNormalizer.html">
   StringNormalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sub.html">
   Sub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Sum.html">
   Sum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tan.html">
   Tan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tanh.html">
   Tanh
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__TfIdfVectorizer.html">
   TfIdfVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__ThresholdedRelu.html">
   ThresholdedRelu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Tile.html">
   Tile
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__TopK.html">
   TopK
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Transpose.html">
   Transpose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Trilu.html">
   Trilu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unique.html">
   Unique
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Unsqueeze.html">
   Unsqueeze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Upsample.html">
   Upsample
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Where.html">
   Where
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx__Xor.html">
   Xor
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
   ai.onnx.ml - ArrayFeatureExtractor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
   ai.onnx.ml - Binarizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CastMap.html">
   ai.onnx.ml - CastMap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
   ai.onnx.ml - CategoryMapper
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
   ai.onnx.ml - DictVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
   ai.onnx.ml - FeatureVectorizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Imputer.html">
   ai.onnx.ml - Imputer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
   ai.onnx.ml - LabelEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
   ai.onnx.ml - LinearClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
   ai.onnx.ml - LinearRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
   ai.onnx.ml - Normalizer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
   ai.onnx.ml - OneHotEncoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
   ai.onnx.ml - SVMClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
   ai.onnx.ml - SVMRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_Scaler.html">
   ai.onnx.ml - Scaler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
   ai.onnx.ml - TreeEnsembleClassifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
   ai.onnx.ml - TreeEnsembleRegressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
   ai.onnx.ml - ZipMap
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
   ai.onnx.preview.training - Adagrad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
   ai.onnx.preview.training - Adam
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
   ai.onnx.preview.training - Gradient
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
   ai.onnx.preview.training - Momentum
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="table_main.html">
   operator table for domain main
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_ml.html">
   operator table for domain ai.onnx.ml
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table_ai_onnx_preview_training.html">
   operator table for domain ai.onnx.preview.training
  </a>
 </li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="logsoftmax">
<span id="l-onnx-doc-logsoftmax"></span><h1>LogSoftmax<a class="headerlink" href="#logsoftmax" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#logsoftmax-13" id="id3">LogSoftmax - 13</a></p></li>
<li><p><a class="reference internal" href="#logsoftmax-11" id="id4">LogSoftmax - 11</a></p></li>
<li><p><a class="reference internal" href="#logsoftmax-1" id="id5">LogSoftmax - 1</a></p></li>
</ul>
</nav>
<section id="logsoftmax-13">
<span id="l-onnx-op-logsoftmax-13"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">LogSoftmax - 13</a><a class="headerlink" href="#logsoftmax-13" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#LogSoftmax">LogSoftmax (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>13</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 13</strong>.</p>
<p><strong>Summary</strong></p>
<p>The operator computes the log of softmax values for the given input:</p>
<blockquote>
<div><p>LogSoftmax(input, axis) = Log(Softmax(input, axis=axis))</p>
</div></blockquote>
<p>The “axis” attribute indicates the dimension along which LogSoftmax
will be performed. The output tensor has the same shape
and contains the LogSoftmax values of the corresponding input.</p>
<p><strong>Attributes</strong></p>
<ul>
<li><dl class="simple">
<dt><strong>axis</strong>:</dt><dd><p>Describes the dimension LogSoftmax will be performed on. Negative</p>
</dd>
</dl>
<p>value means counting dimensions from the back. Accepted range is
[-r, r-1] where r = rank(input).</p>
</li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
The input tensor of rank &gt;= axis.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
The output values with the same shape as the input tensor.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>default</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;LogSoftmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># expected output</span>
<span class="c1"># [[-2.4076061 -1.407606  -0.407606 ]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">logsoftmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_logsoftmax_example_1&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>_logsoftmax_axis</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10001</span><span class="p">,</span> <span class="mi">10002</span><span class="p">,</span> <span class="mi">10003</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># expected output</span>
<span class="c1"># [[-3.4401896  -2.4401896  -1.4401896  -0.44018966]</span>
<span class="c1"># [-3.4401896  -2.4401896  -1.4401896  -0.44018966]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">logsoftmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;LogSoftmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_logsoftmax_large_number&quot;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;LogSoftmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">logsoftmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_logsoftmax_axis_0&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;LogSoftmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">logsoftmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_logsoftmax_axis_1&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;LogSoftmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">logsoftmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_logsoftmax_axis_2&quot;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;LogSoftmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">logsoftmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_logsoftmax_negative_axis&quot;</span><span class="p">)</span>

<span class="c1"># default axis is -1</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s2">&quot;LogSoftmax&quot;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;test_logsoftmax_default_axis&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to106__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to106__1"><a href="#difflib_chg_to106__1">n</a></td><td class="diff_header" id="from106_1">1</td><td nowrap="nowrap"><span class="diff_sub">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;logsoftmax&nbsp;(log&nbsp;of&nbsp;softmax)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</span></td><td class="diff_next"><a href="#difflib_chg_to106__1">n</a></td><td class="diff_header" id="to106_1">1</td><td nowrap="nowrap"><span class="diff_add">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;log&nbsp;of&nbsp;softmax&nbsp;values&nbsp;for&nbsp;the&nbsp;given&nbsp;input:</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_3">3</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_2">2</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to106__2">n</a></td><td class="diff_header" id="from106_4">4</td><td nowrap="nowrap"><span class="diff_sub">The&nbsp;input&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</span></td><td class="diff_next"><a href="#difflib_chg_to106__2">n</a></td><td class="diff_header" id="to106_3">3</td><td nowrap="nowrap"><span class="diff_add">&nbsp;LogSoftmax(input,&nbsp;axis)&nbsp;=&nbsp;Log(Softmax(input,&nbsp;axis=axis))</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_5">5</td><td nowrap="nowrap"><span class="diff_sub">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header" id="to106_4">4</td><td nowrap="nowrap"><span class="diff_add">&nbsp;</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_6">6</td><td nowrap="nowrap"><span class="diff_sub">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</span></td><td class="diff_next"></td><td class="diff_header" id="to106_5">5</td><td nowrap="nowrap"><span class="diff_add">The&nbsp;"axis"&nbsp;attribute&nbsp;indicates&nbsp;the&nbsp;dimension&nbsp;along&nbsp;which&nbsp;LogSoftmax</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_7">7</td><td nowrap="nowrap"><span class="diff_sub">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_8">8</td><td nowrap="nowrap"><span class="diff_sub">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_9">9</td><td nowrap="nowrap"><span class="diff_sub">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_10">10</td><td nowrap="nowrap"><span class="diff_sub">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_11">11</td><td nowrap="nowrap"><span class="diff_sub">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_12">12</td><td nowrap="nowrap"><span class="diff_sub">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_13">13</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">throw&nbsp;</span>er<span class="diff_chg">r</span>or<span class="diff_chg">s</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td><td class="diff_next"></td><td class="diff_header" id="to106_6">6</td><td nowrap="nowrap">will&nbsp;<span class="diff_chg">be&nbsp;p</span>er<span class="diff_chg">f</span>or<span class="diff_chg">med</span>.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to106__2"></td><td class="diff_header" id="from106_14">14</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">l</span>og<span class="diff_chg">s</span>oftmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td><td class="diff_next"></td><td class="diff_header" id="to106_7">7</td><td nowrap="nowrap">and&nbsp;contains&nbsp;the&nbsp;<span class="diff_chg">L</span>og<span class="diff_chg">S</span>oftmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_15">15</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_8">8</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_16">16</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to106_9">9</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_17">17</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_10">10</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_18">18</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to106_11">11</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to106__3">n</a></td><td class="diff_header" id="from106_19">19</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</span></td><td class="diff_next"><a href="#difflib_chg_to106__3">n</a></td><td class="diff_header" id="to106_12">12</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;&nbsp;Describes&nbsp;the&nbsp;dimension&nbsp;LogSoftmax&nbsp;will&nbsp;be&nbsp;performed&nbsp;on.&nbsp;Negative</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_20">20</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size.&nbsp;Negative</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to106_13">13</td><td nowrap="nowrap">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to106__3"></td><td class="diff_header" id="from106_22">22</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td><td class="diff_next"></td><td class="diff_header" id="to106_14">14</td><td nowrap="nowrap">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_23">23</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_15">15</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_24">24</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to106_16">16</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_25">25</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_17">17</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_26">26</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to106_18">18</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to106__4">n</a></td><td class="diff_header" id="from106_27">27</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</span></td><td class="diff_next"><a href="#difflib_chg_to106__4">n</a></td><td class="diff_header" id="to106_19">19</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;of&nbsp;rank&nbsp;&gt;=&nbsp;axis.</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to106__4"></td><td class="diff_header" id="from106_28">28</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;described&nbsp;above.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_29">29</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_20">20</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_30">30</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to106_21">21</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_31">31</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_22">22</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_32">32</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to106_23">23</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to106__5">n</a></td><td class="diff_header" id="from106_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor<span class="diff_chg">&nbsp;(the&nbsp;original</span></td><td class="diff_next"><a href="#difflib_chg_to106__5">n</a></td><td class="diff_header" id="to106_24">24</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as<span class="diff_add">&nbsp;the</span>&nbsp;input&nbsp;tensor<span class="diff_chg">.</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to106__5"></td><td class="diff_header" id="from106_34">34</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_35">35</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_25">25</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_36">36</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to106_26">26</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_37">37</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to106_27">27</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_38">38</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to106_28">28</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to106__top">t</a></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"><a href="#difflib_chg_to106__top">t</a></td><td class="diff_header" id="to106_29">29</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;tensor(bfloat16),</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to106_30">30</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to106_31">31</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to106_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to106_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from106_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to106_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="logsoftmax-11">
<span id="l-onnx-op-logsoftmax-11"></span><h2><a class="toc-backref" href="#id4" role="doc-backlink">LogSoftmax - 11</a><a class="headerlink" href="#logsoftmax-11" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#LogSoftmax">LogSoftmax (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>11</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 11</strong>.</p>
<p><strong>Summary</strong></p>
<dl class="simple">
<dt>The operator computes the logsoftmax (log of softmax) values for each layer in the batch</dt><dd><p>of the given input.</p>
</dd>
</dl>
<p>The input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input in [a_0, a_1, …, a_{k-1}, a_k, …, a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * … * a_{k-1}, a_k * … * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * … * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * … * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors. The output tensor has the same shape
and contains the logsoftmax values of the corresponding input.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>axis</strong>:
Describes the axis of the inputs when coerced to 2D; defaults to one
because the 0th axis most likely describes the batch_size. Negative
value means counting dimensions from the back. Accepted range is
[-r, r-1] where r = rank(input).</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
The input tensor that’s coerced into a 2D matrix of size (NxD) as
described above.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
The output values with the same shape as input tensor (the original
size without coercion).</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
<p><strong>Differences</strong></p>
<table class="diff" id="difflib_chg_to107__top"
       cellspacing="0" cellpadding="0" rules="groups" >
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
    <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>

    <tbody>
        <tr><td class="diff_next" id="difflib_chg_to107__1"><a href="#difflib_chg_to107__0">f</a></td><td class="diff_header" id="from107_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;logsoftmax&nbsp;(log&nbsp;of&nbsp;softmax)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td><td class="diff_next"><a href="#difflib_chg_to107__0">f</a></td><td class="diff_header" id="to107_1">1</td><td nowrap="nowrap">The&nbsp;operator&nbsp;computes&nbsp;the&nbsp;logsoftmax&nbsp;(log&nbsp;of&nbsp;softmax)&nbsp;values&nbsp;for&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;batch</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to107__1">n</a></td><td class="diff_header" id="from107_2">2</td><td nowrap="nowrap"><span class="diff_sub">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.&nbsp;The&nbsp;input&nbsp;is&nbsp;a&nbsp;2-D&nbsp;tensor&nbsp;(Tensor&lt;float&gt;)&nbsp;of&nbsp;size</span></td><td class="diff_next"><a href="#difflib_chg_to107__1">n</a></td><td class="diff_header" id="to107_2">2</td><td nowrap="nowrap"><span class="diff_add">&nbsp;of&nbsp;the&nbsp;given&nbsp;input.</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_3">3</td><td nowrap="nowrap"><span class="diff_sub">(batch_size&nbsp;x&nbsp;input_feature_dimensions).&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_4">4</td><td nowrap="nowrap"><span class="diff_sub">and&nbsp;contains&nbsp;the&nbsp;logsoftmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_5">5</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_3">3</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to107__2">n</a></td><td class="diff_header" id="from107_6">6</td><td nowrap="nowrap"><span class="diff_chg">I</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td><td class="diff_next"><a href="#difflib_chg_to107__2">n</a></td><td class="diff_header" id="to107_4">4</td><td nowrap="nowrap"><span class="diff_chg">The&nbsp;i</span>nput&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;explicitly&nbsp;be&nbsp;a&nbsp;2D&nbsp;vector;&nbsp;rather,&nbsp;it&nbsp;will&nbsp;be</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_7">7</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to107_5">5</td><td nowrap="nowrap">coerced&nbsp;into&nbsp;one.&nbsp;For&nbsp;an&nbsp;arbitrary&nbsp;n-dimensional&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_8">8</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td><td class="diff_next"></td><td class="diff_header" id="to107_6">6</td><td nowrap="nowrap">input&nbsp;\in&nbsp;[a_0,&nbsp;a_1,&nbsp;...,&nbsp;a_{k-1},&nbsp;a_k,&nbsp;...,&nbsp;a_{n-1}]&nbsp;and&nbsp;k&nbsp;is</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_9">9</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td><td class="diff_next"></td><td class="diff_header" id="to107_7">7</td><td nowrap="nowrap">the&nbsp;axis&nbsp;provided,&nbsp;then&nbsp;input&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2-dimensional&nbsp;tensor&nbsp;with</td></tr>
        <tr><td class="diff_next" id="difflib_chg_to107__2"></td><td class="diff_header" id="from107_10">10</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td><td class="diff_next"></td><td class="diff_header" id="to107_8">8</td><td nowrap="nowrap">dimensions&nbsp;[a_0&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{k-1},&nbsp;a_k&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}].&nbsp;For&nbsp;the&nbsp;default</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_11">11</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td><td class="diff_next"></td><td class="diff_header" id="to107_9">9</td><td nowrap="nowrap">case&nbsp;where&nbsp;axis=1,&nbsp;this&nbsp;means&nbsp;the&nbsp;input&nbsp;tensor&nbsp;will&nbsp;be&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;tensor</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_12">12</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td><td class="diff_next"></td><td class="diff_header" id="to107_10">10</td><td nowrap="nowrap">of&nbsp;dimensions&nbsp;[a_0,&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}],&nbsp;where&nbsp;a_0&nbsp;is&nbsp;often&nbsp;the&nbsp;batch&nbsp;size.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_13">13</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td><td class="diff_next"></td><td class="diff_header" id="to107_11">11</td><td nowrap="nowrap">In&nbsp;this&nbsp;situation,&nbsp;we&nbsp;must&nbsp;have&nbsp;a_0&nbsp;=&nbsp;N&nbsp;and&nbsp;a_1&nbsp;*&nbsp;...&nbsp;*&nbsp;a_{n-1}&nbsp;=&nbsp;D.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_14">14</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td><td class="diff_next"></td><td class="diff_header" id="to107_12">12</td><td nowrap="nowrap">Each&nbsp;of&nbsp;these&nbsp;dimensions&nbsp;must&nbsp;be&nbsp;matched&nbsp;correctly,&nbsp;or&nbsp;else&nbsp;the&nbsp;operator</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to107__3">n</a></td><td class="diff_header" id="from107_15">15</td><td nowrap="nowrap"><span class="diff_sub">will&nbsp;throw&nbsp;errors.</span></td><td class="diff_next"><a href="#difflib_chg_to107__3">n</a></td><td class="diff_header" id="to107_13">13</td><td nowrap="nowrap"><span class="diff_add">will&nbsp;throw&nbsp;errors.&nbsp;The&nbsp;output&nbsp;tensor&nbsp;has&nbsp;the&nbsp;same&nbsp;shape</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_14">14</td><td nowrap="nowrap"><span class="diff_add">and&nbsp;contains&nbsp;the&nbsp;logsoftmax&nbsp;values&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;input.</span></td></tr>
        <tr><td class="diff_next" id="difflib_chg_to107__3"></td><td class="diff_header" id="from107_16">16</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_15">15</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_17">17</td><td nowrap="nowrap">**Attributes**</td><td class="diff_next"></td><td class="diff_header" id="to107_16">16</td><td nowrap="nowrap">**Attributes**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_18">18</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_17">17</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_19">19</td><td nowrap="nowrap">*&nbsp;**axis**:</td><td class="diff_next"></td><td class="diff_header" id="to107_18">18</td><td nowrap="nowrap">*&nbsp;**axis**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td><td class="diff_next"></td><td class="diff_header" id="to107_19">19</td><td nowrap="nowrap">&nbsp;&nbsp;Describes&nbsp;the&nbsp;axis&nbsp;of&nbsp;the&nbsp;inputs&nbsp;when&nbsp;coerced&nbsp;to&nbsp;2D;&nbsp;defaults&nbsp;to&nbsp;one</td></tr>
        <tr><td class="diff_next"><a href="#difflib_chg_to107__top">t</a></td><td class="diff_header" id="from107_21">21</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size</td><td class="diff_next"><a href="#difflib_chg_to107__top">t</a></td><td class="diff_header" id="to107_20">20</td><td nowrap="nowrap">&nbsp;&nbsp;because&nbsp;the&nbsp;0th&nbsp;axis&nbsp;most&nbsp;likely&nbsp;describes&nbsp;the&nbsp;batch_size<span class="diff_add">.&nbsp;Negative</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_21">21</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;value&nbsp;means&nbsp;counting&nbsp;dimensions&nbsp;from&nbsp;the&nbsp;back.&nbsp;Accepted&nbsp;range&nbsp;is</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header"></td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_22">22</td><td nowrap="nowrap"><span class="diff_add">&nbsp;&nbsp;[-r,&nbsp;r-1]&nbsp;where&nbsp;r&nbsp;=&nbsp;rank(input).</span></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_22">22</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_23">23</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_23">23</td><td nowrap="nowrap">**Inputs**</td><td class="diff_next"></td><td class="diff_header" id="to107_24">24</td><td nowrap="nowrap">**Inputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_24">24</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_25">25</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_25">25</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to107_26">26</td><td nowrap="nowrap">*&nbsp;**input**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_26">26</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td><td class="diff_next"></td><td class="diff_header" id="to107_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;input&nbsp;tensor&nbsp;that's&nbsp;coerced&nbsp;into&nbsp;a&nbsp;2D&nbsp;matrix&nbsp;of&nbsp;size&nbsp;(NxD)&nbsp;as</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_27">27</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td><td class="diff_next"></td><td class="diff_header" id="to107_28">28</td><td nowrap="nowrap">&nbsp;&nbsp;described&nbsp;above.</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_28">28</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_29">29</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_29">29</td><td nowrap="nowrap">**Outputs**</td><td class="diff_next"></td><td class="diff_header" id="to107_30">30</td><td nowrap="nowrap">**Outputs**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_30">30</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_31">31</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_31">31</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td><td class="diff_next"></td><td class="diff_header" id="to107_32">32</td><td nowrap="nowrap">*&nbsp;**output**&nbsp;(heterogeneous)&nbsp;-&nbsp;**T**:</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_32">32</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td><td class="diff_next"></td><td class="diff_header" id="to107_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;The&nbsp;output&nbsp;values&nbsp;with&nbsp;the&nbsp;same&nbsp;shape&nbsp;as&nbsp;input&nbsp;tensor&nbsp;(the&nbsp;original</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_33">33</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td><td class="diff_next"></td><td class="diff_header" id="to107_34">34</td><td nowrap="nowrap">&nbsp;&nbsp;size&nbsp;without&nbsp;coercion).</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_34">34</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_35">35</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_35">35</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td><td class="diff_next"></td><td class="diff_header" id="to107_36">36</td><td nowrap="nowrap">**Type&nbsp;Constraints**</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_36">36</td><td nowrap="nowrap"></td><td class="diff_next"></td><td class="diff_header" id="to107_37">37</td><td nowrap="nowrap"></td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_37">37</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td><td class="diff_next"></td><td class="diff_header" id="to107_38">38</td><td nowrap="nowrap">*&nbsp;**T**&nbsp;in&nbsp;(</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_38">38</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td><td class="diff_next"></td><td class="diff_header" id="to107_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(double),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_39">39</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td><td class="diff_next"></td><td class="diff_header" id="to107_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float),</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_40">40</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td><td class="diff_next"></td><td class="diff_header" id="to107_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;tensor(float16)</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_41">41</td><td nowrap="nowrap">&nbsp;&nbsp;):</td><td class="diff_next"></td><td class="diff_header" id="to107_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;):</td></tr>
        <tr><td class="diff_next"></td><td class="diff_header" id="from107_42">42</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td><td class="diff_next"></td><td class="diff_header" id="to107_43">43</td><td nowrap="nowrap">&nbsp;&nbsp;Constrain&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;float&nbsp;tensors.</td></tr>
    </tbody>
</table></section>
<section id="logsoftmax-1">
<span id="l-onnx-op-logsoftmax-1"></span><h2><a class="toc-backref" href="#id5" role="doc-backlink">LogSoftmax - 1</a><a class="headerlink" href="#logsoftmax-1" title="Permalink to this heading">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#LogSoftmax">LogSoftmax (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>1</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<dl class="simple">
<dt>The operator computes the logsoftmax (log of softmax) values for each layer in the batch</dt><dd><p>of the given input. The input is a 2-D tensor (Tensor&lt;float&gt;) of size</p>
</dd>
</dl>
<p>(batch_size x input_feature_dimensions). The output tensor has the same shape
and contains the logsoftmax values of the corresponding input.</p>
<p>Input does not need to explicitly be a 2D vector; rather, it will be
coerced into one. For an arbitrary n-dimensional tensor
input in [a_0, a_1, …, a_{k-1}, a_k, …, a_{n-1}] and k is
the axis provided, then input will be coerced into a 2-dimensional tensor with
dimensions [a_0 * … * a_{k-1}, a_k * … * a_{n-1}]. For the default
case where axis=1, this means the input tensor will be coerced into a 2D tensor
of dimensions [a_0, a_1 * … * a_{n-1}], where a_0 is often the batch size.
In this situation, we must have a_0 = N and a_1 * … * a_{n-1} = D.
Each of these dimensions must be matched correctly, or else the operator
will throw errors.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>axis</strong>:
Describes the axis of the inputs when coerced to 2D; defaults to one
because the 0th axis most likely describes the batch_size</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
The input tensor that’s coerced into a 2D matrix of size (NxD) as
described above.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>output</strong> (heterogeneous) - <strong>T</strong>:
The output values with the same shape as input tensor (the original
size without coercion).</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="onnx__Log.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Log</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="onnx__Loop.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Loop</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fas fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logsoftmax-13">
   LogSoftmax - 13
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logsoftmax-11">
   LogSoftmax - 11
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logsoftmax-1">
   LogSoftmax - 1
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="../_sources/onnx_doc_folder/onnx__LogSoftmax.rst.txt">
        <i class="fas fa-file-alt"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=9b1a4fa89bdd0e95b23b"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>