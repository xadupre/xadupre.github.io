
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ONNX Concepts &#8212; Introduction to ONNX 0.1 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="ONNX with Python" href="python.html" />
    <link rel="prev" title="Introduction to ONNX" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../index.html">
<p class="title">Introduction to ONNX</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/index.html">
  API
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Introduction to ONNX
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     ONNX Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python.html">
     ONNX with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="challenges.html">
     Challenges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnxops.html">
     ONNX operators and function
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_onnxruntime/index.html">
   Introduction to onnxruntime
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#input-output-node-initializer-attributes">
   Input, Output, Node, Initializer, Attributes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#serialization-with-protobuf">
   Serialization with protobuf
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metadata">
   Metadata
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#list-of-available-operators-and-domains">
   List of available operators and domains
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supported-types">
   Supported Types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#element-type">
     Element Type
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-tensor">
     Sparse Tensor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-types">
     Other types
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-an-opset-version">
   What is an opset version?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#subgraphs-tests-and-loops">
   Subgraphs, tests and loops
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#if">
     If
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scan">
     Scan
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loop">
     Loop
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extensibility">
   Extensibility
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shape-and-type-inference">
   Shape (and Type) Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tools">
   Tools
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="onnx-concepts">
<h1>ONNX Concepts<a class="headerlink" href="#onnx-concepts" title="Permalink to this headline">Â¶</a></h1>
<p>ONNX can be compared to a programming language specialized
in mathematical functions. It defines all the necessary operations
a machine learning model needs to implement its inference function
with this langage. A linear regression could be represented
the following way:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">onnx_linear_regressor</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="s2">&quot;ONNX code for a linear regression&quot;</span>
    <span class="k">return</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">onnx</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">),</span> <span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
<p id="index-0">This example is very similar to an expression a developper could
write in Python. It can be also represented as a graph which shows
step by step how to transform the features to get a prediction.
Thatâs why a machine learning model implemented with ONNX is often
referenced as an <strong>ONNX graph</strong>.</p>
<img alt="../../_images/linreg1.png" src="../../_images/linreg1.png" />
<p>ONNX aims at providing a common language any machine learning framework
can use to describe its models. The first scenario is to make it easier
to deploy a machine learning model in production. An ONNX interpretor
(or <strong>runtime</strong>) can be specifically implemented and optimized for this task
in the environment where it is deployed. With ONNX, it is possible
to build a unique process to deploy a model in production and independant
from the learning framework used to build the model.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#input-output-node-initializer-attributes" id="id1">Input, Output, Node, Initializer, Attributes</a></p></li>
<li><p><a class="reference internal" href="#serialization-with-protobuf" id="id2">Serialization with protobuf</a></p></li>
<li><p><a class="reference internal" href="#metadata" id="id3">Metadata</a></p></li>
<li><p><a class="reference internal" href="#list-of-available-operators-and-domains" id="id4">List of available operators and domains</a></p></li>
<li><p><a class="reference internal" href="#supported-types" id="id5">Supported Types</a></p>
<ul>
<li><p><a class="reference internal" href="#element-type" id="id6">Element Type</a></p></li>
<li><p><a class="reference internal" href="#sparse-tensor" id="id7">Sparse Tensor</a></p></li>
<li><p><a class="reference internal" href="#other-types" id="id8">Other types</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#what-is-an-opset-version" id="id9">What is an opset version?</a></p></li>
<li><p><a class="reference internal" href="#subgraphs-tests-and-loops" id="id10">Subgraphs, tests and loops</a></p>
<ul>
<li><p><a class="reference internal" href="#if" id="id11">If</a></p></li>
<li><p><a class="reference internal" href="#scan" id="id12">Scan</a></p></li>
<li><p><a class="reference internal" href="#loop" id="id13">Loop</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#extensibility" id="id14">Extensibility</a></p></li>
<li><p><a class="reference internal" href="#shape-and-type-inference" id="id15">Shape (and Type) Inference</a></p></li>
<li><p><a class="reference internal" href="#tools" id="id16">Tools</a></p></li>
</ul>
</div>
<div class="section" id="input-output-node-initializer-attributes">
<h2><a class="toc-backref" href="#id1">Input, Output, Node, Initializer, Attributes</a><a class="headerlink" href="#input-output-node-initializer-attributes" title="Permalink to this headline">Â¶</a></h2>
<p>Building an ONNX graph means implementing a function
with the ONNX language or more precisely the <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">ONNX operators</a>.
A linear regression would be written this way.
The following lines do not follow python syntax.
It is just a kind of pseudo code to illustrate the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">axc</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

<span class="n">onnx</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">axc</span>
</pre></div>
</div>
<p>This code implements a function with the signature <cite>f(x, a, c) -&gt; axc</cite>.
And <em>x</em>, <em>a</em>, <em>c</em> are the <strong>inputs</strong>, <em>axc</em> is the <strong>output</strong>.
<em>ax</em> is an intermediate result.
Inputs and outputs are changing at each inference.
<em>MatMul</em> and <em>Add</em> are the <strong>nodes</strong>. They also have inputs and outputs.
A node has also a type, one of the operators in
<a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">ONNX operators</a>. This graph was built with the example
in Section <a class="reference internal" href="python.html#l-onnx-linear-regression-onnx-api"><span class="std std-ref">A simple example: a linear regression</span></a>.</p>
<p>The graph could also have an <strong>initializer</strong>. When an input
never changes such as the coefficients of the linear regression,
it is most efficient to turn it into a constant stored in the graph.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">initializer</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">initializer</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">axc</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

<span class="n">onnx</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">axc</span>
</pre></div>
</div>
<p>Visually, this graph would look like the following image.
The right side describes operator <em>Add</em> where the second input
is defined as an initializer. This graph was obtained with this
code <a class="reference internal" href="python.html#l-onnx-linear-regression-onnx-api-init"><span class="std std-ref">Initializer, default value</span></a>.</p>
<img alt="../../_images/linreg2.png" src="../../_images/linreg2.png" />
<p>An <strong>attribute</strong> is a fixed parameter of an operator. Operator <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gemm">Gemm</a>
has four attributes, <em>alpha</em>, <em>beta</em>, <em>transA</em>, <em>transB</em>. Unless the runtime
allows it through its API, once it has loaded the ONNX graph, these values
cannot be changed and remain frozen for all the predictions.</p>
</div>
<div class="section" id="serialization-with-protobuf">
<h2><a class="toc-backref" href="#id2">Serialization with protobuf</a><a class="headerlink" href="#serialization-with-protobuf" title="Permalink to this headline">Â¶</a></h2>
<p>The deployment of a machine learned model into production
usually requires to replicate the entire ecosystem used to
train the model, most of the time with a <a class="reference external" href="https://en.wikipedia.org/wiki/Docker_(software)">docker</a>.
Once a model is converted into ONNX, the production environment
only needs a runtime to execute the graph defined with ONNX
operators. This runtime can be developped in any language
suitable for the production application, C, java, python, javascript,
C#, Webassembly, ARMâ¦</p>
<p>But to make that happen, the ONNX graph needs to be saved.
ONNX uses <a class="reference external" href="https://developers.google.com/protocol-buffers">protobuf</a> to serialize the graph into
one single block
(see <a class="reference external" href="https://developers.google.com/protocol-buffers/docs/pythontutorial#parsing-and-serialization">Parsing and Serialization</a>). It aims at optimizing the model size
as much as possible.</p>
</div>
<div class="section" id="metadata">
<h2><a class="toc-backref" href="#id3">Metadata</a><a class="headerlink" href="#metadata" title="Permalink to this headline">Â¶</a></h2>
<p>Machine learned models are continuously refreshed. It is important
to keep track of the model version, the author of the model,
how it was trained. ONNX offers the possibility to store additional data
into the model itself.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>doc_string</strong>: Human-readable documentation for this model.</dt><dd><p>Markdown is allowed.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>domain</strong>: A reverse-DNS name to indicate the model namespace or domain,</dt><dd><p>for example, âorg.onnxâ</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>metadata_props</strong>: Named metadata as dictionary <cite>map&lt;string,string&gt;</cite>,</dt><dd><p><cite>(values, keys)</cite> should be distinct.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>model_author</strong>: A comma-separated list of names,</dt><dd><p>The personal name of the author(s) of the model, and/or their organizations.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>model_license</strong>: The well-known name or URL of the license</dt><dd><p>under which the model is made available.</p>
</dd>
</dl>
</li>
<li><p><strong>model_version</strong>: The version of the model itself, encoded in an integer.</p></li>
<li><p><strong>producer_name</strong>: The name of the tool used to generate the model.</p></li>
<li><p><strong>producer_version</strong>: The version of the generating tool.</p></li>
<li><dl class="simple">
<dt><strong>training_info</strong>: An optional extension that contains</dt><dd><p>information for training (see <a class="reference internal" href="../../api/onnx_python/classes.html#l-traininginfoproto"><span class="std std-ref">TrainingInfoProto</span></a>)</p>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="list-of-available-operators-and-domains">
<h2><a class="toc-backref" href="#id4">List of available operators and domains</a><a class="headerlink" href="#list-of-available-operators-and-domains" title="Permalink to this headline">Â¶</a></h2>
<p>The main list is described here: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">ONNX operators</a>.
It merges standard matrix operators (Add, Sub, MatMul, Transpose,
Greater, IsNaN, Shape, Reshapeâ¦),
reductions (ReduceSum, ReduceMin, â¦)
image transformations (Conv, MaxPool, â¦),
deep neural networks layer (RNN, DropOut, â¦),
activations functions (Relu, Softmax, â¦).
It covers most of the operations needed to implement
inference functions from standard and deep machine learning.
ONNX does not implement every existing machine learning operator,
the list of operator would be infinite.</p>
<p>The main list of operators is identified with a domain <strong>ai.onnx</strong>.
A <strong>domain</strong> can be defined as a set of operators.
A few operators in this list are dedicated to text but they hardly cover
the needs. The main list is also missing tree based models very
popular in standard machine learning.
These are part of another domain <strong>ai.onnx.ml</strong> <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md">ONNX ML operators</a>,
it includes tree bases models (TreeEnsmble Regressor, â¦),
preprocessing (OneHotEncoder, LabelEncoder, â¦), SVM models
(SVMRegressor, â¦), imputer (Imputer).</p>
<p>ONNX only defines these two domains. But the library <a class="reference external" href="https://github.com/onnx/onnx">onnx</a>
supports any custom domains and operators
(see <a class="reference internal" href="#l-onnx-extensibility"><span class="std std-ref">Extensibility</span></a>).</p>
</div>
<div class="section" id="supported-types">
<h2><a class="toc-backref" href="#id5">Supported Types</a><a class="headerlink" href="#supported-types" title="Permalink to this headline">Â¶</a></h2>
<p>ONNX specifications is optimized for numerical competition with
tensors. A <a class="reference external" href="https://en.wikipedia.org/wiki/Tensor">tensor</a> is a multidimensional array. It is defined
by:</p>
<ul class="simple">
<li><p>a type: the element type, the same for all elements in the tensor</p></li>
<li><p>a shape: an array with all dimensions, this array can be empty,
a dimension can be null</p></li>
<li><p>a contiguous array: it represents all the values</p></li>
</ul>
<p>This definition do not include <em>strides</em> or the possibility to define
a view of a tensor based on an existing tensor. An ONNX tensor is a dense
full array with no strides.</p>
<div class="section" id="element-type">
<h3><a class="toc-backref" href="#id6">Element Type</a><a class="headerlink" href="#element-type" title="Permalink to this headline">Â¶</a></h3>
<p>ONNX was initially developped to help deploying deep learning model.
Thatâs why the specifications was initially designed for floats (32 bits).
The current version supports all common types. Dictionary
<a class="reference internal" href="../../api/onnx_python/spec.html#l-onnx-types-mapping"><span class="std std-ref">TENSOR_TYPE_TO_NP_TYPE</span></a> gives the correspondance between <a class="reference external" href="https://onnx.ai/">ONNX</a>
and <a class="reference external" href="https://numpy.org/">numpy</a>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;^[0-9A-Z_]+$&#39;</span><span class="p">)</span>

<span class="n">values</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">TensorProto</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">att</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;DESCRIPTOR&#39;</span><span class="p">}:</span>
        <span class="k">continue</span>
    <span class="k">if</span> <span class="n">reg</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">att</span><span class="p">):</span>
        <span class="n">values</span><span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">TensorProto</span><span class="p">,</span> <span class="n">att</span><span class="p">)]</span> <span class="o">=</span> <span class="n">att</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">att</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">si</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">si</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">si</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">si</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: onnx.TensorProto.</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">si</span><span class="p">,</span> <span class="n">att</span><span class="p">))</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="mi">0</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UNDEFINED</span>
     <span class="mi">1</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span>
     <span class="mi">2</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span>
     <span class="mi">3</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT8</span>
     <span class="mi">4</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT16</span>
     <span class="mi">5</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT16</span>
     <span class="mi">6</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT32</span>
     <span class="mi">7</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span>
     <span class="mi">8</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">STRING</span>
     <span class="mi">9</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span>
    <span class="mi">10</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT16</span>
    <span class="mi">11</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span>
    <span class="mi">12</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT32</span>
    <span class="mi">13</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT64</span>
    <span class="mi">14</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">COMPLEX64</span>
    <span class="mi">15</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">COMPLEX128</span>
    <span class="mi">16</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">BFLOAT16</span>
</pre></div>
</div>
<p>ONNX is strongly typed and its definition does not support
implicit cast. It is impossible to add two tensors or matrices
with different types even if other languages does. Thatâs why explicit
cast must be inserted in a graph.</p>
</div>
<div class="section" id="sparse-tensor">
<h3><a class="toc-backref" href="#id7">Sparse Tensor</a><a class="headerlink" href="#sparse-tensor" title="Permalink to this headline">Â¶</a></h3>
<p>Sparse tensors are useful to represent arrays having many null coefficients.
ONNX supports 2D sparse tensor. Class <a class="reference internal" href="../../api/onnx_python/classes.html#l-onnx-sparsetensor-proto"><span class="std std-ref">SparseTensorProto</span></a>
defines attributes <cite>dims</cite>, <cite>indices</cite> (int64) and <cite>values</cite>.</p>
</div>
<div class="section" id="other-types">
<h3><a class="toc-backref" href="#id8">Other types</a><a class="headerlink" href="#other-types" title="Permalink to this headline">Â¶</a></h3>
<p>In addition to tensors and sparse tensors, ONNX supports sequences of tensors,
map of tensors, sequences of map of tensors through types
<a class="reference internal" href="../../api/onnx_python/classes.html#l-onnx-sequence-proto"><span class="std std-ref">SequenceProto</span></a>, <a class="reference internal" href="../../api/onnx_python/classes.html#l-onnx-map-proto"><span class="std std-ref">MapProto</span></a>. They are rarely used.</p>
</div>
</div>
<div class="section" id="what-is-an-opset-version">
<h2><a class="toc-backref" href="#id9">What is an opset version?</a><a class="headerlink" href="#what-is-an-opset-version" title="Permalink to this headline">Â¶</a></h2>
<p>The opset is mapped to the version of the <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> package.
It is incremented every time the minor version increases.
Every version brings updated or new operators.
Pages <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Changelog.md">ChangeLogs</a> keeps tracks of these changes.
The current version is the following.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="s2">&quot; opset=&quot;</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">defs</span><span class="o">.</span><span class="n">onnx_opset_version</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="mf">1.11.0</span><span class="n">rc2</span>  <span class="n">opset</span><span class="o">=</span> <span class="mi">16</span>
</pre></div>
</div>
<p>An opset is also attached to every ONNX graphs. It is a global
information. It defines the version of all operators inside the graph.
Operator <em>Add</em> was updated in version 6, 7, 13 and 14. If the
graph opset is 15, it means operator <em>Add</em> follows specifications
version 14. If the graph opset is 12, then operator <em>Add</em> follows
specifications version 7. An operator in a graph follows its most
recent definition below (or equal) the global graph opset.</p>
<p>A graph may include operators from several domains, <cite>ai.onnx</cite> and
<cite>ai.onnx.ml</cite> for example. In that case, the graph must defines a
global opset for every domain. The rule is applied to every
operators within the same domain.</p>
</div>
<div class="section" id="subgraphs-tests-and-loops">
<h2><a class="toc-backref" href="#id10">Subgraphs, tests and loops</a><a class="headerlink" href="#subgraphs-tests-and-loops" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference external" href="https://onnx.ai/">ONNX</a> implements tests and loops. They all take another ONNX
graphs as an attribute. These structures are usually slow and complex.
It is better to avoid them if possible.</p>
<div class="section" id="if">
<h3><a class="toc-backref" href="#id11">If</a><a class="headerlink" href="#if" title="Permalink to this headline">Â¶</a></h3>
<p>Operator <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#If">If</a> executes
one of the two graphs depending one the condition evaluation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>If(condition) then
    exeute this ONNX graph (`then_branch`)
else
    exeute this ONNX graph (`else_branch`)
</pre></div>
</div>
<p>Those two graphs can use any result already computed in the
graph and must produce the exact same number of outputs.
These outputs will be the output of the operator <cite>If</cite>.</p>

    <div id="gdot-2035936175296-cont"><div id="gdot-2035936175296" style="width:100%;height:100%;"></div>
    <script>

    require(['../../_static/viz.js'], function() { var svgGraph = Viz(" digraph{\n  orientation=portrait;\n  size=7;\n  nodesep=0.05;\n  ranksep=0.25;\n\n  x1 [shape=box color=red label=\"x1\\nfloat((0, 2))\" fontsize=10];\n  x2 [shape=box color=red label=\"x2\\nfloat((0, 2))\" fontsize=10];\n\n  y [shape=box color=green label=\"y\\nfloat(('?',))\" fontsize=10];\n\n\n  Re_reduced02 [shape=box label=\"Re_reduced02\" fontsize=10];\n  Re_ReduceSum1 [shape=box style=\"filled,rounded\" color=orange label=\"ReduceSum\\n(Re_ReduceSum1)\" fontsize=10];\n  x2 -> Re_ReduceSum1;\n  Re_ReduceSum1 -> Re_reduced02;\n\n  Re_reduced0 [shape=box label=\"Re_reduced0\" fontsize=10];\n  Re_ReduceSum [shape=box style=\"filled,rounded\" color=orange label=\"ReduceSum\\n(Re_ReduceSum)\" fontsize=10];\n  x1 -> Re_ReduceSum;\n  Re_ReduceSum -> Re_reduced0;\n\n  Gr_C0 [shape=box label=\"Gr_C0\" fontsize=10];\n  Gr_Greater [shape=box style=\"filled,rounded\" color=orange label=\"Greater\\n(Gr_Greater)\" fontsize=10];\n  Re_reduced0 -> Gr_Greater;\n  Re_reduced02 -> Gr_Greater;\n  Gr_Greater -> Gr_C0;\n\n  subgraph cluster_If2037718928256_2037153381744 {\n    label=\"If\\n(If_If)\\nelse_branch=node {\\n  input: 'x...\\nthen_branch=node {\\n  input: 'x...\";\n    fontsize=10;\n    color=black;\n    B_absxythen [shape=box color=green label=\"absxythen\\nfloat(('?',))\" fontsize=10];\n  \n  \n    B_Ad_Add [shape=box style=\"filled,rounded\" color=orange label=\"Add\\n(Ad_Add)\" fontsize=10];\n    B_x1 -> B_Ad_Add;\n    B_x2 -> B_Ad_Add;\n    B_Ad_Add -> B_absxythen;\n  }\n  B_absxythen -> y;\n  subgraph cluster_If2037718928256_2037153381680 {\n    label=\"If\\n(If_If)\\nelse_branch=node {\\n  input: 'x...\\nthen_branch=node {\\n  input: 'x...\";\n    fontsize=10;\n    color=black;\n    B_absxyelse [shape=box color=green label=\"absxyelse\\nfloat(('?',))\" fontsize=10];\n  \n  \n    B_Su_Sub [shape=box style=\"filled,rounded\" color=orange label=\"Sub\\n(Su_Sub)\" fontsize=10];\n    B_x1 -> B_Su_Sub;\n    B_x2 -> B_Su_Sub;\n    B_Su_Sub -> B_absxyelse;\n  }\n  B_absxyelse -> y;\n  If_If -> B_Ad_Add [lhead=cluster_If2037718928256_2037153381744];\n  If_If -> B_Su_Sub [lhead=cluster_If2037718928256_2037153381680];\n  Gr_C0 -> If_If;\n  If_If -> y;\n}\n");
    document.getElementById('gdot-2035936175296').innerHTML = svgGraph; });
    
</script>
</div></div>
<div class="section" id="scan">
<span id="l-operator-scan-onnx-tutorial"></span><h3><a class="toc-backref" href="#id12">Scan</a><a class="headerlink" href="#scan" title="Permalink to this headline">Â¶</a></h3>
<p>Operator <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Scan">Scan</a> implements a loop with a fixed number of iterations.
It loops over the rows (or any other dimension) of the inputs and concatenate
the outputs along the same axis. Letâs see an example which implements
pairwise distances: <img class="math" src="../../_images/math/b1a50d391161a33c6020ca20dacf8306750aa104.png" alt="M(i,j) = \norm{X_i - X_j}^2"/>.</p>

    <div id="gdot-2035936174912-cont"><div id="gdot-2035936174912" style="width:100%;height:100%;"></div>
    <script>

    require(['../../_static/viz.js'], function() { var svgGraph = Viz(" digraph{\n  orientation=portrait;\n  size=7;\n  nodesep=0.05;\n  ranksep=0.25;\n\n  x [shape=box color=red label=\"x\\nfloat(('?',))\" fontsize=10];\n\n  Y [shape=box color=green label=\"Y\\nfloat((0, 0))\" fontsize=10];\n\n\n  scan0_{idself} [shape=box label=\"scan0_{idself}\" fontsize=10];\n  scan1_{idself} [shape=box label=\"scan1_{idself}\" fontsize=10];\n  subgraph cluster_Scan2037718962336_2036854926640 {\n    label=\"Scan\\n(Sc_Scan)\\nbody=node {\\n  input: 'next_in'...\\nnum_scan_inputs=1\";\n    fontsize=10;\n    color=black;\n    B_next_in [shape=box color=red label=\"next_in\\nfloat(('?',))\" fontsize=10];\n    B_next [shape=box color=red label=\"next\\nfloat(('?',))\" fontsize=10];\n  \n    B_next_out [shape=box color=green label=\"next_out\\nfloat((0, 0))\" fontsize=10];\n    B_scan_out [shape=box color=green label=\"scan_out\\nfloat((0,))\" fontsize=10];\n  \n    B_Sq_Squeezecst [shape=box label=\"Sq_Squeezecst\\nint64((1,))\\n[1]\" fontsize=10];\n  \n    B_diff [shape=box label=\"diff\" fontsize=10];\n    B_Su_Sub [shape=box style=\"filled,rounded\" color=orange label=\"Sub\\n(Su_Sub)\" fontsize=10];\n    B_next_in -> B_Su_Sub;\n    B_next -> B_Su_Sub;\n    B_Su_Sub -> B_diff;\n  \n    B_Id_Identity [shape=box style=\"filled,rounded\" color=orange label=\"Identity\\n(Id_Identity)\" fontsize=10];\n    B_next_in -> B_Id_Identity;\n    B_Id_Identity -> B_next_out;\n  \n    B_norm [shape=box label=\"norm\" fontsize=10];\n    B_Re_ReduceSumSquare [shape=box style=\"filled,rounded\" color=orange label=\"ReduceSumSquare\\n(Re_ReduceSumSquare)\\naxes=[1]\" fontsize=10];\n    B_diff -> B_Re_ReduceSumSquare;\n    B_Re_ReduceSumSquare -> B_norm;\n  \n    B_Sq_Squeeze [shape=box style=\"filled,rounded\" color=orange label=\"Squeeze\\n(Sq_Squeeze)\" fontsize=10];\n    B_norm -> B_Sq_Squeeze;\n    B_Sq_Squeezecst -> B_Sq_Squeeze;\n    B_Sq_Squeeze -> B_scan_out;\n  }\n  x -> B_next_in;\n  x -> B_next;\n  B_next_out -> scan0_{idself};\n  B_scan_out -> scan1_{idself};\n  Sc_Scan -> B_Su_Sub [lhead=cluster_Scan2037718962336_2036854926640];\n  x -> Sc_Scan;\n  x -> Sc_Scan;\n  Sc_Scan -> scan0_{idself};\n  Sc_Scan -> scan1_{idself};\n\n  Id_Identity1 [shape=box style=\"filled,rounded\" color=orange label=\"Identity\\n(Id_Identity1)\" fontsize=10];\n  scan1_{idself} -> Id_Identity1;\n  Id_Identity1 -> Y;\n}\n");
    document.getElementById('gdot-2035936174912').innerHTML = svgGraph; });
    
</script>
</div><p>This loop is efficient even if it is still slower than a custom implementation
of pairwise distances. It assumes inputs and outputs are tensors and
automatically concatenate the outputs of every iteration into single
tensors. The previous example only have one but it could have several.</p>
</div>
<div class="section" id="loop">
<h3><a class="toc-backref" href="#id13">Loop</a><a class="headerlink" href="#loop" title="Permalink to this headline">Â¶</a></h3>
<p>Operator <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Loop">Loop</a> implements a for and a while loop. It can do a fixed
number of iterators and/or ends when a condition is not met anymore.
Outputs are processed in two different ways. First one is similar to
loop <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Scan">Scan</a>, outputs are concatenate into tensors (along the first
dimension). This also means that these outputs must have compatible shapes.
Second mechanism concatenates tensors into a sequence of tensors.</p>
</div>
</div>
<div class="section" id="extensibility">
<span id="l-onnx-extensibility"></span><h2><a class="toc-backref" href="#id14">Extensibility</a><a class="headerlink" href="#extensibility" title="Permalink to this headline">Â¶</a></h2>
<p>ONNX defines a list of operators as the standard: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md">ONNX ML operators</a>.
It extends this list with other operators specific to standard
machine learning <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md">ONNX ML operators</a>. However it is very possible
to define your own operators under this domain or a new one.
<a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> defines custom operators to improve inference
performance: <a class="reference external" href="https://github.com/microsoft/onnxruntime/blob/master/docs/ContribOperators.md">Contrib Operators</a>. Every node has a type, a name,
named inputs and outputs, and attributes. As long as a node is described
under these constraints, a node can be added to any ONNX graph.</p>
<p>One example is the operator CDist. Notebook <a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/notebooks/onnx_pdist.html">Pairwise distances with ONNX (pdist)</a>
goes into the details of it. Pairwise distances, as shown in section
<a class="reference internal" href="#l-operator-scan-onnx-tutorial"><span class="std std-ref">Scan</span></a>, can be implemented with operator
Scan. However, a dedicated operator called CDist is proved significantly
faster, significantly enough to make the effort to implement a dedicated runtime
for it.</p>
</div>
<div class="section" id="shape-and-type-inference">
<h2><a class="toc-backref" href="#id15">Shape (and Type) Inference</a><a class="headerlink" href="#shape-and-type-inference" title="Permalink to this headline">Â¶</a></h2>
<p>Knowing the shapes of results is not necessary to execute an ONNX graph
but this information can be used to make it faster. If you have the following
graph:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">z</span>
<span class="n">Abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">w</span>
</pre></div>
</div>
<p>If <em>x</em> and <em>y</em> have the same shape, then <em>z</em> and <em>w</em> also have the same
shape. Knowing that, it is possible to reuse the buffer allocated for <em>z</em>,
to compute the absolute value <em>w</em> inplace. Shape inference helps the
runtime to manage the memory and therefore to be more efficient.</p>
<p>ONNX package can compute in most of the cases the output shape
knowing the input shape for every standard operator. It cannot
obviously do that for any custom operator outside of the official
list.</p>
</div>
<div class="section" id="tools">
<h2><a class="toc-backref" href="#id16">Tools</a><a class="headerlink" href="#tools" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference external" href="https://github.com/lutzroeder/netron">netron</a> is very useful to help visualize ONNX graphs.
Thatâs the only one without programming. The first screenshot was
made with this tool.</p>
<img alt="../../_images/linreg1.png" src="../../_images/linreg1.png" />
<p><a class="reference external" href="https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx2py.py">onnx2py.py</a>
creates a python file from an ONNX graph. This script can create
the same graph. It may be modified by a user to change the graph.</p>
</div>
</div>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction to ONNX</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="python.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ONNX with Python</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>