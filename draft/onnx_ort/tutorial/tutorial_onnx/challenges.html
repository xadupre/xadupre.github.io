
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Challenges &#8212; Introduction to ONNX 0.1 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="ONNX operators and function" href="onnxops.html" />
    <link rel="prev" title="ONNX with Python" href="python.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../index.html">
<p class="title">Introduction to ONNX</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/index.html">
  API
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Introduction to ONNX
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="concepts.html">
     ONNX Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python.html">
     ONNX with Python
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Challenges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnxops.html">
     ONNX operators and function
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_onnxruntime/index.html">
   Introduction to onnxruntime
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-converting-library">
   What is a converting library?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#opsets">
   Opsets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-api">
   Other API
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-class-graph-with-a-method-add-node">
     A class Graph with a method add_node
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#operator-as-function">
     Operator as function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imitating-existing-api">
     Imitating existing API
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tricks-learned-from-experience">
   Tricks learned from experience
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#discrepancies">
     Discrepancies
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#isolationforest-trick">
     IsolationForest Trick
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#discretization">
     Discretization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contribute">
     Contribute
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build">
     Build
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build-the-documentation">
     Build the documentation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#update-an-existing-operator">
     Update an existing operator
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="challenges">
<h1>Challenges<a class="headerlink" href="#challenges" title="Permalink to this headline">¶</a></h1>
<p>Using ONNX in production means the prediction function
of a model can be implemented with ONNX operators.
A runtime must be chosen, one available on the platform
the model is deployed. Discrepancies are checked
and finally the latency is measured.
The first step about the model conversion can be easy
if there exists a converting library for this framework
supporting all the pieces of the model. If it is not the
case, the missing parts must be implemented in ONNX.
That may be very time consuming.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#what-is-a-converting-library" id="id2">What is a converting library?</a></p></li>
<li><p><a class="reference internal" href="#opsets" id="id3">Opsets</a></p></li>
<li><p><a class="reference internal" href="#other-api" id="id4">Other API</a></p>
<ul>
<li><p><a class="reference internal" href="#a-class-graph-with-a-method-add-node" id="id5">A class Graph with a method add_node</a></p></li>
<li><p><a class="reference internal" href="#operator-as-function" id="id6">Operator as function</a></p></li>
<li><p><a class="reference internal" href="#imitating-existing-api" id="id7">Imitating existing API</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tricks-learned-from-experience" id="id8">Tricks learned from experience</a></p>
<ul>
<li><p><a class="reference internal" href="#discrepancies" id="id9">Discrepancies</a></p></li>
<li><p><a class="reference internal" href="#isolationforest-trick" id="id10">IsolationForest Trick</a></p></li>
<li><p><a class="reference internal" href="#discretization" id="id11">Discretization</a></p></li>
<li><p><a class="reference internal" href="#contribute" id="id12">Contribute</a></p></li>
<li><p><a class="reference internal" href="#build" id="id13">Build</a></p></li>
<li><p><a class="reference internal" href="#build-the-documentation" id="id14">Build the documentation</a></p></li>
<li><p><a class="reference internal" href="#update-an-existing-operator" id="id15">Update an existing operator</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="what-is-a-converting-library">
<h2><a class="toc-backref" href="#id2">What is a converting library?</a><a class="headerlink" href="#what-is-a-converting-library" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/onnx/sklearn-onnx">sklearn-onnx</a> converts <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> models
into ONNX. It rewrites the prediction function of a model,
whatever it is, with ONNX operators using the API introduced
above. It ensures that the predictions are equal or at least
very close to the expected predictions computed with the
original model.</p>
<p>Machine learning libraries usually have their own design.
That’s why there exists a specific converting library for
each of them. Many of them are listed there:
<a class="reference external" href="https://github.com/onnx/tutorials#converting-to-onnx-format">Converting to ONNX format</a>.
Here is a short list:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/onnx/sklearn-onnx">sklearn-onnx</a>: converts models from <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/tensorflow-onnx">tensorflow-onnx</a>:
converts models from <a class="reference external" href="https://www.tensorflow.org/">tensorflow</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/onnxmltools">onnxmltools</a>: converts models from <a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/">lightgbm</a>,
<a class="reference external" href="https://xgboost.readthedocs.io/en/latest/">xgboost</a>, <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/">pyspark</a>, <a class="reference external" href="https://github.com/cjlin1/libsvm">libsvm</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/master/onnx.html">torch.onnx</a>:
converts model from <a class="reference external" href="https://pytorch.org/">pytorch</a></p></li>
</ul>
<p>The main challenge for all these libraries is to keep up the rythm.
They must be updated everytime ONNX or the library they support
have a new released version. That means three to five new releases
per year.</p>
<p>Converting libraries are not compatible among each others.
<a class="reference external" href="https://github.com/onnx/tensorflow-onnx">tf2onnx</a> is dedicated to <a class="reference external" href="https://www.tensorflow.org/">tensorflow</a> and only
<a class="reference external" href="https://www.tensorflow.org/">tensorflow</a>. The same goes for <a class="reference external" href="https://github.com/onnx/sklearn-onnx">sklearn-onnx</a>
specialized into <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>.</p>
<p>One challenge is customization. It is difficult to support
custom pieces in a machine learned model.
They have to write the specific converter for this piece.
Somehow, it is like implementing
twice the prediction function. There is one easy case:
deep learning frameworks have their own primitives to ensure
the same code can be executed on different environment.
As long as a custom layer or a subpart is using pieces of
<a class="reference external" href="https://pytorch.org/">pytorch</a> or <a class="reference external" href="https://www.tensorflow.org/">tensorflow</a>, there is not much to do.
It is a different story for <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>. This package
does not have its own addition or multiplication, it relies
on <a class="reference external" href="https://numpy.org/">numpy</a> or <a class="reference external" href="https://scipy.org/">scipy</a>. The user must implement
its transformer or predictor with ONNX primitives, whether or
not it was implemented with <a class="reference external" href="https://numpy.org/">numpy</a>. Example
<a class="reference external" href="https://onnx.ai/sklearn-onnx/auto_tutorial/plot_icustom_converter.html">Implement a new converter</a>
shows what it looks like.</p>
</div>
<div class="section" id="opsets">
<h2><a class="toc-backref" href="#id3">Opsets</a><a class="headerlink" href="#opsets" title="Permalink to this headline">¶</a></h2>
<p>ONNX releases package with version number like
<cite>major.minor.fix</cite>. Every minor update means the list of operators
is different or the signature has changed. It is also associated to
an opset, version <cite>1.10</cite> is opset 15, <cite>1.11</cite> will be opset 16.
Every ONNX graph should define the opset it follows. Changing this
version without updating the operators could make the graph invalid.
If the opset is left unspecified, ONNX will consider that the graph
is valid for the latest opset.</p>
<p>New opsets usually introduce new operators. A same inference function
could be implemented differently, usually in a more efficient way.
However, the runtime the model is running on may not
support newest opsets or at least not in the installed version.
That’s why every converting library offers the
possibility to create an ONNX graph for a specific opset usually called
<code class="docutils literal notranslate"><span class="pre">target_opset</span></code>. ONNX language describes simple and complex operators.
Changing the opset is similar to upgrade a library. <a class="reference external" href="https://github.com/onnx/onnx">onnx</a>
and onnx runtimes must support backward compatibility.</p>
</div>
<div class="section" id="other-api">
<h2><a class="toc-backref" href="#id4">Other API</a><a class="headerlink" href="#other-api" title="Permalink to this headline">¶</a></h2>
<p>Examples in previous sections show that <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> API is
very verbose. It is also difficult to get a whole picture of
a graph by reading the code unless it is a small one. Almost
every converting library has implemented a different API
to create a graph, usually more simple, less verbose
than the API of <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> package.
All API automate the addition of initializers, hide the creation
of a name of every intermediate result, deal with different
version for different opset.</p>
<div class="section" id="a-class-graph-with-a-method-add-node">
<h3><a class="toc-backref" href="#id5">A class Graph with a method add_node</a><a class="headerlink" href="#a-class-graph-with-a-method-add-node" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://github.com/onnx/tensorflow-onnx">tf2onnx</a> implements a class graph.
It rewrites tensorflow function with ONNX operator when
ONNX does not have a similar function (see <a class="reference external" href="https://github.com/onnx/tensorflow-onnx/blob/master/tf2onnx/onnx_opset/math.py#L414">Erf</a>.</p>
<p><a class="reference external" href="https://github.com/onnx/sklearn-onnx">sklearn-onnx</a> defines two different API. The first one
introduced in that example
<a class="reference external" href="https://onnx.ai/sklearn-onnx/auto_tutorial/plot_jcustom_syntax.html">Two ways to implement a converter</a>
follows a similar design that <a class="reference external" href="https://github.com/onnx/tensorflow-onnx">tf2onnx</a>.
Following line are extracted from the converter of a linear
classifier.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># initializer</span>

<span class="n">coef</span> <span class="o">=</span> <span class="n">scope</span><span class="o">.</span><span class="n">get_unique_variable_name</span><span class="p">(</span><span class="s1">&#39;coef&#39;</span><span class="p">)</span>
<span class="n">model_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="n">classifier_attrs</span><span class="p">[</span><span class="s1">&#39;coefficients&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">model_coef</span> <span class="o">=</span> <span class="n">model_coef</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">number_of_classes</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="n">container</span><span class="o">.</span><span class="n">add_initializer</span><span class="p">(</span>
    <span class="n">coef</span><span class="p">,</span> <span class="n">proto_dtype</span><span class="p">,</span> <span class="n">model_coef</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">model_coef</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

<span class="n">intercept</span> <span class="o">=</span> <span class="n">scope</span><span class="o">.</span><span class="n">get_unique_variable_name</span><span class="p">(</span><span class="s1">&#39;intercept&#39;</span><span class="p">)</span>
<span class="n">model_intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="n">classifier_attrs</span><span class="p">[</span><span class="s1">&#39;intercepts&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">model_intercept</span> <span class="o">=</span> <span class="n">model_intercept</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">number_of_classes</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="n">container</span><span class="o">.</span><span class="n">add_initializer</span><span class="p">(</span>
    <span class="n">intercept</span><span class="p">,</span> <span class="n">proto_dtype</span><span class="p">,</span> <span class="n">model_intercept</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
    <span class="n">model_intercept</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

<span class="c1"># add nodes</span>

<span class="n">multiplied</span> <span class="o">=</span> <span class="n">scope</span><span class="o">.</span><span class="n">get_unique_variable_name</span><span class="p">(</span><span class="s1">&#39;multiplied&#39;</span><span class="p">)</span>
<span class="n">container</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span>
    <span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">operator</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">full_name</span><span class="p">,</span> <span class="n">coef</span><span class="p">],</span> <span class="n">multiplied</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">get_unique_operator_name</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">))</span>

<span class="c1"># [...]</span>

<span class="n">argmax_output_name</span> <span class="o">=</span> <span class="n">scope</span><span class="o">.</span><span class="n">get_unique_variable_name</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
<span class="n">container</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s1">&#39;ArgMax&#39;</span><span class="p">,</span> <span class="n">raw_score_name</span><span class="p">,</span> <span class="n">argmax_output_name</span><span class="p">,</span>
                   <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">get_unique_operator_name</span><span class="p">(</span><span class="s1">&#39;ArgMax&#39;</span><span class="p">),</span>
                   <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="operator-as-function">
<h3><a class="toc-backref" href="#id6">Operator as function</a><a class="headerlink" href="#operator-as-function" title="Permalink to this headline">¶</a></h3>
<p>The second API shown in
<a class="reference external" href="https://onnx.ai/sklearn-onnx/auto_tutorial/plot_icustom_converter.html">Implement a new converter</a>
is more compact and defines
every ONNX operator as composable functions.
The syntax looks like this for <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">KMeans</a>,
less verbose and easier to read.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rs</span> <span class="o">=</span> <span class="n">OnnxReduceSumSquare</span><span class="p">(</span>
    <span class="n">input_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">op_version</span><span class="o">=</span><span class="n">opv</span><span class="p">)</span>

<span class="n">gemm_out</span> <span class="o">=</span> <span class="n">OnnxMatMul</span><span class="p">(</span>
    <span class="n">input_name</span><span class="p">,</span> <span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">),</span> <span class="n">op_version</span><span class="o">=</span><span class="n">opv</span><span class="p">)</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">OnnxAdd</span><span class="p">(</span><span class="n">rs</span><span class="p">,</span> <span class="n">gemm_out</span><span class="p">,</span> <span class="n">op_version</span><span class="o">=</span><span class="n">opv</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">OnnxAdd</span><span class="p">(</span><span class="n">C2</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">op_version</span><span class="o">=</span><span class="n">opv</span><span class="p">)</span>
<span class="n">ll</span> <span class="o">=</span> <span class="n">OnnxArgMin</span><span class="p">(</span><span class="n">y2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">out</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">op_version</span><span class="o">=</span><span class="n">opv</span><span class="p">)</span>
<span class="n">y2s</span> <span class="o">=</span> <span class="n">OnnxSqrt</span><span class="p">(</span><span class="n">y2</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">op_version</span><span class="o">=</span><span class="n">opv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="imitating-existing-api">
<h3><a class="toc-backref" href="#id7">Imitating existing API</a><a class="headerlink" href="#imitating-existing-api" title="Permalink to this headline">¶</a></h3>
<p>A last approach aims at removing one implementation (<a class="reference external" href="https://numpy.org/">numpy</a>
+ <a class="reference external" href="https://github.com/onnx/onnx">onnx</a>).
<a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/tutorial/numpy_api_onnx.html">Numpy to ONNX: Create ONNX graphs with an API similar to numpy</a>.
Many <a class="reference external" href="https://numpy.org/">numpy</a> functions are implemented with ONNX operators.
Implementing a transformer with these functions automatically
offers the conversion to ONNX for free.
The following come from the example linked above.
It looks like <a class="reference external" href="https://numpy.org/">numpy</a> syntax but every function is
converted into ONNX primitives.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlprodict.npy.numpy_onnx_impl</span> <span class="k">as</span> <span class="nn">nxnp</span>
<span class="kn">import</span> <span class="nn">mlprodict.npy.numpy_onnx_impl_skl</span> <span class="k">as</span> <span class="nn">nxnpskl</span>

<span class="nd">@onnxsklearn_class</span><span class="p">(</span><span class="s2">&quot;onnx_graph&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CustomTransformerOnnx</span><span class="p">(</span><span class="n">TransformerMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">):</span>

    <span class="c1"># [...__init__...fit...]</span>

    <span class="k">def</span> <span class="nf">onnx_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperplan_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centers_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">sign</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">@</span> <span class="n">h</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">cast</span> <span class="o">=</span> <span class="n">sign</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Function logistic_regression is not a numpy function.</span>
        <span class="c1"># It calls the converter for a LogisticRegression</span>
        <span class="c1"># implemented in sklearn-onnx.</span>
        <span class="n">prob0</span> <span class="o">=</span> <span class="n">nxnpskl</span><span class="o">.</span><span class="n">logistic_regression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr0_</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">prob1</span> <span class="o">=</span> <span class="n">nxnpskl</span><span class="o">.</span><span class="n">logistic_regression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr1_</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">prob1</span> <span class="o">*</span> <span class="n">cast</span> <span class="o">-</span> <span class="n">prob0</span> <span class="o">*</span> <span class="p">(</span><span class="n">cast</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">nxnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">MultiOnnxVar</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="tricks-learned-from-experience">
<h2><a class="toc-backref" href="#id8">Tricks learned from experience</a><a class="headerlink" href="#tricks-learned-from-experience" title="Permalink to this headline">¶</a></h2>
<div class="section" id="discrepancies">
<h3><a class="toc-backref" href="#id9">Discrepancies</a><a class="headerlink" href="#discrepancies" title="Permalink to this headline">¶</a></h3>
<p>ONNX is strongly typed and optimizes for float32, the most
common type in deep learning. Libraries in standard
machine learning use both float32 and float64. <a class="reference external" href="https://numpy.org/">numpy</a>
usually cast to the most generic type, float64. It has no significant
impact when the prediction function is contiguous.
When it is not, the right type must be used. Example
` Issues when switching to float
&lt;<a class="reference external" href="https://onnx.ai/sklearn-onnx/auto_tutorial/plot_ebegin_float_double.html">https://onnx.ai/sklearn-onnx/auto_tutorial/plot_ebegin_float_double.html</a>&gt;`_
gives more insights on that topic.</p>
<p>Parallelization changes the order of computation. It is usually
not significant but it may explain some weird discrepancies.
<cite>1 + 1e17 - 1e17 = 0</cite> but <cite>1e17 - 1e17 + 1 = 1</cite>. High order of
magnitude are rare but not so rare when a model uses the inverse
of a matrix.</p>
</div>
<div class="section" id="isolationforest-trick">
<h3><a class="toc-backref" href="#id10">IsolationForest Trick</a><a class="headerlink" href="#isolationforest-trick" title="Permalink to this headline">¶</a></h3>
<p>ONNX only implements a <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md#ai.onnx.ml.TreeEnsembleRegressor">TreeEnsembleRegressor</a> but
it does not offer the possibility to retrieve any information
about the path the decision followed or statistics to the graph.
The trick is to used one forest to predict the leave index and map
this leave index one or multiple times with the information needed.</p>
<img alt="../../_images/iff.png" src="../../_images/iff.png" />
</div>
<div class="section" id="discretization">
<h3><a class="toc-backref" href="#id11">Discretization</a><a class="headerlink" href="#discretization" title="Permalink to this headline">¶</a></h3>
<p>Looking in which interval a feature falls into. That’s easy to do
with <a class="reference external" href="https://numpy.org/">numpy</a> but not so easy to do efficiently with ONNX.
The fastest way is to use a TreeEnsembleRegressor, a binary search,
which outputs the interval index. That’s what this example
implements:
<a class="reference external" href="https://onnx.ai/sklearn-onnx/auto_tutorial/plot_woe_transformer.html">Converter for WOE</a>.</p>
</div>
<div class="section" id="contribute">
<h3><a class="toc-backref" href="#id12">Contribute</a><a class="headerlink" href="#contribute" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://github.com/onnx/onnx">onnx repository</a> must be forked and cloned.</p>
</div>
<div class="section" id="build">
<h3><a class="toc-backref" href="#id13">Build</a><a class="headerlink" href="#build" title="Permalink to this headline">¶</a></h3>
<p>The windows build requires conda. The following steps might not be up to date.
Folder <a class="reference external" href="https://github.com/onnx/onnx/tree/master/.azure-pipelines">onnx/.azure-pipelines</a>
contains the latest instructions.</p>
<p><strong>Windows</strong></p>
<p>The build is easier with <a class="reference external" href="https://www.anaconda.com/">Anaconda</a>. First: create an environment.
It must be done only once.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">create</span> <span class="o">--</span><span class="n">yes</span> <span class="o">--</span><span class="n">quiet</span> <span class="o">--</span><span class="n">name</span> <span class="n">py3</span><span class="mf">.9</span> <span class="n">python</span><span class="o">=</span><span class="mf">3.9</span>
<span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">n</span> <span class="n">py3</span><span class="mf">.9</span> <span class="o">-</span><span class="n">y</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">numpy</span> <span class="n">libprotobuf</span><span class="o">=</span><span class="mf">3.16.0</span>
</pre></div>
</div>
<p>Then build the package:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>git submodule update --init --recursive
set ONNX_BUILD_TESTS=1
set ONNX_ML=$(onnx_ml)
set CMAKE_ARGS=-DONNX_USE_PROTOBUF_SHARED_LIBS=ON -DONNX_USE_LITE_PROTO=ON -DONNX_WERROR=ON

python setup.py -q install
python setup.py bdist_wheel
</pre></div>
</div>
<p>The package can now be installed.</p>
</div>
<div class="section" id="build-the-documentation">
<h3><a class="toc-backref" href="#id14">Build the documentation</a><a class="headerlink" href="#build-the-documentation" title="Permalink to this headline">¶</a></h3>
<p>The package must be built first (see previous section).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>set ONNX_BUILD_TESTS=1
set ONNX_ML=$(onnx_ml)
set CMAKE_ARGS=-DONNX_USE_PROTOBUF_SHARED_LIBS=ON -DONNX_USE_LITE_PROTO=ON -DONNX_WERROR=ON

python onnx\gen_proto.py -l
python onnx\gen_proto.py -l --ml
python setup.py develop
python onnx\backend\test\cmd_tools.py generate-data
python onnx\backend\test\stat_coverage.py
python onnx\defs\gen_doc.py
set ONNX_ML=0
python onnx\defs\gen_doc.py
set ONNX_ML=1
</pre></div>
</div>
</div>
<div class="section" id="update-an-existing-operator">
<h3><a class="toc-backref" href="#id15">Update an existing operator</a><a class="headerlink" href="#update-an-existing-operator" title="Permalink to this headline">¶</a></h3>
<p>All operators are defined in folder
<a class="reference external" href="https://github.com/onnx/onnx/tree/master/onnx/defs">onnx/onnx/defs</a>.
There are two files in every subfolder, one called <cite>defs.cc</cite> and another one
called <cite>old.cc</cite>.</p>
<ul class="simple">
<li><p><cite>defs.cc</cite>: contains the most recent definition for every operator</p></li>
<li><p><cite>old.cc</cite>: contains the deprecated version of the operators in previous opset</p></li>
</ul>
<p>Updating an operator means copying the definition from <cite>defs.cc</cite> to <cite>old.cc</cite>
and updating the existing one in <cite>defs.cc</cite>.</p>
<p>One file following the pattern <cite>onnx/defs/operator_sets*.h</cite>
must be modified. These headers registers the list
of existing operators.</p>
<p>File <a class="reference external" href="https://github.com/onnx/onnx/tree/master/onnx/defs/schema.h">onnx/defs/schema.h</a>
contains the latest opset version. It must updated too if one opset
was upgraded.</p>
<p>File <a class="reference external" href="https://github.com/onnx/onnx/tree/master/onnx/version_converter/convert.h">onnx/version_converter/convert.h</a>
contains rules to apply when converter a node from an opset to the next one.
This file may be updated too.</p>
<p>The package must be compiled and the documentation must be generated
again to automatically update the markdown documentation and it must
be included into the PR.</p>
<p>Then unit test must be updated.</p>
<p><strong>Summary</strong></p>
<ul class="simple">
<li><p>Modify files <cite>defs.cc</cite>, <cite>old.cc</cite>, <cite>onnx/defs/operator_sets*.h</cite>,
<cite>onnx/defs/schema.h</cite></p></li>
<li><p>Optional: modify file <cite>onnx/version_converter/convert.h</cite></p></li>
<li><p>Build onnx.</p></li>
<li><p>Build the documentation.</p></li>
<li><p>Update unit test.</p></li>
</ul>
<p>The PR should include the modified files and the modified markdown documentation,
usually a subset of
<cite>docs/docs/Changelog-ml.md</cite>, <cite>docs/Changelog.md</cite>,
<cite>docs/Operators-ml.md</cite>, <cite>docs/Operators.md</cite>,
<cite>docs/TestCoverage-ml.md</cite>, <cite>docs/TestCoverage.md</cite>.</p>
</div>
</div>
</div>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="python.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">ONNX with Python</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="onnxops.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ONNX operators and function</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>