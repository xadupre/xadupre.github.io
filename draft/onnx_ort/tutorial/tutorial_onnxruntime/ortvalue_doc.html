
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>OrtValue &#8212; Introduction to ONNX 0.1 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Inference with onnxruntime in Python" href="inference.html" />
    <link rel="prev" title="Introduction to onnxruntime" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../index.html">
<p class="title">Introduction to ONNX</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/index.html">
  API
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_onnx/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Introduction to onnxruntime
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     OrtValue
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inference.html">
     Inference with onnxruntime in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="training_ort_api.html">
     Training with onnxruntime
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extensions.html">
     Extensions
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#device">
   Device
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#memory-allocator">
   Memory Allocator
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   OrtValue
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creation-from-numpy">
     Creation from numpy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creation-from-a-new-buffer">
     Creation from a new buffer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#export-to-numpy">
     Export to numpy
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dlpack">
   DLPack
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conversion">
     Conversion
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ortvaluevector">
     OrtValueVector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#boolean-ambiguity">
     Boolean ambiguity
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sparse-tensors">
   Sparse Tensors
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="ortvalue">
<h1>OrtValue<a class="headerlink" href="#ortvalue" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://numpy.org/">numpy</a> has its <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, <a class="reference external" href="https://pytorch.org/">pytorch</a> has
its <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.10.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a>. <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> has its
<cite>OrtValue</cite>. As opposed to the other two framework,
<cite>OrtValue</cite> does not support simple operations such as
addition, subtraction, multiplication or division. It can only be
used to be consumed by <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> or converted into another
object such as <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>. An <cite>OrtValue</cite> can hold more than
a dense tensor, it can also be a sparse tensor, a sequence of tensors
or a map of tensors. Like <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.10.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a>, the data can be located
on CPU, CUDA, …</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#device" id="id3">Device</a></p></li>
<li><p><a class="reference internal" href="#memory-allocator" id="id4">Memory Allocator</a></p></li>
<li><p><a class="reference internal" href="#id1" id="id5">OrtValue</a></p>
<ul>
<li><p><a class="reference internal" href="#creation-from-numpy" id="id6">Creation from numpy</a></p></li>
<li><p><a class="reference internal" href="#creation-from-a-new-buffer" id="id7">Creation from a new buffer</a></p></li>
<li><p><a class="reference internal" href="#export-to-numpy" id="id8">Export to numpy</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#dlpack" id="id9">DLPack</a></p>
<ul>
<li><p><a class="reference internal" href="#conversion" id="id10">Conversion</a></p></li>
<li><p><a class="reference internal" href="#ortvaluevector" id="id11">OrtValueVector</a></p></li>
<li><p><a class="reference internal" href="#boolean-ambiguity" id="id12">Boolean ambiguity</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#sparse-tensors" id="id13">Sparse Tensors</a></p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> implements a C class named <cite>OrtValue</cite>
but referred as <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a>
and a python wrapper for it also named <a class="reference external" href="http://www.xavierdupre.fr/app/onnxruntime_training/helpsphinx/api/tensors.html#ortvalue">OrtValue</a>.
This documentation uses <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a> directly.
The wrapper is usually calling the same C functions.
The same goes for <a class="reference external" href="http://www.xavierdupre.fr/app/onnxruntime_training/helpsphinx/api/tensors.html#ortdevice">OrtDevice</a> and <a class="reference external" href="http://www.xavierdupre.fr/app/onnxruntime_training/helpsphinx/api/tensors.html#ortdevice">OrtDevice</a>.
They can be imported like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="device">
<span id="l-doc-device"></span><h2><a class="toc-backref" href="#id3">Device</a><a class="headerlink" href="#device" title="Permalink to this headline">¶</a></h2>
<p>A device is associated to a tensor. It indicates
where the data is stored. It is defined by:</p>
<ul class="simple">
<li><p>a device type: CPU, CUDA, FGPA</p></li>
<li><p>a device index: if there are many devices of the
same type, it tells which one is used.</p></li>
<li><p>an allocator: it is possible to change the way
memory is allocated.</p></li>
</ul>
<p>Next example shows how to create a CPU device.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">)</span>

<span class="n">ort_device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span>
    <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">default_memory</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ort_device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ort_device</span><span class="o">.</span><span class="n">device_type</span><span class="p">(),</span> <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">&lt;</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">capi</span><span class="o">.</span><span class="n">onnxruntime_pybind11_state</span><span class="o">.</span><span class="n">OrtDevice</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x000001FFB3F392B0</span><span class="o">&gt;</span>
    <span class="mi">0</span> <span class="mi">0</span>
</pre></div>
</div>
<p>And the next one how to create a CUDA device.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">)</span>

<span class="n">ort_device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span>
    <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">default_memory</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ort_device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ort_device</span><span class="o">.</span><span class="n">device_type</span><span class="p">(),</span> <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">&lt;</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">capi</span><span class="o">.</span><span class="n">onnxruntime_pybind11_state</span><span class="o">.</span><span class="n">OrtDevice</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x000001FFB3F3F630</span><span class="o">&gt;</span>
    <span class="mi">1</span> <span class="mi">1</span>
</pre></div>
</div>
<p>The class has three methods:</p>
<ul class="simple">
<li><p><em>device_type()</em>: returns the device type</p></li>
<li><p><em>device_id()</em>: returns the device index</p></li>
<li><p><em>device_mem_type()</em>: <em>not available yet</em></p></li>
</ul>
</div>
<div class="section" id="memory-allocator">
<h2><a class="toc-backref" href="#id4">Memory Allocator</a><a class="headerlink" href="#memory-allocator" title="Permalink to this headline">¶</a></h2>
<p id="index-0"><strong>to be continued later</strong></p>
</div>
<div class="section" id="id1">
<h2><a class="toc-backref" href="#id5">OrtValue</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>This class is a generic type. It hides any supported type
by <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a>, a tensor, a sparse tensor,
a sequence of tensors, a map of tensors. From python point of view,
it is only a container. It is only possible to export,
convert or get information about it. The only way to manipulate
<em>OrtValue</em> is to go through an ONNX graph loaded by
an <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a>.
Following section refers to the C implementation of <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a>.</p>
<div class="section" id="creation-from-numpy">
<h3><a class="toc-backref" href="#id6">Creation from numpy</a><a class="headerlink" href="#creation-from-numpy" title="Permalink to this headline">¶</a></h3>
<p>The most easier way is to create an <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a> from
a <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>. Next example does that on CPU.
However even that simple example hides some important detail.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.print_helper</span> <span class="kn">import</span> <span class="n">str_ortvalue</span>

<span class="n">vect</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ort_value</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span><span class="n">vect</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ort_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">str_ortvalue</span><span class="p">(</span><span class="n">ort_value</span><span class="p">))</span>

<span class="c1"># Data pointers?</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ort_value</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vect</span><span class="o">.</span><span class="n">__array_interface__</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">&lt;</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">capi</span><span class="o">.</span><span class="n">onnxruntime_pybind11_state</span><span class="o">.</span><span class="n">OrtValue</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x000001FFB3F546B0</span><span class="o">&gt;</span>
    <span class="n">device</span><span class="o">=</span><span class="n">Cpu</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,)</span> <span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mf">100.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>
    <span class="mi">2197685532192</span>
    <span class="p">(</span><span class="mi">2197685532192</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The last two lines show that both objects points to the same location.
To avoid copying the data, <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> only creates a structure
wrapping the same memory buffer. As a result, the numpy array must
<strong>remain alive</strong> as long as the instance of <cite>C_OrtValue</cite> is.
If it does not, the program usually crashes with no exception but a
segmentation fault.</p>
</div>
<div class="section" id="creation-from-a-new-buffer">
<h3><a class="toc-backref" href="#id7">Creation from a new buffer</a><a class="headerlink" href="#creation-from-a-new-buffer" title="Permalink to this headline">¶</a></h3>
<p>Method <cite>ortvalue_from_shape_and_type</cite> can create a new
<a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a> owning its buffer.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.print_helper</span> <span class="kn">import</span> <span class="n">str_ortvalue</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ort_value</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_shape_and_type</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ort_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">str_ortvalue</span><span class="p">(</span><span class="n">ort_value</span><span class="p">))</span>

<span class="c1"># Address can be given to another C function to populate the buffer.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ort_value</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">&lt;</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">capi</span><span class="o">.</span><span class="n">onnxruntime_pybind11_state</span><span class="o">.</span><span class="n">OrtValue</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x000001FFA8F8E2B0</span><span class="o">&gt;</span>
    <span class="n">device</span><span class="o">=</span><span class="n">Cpu</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">1.1350569195656135e-07</span><span class="p">,</span> <span class="mf">7.160635152699815e-43</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8201003313018937e-14</span><span class="p">,</span> <span class="mf">7.160635152699815e-43</span><span class="p">,</span> <span class="mf">1.401298464324817e-45</span><span class="p">,</span> <span class="s1">&#39;...&#39;</span><span class="p">,</span> <span class="mf">1.641398288448757e-37</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.104039770140103e-38</span><span class="p">,</span> <span class="mf">1.648576159482898e-14</span><span class="p">,</span> <span class="mf">981555712.0</span><span class="p">,</span> <span class="mf">2.4178522156900107e+24</span><span class="p">]</span>
    <span class="mi">2197684887616</span>
</pre></div>
</div>
</div>
<div class="section" id="export-to-numpy">
<h3><a class="toc-backref" href="#id8">Export to numpy</a><a class="headerlink" href="#export-to-numpy" title="Permalink to this headline">¶</a></h3>
<p>Unless it is reused by another library or <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a>
itself, the only way to access the data is contains is to
create a numpy array with method <cite>numpy</cite>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.print_helper</span> <span class="kn">import</span> <span class="n">str_ortvalue</span>

<span class="n">vect</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ort_value</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span><span class="n">vect</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ort_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">str_ortvalue</span><span class="p">(</span><span class="n">ort_value</span><span class="p">))</span>

<span class="c1"># Data pointers?</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ort_value</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vect</span><span class="o">.</span><span class="n">__array_interface__</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>

<span class="c1"># to numpy</span>
<span class="n">vect2</span> <span class="o">=</span> <span class="n">ort_value</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vect2</span><span class="o">.</span><span class="n">__array_interface__</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">&lt;</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">capi</span><span class="o">.</span><span class="n">onnxruntime_pybind11_state</span><span class="o">.</span><span class="n">OrtValue</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x000001FFA9024530</span><span class="o">&gt;</span>
    <span class="n">device</span><span class="o">=</span><span class="n">Cpu</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,)</span> <span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mf">100.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>
    <span class="mi">2197685532192</span>
    <span class="p">(</span><span class="mi">2197685532192</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">2197685532288</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Method <cite>numpy</cite> makes a copy. Next section brings more details
about avoiding that copy.</p>
</div>
</div>
<div class="section" id="dlpack">
<h2><a class="toc-backref" href="#id9">DLPack</a><a class="headerlink" href="#dlpack" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/dmlc/dlpack">DLPack</a> is protocol imagined to avoid copying memory when data
is created by one framework and used by another one. The safest way is
to copy entirely the data in its own containers. But that costs a lot
if the data is big or may be even difficult if the data is big compared
to the memory size. The DLpack structure describes a tensor, or a multidimensional
vector with a specific element type and a specific shape. It also
keeps the location or device where the data is (CPU, CUDA, …).
When a library B receives a DLpack structure from a library A, it:</p>
<ul class="simple">
<li><p>creates its own to store any information it needs</p></li>
<li><p>it deletes the structure it receives by calling a destructor
store in the structure itself.</p></li>
</ul>
<p>The library B takes ownership of the data and is now responsible for
its deletion unless a library C requests its ownship through a DLpack
structure as well.</p>
<p><a class="reference external" href="https://pytorch.org/">pytorch</a> implements this through two functions <cite>to_dlpack</cite> and
<cite>from_dlpack</cite> (see <a class="reference external" href="https://pytorch.org/docs/stable/dlpack.html">torch.utils.dlpack</a>).
<a class="reference external" href="https://numpy.org/">numpy</a> implements it as well. The changes were merged in
<a class="reference external" href="https://github.com/numpy/numpy/pull/19083">PR 19083</a>.</p>
<p><a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a> implements a couple of scenarios based
on <a class="reference external" href="https://pytorch.org/">pytorch</a> and needs this protocol to avoid unnecessary
data transfer.</p>
<div class="section" id="conversion">
<h3><a class="toc-backref" href="#id10">Conversion</a><a class="headerlink" href="#conversion" title="Permalink to this headline">¶</a></h3>
<p>Method <cite>to_dlpack</cite> exports a <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a> into a DLPack stucture.
Static method <cite>from_dlpack</cite> creates <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a> from a DLPack stucture.
Everytime one of these methods is used, the previous container loses
ownership to the next one. Only this one must be used. It becomes
responsible for the data deletion.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.print_helper</span> <span class="kn">import</span> <span class="n">str_ortvalue</span>

<span class="n">vect</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ort_value</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span><span class="n">vect</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ptr&quot;</span><span class="p">,</span> <span class="n">ort_value</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">())</span>

<span class="c1"># export</span>
<span class="n">dlp</span> <span class="o">=</span> <span class="n">ort_value</span><span class="o">.</span><span class="n">to_dlpack</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dlp</span><span class="p">)</span>

<span class="c1"># export back to onnxruntime</span>
<span class="n">ort_value_back</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">dlp</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="c1"># dlp structure is no longer valid</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ptr&quot;</span><span class="p">,</span> <span class="n">ort_value_back</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">str_ortvalue</span><span class="p">(</span><span class="n">ort_value_back</span><span class="p">))</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">ptr</span> <span class="mi">2197685532288</span>
    <span class="o">&lt;</span><span class="n">capsule</span> <span class="nb">object</span> <span class="s2">&quot;dltensor&quot;</span> <span class="n">at</span> <span class="mh">0x000001FFB3F96930</span><span class="o">&gt;</span>
    <span class="n">ptr</span> <span class="mi">2197685532288</span>
    <span class="n">device</span><span class="o">=</span><span class="n">Cpu</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,)</span> <span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mf">100.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>
</pre></div>
</div>
<p id="index-1"><strong>to be continued later</strong></p>
<p>See <a class="reference external" href="https://github.com/microsoft/onnxruntime/pull/9610">PR 9610</a>.</p>
</div>
<div class="section" id="ortvaluevector">
<h3><a class="toc-backref" href="#id11">OrtValueVector</a><a class="headerlink" href="#ortvaluevector" title="Permalink to this headline">¶</a></h3>
<p>This container is equivalent to a list of <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/ortvalue.html#c-class-ortvaluevector">C_OrtValue</a>.
It optimizes the conversion to DLPack structure (see <a class="reference external" href="https://github.com/microsoft/onnxruntime/pull/9610">PR 9610</a>).</p>
<p id="index-2"><strong>to be continued later</strong></p>
</div>
<div class="section" id="boolean-ambiguity">
<h3><a class="toc-backref" href="#id12">Boolean ambiguity</a><a class="headerlink" href="#boolean-ambiguity" title="Permalink to this headline">¶</a></h3>
<p>Boolean type is usually represented as a vector of unsigned bytes.
This information is not actually stored in the DLPack structure
and there is no way to distinguish between the two. That’s why
method <cite>from_dlpack</cite> has an additional parameter. You can read
more about this in <a class="reference external" href="https://github.com/dmlc/dlpack/issues/75">issue 75</a>.</p>
</div>
</div>
<div class="section" id="sparse-tensors">
<h2><a class="toc-backref" href="#id13">Sparse Tensors</a><a class="headerlink" href="#sparse-tensors" title="Permalink to this headline">¶</a></h2>
<p>Sparse tensors only represent 2D matrices and are much more efficient
in standard machine learning to represent categories or text features.
This structure is usually created by an operator such as
<a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnx_docs/Operators-ml.html?highlight=onehotencoding#a-name-ai-onnx-ml-onehotencoder-a-a-name-ai-onnx-ml-onehotencoder-ai-onnx-ml-onehotencoder-a">OneHotEncoder</a> or <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnx_docs/Operators.html#a-name-tfidfvectorizer-a-a-name-tfidfvectorizer-tfidfvectorizer-a">TfIdfVectorizer</a>.</p>
<p>The following example shows how to create a sparse tensor
(C version, <a class="reference external" href="http://www.xavierdupre.fr/app/onnxruntime_training/helpsphinx/api/tensors.html#sparsetensor">C_SparseTensor</a>) from a <a class="reference external" href="https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)">CSR</a> matrix
and to convert it back to this format.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">SparseTensor</span> <span class="k">as</span> <span class="n">C_SparseTensor</span><span class="p">,</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">)</span>

<span class="n">ort_device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span>
    <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">default_memory</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">dense</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sparse ratio:&quot;</span><span class="p">,</span> <span class="n">dense</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">dense</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

<span class="n">csr</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span><span class="n">dense</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;csr_matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">csr</span><span class="p">)</span>

<span class="n">ort_sparse</span> <span class="o">=</span> <span class="n">C_SparseTensor</span><span class="o">.</span><span class="n">sparse_csr_from_numpy</span><span class="p">(</span>
    <span class="n">csr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
    <span class="n">csr</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">csr</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">csr</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span>
    <span class="n">ort_device</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ort_sparse.values() -&gt;&quot;</span><span class="p">,</span> <span class="n">ort_sparse</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="c1"># Back to csr_matrix.</span>
<span class="n">ort_csr</span> <span class="o">=</span> <span class="n">ort_sparse</span><span class="o">.</span><span class="n">get_csrc_data</span><span class="p">()</span>

<span class="n">csr2</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span>
    <span class="p">(</span><span class="n">ort_sparse</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">ort_csr</span><span class="o">.</span><span class="n">inner</span><span class="p">(),</span> <span class="n">ort_csr</span><span class="o">.</span><span class="n">outer</span><span class="p">()),</span>
    <span class="n">shape</span><span class="o">=</span><span class="n">ort_sparse</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;retrieved:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">csr2</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">sparse</span> <span class="n">ratio</span><span class="p">:</span> <span class="mf">0.017</span>
    <span class="n">csr_matrix</span><span class="p">:</span>
      <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">26</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">38</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">39</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">58</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">61</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">67</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">71</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">83</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">88</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">93</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
    <span class="n">ort_sparse</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>
    <span class="n">retrieved</span><span class="p">:</span>
      <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">26</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">38</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">39</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">58</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">61</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">67</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">71</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">83</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">88</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">93</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
</pre></div>
</div>
<p>Previous example was changed to do the same with format
<a class="reference external" href="https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)">COO</a>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">coo_matrix</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">SparseTensor</span> <span class="k">as</span> <span class="n">C_SparseTensor</span><span class="p">,</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">)</span>

<span class="n">ort_device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span>
    <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">default_memory</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">dense</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sparse ratio:&quot;</span><span class="p">,</span> <span class="n">dense</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">dense</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

<span class="n">coo</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">(</span><span class="n">dense</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;coo_matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coo</span><span class="p">)</span>

<span class="n">ort_sparse</span> <span class="o">=</span> <span class="n">C_SparseTensor</span><span class="o">.</span><span class="n">sparse_coo_from_numpy</span><span class="p">(</span>
    <span class="n">coo</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
    <span class="n">coo</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">coo</span><span class="o">.</span><span class="n">row</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">coo</span><span class="o">.</span><span class="n">col</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))]),</span>
    <span class="n">ort_device</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ort_sparse.values() -&gt;&quot;</span><span class="p">,</span> <span class="n">ort_sparse</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="c1"># Back to coo_matrix.</span>
<span class="n">ort_coo</span> <span class="o">=</span> <span class="n">ort_sparse</span><span class="o">.</span><span class="n">get_coo_data</span><span class="p">()</span>

<span class="n">indices</span> <span class="o">=</span> <span class="n">ort_coo</span><span class="o">.</span><span class="n">indices</span><span class="p">()</span>
<span class="n">coo2</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">(</span>
    <span class="p">(</span><span class="n">ort_sparse</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="p">(</span><span class="n">indices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])),</span>
    <span class="n">shape</span><span class="o">=</span><span class="n">ort_sparse</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;retrieved:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coo2</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">sparse</span> <span class="n">ratio</span><span class="p">:</span> <span class="mf">0.025</span>
    <span class="n">coo_matrix</span><span class="p">:</span>
      <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">34</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">41</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">47</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">52</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">66</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">67</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">68</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">83</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">94</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">98</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">98</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">99</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
    <span class="n">ort_sparse</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span>
     <span class="mf">1.</span><span class="p">]</span>
    <span class="n">retrieved</span><span class="p">:</span>
      <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">34</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">41</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">47</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">52</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">66</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">67</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">68</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">83</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">94</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">98</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">98</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>	<span class="mf">1.0</span>
      <span class="p">(</span><span class="mi">99</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>	<span class="mf">1.0</span>
</pre></div>
</div>
</div>
</div>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction to onnxruntime</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="inference.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Inference with onnxruntime in Python</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>