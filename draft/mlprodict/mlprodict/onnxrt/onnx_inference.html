
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>module onnxrt.onnx_inference &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="../../_static/project_ico.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="module onnxrt.onnx_inference_exports" href="onnx_inference_exports.html" />
    <link rel="prev" title="module onnxrt.excs" href="excs.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../i_cmd.html">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../i_index.html">
  FAQ, code, â€¦
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../all_indexes.html">
   All indexes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../all_report.html">
   Statistics on code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../filechanges.html">
   Changes
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../index_module.html">
   Modules
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       __init__
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../__main__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       __main__
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/_create_asv_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark._create_asv_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/asv_exports.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.asv_exports
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/common_asv_skl.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.common_asv_skl
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/create_asv.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.create_asv
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_classifier.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_classifier
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_classifier_raw_scores.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_classifier_raw_scores
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_clustering.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_clustering
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_multi_classifier.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_multi_classifier
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_outlier.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_outlier
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_regressor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_regressor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_trainable_transform.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_trainable_transform
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_transform.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_transform
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../asv_benchmark/template/skl_model_transform_positive.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       asv_benchmark.template.skl_model_transform_positive
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/asv2csv.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.asv2csv
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/asv_bench.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.asv_bench
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/convert_validate.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.convert_validate
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/einsum.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.einsum
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/onnx_code.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.onnx_code
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/optimize.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.optimize
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/replay.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.replay
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/validate.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.validate
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/cc/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.cc
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/cc/c_compilation.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.cc.c_compilation
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/g_sklearn_identify.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.g_sklearn_identify
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/g_sklearn_linear_model.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.g_sklearn_linear_model
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/g_sklearn_main.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.g_sklearn_main
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/g_sklearn_preprocessing.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.g_sklearn_preprocessing
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/g_sklearn_tree.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.g_sklearn_tree
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/g_sklearn_type_helpers.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.g_sklearn_type_helpers
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/api_extension.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar.api_extension
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/exc.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar.exc
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/gactions.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar.gactions
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/gactions_num.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar.gactions_num
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/gactions_tensor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar.gactions_tensor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/gmlactions.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar.gmlactions
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../grammar/grammar_sklearn/grammar/gtypes.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       grammar.grammar_sklearn.grammar.gtypes
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nb_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       nb_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/_cache/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy._cache
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/numpy_onnx_impl.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.numpy_onnx_impl
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/numpy_onnx_impl_body.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.numpy_onnx_impl_body
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/numpy_onnx_impl_skl.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.numpy_onnx_impl_skl
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/numpy_onnx_pyrt.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.numpy_onnx_pyrt
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/numpy_onnx_pyrt_skl.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.numpy_onnx_pyrt_skl
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/onnx_numpy_annotation.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.onnx_numpy_annotation
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/onnx_numpy_compiler.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.onnx_numpy_compiler
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/onnx_numpy_wrapper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.onnx_numpy_wrapper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/onnx_sklearn_wrapper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.onnx_sklearn_wrapper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/onnx_variable.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.onnx_variable
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/onnx_version.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.onnx_version
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/xop.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.xop
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/xop_auto.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.xop_auto
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/xop_auto_import_.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.xop_auto_import_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/xop_convert.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.xop_convert
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/xop_opset.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.xop_opset
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/xop_sphinx.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.xop_sphinx
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../npy/xop_variable.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       npy.xop_variable
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/convert.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.convert
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/helpers/lgbm_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.helpers.lgbm_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/onnx_ops/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.onnx_ops
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/onnx_ops/onnx_complex.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.onnx_ops.onnx_complex
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/onnx_ops/onnx_fft.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.onnx_ops.onnx_fft
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/onnx_ops/onnx_gradient_op.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.onnx_ops.onnx_gradient_op
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/onnx_ops/onnx_tokenizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.onnx_ops.onnx_tokenizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/operator_converters/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.operator_converters
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/operator_converters/conv_lightgbm.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.operator_converters.conv_lightgbm
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/operator_converters/conv_transfer_transformer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.operator_converters.conv_transfer_transformer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/operator_converters/conv_xgboost.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.operator_converters.conv_xgboost
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/operator_converters/parse_lightgbm.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.operator_converters.parse_lightgbm
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/register.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.register
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/register_rewritten_converters.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.register_rewritten_converters
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/scorers/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.scorers
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/scorers/cdist_score.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.scorers.cdist_score
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/scorers/register.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.scorers.register
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/sklconv/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.sklconv
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/sklconv/function_transformer_converters.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.sklconv.function_transformer_converters
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/sklconv/svm_converters.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.sklconv.svm_converters
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/sklconv/tree_converters.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.sklconv.tree_converters
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_conv/validate_scenarios.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_conv.validate_scenarios
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/exports/numpy_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.exports.numpy_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/exports/skl2onnx_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.exports.skl2onnx_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/exports/tf2onnx_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.exports.tf2onnx_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/model_checker.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.model_checker
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx2py_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx2py_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_export.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_export
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_export_templates.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_export_templates
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_grammar/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_grammar
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_grammar/node_visitor_translator.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_grammar.node_visitor_translator
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_grammar/onnx_translation.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_grammar.onnx_translation
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_grammar/onnx_translator.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_grammar.onnx_translator
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_manipulations.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_manipulations
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/onnx_tools.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.onnx_tools
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/_main_onnx_optim.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim._main_onnx_optim
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/_onnx_optimisation_common.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim._onnx_optimisation_common
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/graph_schema_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim.graph_schema_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/onnx_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim.onnx_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/onnx_optimisation.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim.onnx_optimisation
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/onnx_optimisation_identity.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim.onnx_optimisation_identity
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/onnx_optimisation_redundant.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim.onnx_optimisation_redundant
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/onnx_optimisation_unused.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim.onnx_optimisation_unused
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onnx_tools/optim/sklearn_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnx_tools.optim.sklearn_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backend.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.backend
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backend_micropy.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.backend_micropy
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backend_ort.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.backend_ort
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backend_py.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.backend_py
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backend_pyc.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.backend_pyc
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backend_pyeval.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.backend_pyeval
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backend_shape.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.backend_shape
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="doc/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.doc
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="doc/doc_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.doc.doc_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="doc/doc_write_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.doc.doc_write_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="excs.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.excs
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.onnx_inference
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_inference_exports.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.onnx_inference_exports
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_inference_node.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.onnx_inference_node
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_micro_runtime.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.onnx_micro_runtime
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_shape_inference.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.onnx_shape_inference
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/_new_ops.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu._new_ops
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/_op.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu._op
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/_op_classifier_string.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu._op_classifier_string
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/_op_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu._op_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/_op_list.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu._op_list
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/_op_numpy_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu._op_numpy_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/_op_onnx_numpy.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu._op_onnx_numpy
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_abs.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_abs
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_acos.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_acos
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_acosh.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_acosh
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_add.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_add
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_and.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_and
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_argmax.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_argmax
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_argmin.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_argmin
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_array_feature_extractor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_array_feature_extractor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_asin.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_asin
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_asinh.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_asinh
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_atan.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_atan
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_atanh.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_atanh
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_average_pool.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_average_pool
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_batch_normalization.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_batch_normalization
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_binarizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_binarizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_bitshift.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_bitshift
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_broadcast_gradient_args.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_broadcast_gradient_args
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_cast.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_cast
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_category_mapper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_category_mapper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_cdist.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_cdist
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_ceil.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_ceil
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_celu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_celu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_clip.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_clip
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_complex_abs.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_complex_abs
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_compress.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_compress
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_concat.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_concat
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_concat_from_sequence.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_concat_from_sequence
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_constant.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_constant
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_constant_of_shape.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_constant_of_shape
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_conv.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_conv
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_conv_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_conv_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_conv_transpose.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_conv_transpose
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_conv_transpose_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_conv_transpose_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_cos.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_cos
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_cosh.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_cosh
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_cum_sum.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_cum_sum
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_debug.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_debug
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_dequantize_linear.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_dequantize_linear
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_det.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_det
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_dict_vectorizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_dict_vectorizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_div.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_div
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_dropout.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_dropout
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_einsum.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_einsum
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_elu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_elu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_equal.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_equal
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_erf.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_erf
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_exp.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_exp
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_expand.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_expand
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_eyelike.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_eyelike
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_feature_vectorizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_feature_vectorizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_fft.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_fft
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_fft2d.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_fft2d
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_flatten.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_flatten
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_floor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_floor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_fused_matmul.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_fused_matmul
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_gather.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_gather
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_gather_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_gather_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_gather_elements.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_gather_elements
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_gemm.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_gemm
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_global_average_pool.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_global_average_pool
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_greater.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_greater
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_hard_sigmoid.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_hard_sigmoid
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_hardmax.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_hardmax
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_identity.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_identity
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_if.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_if
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_imputer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_imputer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_isinf.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_isinf
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_isnan.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_isnan
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_label_encoder.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_label_encoder
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_leaky_relu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_leaky_relu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_less.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_less
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_linear_classifier.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_linear_classifier
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_linear_regressor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_linear_regressor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_log.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_log
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_log_softmax.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_log_softmax
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_loop.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_loop
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_lp_normalization.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_lp_normalization
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_matmul.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_matmul
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_max.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_max
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_max_pool.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_max_pool
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_max_pool_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_max_pool_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_mean.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_mean
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_min.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_min
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_mod.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_mod
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_mul.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_mul
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_neg.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_neg
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_negative_log_likelihood_loss.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_negative_log_likelihood_loss
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_normalizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_normalizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_not.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_not
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_one_hot_encoder.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_one_hot_encoder
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_or.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_or
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_pad.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_pad
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_pow.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_pow
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_prelu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_prelu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_qlinear_conv.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_qlinear_conv
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_qlinear_conv_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_qlinear_conv_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_quantize_linear.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_quantize_linear
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_random.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_random
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_range.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_range
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reciprocal.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reciprocal
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_l1.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_l1
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_l2.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_l2
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_log_sum.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_log_sum
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_log_sum_exp.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_log_sum_exp
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_max.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_max
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_mean.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_mean
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_min.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_min
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_prod.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_prod
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_sum.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_sum
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reduce_sum_square.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reduce_sum_square
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_relu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_relu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_reshape.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_reshape
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_rfft.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_rfft
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_rnn.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_rnn
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_round.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_round
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_scaler.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_scaler
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_scan.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_scan
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_scatter_elements.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_scatter_elements
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_selu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_selu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sequence_at.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sequence_at
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sequence_construct.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sequence_construct
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sequence_insert.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sequence_insert
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_shape.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_shape
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sigmoid.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sigmoid
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sign.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sign
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sin.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sin
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sinh.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sinh
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_size.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_size
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_slice.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_slice
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_softmax.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_softmax
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_softmax_cross_entropy_loss.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_softmax_cross_entropy_loss
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_solve.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_solve
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_split.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_split
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sqrt.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sqrt
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_squeeze.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_squeeze
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_string_normalizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_string_normalizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sub.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sub
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_sum.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_sum
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_svm_classifier.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_svm_classifier
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_svm_classifier_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_svm_classifier_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_svm_regressor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_svm_regressor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_svm_regressor_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_svm_regressor_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tan.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tan
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tanh.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tanh
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tfidfvectorizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tfidfvectorizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tfidfvectorizer_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tfidfvectorizer_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tokenizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tokenizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_topk.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_topk
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_transpose.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_transpose
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tree_ensemble_classifier.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tree_ensemble_classifier
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tree_ensemble_classifier_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tree_ensemble_classifier_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tree_ensemble_classifier_p_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tree_ensemble_classifier_p_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tree_ensemble_regressor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tree_ensemble_regressor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tree_ensemble_regressor_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tree_ensemble_regressor_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_tree_ensemble_regressor_p_.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_tree_ensemble_regressor_p_
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_trilu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_trilu
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_unsqueeze.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_unsqueeze
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_where.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_where
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_xor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_xor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_yield_op.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_yield_op
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_cpu/op_zipmap.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_cpu.op_zipmap
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_empty/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_empty
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_empty/_op.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_empty._op
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_onnxruntime/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_onnxruntime
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_onnxruntime/_op.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_onnxruntime._op
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_shape/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_shape
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_shape/_element_unary.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_shape._element_unary
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_shape/_element_wise.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_shape._element_wise
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_shape/_op_shape_op.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_shape._op_shape_op
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_shape/shape_container.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_shape.shape_container
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_shape/shape_excs.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_shape.shape_excs
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_shape/shape_result.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_shape.shape_result
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_whole/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_whole
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ops_whole/session.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.ops_whole.session
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="shape_object.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.shape_object
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="type_object.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.type_object
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/_validate_problems_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate._validate_problems_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/data/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.data
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/side_by_side.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.side_by_side
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_benchmark.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_benchmark
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_benchmark_replay.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_benchmark_replay
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_difference.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_difference
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_latency.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_latency
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_problems.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_problems
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_python.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_python
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_scenarios.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_scenarios
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="validate/validate_summary.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       onnxrt.validate.validate_summary
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/plotting.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting.plotting
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/plotting_benchmark.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting.plotting_benchmark
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/plotting_onnx.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting.plotting_onnx
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/plotting_validate_graph.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting.plotting_validate_graph
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/text_plot.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting.text_plot
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sklapi/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       sklapi
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sklapi/onnx_pipeline.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       sklapi.onnx_pipeline
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sklapi/onnx_speed_up.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       sklapi.onnx_speed_up
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sklapi/onnx_tokenizer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       sklapi.onnx_tokenizer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sklapi/onnx_transformer.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       sklapi.onnx_transformer
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/blas_lapack.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.blas_lapack
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/direct_blas_lapack.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.direct_blas_lapack
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/einsum_bench.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.einsum_bench
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/einsum_fct.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.einsum_fct
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/einsum_impl.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.einsum_impl
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/einsum_impl_classes.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.einsum_impl_classes
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/einsum_impl_ext.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.einsum_impl_ext
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/einsum/einsum_ml.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.einsum.einsum_ml
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/experimental.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.experimental
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/experimental_c_impl/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.experimental_c_impl
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/experimental_c_impl/experimental_c.cpython-39-x86_64-linux-gnu.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.experimental_c_impl.experimental_c
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/model_verification.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.model_verification
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/onnx_backend.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.onnx_backend
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/script_testing.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.script_testing
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/quantized_tensor.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils.quantized_tensor
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/tests_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils.tests_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/utils_backend.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils.utils_backend
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/utils_backend_common.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils.utils_backend_common
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/utils_backend_common_compare.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils.utils_backend_common_compare
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/utils_backend_onnxruntime.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils.utils_backend_onnxruntime
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/test_utils/utils_backend_python.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.test_utils.utils_backend_python
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../testing/verify_code.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       testing.verify_code
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/asv_options_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.asv_options_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/cleaning.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.cleaning
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/code_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.code_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/filename_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.filename_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/graphs.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.graphs
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/model_info.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.model_info
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/onnx_inference_ort_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.onnx_inference_ort_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/ort_wrapper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.ort_wrapper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tools/zoo.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       tools.zoo
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../i_faq.html">
   FAQ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../i_nb.html">
   Magic commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../blog/blogindex.html">
   Blog Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../license.html">
   License
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   mlprodict
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#short-summary">
   Short summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classes">
   Classes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties">
   Properties
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#static-methods">
   Static Methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods">
   Methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-mlprodict.onnxrt.onnx_inference">
   Documentation
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="module-onnxrt-onnx-inference">
<span id="f-onnxinference"></span><h1>module <code class="docutils literal notranslate"><span class="pre">onnxrt.onnx_inference</span></code><a class="headerlink" href="#module-onnxrt-onnx-inference" title="Permalink to this headline">#</a></h1>
<div class="graphviz"><object data="../../_images/inheritance-11003aa7b88fcebd09194828a86d19e45662401b.svg" type="image/svg+xml" class="inheritance graphviz">
<p class="warning">Inheritance diagram of mlprodict.onnxrt.onnx_inference</p></object></div>
<section id="short-summary">
<h2>Short summary<a class="headerlink" href="#short-summary" title="Permalink to this headline">#</a></h2>
<p>module <code class="docutils literal notranslate"><span class="pre">mlprodict.onnxrt.onnx_inference</span></code></p>
<p>Implements a class able to compute the predictions
from on an <a class="reference external" href="https://onnx.ai/">ONNX</a> model.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L7">source on GitHub</a></p>
</section>
<section id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">#</a></h2>
<table class="table">
<colgroup>
<col style="width: 38%" />
<col style="width: 62%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>class</p></th>
<th class="head"><p>truncated documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference" title="mlprodict.onnxrt.onnx_inference.OnnxInference"><code class="xref py py-class docutils literal notranslate"><span class="pre">OnnxInference</span></code></a></p></td>
<td><p>Loads an <a class="reference external" href="https://onnx.ai/">ONNX</a> file or object or stream. Computes the output of the <a class="reference external" href="https://onnx.ai/">ONNX</a> graph. Several runtimes â€¦</p></td>
</tr>
</tbody>
</table>
</section>
<section id="properties">
<h2>Properties<a class="headerlink" href="#properties" title="Permalink to this headline">#</a></h2>
<table class="table">
<colgroup>
<col style="width: 49%" />
<col style="width: 51%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>property</p></th>
<th class="head"><p>truncated documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.input_names" title="mlprodict.onnxrt.onnx_inference.OnnxInference.input_names"><code class="xref py py-meth docutils literal notranslate"><span class="pre">input_names</span></code></a></p></td>
<td><p>Returns the names of all inputs. It does not include the optional inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes" title="mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">input_names_shapes</span></code></a></p></td>
<td><p>Returns the names and shapes of all inputs. This method assumes all inputs are tensors. It does not include â€¦</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes_types" title="mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes_types"><code class="xref py py-meth docutils literal notranslate"><span class="pre">input_names_shapes_types</span></code></a></p></td>
<td><p>Returns the names, shapes, types of all inputs. This method assumes all inputs are tensors. It does not â€¦</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.output_names" title="mlprodict.onnxrt.onnx_inference.OnnxInference.output_names"><code class="xref py py-meth docutils literal notranslate"><span class="pre">output_names</span></code></a></p></td>
<td><p>Returns the names of all outputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes" title="mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">output_names_shapes</span></code></a></p></td>
<td><p>Returns the names and shapes of all outputs. This method assumes all inputs are tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes_types" title="mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes_types"><code class="xref py py-meth docutils literal notranslate"><span class="pre">output_names_shapes_types</span></code></a></p></td>
<td><p>Returns the names, shapes, types of all outputs. This method assumes all inputs are tensors. It does not â€¦</p></td>
</tr>
</tbody>
</table>
</section>
<section id="static-methods">
<h2>Static Methods<a class="headerlink" href="#static-methods" title="Permalink to this headline">#</a></h2>
<table class="table">
<colgroup>
<col style="width: 80%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>staticmethod</p></th>
<th class="head"><p>truncated documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._get_type_property" title="mlprodict.onnxrt.onnx_inference.OnnxInference._get_type_property"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_get_type_property</span></code></a></p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="methods">
<h2>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">#</a></h2>
<table class="table">
<colgroup>
<col style="width: 48%" />
<col style="width: 52%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>method</p></th>
<th class="head"><p>truncated documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__getitem__" title="mlprodict.onnxrt.onnx_inference.OnnxInference.__getitem__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__getitem__</span></code></a></p></td>
<td><p>Returns the ONNX verions of a node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__getstate__" title="mlprodict.onnxrt.onnx_inference.OnnxInference.__getstate__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__getstate__</span></code></a></p></td>
<td><p>To pickle the object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__init__" title="mlprodict.onnxrt.onnx_inference.OnnxInference.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__repr__" title="mlprodict.onnxrt.onnx_inference.OnnxInference.__repr__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__repr__</span></code></a></p></td>
<td><p>usual</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__setstate__" title="mlprodict.onnxrt.onnx_inference.OnnxInference.__setstate__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__setstate__</span></code></a></p></td>
<td><p>To unpickle the object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__str__" title="mlprodict.onnxrt.onnx_inference.OnnxInference.__str__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__str__</span></code></a></p></td>
<td><p>usual</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run" title="mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_build_compile_run</span></code></a></p></td>
<td><p>Rewrite the run function in python, compiles it, and adds it as a method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._guess_inplace" title="mlprodict.onnxrt.onnx_inference.OnnxInference._guess_inplace"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_guess_inplace</span></code></a></p></td>
<td><p>Looks into every node of the graph to see if there is a way to do the computation inplace. By default (<em>input_inplace=False</em>), â€¦</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._guess_input_dtype" title="mlprodict.onnxrt.onnx_inference.OnnxInference._guess_input_dtype"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_guess_input_dtype</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._init" title="mlprodict.onnxrt.onnx_inference.OnnxInference._init"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_init</span></code></a></p></td>
<td><p>Prepares the instance to deliver predictions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime" title="mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_run_sequence_runtime</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime_compiled" title="mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime_compiled"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_run_sequence_runtime_compiled</span></code></a></p></td>
<td><p>Executes a compiled version of <code class="xref py py-meth docutils literal notranslate"><span class="pre">_run_sequence_runtime()</span></code>, compiled with method <code class="xref py py-meth docutils literal notranslate"><span class="pre">_build_compile_run()</span></code>. â€¦</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._run_whole_runtime" title="mlprodict.onnxrt.onnx_inference.OnnxInference._run_whole_runtime"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_run_whole_runtime</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._set_shape_inference_runtime" title="mlprodict.onnxrt.onnx_inference.OnnxInference._set_shape_inference_runtime"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_set_shape_inference_runtime</span></code></a></p></td>
<td><p>Set shapes based on shape inference relying on the runtime. The values are stored in every node.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._set_size_inference_runtime" title="mlprodict.onnxrt.onnx_inference.OnnxInference._set_size_inference_runtime"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_set_size_inference_runtime</span></code></a></p></td>
<td><p>Set sizes allocated during inference relying on the runtime. The values are stored in every node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._set_type_inference_runtime" title="mlprodict.onnxrt.onnx_inference.OnnxInference._set_type_inference_runtime"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_set_type_inference_runtime</span></code></a></p></td>
<td><p>Set types based on type inference relying on the runtime. The values are stored in every node.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.build_intermediate" title="mlprodict.onnxrt.onnx_inference.OnnxInference.build_intermediate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_intermediate</span></code></a></p></td>
<td><p>Builds every possible <a class="reference external" href="https://onnx.ai/">ONNX</a> file which computes one specific intermediate output from the inputs. â€¦</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.check_model" title="mlprodict.onnxrt.onnx_inference.OnnxInference.check_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">check_model</span></code></a></p></td>
<td><p>Checks the model follow <a class="reference external" href="https://onnx.ai/">ONNX</a> conventions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.display_sequence" title="mlprodict.onnxrt.onnx_inference.OnnxInference.display_sequence"><code class="xref py py-meth docutils literal notranslate"><span class="pre">display_sequence</span></code></a></p></td>
<td><p>Shows the sequence of nodes to run if <code class="docutils literal notranslate"><span class="pre">runtime=='python'</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.get_execution_order" title="mlprodict.onnxrt.onnx_inference.OnnxInference.get_execution_order"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_execution_order</span></code></a></p></td>
<td><p>This function returns a dictionary <cite>{(kind, name): (order, op)}</cite>, <em>name</em> can be a node name or a result name. In â€¦</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.get_profiling" title="mlprodict.onnxrt.onnx_inference.OnnxInference.get_profiling"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_profiling</span></code></a></p></td>
<td><p>Returns the profiling after a couple of execution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.global_index" title="mlprodict.onnxrt.onnx_inference.OnnxInference.global_index"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_index</span></code></a></p></td>
<td><p>Maps every name to one integer to avoid using dictionaries when running the predictions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.infer_shapes" title="mlprodict.onnxrt.onnx_inference.OnnxInference.infer_shapes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">infer_shapes</span></code></a></p></td>
<td><p>Computes expected shapes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.infer_sizes" title="mlprodict.onnxrt.onnx_inference.OnnxInference.infer_sizes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">infer_sizes</span></code></a></p></td>
<td><p>Computes expected sizes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.infer_types" title="mlprodict.onnxrt.onnx_inference.OnnxInference.infer_types"><code class="xref py py-meth docutils literal notranslate"><span class="pre">infer_types</span></code></a></p></td>
<td><p>Computes expected shapes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.reduce_size" title="mlprodict.onnxrt.onnx_inference.OnnxInference.reduce_size"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reduce_size</span></code></a></p></td>
<td><p>Reduces the memory footprint as much as possible.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.run" title="mlprodict.onnxrt.onnx_inference.OnnxInference.run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run</span></code></a></p></td>
<td><p>Computes the predictions for this <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.run2onnx" title="mlprodict.onnxrt.onnx_inference.OnnxInference.run2onnx"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run2onnx</span></code></a></p></td>
<td><p>Executes the graphs with the given inputs, then adds the intermediate results into ONNX nodes in the original graph. â€¦</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.shape_inference" title="mlprodict.onnxrt.onnx_inference.OnnxInference.shape_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">shape_inference</span></code></a></p></td>
<td><p>Infers the shape of the outputs with <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> package.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.switch_initializers_dtype" title="mlprodict.onnxrt.onnx_inference.OnnxInference.switch_initializers_dtype"><code class="xref py py-meth docutils literal notranslate"><span class="pre">switch_initializers_dtype</span></code></a></p></td>
<td><p>Switches all initializers to <code class="docutils literal notranslate"><span class="pre">numpy.float64</span></code>. If <em>model</em> is None, a simple cast is done. Otherwise, the function â€¦</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.to_sequence" title="mlprodict.onnxrt.onnx_inference.OnnxInference.to_sequence"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to_sequence</span></code></a></p></td>
<td><p>Produces a graph to facilitate the execution. One example:</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-mlprodict.onnxrt.onnx_inference">
<span id="documentation"></span><h2>Documentation<a class="headerlink" href="#module-mlprodict.onnxrt.onnx_inference" title="Permalink to this headline">#</a></h2>
<p>Implements a class able to compute the predictions
from on an <a class="reference external" href="https://onnx.ai/">ONNX</a> model.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L7">source on GitHub</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlprodict.onnxrt.onnx_inference.</span></span><span class="sig-name descname"><span class="pre">OnnxInference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_or_bytes_or_stream</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_run</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ir_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_opset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">session_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inside_loop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_opset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">existing_functions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Loads an <a class="reference external" href="https://onnx.ai/">ONNX</a> file or object or stream.
Computes the output of the <a class="reference external" href="https://onnx.ai/">ONNX</a> graph.
Several runtimes are available.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'python'</span></code>: the runtime implements every onnx operator
needed to run a <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> model by using <a class="reference external" href="https://www.numpy.org/">numpy</a>
or C++ code.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'python_compiled'</span></code>: it is the same runtime than the previous
one except every operator is called from a compiled function
(<a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run" title="mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_build_compile_run</span></code></a>) instead for a method going through
the list of operator</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'onnxruntime1'</span></code>: uses <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> (or <cite>onnxruntime1-cuda</cite>, â€¦)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'onnxruntime2'</span></code>: this mode is mostly used to debug as
python handles calling every operator but <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a>
is called for every of them, this process may fail due to
wrong inference type specially of the graph includes
custom nodes, in that case, it is better to compute the output
of intermediates nodes. It is much slower as fo every output, every
node is computed but more robust.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onnx_or_bytes_or_stream</strong> â€“ <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> object,
bytes, or filename or stream</p></li>
<li><p><strong>runtime</strong> â€“ runtime options</p></li>
<li><p><strong>skip_run</strong> â€“ do not build the runtime</p></li>
<li><p><strong>inplace</strong> â€“ use inplace computation as much as possible</p></li>
<li><p><strong>input_inplace</strong> â€“ the computation is allowed
to overwrite the input, see <a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._guess_inplace" title="mlprodict.onnxrt.onnx_inference.OnnxInference._guess_inplace"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_guess_inplace</span></code></a></p></li>
<li><p><strong>ir_version</strong> â€“ if not None, overwrite the default version</p></li>
<li><p><strong>target_opset</strong> â€“ used to overwrite <em>target_opset</em></p></li>
<li><p><strong>runtime_options</strong> â€“ specific options for the runtime</p></li>
<li><p><strong>inside_loop</strong> â€“ tells the runtime the graph is meant to
be repeated multiple times (in that case, inputs and
outputs may share the same name)</p></li>
<li><p><strong>static_inputs</strong> â€“ Loop can use static variables,
variables from the graph which runs the loop
(enumerate of strings)</p></li>
<li><p><strong>new_outputs</strong> â€“ if the loading fails, it might worth
cutting the graph, if not None, the graph will
be cut to have these new_outputs as the final outputs</p></li>
<li><p><strong>new_opset</strong> â€“ overwrite the main opset and replaces
by this new one</p></li>
<li><p><strong>existing_functions</strong> â€“ a model may contain several local functions,
this parameter is used when a local function is calling another
local function previously defined.</p></li>
</ul>
</dd>
</dl>
<p>Among the possible runtime_options, there are:
* <em>enable_profiling</em>: enables profiling for <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a>
* <em>session_options</em>: an instance of <em>SessionOptions</em> from</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a></p>
</div></blockquote>
<ul class="simple">
<li><p><em>ir_version</em>: change ir_version</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.7: </span>Parameters <em>new_outputs</em>, <em>new_opset</em> were added.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.8: </span>Parameters <em>static_inputs</em>, <em>device</em> were added.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.9: </span>Parameters <em>existing_functions</em> was added.
Removes <em>device</em> parameter. See runtime.
Runtime <cite>onnxruntime1-cuda</cite> was added.</p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L96">source on GitHub</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__getitem__" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the ONNX verions of a node.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1195">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.__getstate__">
<span class="sig-name descname"><span class="pre">__getstate__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__getstate__" title="Permalink to this definition">#</a></dt>
<dd><p>To pickle the object.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L142">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_or_bytes_or_stream</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_run</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ir_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_opset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">session_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inside_loop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_opset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">existing_functions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__init__" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__repr__" title="Permalink to this definition">#</a></dt>
<dd><p>usual</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L330">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.__setstate__">
<span class="sig-name descname"><span class="pre">__setstate__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__setstate__" title="Permalink to this definition">#</a></dt>
<dd><p>To unpickle the object.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L156">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.__str__">
<span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.__str__" title="Permalink to this definition">#</a></dt>
<dd><p>usual</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L317">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run">
<span class="sig-name descname"><span class="pre">_build_compile_run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run" title="Permalink to this definition">#</a></dt>
<dd><p>Rewrite the run function in python,
compiles it, and adds it as a method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>debug</strong> â€“ insert debugging code</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>method name, callable object</p>
</dd>
</dl>
<div class="admonition-exref admonition" id="indexexref-ex0">
<p class="admonition-title">Run a model with runtime â€˜python_compiledâ€™</p>
<p>The following code trains a model and compute
the predictions with runtime <code class="docutils literal notranslate"><span class="pre">'python_compiled'</span></code>.
It converts the onnx graph into a python function
which calls every operator. Its code is printed
below.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt</span> <span class="kn">import</span> <span class="n">OnnxInference</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">clr</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
    <span class="n">base_estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">clr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">model_def</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">clr</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="n">target_opset</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="n">oinf2</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">model_def</span><span class="p">,</span> <span class="n">runtime</span><span class="o">=</span><span class="s1">&#39;python_compiled&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">oinf2</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">]}))</span>

<span class="c1"># prints out the python function equivalent</span>
<span class="c1"># to the onnx graph</span>
<span class="nb">print</span><span class="p">(</span><span class="n">oinf2</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">{</span><span class="s1">&#39;output_label&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="s1">&#39;output_probability&#39;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="n">OnnxInference</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">compiled_run</span><span class="p">(</span><span class="n">dict_inputs</span><span class="p">,</span> <span class="n">yield_ops</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">yield_ops</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;yields_ops should be None.&#39;</span><span class="p">)</span>
            <span class="c1"># init: classes (classes)</span>
            <span class="c1"># init: clip_min (clip_min)</span>
            <span class="c1"># init: inverted_n_classes (inverted_n_classes)</span>
            <span class="c1"># init: mul_operand (mul_operand)</span>
            <span class="c1"># init: n_classes_minus_one (n_classes_minus_one)</span>
            <span class="c1"># init: shape_tensor (shape_tensor)</span>
            <span class="c1"># init: shape_tensor3 (shape_tensor3)</span>
            <span class="c1"># init: zero_scalar (zero_scalar)</span>
            <span class="c1"># inputs</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">dict_inputs</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
            <span class="p">(</span><span class="n">elab_name_0</span><span class="p">,</span> <span class="n">eprob_name_0</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n0_treeensembleclassifier_1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="p">(</span><span class="n">elab_name_1</span><span class="p">,</span> <span class="n">eprob_name_1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n1_treeensembleclassifier_1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="p">(</span><span class="n">clipped_proba1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n2_clip_11</span><span class="p">(</span><span class="n">eprob_name_1</span><span class="p">,</span> <span class="n">clip_min</span><span class="p">)</span>
            <span class="p">(</span><span class="n">clipped_proba</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n3_clip_11</span><span class="p">(</span><span class="n">eprob_name_0</span><span class="p">,</span> <span class="n">clip_min</span><span class="p">)</span>
            <span class="p">(</span><span class="n">log_proba1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n4_log</span><span class="p">(</span><span class="n">clipped_proba1</span><span class="p">)</span>
            <span class="p">(</span><span class="n">log_proba</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n5_log</span><span class="p">(</span><span class="n">clipped_proba</span><span class="p">)</span>
            <span class="p">(</span><span class="n">reduced_proba1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n6_reducesum_11</span><span class="p">(</span><span class="n">log_proba1</span><span class="p">)</span>
            <span class="p">(</span><span class="n">reduced_proba</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n7_reducesum_11</span><span class="p">(</span><span class="n">log_proba</span><span class="p">)</span>
            <span class="p">(</span><span class="n">reshaped_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n8_reshape_5</span><span class="p">(</span><span class="n">reduced_proba</span><span class="p">,</span> <span class="n">shape_tensor</span><span class="p">)</span>
            <span class="p">(</span><span class="n">reshaped_result1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n9_reshape_5</span><span class="p">(</span><span class="n">reduced_proba1</span><span class="p">,</span> <span class="n">shape_tensor</span><span class="p">)</span>
            <span class="p">(</span><span class="n">prod_result1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n10_mul</span><span class="p">(</span><span class="n">reshaped_result1</span><span class="p">,</span> <span class="n">inverted_n_classes</span><span class="p">)</span>
            <span class="p">(</span><span class="n">prod_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n11_mul</span><span class="p">(</span><span class="n">reshaped_result</span><span class="p">,</span> <span class="n">inverted_n_classes</span><span class="p">)</span>
            <span class="p">(</span><span class="n">sub_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n12_sub</span><span class="p">(</span><span class="n">log_proba</span><span class="p">,</span> <span class="n">prod_result</span><span class="p">)</span>
            <span class="p">(</span><span class="n">sub_result1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n13_sub</span><span class="p">(</span><span class="n">log_proba1</span><span class="p">,</span> <span class="n">prod_result1</span><span class="p">)</span>
            <span class="p">(</span><span class="n">samme_proba</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n14_mul</span><span class="p">(</span><span class="n">sub_result</span><span class="p">,</span> <span class="n">n_classes_minus_one</span><span class="p">)</span>
            <span class="p">(</span><span class="n">samme_proba1</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n15_mul</span><span class="p">(</span><span class="n">sub_result1</span><span class="p">,</span> <span class="n">n_classes_minus_one</span><span class="p">)</span>
            <span class="p">(</span><span class="n">summation_prob</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n16_sum</span><span class="p">(</span><span class="n">samme_proba</span><span class="p">,</span> <span class="n">samme_proba1</span><span class="p">)</span>
            <span class="p">(</span><span class="n">div_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n17_div</span><span class="p">(</span><span class="n">summation_prob</span><span class="p">,</span> <span class="n">n_classes_minus_one</span><span class="p">)</span>
            <span class="p">(</span><span class="n">exp_operand</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n18_mul</span><span class="p">(</span><span class="n">div_result</span><span class="p">,</span> <span class="n">mul_operand</span><span class="p">)</span>
            <span class="p">(</span><span class="n">exp_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n19_exp</span><span class="p">(</span><span class="n">exp_operand</span><span class="p">)</span>
            <span class="p">(</span><span class="n">reduced_exp_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n20_reducesum_11</span><span class="p">(</span><span class="n">exp_result</span><span class="p">)</span>
            <span class="p">(</span><span class="n">normaliser</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n21_reshape_5</span><span class="p">(</span><span class="n">reduced_exp_result</span><span class="p">,</span> <span class="n">shape_tensor</span><span class="p">)</span>
            <span class="p">(</span><span class="n">cast_normaliser</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n22_cast</span><span class="p">(</span><span class="n">normaliser</span><span class="p">)</span>
            <span class="p">(</span><span class="n">comparison_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n23_equal</span><span class="p">(</span><span class="n">cast_normaliser</span><span class="p">,</span> <span class="n">zero_scalar</span><span class="p">)</span>
            <span class="p">(</span><span class="n">cast_output</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n24_cast</span><span class="p">(</span><span class="n">comparison_result</span><span class="p">)</span>
            <span class="p">(</span><span class="n">zero_filtered_normaliser</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n25_add</span><span class="p">(</span><span class="n">normaliser</span><span class="p">,</span> <span class="n">cast_output</span><span class="p">)</span>
            <span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n26_div</span><span class="p">(</span><span class="n">exp_result</span><span class="p">,</span> <span class="n">zero_filtered_normaliser</span><span class="p">)</span>
            <span class="p">(</span><span class="n">output_probability</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n27_zipmap</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
            <span class="p">(</span><span class="n">argmax_output</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n28_argmax_12</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
            <span class="p">(</span><span class="n">array_feature_extractor_result</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n29_arrayfeatureextractor</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">argmax_output</span><span class="p">)</span>
            <span class="p">(</span><span class="n">reshaped_result2</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n30_reshape_5</span><span class="p">(</span><span class="n">array_feature_extractor_result</span><span class="p">,</span> <span class="n">shape_tensor3</span><span class="p">)</span>
            <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n31_cast</span><span class="p">(</span><span class="n">reshaped_result2</span><span class="p">)</span>
            <span class="p">(</span><span class="n">output_label</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">n32_cast</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s1">&#39;output_label&#39;</span><span class="p">:</span> <span class="n">output_label</span><span class="p">,</span>
                <span class="s1">&#39;output_probability&#39;</span><span class="p">:</span> <span class="n">output_probability</span><span class="p">,</span>
            <span class="p">}</span>
</pre></div>
</div>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1586">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._get_type_property">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">_get_type_property</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">info</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prop</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._get_type_property" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._guess_inplace">
<span class="sig-name descname"><span class="pre">_guess_inplace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._guess_inplace" title="Permalink to this definition">#</a></dt>
<dd><p>Looks into every node of the graph to see
if there is a way to do the computation
inplace. By default (<em>input_inplace=False</em>),
the function assumes inputs cannot be modified
so the first node cannot do inplace computation.
This function only works with the python runtime.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_inplace</strong> â€“ the computation is allowed
to overwrite the input</p>
</dd>
</dl>
<p>This function checks that one node is used only
once and then can be modified by the next node.
Nodes <cite>A</cite>, <cite>C</cite> can be overwritten by the computation.
Node <cite>B</cite> cannot as it is used by two nodes.</p>
<div class="align-default"><img height="200" src="../../_images/blockdiag-d28ebc69b9a8de4eecc87395c2c774b3f025427e.png" width="832" /></div>
<p>It does not handle specific case such node <cite>B</cite> being
overwritten by node <cite>C</cite> but without changing its shape
and node <cite>D</cite> only needs the shape of <cite>B</cite>. Then <cite>B</cite> could
be overwritten as well.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1491">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._guess_input_dtype">
<span class="sig-name descname"><span class="pre">_guess_input_dtype</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._guess_input_dtype" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._init">
<span class="sig-name descname"><span class="pre">_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">existing_functions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._init" title="Permalink to this definition">#</a></dt>
<dd><p>Prepares the instance to deliver predictions.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L172">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime">
<span class="sig-name descname"><span class="pre">_run_sequence_runtime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_right_away</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yield_ops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fLOG</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime_compiled">
<span class="sig-name descname"><span class="pre">_run_sequence_runtime_compiled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_right_away</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yield_ops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fLOG</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime_compiled" title="Permalink to this definition">#</a></dt>
<dd><p>Executes a compiled version of <a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime" title="mlprodict.onnxrt.onnx_inference.OnnxInference._run_sequence_runtime"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_run_sequence_runtime</span></code></a>,
compiled with method <a class="reference internal" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run" title="mlprodict.onnxrt.onnx_inference.OnnxInference._build_compile_run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_build_compile_run</span></code></a>.
Every parameter with a default value is ignored.
Switch to <code class="docutils literal notranslate"><span class="pre">runtime='python'</span></code> to enable those.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L293">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._run_whole_runtime">
<span class="sig-name descname"><span class="pre">_run_whole_runtime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_right_away</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yield_ops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fLOG</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._run_whole_runtime" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._set_shape_inference_runtime">
<span class="sig-name descname"><span class="pre">_set_shape_inference_runtime</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._set_shape_inference_runtime" title="Permalink to this definition">#</a></dt>
<dd><p>Set shapes based on shape inference
relying on the runtime.
The values are stored in every node.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1300">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._set_size_inference_runtime">
<span class="sig-name descname"><span class="pre">_set_size_inference_runtime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._set_size_inference_runtime" title="Permalink to this definition">#</a></dt>
<dd><p>Set sizes allocated during inference
relying on the runtime.
The values are stored in every node.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1420">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference._set_type_inference_runtime">
<span class="sig-name descname"><span class="pre">_set_type_inference_runtime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference._set_type_inference_runtime" title="Permalink to this definition">#</a></dt>
<dd><p>Set types based on type inference
relying on the runtime.
The values are stored in every node.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1364">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.build_intermediate">
<span class="sig-name descname"><span class="pre">build_intermediate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fLOG</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.build_intermediate" title="Permalink to this definition">#</a></dt>
<dd><p>Builds every possible <a class="reference external" href="https://onnx.ai/">ONNX</a> file
which computes one specific intermediate output
from the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> â€“ subsets of outputs to get,
None to get all outputs,</p></li>
<li><p><strong>overwrite_types</strong> â€“ shape inference does not work all the time,
this allows to force types when building intermediate
results, see <a class="reference internal" href="../onnx_tools/onnx_manipulations.html#mlprodict.onnx_tools.onnx_manipulations.select_model_inputs_outputs" title="mlprodict.onnx_tools.onnx_manipulations.select_model_inputs_outputs"><code class="xref py py-func docutils literal notranslate"><span class="pre">select_model_inputs_outputs</span></code></a></p></li>
<li><p><strong>verbose</strong> â€“ displays intermediate information</p></li>
<li><p><strong>fLOG</strong> â€“ logging function</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.OrderedDict">collections.OrderedDict</a></p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1089">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.check_model">
<span class="sig-name descname"><span class="pre">check_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.check_model" title="Permalink to this definition">#</a></dt>
<dd><p>Checks the model follow <a class="reference external" href="https://onnx.ai/">ONNX</a> conventions.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L336">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.display_sequence">
<span class="sig-name descname"><span class="pre">display_sequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.display_sequence" title="Permalink to this definition">#</a></dt>
<dd><p>Shows the sequence of nodes to run if <code class="docutils literal notranslate"><span class="pre">runtime=='python'</span></code>.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L888">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.get_execution_order">
<span class="sig-name descname"><span class="pre">get_execution_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.get_execution_order" title="Permalink to this definition">#</a></dt>
<dd><p>This function returns a dictionary <cite>{(kind, name): (order, op)}</cite>,
<em>name</em> can be a node name or a result name. In that case,
it gets the execution order than the node which created it.
The function returns None if the order is not available
(the selected runtime does not return it). <em>kind</em> is either
<cite>â€˜nodeâ€™</cite> or <cite>â€˜nodeâ€™</cite>. If two nodes have the same name,
returned order is the last one. Initializers gets an execution
order equal to -1, inputs to 0, all others results are &gt;= 1.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.7.</span></p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1759">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.get_profiling">
<span class="sig-name descname"><span class="pre">get_profiling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">as_df</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.get_profiling" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the profiling after a couple of execution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>as_df</strong> â€“ return the results as a dataframe (True)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dataframe or list of dictionaries</p>
</dd>
</dl>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.6.</span></p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1730">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.global_index">
<span class="sig-name descname"><span class="pre">global_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.global_index" title="Permalink to this definition">#</a></dt>
<dd><p>Maps every name to one integer to avoid using dictionaries
when running the predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> â€“ outputs name</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>integer</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L452">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.infer_shapes">
<span class="sig-name descname"><span class="pre">infer_shapes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.infer_shapes" title="Permalink to this definition">#</a></dt>
<dd><p>Computes expected shapes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>dictionary of shapes</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1356">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.infer_sizes">
<span class="sig-name descname"><span class="pre">infer_sizes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.infer_sizes" title="Permalink to this definition">#</a></dt>
<dd><p>Computes expected sizes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> â€“ inputs as a dictionary</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary of dictionary of sizes</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1459">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.infer_types">
<span class="sig-name descname"><span class="pre">infer_types</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.infer_types" title="Permalink to this definition">#</a></dt>
<dd><p>Computes expected shapes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> â€“ needed when this class host a function and not a graph</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary of types</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1412">source on GitHub</a></p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.input_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_names</span></span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.input_names" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the names of all inputs.
It does not include the optional inputs.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.6: </span>The list does not include optional inputs anymore.</p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L356">source on GitHub</a></p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_names_shapes</span></span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the names and shapes of all inputs.
This method assumes all inputs are tensors.
It does not include the optional inputs.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.6: </span>The list does not include optional inputs anymore.</p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L371">source on GitHub</a></p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes_types">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_names_shapes_types</span></span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.input_names_shapes_types" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the names, shapes, types of all inputs.
This method assumes all inputs are tensors.
It does not include the optional inputs.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.6: </span>The list does not include optional inputs anymore.</p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L396">source on GitHub</a></p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.output_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_names</span></span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.output_names" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the names of all outputs.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L411">source on GitHub</a></p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_names_shapes</span></span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the names and shapes of all outputs.
This method assumes all inputs are tensors.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L421">source on GitHub</a></p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes_types">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_names_shapes_types</span></span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.output_names_shapes_types" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the names, shapes, types of all outputs.
This method assumes all inputs are tensors.
It does not include the optional outputs.</p>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L436">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.reduce_size">
<span class="sig-name descname"><span class="pre">reduce_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pickable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.reduce_size" title="Permalink to this definition">#</a></dt>
<dd><p>Reduces the memory footprint as much as possible.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>pickable</strong> â€“ keeps a pickle object?</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1713">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_right_away</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yield_ops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fLOG</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.run" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the predictions for this <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> â€“ inputs as dictionary or a dataframe</p></li>
<li><p><strong>clean_right_away</strong> â€“ clean the intermediate outputs
as soon as they are not needed</p></li>
<li><p><strong>intermediate</strong> â€“ returns a dictionary of intermediate
variables instead of the results only</p></li>
<li><p><strong>verbose</strong> â€“ display information while predicting</p></li>
<li><p><strong>node_time</strong> â€“ measure time of each node</p></li>
<li><p><strong>overwrite_types</strong> â€“ shape inference does not work all the time,
this allows to force types when building intermediate
results, see <a class="reference internal" href="../onnx_tools/onnx_manipulations.html#mlprodict.onnx_tools.onnx_manipulations.select_model_inputs_outputs" title="mlprodict.onnx_tools.onnx_manipulations.select_model_inputs_outputs"><code class="xref py py-func docutils literal notranslate"><span class="pre">select_model_inputs_outputs</span></code></a></p></li>
<li><p><strong>yield_ops</strong> â€“ dictionary to overwrite the output of
operator <em>YieldOp</em></p></li>
<li><p><strong>fLOG</strong> â€“ logging function if <em>verbose &gt; 0</em></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>outputs as dictionary
and a second dictionary of the time spent
in each node if <em>node_time</em> is True</p>
</dd>
</dl>
<div class="admonition-exref admonition" id="indexexref-ex1">
<p class="admonition-title">Computes predictions with any runtime</p>
<p>The following example compares predictions
between <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> and this runtime
for the python runtime.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt</span> <span class="kn">import</span> <span class="n">OnnxInference</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">clr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">clr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">exp</span> <span class="o">=</span> <span class="n">clr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span>

<span class="n">model_def</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">clr</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="n">target_opset</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">oinf</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">model_def</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">oinf</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">]})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[</span> <span class="mf">1.197</span>  <span class="mf">1.451</span> <span class="o">-</span><span class="mf">0.042</span>  <span class="mf">1.362</span>  <span class="mf">1.603</span><span class="p">]</span>
    <span class="p">{</span><span class="s1">&#39;variable&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([[</span> <span class="mf">1.197</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">1.451</span><span class="p">],</span>
           <span class="p">[</span><span class="o">-</span><span class="mf">0.042</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">1.362</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">1.603</span><span class="p">]])}</span>
</pre></div>
</div>
</div>
<p>The function returns all intermediate outputs
if <em>intermediate</em> is True. In case of runtime
<em>onnxruntime1</em>, if intermediate is True,
the first class builds all <a class="reference external" href="https://onnx.ai/">ONNX</a> cut out
to keep the one output and converted into
<em>OnnxInference</em>.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.8: </span>Parameter <em>yield_ops</em> was added.</p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L793">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.run2onnx">
<span class="sig-name descname"><span class="pre">run2onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fLOG</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_parameter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">suffix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'_DBG'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DEBUG'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">domain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DEBUG'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">domain_opset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.run2onnx" title="Permalink to this definition">#</a></dt>
<dd><p>Executes the graphs with the given inputs, then adds the intermediate
results into ONNX nodes in the original graph. Once saved, it can be
looked with a tool such as <a class="reference external" href="https://github.com/lutzroeder/netron">netron</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> â€“ inputs as dictionary or a dataframe</p></li>
<li><p><strong>verbose</strong> â€“ display information while predicting</p></li>
<li><p><strong>fLOG</strong> â€“ logging function if <em>verbose &gt; 0</em></p></li>
<li><p><strong>as_parameter</strong> â€“ add new nodes with results as one parameter
(True) or as initializer (False)</p></li>
<li><p><strong>suffix</strong> â€“ suffix to add to new results</p></li>
<li><p><strong>param_name</strong> â€“ name of the parameter to add
(by default the result name), it can be a function
<cite>param_name(reult_name) -&gt; parameter_name</cite></p></li>
<li><p><strong>node_type</strong> â€“ type of the new node</p></li>
<li><p><strong>domain</strong> â€“ domain the new node</p></li>
<li><p><strong>domain_opset</strong> â€“ opset for <em>domain</em></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>outputs as dictionary
and the onnx graph with new nodes</p>
</dd>
</dl>
<p>The following example shows how to use it.</p>

    <div id="gdot-139922881012880-cont"><div id="gdot-139922881012880" style="width:100%;height:100%;"></div>
    <script>

    require(['../../_static/viz.js'], function() { var svgGraph = Viz(" digraph{\n  ranksep=0.25;\n  nodesep=0.05;\n  orientation=portrait;\n  size=7;\n\n  X [shape=box color=red label=\"X\\nfloat((0, 2))\" fontsize=10];\n\n  variable [shape=box color=green label=\"variable\\nfloat((0, 1))\" fontsize=10];\n\n\n  variable_DBG [shape=box label=\"variable_DBG\" fontsize=10];\n  LinearRegressor_DBG [shape=box style=\"filled,rounded\" color=orange label=\"LinearRegressor\\n(LinearRegressor_DBG)\\ncoefficients=[ 0.735 -0.638]\\nintercepts=[-1.343]\" fontsize=10];\n  X -> LinearRegressor_DBG;\n  LinearRegressor_DBG -> variable_DBG;\n\n  DEBUG [shape=box style=\"filled,rounded\" color=orange label=\"DEBUG\\n(DEBUG)\\nvariable=[[0.172]\\n [0.343]\\n [...\" fontsize=10];\n  variable_DBG -> DEBUG;\n  DEBUG -> variable;\n}\n");
    document.getElementById('gdot-139922881012880').innerHTML = svgGraph; });
    
</script>
</div><div class="versionadded">
<p><span class="versionmodified added">New in version 0.7.</span></p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L874">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.shape_inference">
<span class="sig-name descname"><span class="pre">shape_inference</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.shape_inference" title="Permalink to this definition">#</a></dt>
<dd><p>Infers the shape of the outputs
with <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> package.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A new <a class="reference external" href="https://onnx.ai/">ONNX</a> graph which defined outputs.</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L345">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.switch_initializers_dtype">
<span class="sig-name descname"><span class="pre">switch_initializers_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype_in=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype_out=&lt;class</span> <span class="pre">'numpy.float64'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.switch_initializers_dtype" title="Permalink to this definition">#</a></dt>
<dd><p>Switches all initializers to <code class="docutils literal notranslate"><span class="pre">numpy.float64</span></code>. If <em>model</em>
is None, a simple cast is done. Otherwise, the function assumes
the model is a <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> pipeline.
This only works if the runtime is <code class="docutils literal notranslate"><span class="pre">'python'</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> â€“ <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> model or None</p></li>
<li><p><strong>dtype_in</strong> â€“ previous type</p></li>
<li><p><strong>dtype_out</strong> â€“ next type</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>done operations</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L1237">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.OnnxInference.to_sequence">
<span class="sig-name descname"><span class="pre">to_sequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">existing_functions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.OnnxInference.to_sequence" title="Permalink to this definition">#</a></dt>
<dd><p>Produces a graph to facilitate the execution.</p>
<p>One example:</p>
<div class="admonition-exref admonition" id="indexexref-ex2">
<p class="admonition-title">Convert ONNX into graph</p>
<p>An example on how to convert an <a class="reference external" href="https://onnx.ai/">ONNX</a>
graph into a graph.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">mlprodict.npy.xop</span> <span class="kn">import</span> <span class="n">loadop</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt</span> <span class="kn">import</span> <span class="n">OnnxInference</span>

<span class="n">OnnxAiOnnxMlLinearRegressor</span> <span class="o">=</span> <span class="n">loadop</span><span class="p">(</span>
    <span class="p">(</span><span class="s1">&#39;ai.onnx.ml&#39;</span><span class="p">,</span> <span class="s1">&#39;LinearRegressor&#39;</span><span class="p">))</span>

<span class="n">pars</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">coefficients</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]),</span>
            <span class="n">intercepts</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span>
            <span class="n">post_transform</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">)</span>
<span class="n">onx</span> <span class="o">=</span> <span class="n">OnnxAiOnnxMlLinearRegressor</span><span class="p">(</span>
    <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span> <span class="o">**</span><span class="n">pars</span><span class="p">)</span>
<span class="n">model_def</span> <span class="o">=</span> <span class="n">onx</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span>
    <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">pars</span><span class="p">[</span><span class="s1">&#39;coefficients&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">},</span>
    <span class="n">target_opset</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">oinf</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">model_def</span><span class="p">)</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">oinf</span><span class="o">.</span><span class="n">to_sequence</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">{</span><span class="s1">&#39;functions&#39;</span><span class="p">:</span> <span class="p">{},</span>
     <span class="s1">&#39;inits&#39;</span><span class="p">:</span> <span class="p">{},</span>
     <span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;elem&#39;</span><span class="p">:</span> <span class="s1">&#39;float&#39;</span><span class="p">,</span> <span class="s1">&#39;kind&#39;</span><span class="p">:</span> <span class="s1">&#39;tensor&#39;</span><span class="p">,</span> <span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,)}}},</span>
     <span class="s1">&#39;intermediate&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
     <span class="s1">&#39;ir_version&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
     <span class="s1">&#39;nodes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;_linearregressor&#39;</span><span class="p">:</span> <span class="n">Onnx</span><span class="o">-</span><span class="n">LinearRegressor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Y</span>    <span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;_linearregressor&#39;</span><span class="p">)},</span>
     <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;elem&#39;</span><span class="p">:</span> <span class="s1">&#39;float&#39;</span><span class="p">,</span>
                                <span class="s1">&#39;kind&#39;</span><span class="p">:</span> <span class="s1">&#39;tensor&#39;</span><span class="p">,</span>
                                <span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;?&#39;</span><span class="p">,)}}},</span>
     <span class="s1">&#39;sequence&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">Onnx</span><span class="o">-</span><span class="n">LinearRegressor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Y</span>    <span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;_linearregressor&#39;</span><span class="p">)],</span>
     <span class="s1">&#39;statics&#39;</span><span class="p">:</span> <span class="p">{},</span>
     <span class="s1">&#39;targets&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}}</span>
</pre></div>
</div>
<p>See an example of representation in notebook
<a class="reference internal" href="../../notebooks/onnx_visualization.html#onnxvisualizationrst"><span class="std std-ref">ONNX visualization</span></a>.</p>
</div>
<p><a class="reference external" href="https://github.com/sdpython/mlprodict/blob/master/mlprodict/onnxrt/onnx_inference.py#L498">source on GitHub</a></p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlprodict.onnxrt.onnx_inference.iskeyword">
<span class="sig-prename descclassname"><span class="pre">mlprodict.onnxrt.onnx_inference.</span></span><span class="sig-name descname"><span class="pre">iskeyword</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlprodict.onnxrt.onnx_inference.iskeyword" title="Permalink to this definition">#</a></dt>
<dd><p>x.__contains__(y) &lt;==&gt; y in x.</p>
</dd></dl>

</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="excs.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">module <code class="docutils literal notranslate"><span class="pre">onnxrt.excs</span></code></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="onnx_inference_exports.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">module <code class="docutils literal notranslate"><span class="pre">onnxrt.onnx_inference_exports</span></code></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier DuprÃ©.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>