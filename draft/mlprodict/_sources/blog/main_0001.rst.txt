
:orphan:

|rss_image| :ref:`<== <ap-main-0>`  **blog page - 2/3** :ref:`==> <ap-main-2>` :ref:`Blog <ap-main-0>` :ref:`onnx (8) <ap-cat-onnx-0>` :ref:`runtime (3) <ap-cat-runtime-0>`

.. |rss_image| image:: feed-icon-16x16.png
    :target: ../_downloads/rss.xml
    :alt: RSS

----


.. _ap-main-1:

blog page - 2/3
+++++++++++++++

.. blogpostagg::
    :title: Custom C++ TopK
    :date: 2019-12-16
    :keywords: scikit-learn,topk,argpartition
    :categories: benchmark
    :rawfile: 2019/2019-12-16_topk.rst

    It started with the fact the python runtime for
    the AdaBoostRegressor was quite slow. I noticed three
    operators were quite slow even though their implementation
    was based on :epkg:`numpy`: *TopK*, *ArrayFeatureExtractor*
    and *GatherElement*. I made a custom implementation
    of the first two.
    

    ...




.. blogpostagg::
    :title: RandomForestClassifier - prediction for one observation
    :date: 2019-12-04
    :keywords: scikit-learn,py-spy,benchmark,one-off prediction
    :categories: benchmark
    :rawfile: 2019/2019-12-04_py-spy.rst

    I was meeting with Olivier Grisel this morning and
    we were wondering why :epkg:`scikit-learn` was slow
    to compute the prediction of a random forest for
    one observation compare to what :epkg:`onnxruntime` does,
    and more specically some optimized C++ code inspired
    from :epkg:`onnxruntime`.
    We used :epkg:`py-spy` and wrote the following script:
    

    ...




.. blogpostagg::
    :title: The bug which makes you waste time
    :date: 2019-10-04
    :keywords: asv,bug
    :categories: benchmark
    :rawfile: 2019/2019-10-04_asv.rst

    It is not a bug but it is something which makes
    you waste some significant time just to understand
    what's going on. :epkg:`asv` would refuse to detect
    the benchmark I was trying to set up just because
    filenames did contain dots. So, for :epkg:`asv`
    don't add a file ``name.option.py`` but use
    ``name_option.py``.
    A couple of benchmark for tries:
    :epkg:`bench1`, :epkg:`bench2`.




.. blogpostagg::
    :title: Operator CDist
    :date: 2019-09-16
    :keywords: onnxruntime,cdist
    :categories: onnx
    :rawfile: 2019/2019-09-16_cdist.rst

    Notebooks :ref:`onnxpdistrst` shows how much slower
    an :epkg:`ONNX` implementation of function
    :epkg:`cdist`, from 3 to 10 times slower.
    One way to optimize the converted model is to
    create dedicated operator such as one for function
    :epkg:`cdist`. Tutorial :ref:`l-onnx-tutorial-optim`
    explains how to tell function :func:`to_onnx
    <mlprodict.onnx_conv.convert.to_onnx>` to use
    the custom operator `CDist`.




.. blogpostagg::
    :title: Float, double with ONNX
    :date: 2019-08-23
    :keywords: onnx,float,double
    :categories: onnx
    :rawfile: 2019/2019-08-23_onnx_float_double.rst

    Replicating what a library does, :epkg:`scikit-learn` for
    example, is different from implementing a function
    defined in a paper. Every trick needs to be replicated.
    :epkg:`scikit-learn` trees implement a prediction function
    which takes float features and compares them to double
    thresholds. Knowning the :epkg:`ONNX` assumes that comparison
    only happens numbers of the same type, you end up with discrepencies.
    

    ...




.. blogpostagg::
    :title: ONNX updates
    :date: 2019-08-02
    :keywords: onnx,onnxrt,update
    :categories: onnx
    :rawfile: 2019/2019-08-02_onnx_changes.rst

    The python runtime is now almost complete for
    all the supported numerical operator implemented
    in :epkg:`sklearn-onnx`. A couple of notebooks
    introduces a couple of way to investigates issues,
    to benchmark ONNX models with :epkg:`onnxruntime`
    or python runtime, to check the differences between
    the same model. It also extend ONNX with operators not in
    the specification to experiment some assumptions
    and check it is more efficient. Notebook
    :ref:`onnxshakerrst` introduces a way to guess the
    margins introduced by the conversion from double
    to single. There also exists a function to convert numpy
    function into ONNX (see :ref:`l-numpy2onnx-tutorial`).
    Its coverage is probably low but it will improve.




.. blogpostagg::
    :title: ONNX, runtime
    :date: 2019-06-25
    :keywords: onnx,onnxrt
    :categories: onnx
    :rawfile: 2019/2019-06-25_runtime.rst

    Somebody asked me one day if it would be difficult to
    write a runtime for :epkg:`ONNX` in :epkg:`Rust`.
    I just replied that it should not take that long
    but it would require to implement a way to goes
    through the nodes of the :epkg:`ONNX` graph
    and to have an implementation for every
    :epkg:`ONNX Operators`...
    

    ...




.. blogpostagg::
    :title: ONNX, runtime, converters
    :date: 2019-06-15
    :keywords: onnx,onnxrt
    :categories: onnx
    :rawfile: 2019/2019-06-15_onnxrt.rst

    I have been recently working on :epkg:`sklearn-onnx`
    to write converter from :epkg:`scikit-learn` operators
    to :epkg:`ONNX` serialization format. I was talking
    about that a month ago and somebody asked me if there
    was a runtime implemented in `RUST <https://www.rust-lang.org/>`_.
    Not that I know of but I said it would not be too complex
    to implement one.
    

    ...




.. blogpostagg::
    :title: XGBoost into python code
    :date: 2018-04-30
    :keywords: xgboost,pyxgboost,python
    :categories: modules
    :rawfile: 2018/2018-04-30_anothersimilar.rst

    Package `pyxgboost <https://github.com/KOLANICH/pyxgboost>`_
    converts a tree from :epkg:`xgboost` into a :epkg:`Python` code.
    :epkg:`Python` still needs to be used if the models
    has to be deployed but it should be faster for small models.




.. blogpostagg::
    :title: Similar projects
    :date: 2018-03-31
    :keywords: sklearn-porter,onnx,onnxmltools,winmltools
    :categories: modules
    :rawfile: 2018/2018-03-31_similar_project.rst

    I would not say this module is actively maintained.
    It was more fun to have the idea, to test it on some
    simple model than to extend its coverage to all available
    models in :epkg:`scikit-learn`. Some altenatives exists
    but it is still ongoing work.
    `sklearn-porter <https://github.com/nok/sklearn-porter>`_
    proposed to produce code into many languages,
    C++, Javascipt, PHP, Java, Ruby, Go. It only includes
    learners and not transforms.
    `onnx <https://github.com/onnx/onnx>`_ proposes to convert
    any models into a unified format. This module implements
    the format,
    `onnxmltools <https://github.com/onnx/onnxmltools>`_,
    `winmltools <https://pypi.python.org/pypi/winmltools>`_
    do the conversion of many models from
    :epkg:`scikit-learn`,
    `xgboost <https://github.com/dmlc/xgboost>`_,
    `lightgbm <https://github.com/Microsoft/LightGBM>`_.
    The produced file can be used to run prediction on GPU
    and Windows with a dedicated runtime.





----

|rss_image| :ref:`<== <ap-main-0>`  **blog page - 2/3** :ref:`==> <ap-main-2>` :ref:`2020-11 (1) <ap-month-2020-11-0>` :ref:`2021-05 (2) <ap-month-2021-05-0>` :ref:`2021-07 (2) <ap-month-2021-07-0>` :ref:`2021-08 (3) <ap-month-2021-08-0>` :ref:`2022-02 (1) <ap-month-2022-02-0>`