
:orphan:

|rss_image|  **2019-12 - 1/1** :ref:`Blog <ap-main-0>` :ref:`onnx (8) <ap-cat-onnx-0>` :ref:`runtime (3) <ap-cat-runtime-0>`

.. |rss_image| image:: feed-icon-16x16.png
    :target: ../_downloads/rss.xml
    :alt: RSS

----


.. index:: 2019-12


.. _ap-month-2019-12-0:

2019-12 - 1/1
+++++++++++++

.. blogpostagg::
    :title: Custom C++ TopK
    :date: 2019-12-16
    :keywords: scikit-learn,topk,argpartition
    :categories: benchmark
    :rawfile: 2019/2019-12-16_topk.rst

    It started with the fact the python runtime for
    the AdaBoostRegressor was quite slow. I noticed three
    operators were quite slow even though their implementation
    was based on :epkg:`numpy`: *TopK*, *ArrayFeatureExtractor*
    and *GatherElement*. I made a custom implementation
    of the first two.
    

    ...




.. blogpostagg::
    :title: RandomForestClassifier - prediction for one observation
    :date: 2019-12-04
    :keywords: scikit-learn,py-spy,benchmark,one-off prediction
    :categories: benchmark
    :rawfile: 2019/2019-12-04_py-spy.rst

    I was meeting with Olivier Grisel this morning and
    we were wondering why :epkg:`scikit-learn` was slow
    to compute the prediction of a random forest for
    one observation compare to what :epkg:`onnxruntime` does,
    and more specically some optimized C++ code inspired
    from :epkg:`onnxruntime`.
    We used :epkg:`py-spy` and wrote the following script:
    

    ...





----

|rss_image|  **2019-12 - 1/1** :ref:`2020-11 (1) <ap-month-2020-11-0>` :ref:`2021-05 (2) <ap-month-2021-05-0>` :ref:`2021-07 (2) <ap-month-2021-07-0>` :ref:`2021-08 (3) <ap-month-2021-08-0>` :ref:`2022-02 (1) <ap-month-2022-02-0>`