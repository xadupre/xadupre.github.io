
.. _f-backend:

module ``onnxrt.backend``
=========================





.. inheritance-diagram:: mlprodict.onnxrt.backend


Short summary
+++++++++++++

module ``mlprodict.onnxrt.backend``

ONNX Backend for :class:`OnnxInference`.

::

    import unittest
    from onnx.backend.test import BackendTest
    backend_test = BackendTest(backend, __name__)
    back_test.include('.*add.*')
    globals().update(backend_test.enable_report().test_cases)
    unittest.main()


:githublink:`%|py|0`




Classes
+++++++

+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| class                                                                                     | truncated documentation                                                                                                            |
+===========================================================================================+====================================================================================================================================+
| :class:`_CombineModels <mlprodict.onnxrt.backend._CombineModels>`                         |                                                                                                                                    |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| :class:`OnnxInferenceBackend <mlprodict.onnxrt.backend.OnnxInferenceBackend>`             | ONNX backend following the pattern from `onnx/backend/base.py <https://github.com/onnx/onnx/blob/main/onnx/backend/base.py>`_. ... |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| :class:`OnnxInferenceBackendMicro <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro>`   | Same backend as @see cl OnnxInferenceBackend but runtime is @see cl OnnxMicroRuntime.                                              |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| :class:`OnnxInferenceBackendOrt <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt>`       | Same backend as @see cl OnnxInferenceBackend but runtime is `onnxruntime1`.                                                        |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| :class:`OnnxInferenceBackendPyC <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC>`       | Same backend as @see cl OnnxInferenceBackend but runtime is `python_compiled`.                                                     |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| :class:`OnnxInferenceBackendPyEval <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval>` | Same backend as @see cl OnnxInferenceBackend but runtime is @see cl OnnxShapeInference.                                            |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| :class:`OnnxInferenceBackendRep <mlprodict.onnxrt.backend.OnnxInferenceBackendRep>`       | Computes the prediction for an ONNX graph loaded with @see cl OnnxInference.                                                       |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+
| :class:`OnnxInferenceBackendShape <mlprodict.onnxrt.backend.OnnxInferenceBackendShape>`   | Same backend as @see cl OnnxInferenceBackend but runtime is @see cl OnnxShapeInference.                                            |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------+






Properties
++++++++++

+-----------------------------------------------------------------------------+---------------------------+
| property                                                                    | truncated documentation   |
+=============================================================================+===========================+
| :meth:`input_names <mlprodict.onnxrt.backend._CombineModels.input_names>`   | Returns the input names.  |
+-----------------------------------------------------------------------------+---------------------------+
| :meth:`output_names <mlprodict.onnxrt.backend._CombineModels.output_names>` | Returns the output names. |
+-----------------------------------------------------------------------------+---------------------------+




Static Methods
++++++++++++++

+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| staticmethod                                                                                                    | truncated documentation                                                                                              |
+=================================================================================================================+======================================================================================================================+
| :meth:`create_inference_session <mlprodict.onnxrt.backend.OnnxInferenceBackend.create_inference_session>`       | Instantiates an instance of class @see cl OnnxInference. This method should be overwritten to change the runtime ... |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`create_inference_session <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro.create_inference_session>`  |                                                                                                                      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`create_inference_session <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt.create_inference_session>`    |                                                                                                                      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`create_inference_session <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC.create_inference_session>`    |                                                                                                                      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`create_inference_session <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval.create_inference_session>` |                                                                                                                      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`create_inference_session <mlprodict.onnxrt.backend.OnnxInferenceBackendShape.create_inference_session>`  |                                                                                                                      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_compatible <mlprodict.onnxrt.backend.OnnxInferenceBackend.is_compatible>`                             | Returns whether the model is compatible with the backend.                                                            |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_compatible <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro.is_compatible>`                        | Returns whether the model is compatible with the backend.                                                            |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_compatible <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt.is_compatible>`                          | Returns whether the model is compatible with the backend.                                                            |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_compatible <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC.is_compatible>`                          | Returns whether the model is compatible with the backend.                                                            |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_compatible <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval.is_compatible>`                       | Returns whether the model is compatible with the backend.                                                            |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_compatible <mlprodict.onnxrt.backend.OnnxInferenceBackendShape.is_compatible>`                        | Returns whether the model is compatible with the backend.                                                            |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_opset_supported <mlprodict.onnxrt.backend.OnnxInferenceBackend.is_opset_supported>`                   | Returns whether the opset for the model is supported by the backend.                                                 |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_opset_supported <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro.is_opset_supported>`              | Returns whether the opset for the model is supported by the backend.                                                 |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_opset_supported <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt.is_opset_supported>`                | Returns whether the opset for the model is supported by the backend.                                                 |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_opset_supported <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC.is_opset_supported>`                | Returns whether the opset for the model is supported by the backend.                                                 |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_opset_supported <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval.is_opset_supported>`             | Returns whether the opset for the model is supported by the backend.                                                 |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`is_opset_supported <mlprodict.onnxrt.backend.OnnxInferenceBackendShape.is_opset_supported>`              | Returns whether the opset for the model is supported by the backend.                                                 |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`prepare <mlprodict.onnxrt.backend.OnnxInferenceBackend.prepare>`                                         | Loads the model and creates @see cl OnnxInference.                                                                   |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`prepare <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro.prepare>`                                    | Loads the model and creates @see cl OnnxInference.                                                                   |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`prepare <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt.prepare>`                                      | Loads the model and creates @see cl OnnxInference.                                                                   |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`prepare <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC.prepare>`                                      | Loads the model and creates @see cl OnnxInference.                                                                   |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`prepare <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval.prepare>`                                   | Loads the model and creates @see cl OnnxInference.                                                                   |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`prepare <mlprodict.onnxrt.backend.OnnxInferenceBackendShape.prepare>`                                    | Loads the model and creates @see cl OnnxInference.                                                                   |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_model <mlprodict.onnxrt.backend.OnnxInferenceBackend.run_model>`                                     | Computes the prediction.                                                                                             |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_model <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro.run_model>`                                | Computes the prediction.                                                                                             |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_model <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt.run_model>`                                  | Computes the prediction.                                                                                             |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_model <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC.run_model>`                                  | Computes the prediction.                                                                                             |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_model <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval.run_model>`                               | Computes the prediction.                                                                                             |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_model <mlprodict.onnxrt.backend.OnnxInferenceBackendShape.run_model>`                                | Computes the prediction.                                                                                             |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_node <mlprodict.onnxrt.backend.OnnxInferenceBackend.run_node>`                                       | This method is not implemented as it is much more efficient to run a whole model than every node independently.      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_node <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro.run_node>`                                  | This method is not implemented as it is much more efficient to run a whole model than every node independently.      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_node <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt.run_node>`                                    | This method is not implemented as it is much more efficient to run a whole model than every node independently.      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_node <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC.run_node>`                                    | This method is not implemented as it is much more efficient to run a whole model than every node independently.      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_node <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval.run_node>`                                 | This method is not implemented as it is much more efficient to run a whole model than every node independently.      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`run_node <mlprodict.onnxrt.backend.OnnxInferenceBackendShape.run_node>`                                  | This method is not implemented as it is much more efficient to run a whole model than every node independently.      |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`supports_device <mlprodict.onnxrt.backend.OnnxInferenceBackend.supports_device>`                         | Checks whether the backend is compiled with particular device support.                                               |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`supports_device <mlprodict.onnxrt.backend.OnnxInferenceBackendMicro.supports_device>`                    | Checks whether the backend is compiled with particular device support.                                               |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`supports_device <mlprodict.onnxrt.backend.OnnxInferenceBackendOrt.supports_device>`                      | Checks whether the backend is compiled with particular device support.                                               |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`supports_device <mlprodict.onnxrt.backend.OnnxInferenceBackendPyC.supports_device>`                      | Checks whether the backend is compiled with particular device support.                                               |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`supports_device <mlprodict.onnxrt.backend.OnnxInferenceBackendPyEval.supports_device>`                   | Checks whether the backend is compiled with particular device support.                                               |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+
| :meth:`supports_device <mlprodict.onnxrt.backend.OnnxInferenceBackendShape.supports_device>`                    | Checks whether the backend is compiled with particular device support.                                               |
+-----------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+




Methods
+++++++

+---------------------------------------------------------------------------------+-----------------------------------------------------------+
| method                                                                          | truncated documentation                                   |
+=================================================================================+===========================================================+
| :py:meth:`__init__ <mlprodict.onnxrt.backend.OnnxInferenceBackendRep.__init__>` |                                                           |
+---------------------------------------------------------------------------------+-----------------------------------------------------------+
| :py:meth:`__init__ <mlprodict.onnxrt.backend._CombineModels.__init__>`          |                                                           |
+---------------------------------------------------------------------------------+-----------------------------------------------------------+
| :meth:`run <mlprodict.onnxrt.backend.OnnxInferenceBackendRep.run>`              | Computes the prediction. See @see meth OnnxInference.run. |
+---------------------------------------------------------------------------------+-----------------------------------------------------------+
| :meth:`run <mlprodict.onnxrt.backend._CombineModels.run>`                       | Runs shape inferance and onnx inference.                  |
+---------------------------------------------------------------------------------+-----------------------------------------------------------+


Documentation
+++++++++++++

.. automodule:: mlprodict.onnxrt.backend
    :members:
    :special-members: __init__
    :show-inheritance:



