
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gyexamples/plot_opml_random_forest_reg.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_gyexamples_plot_opml_random_forest_reg.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gyexamples_plot_opml_random_forest_reg.py:


.. _l-example-tree-ensemble-reg-bench:

Benchmark Random Forests, Tree Ensemble, (AoS and SoA)
======================================================

The script compares different implementations for the operator
TreeEnsembleRegressor.

* *baseline*: RandomForestRegressor from :epkg:`scikit-learn`
* *ort*: :epkg:`onnxruntime`,
* *mlprodict*: an implementation based on an array of structures,
  every structure describes a node,
* *mlprodict2* similar implementation but instead of having an
  array of structures, it relies on a structure of arrays,
  it parallelizes by blocks of 128 observations and inside
  every block, goes through trees then through observations
  (double loop),
* *mlprodict3*: parallelizes by trees, this implementation
  is faster when the depth is higher than 10.

.. contents::
    :local:

A structure of arrays has better performance:
`Case study: Comparing Arrays of Structures and Structures of
Arrays Data Layouts for a Compute-Intensive Loop
<https://software.intel.com/content/www/us/en/develop/articles/
a-case-study-comparing-aos-arrays-of-structures-and-soa-structures-of-arrays-data-layouts.html>`_.
See also `AoS and SoA <https://en.wikipedia.org/wiki/AoS_and_SoA>`_.

.. faqref::
    :title: Profile the execution

    :epkg:`py-spy` can be used to profile the execution
    of a program. The profile is more informative if the
    code is compiled with debug information.

    ::

        py-spy record --native -r 10 -o plot_random_forest_reg.svg -- python plot_random_forest_reg.py

Import
++++++

.. GENERATED FROM PYTHON SOURCE LINES 46-62

.. code-block:: default

    import warnings
    from time import perf_counter as time
    from multiprocessing import cpu_count
    import numpy
    from numpy.random import rand
    from numpy.testing import assert_almost_equal
    import pandas
    import matplotlib.pyplot as plt
    from sklearn import config_context
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.utils._testing import ignore_warnings
    from skl2onnx import convert_sklearn
    from skl2onnx.common.data_types import FloatTensorType
    from onnxruntime import InferenceSession
    from mlprodict.onnxrt import OnnxInference








.. GENERATED FROM PYTHON SOURCE LINES 63-64

Available optimisation on this machine.

.. GENERATED FROM PYTHON SOURCE LINES 64-69

.. code-block:: default


    from mlprodict.testing.experimental_c_impl.experimental_c import code_optimisation
    print(code_optimisation())






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    AVX-omp=8




.. GENERATED FROM PYTHON SOURCE LINES 70-72

Versions
++++++++

.. GENERATED FROM PYTHON SOURCE LINES 72-97

.. code-block:: default



    def version():
        from datetime import datetime
        import sklearn
        import numpy
        import onnx
        import onnxruntime
        import skl2onnx
        import mlprodict
        df = pandas.DataFrame([
            {"name": "date", "version": str(datetime.now())},
            {"name": "numpy", "version": numpy.__version__},
            {"name": "scikit-learn", "version": sklearn.__version__},
            {"name": "onnx", "version": onnx.__version__},
            {"name": "onnxruntime", "version": onnxruntime.__version__},
            {"name": "skl2onnx", "version": skl2onnx.__version__},
            {"name": "mlprodict", "version": mlprodict.__version__},
        ])
        return df


    version()







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>name</th>
          <th>version</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>date</td>
          <td>2022-03-10 09:47:46.910098</td>
        </tr>
        <tr>
          <th>1</th>
          <td>numpy</td>
          <td>1.21.5</td>
        </tr>
        <tr>
          <th>2</th>
          <td>scikit-learn</td>
          <td>1.0.2</td>
        </tr>
        <tr>
          <th>3</th>
          <td>onnx</td>
          <td>1.11.0</td>
        </tr>
        <tr>
          <th>4</th>
          <td>onnxruntime</td>
          <td>1.10.91</td>
        </tr>
        <tr>
          <th>5</th>
          <td>skl2onnx</td>
          <td>1.11</td>
        </tr>
        <tr>
          <th>6</th>
          <td>mlprodict</td>
          <td>0.8.1747</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 98-100

Implementations to benchmark
++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 100-140

.. code-block:: default


    def fcts_model(X, y, max_depth, n_estimators, n_jobs):
        "RandomForestClassifier."
        rf = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators,
                                   n_jobs=n_jobs)
        rf.fit(X, y)

        initial_types = [('X', FloatTensorType([None, X.shape[1]]))]
        onx = convert_sklearn(rf, initial_types=initial_types)
        sess = InferenceSession(onx.SerializeToString())
        outputs = [o.name for o in sess.get_outputs()]
        oinf = OnnxInference(onx, runtime="python")
        oinf.sequence_[0].ops_._init(numpy.float32, 1)
        name = outputs[0]
        oinf2 = OnnxInference(onx, runtime="python")
        oinf2.sequence_[0].ops_._init(numpy.float32, 2)
        oinf3 = OnnxInference(onx, runtime="python")
        oinf3.sequence_[0].ops_._init(numpy.float32, 3)

        def predict_skl_predict(X, model=rf):
            return rf.predict(X)

        def predict_onnxrt_predict(X, sess=sess):
            return sess.run(outputs[:1], {'X': X})[0]

        def predict_onnx_inference(X, oinf=oinf):
            return oinf.run({'X': X})[name]

        def predict_onnx_inference2(X, oinf2=oinf2):
            return oinf2.run({'X': X})[name]

        def predict_onnx_inference3(X, oinf3=oinf3):
            return oinf3.run({'X': X})[name]

        return {'predict': (
            predict_skl_predict, predict_onnxrt_predict,
            predict_onnx_inference, predict_onnx_inference2,
            predict_onnx_inference3)}









.. GENERATED FROM PYTHON SOURCE LINES 141-143

Benchmarks
++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 143-261

.. code-block:: default


    def allow_configuration(**kwargs):
        return True


    def bench(n_obs, n_features, max_depths, n_estimatorss, n_jobss,
              methods, repeat=10, verbose=False):
        res = []
        for nfeat in n_features:

            ntrain = 50000
            X_train = numpy.empty((ntrain, nfeat)).astype(numpy.float32)
            X_train[:, :] = rand(ntrain, nfeat)[:, :]
            eps = rand(ntrain) - 0.5
            y_train = X_train.sum(axis=1) + eps

            for n_jobs in n_jobss:
                for max_depth in max_depths:
                    for n_estimators in n_estimatorss:
                        fcts = fcts_model(X_train, y_train,
                                          max_depth, n_estimators, n_jobs)

                        for n in n_obs:
                            for method in methods:

                                fct1, fct2, fct3, fct4, fct5 = fcts[method]

                                if not allow_configuration(
                                        n=n, nfeat=nfeat, max_depth=max_depth,
                                        n_estimator=n_estimators, n_jobs=n_jobs,
                                        method=method):
                                    continue

                                obs = dict(n_obs=n, nfeat=nfeat,
                                           max_depth=max_depth,
                                           n_estimators=n_estimators,
                                           method=method,
                                           n_jobs=n_jobs)

                                # creates different inputs to avoid caching
                                Xs = []
                                for r in range(repeat):
                                    x = numpy.empty((n, nfeat))
                                    x[:, :] = rand(n, nfeat)[:, :]
                                    Xs.append(x.astype(numpy.float32))

                                # measures the baseline
                                with config_context(assume_finite=True):
                                    st = time()
                                    repeated = 0
                                    for X in Xs:
                                        p1 = fct1(X)
                                        repeated += 1
                                        if time() - st >= 1:
                                            break  # stops if longer than a second
                                    end = time()
                                    obs["time_skl"] = (end - st) / repeated

                                # measures the new implementation
                                st = time()
                                r2 = 0
                                for X in Xs:
                                    p2 = fct2(X)
                                    r2 += 1
                                    if r2 >= repeated:
                                        break
                                end = time()
                                obs["time_ort"] = (end - st) / r2

                                # measures the other new implementation
                                st = time()
                                r2 = 0
                                for X in Xs:
                                    p2 = fct3(X)
                                    r2 += 1
                                    if r2 >= repeated:
                                        break
                                end = time()
                                obs["time_mlprodict"] = (end - st) / r2

                                # measures the other new implementation 2
                                st = time()
                                r2 = 0
                                for X in Xs:
                                    p2 = fct4(X)
                                    r2 += 1
                                    if r2 >= repeated:
                                        break
                                end = time()
                                obs["time_mlprodict2"] = (end - st) / r2

                                # measures the other new implementation 3
                                st = time()
                                r2 = 0
                                for X in Xs:
                                    p2 = fct5(X)
                                    r2 += 1
                                    if r2 >= repeated:
                                        break
                                end = time()
                                obs["time_mlprodict3"] = (end - st) / r2

                                # final
                                res.append(obs)
                                if verbose and (len(res) % 1 == 0 or n >= 10000):
                                    print("bench", len(res), ":", obs)

                                # checks that both produce the same outputs
                                if n <= 10000:
                                    if len(p1.shape) == 1 and len(p2.shape) == 2:
                                        p2 = p2.ravel()
                                    try:
                                        assert_almost_equal(
                                            p1.ravel(), p2.ravel(), decimal=5)
                                    except AssertionError as e:
                                        warnings.warn(str(e))
        return res








.. GENERATED FROM PYTHON SOURCE LINES 262-264

Graphs
++++++

.. GENERATED FROM PYTHON SOURCE LINES 264-332

.. code-block:: default



    def plot_rf_models(dfr):

        def autolabel(ax, rects):
            for rect in rects:
                height = rect.get_height()
                ax.annotate('%1.1fx' % height,
                            xy=(rect.get_x() + rect.get_width() / 2, height),
                            xytext=(0, 3),  # 3 points vertical offset
                            textcoords="offset points",
                            ha='center', va='bottom',
                            fontsize=8)

        engines = [_.split('_')[-1] for _ in dfr.columns if _.startswith("time_")]
        engines = [_ for _ in engines if _ != 'skl']
        for engine in engines:
            dfr["speedup_%s" % engine] = dfr["time_skl"] / dfr["time_%s" % engine]
        print(dfr.tail().T)

        ncols = 4
        fig, axs = plt.subplots(len(engines), ncols, figsize=(
            14, 4 * len(engines)), sharey=True)

        row = 0
        for row, engine in enumerate(engines):
            pos = 0
            name = "RandomForestRegressor - %s" % engine
            for max_depth in sorted(set(dfr.max_depth)):
                for nf in sorted(set(dfr.nfeat)):
                    for est in sorted(set(dfr.n_estimators)):
                        for n_jobs in sorted(set(dfr.n_jobs)):
                            sub = dfr[(dfr.max_depth == max_depth) &
                                      (dfr.nfeat == nf) &
                                      (dfr.n_estimators == est) &
                                      (dfr.n_jobs == n_jobs)]
                            ax = axs[row, pos]
                            labels = sub.n_obs
                            means = sub["speedup_%s" % engine]

                            x = numpy.arange(len(labels))
                            width = 0.90

                            rects1 = ax.bar(x, means, width, label='Speedup')
                            if pos == 0:
                                ax.set_yscale('log')
                                ax.set_ylim([0.1, max(dfr["speedup_%s" % engine])])

                            if pos == 0:
                                ax.set_ylabel('Speedup')
                            ax.set_title(
                                '%s\ndepth %d - %d features\n %d estimators %d '
                                'jobs' % (name, max_depth, nf, est, n_jobs))
                            if row == len(engines) - 1:
                                ax.set_xlabel('batch size')
                            ax.set_xticks(x)
                            ax.set_xticklabels(labels)
                            autolabel(ax, rects1)
                            for tick in ax.xaxis.get_major_ticks():
                                tick.label.set_fontsize(8)
                            for tick in ax.yaxis.get_major_ticks():
                                tick.label.set_fontsize(8)
                            pos += 1

        fig.tight_layout()
        return fig, ax









.. GENERATED FROM PYTHON SOURCE LINES 333-335

Run benchs
++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 335-364

.. code-block:: default


    @ignore_warnings(category=FutureWarning)
    def run_bench(repeat=100, verbose=False):
        n_obs = [1, 10, 100, 1000, 10000]
        methods = ['predict']
        n_features = [30]
        max_depths = [6, 8, 10, 12]
        n_estimatorss = [100]
        n_jobss = [cpu_count()]

        start = time()
        results = bench(n_obs, n_features, max_depths, n_estimatorss, n_jobss,
                        methods, repeat=repeat, verbose=verbose)
        end = time()

        results_df = pandas.DataFrame(results)
        print("Total time = %0.3f sec cpu=%d\n" % (end - start, cpu_count()))

        # plot the results
        return results_df


    name = "plot_random_forest_reg"
    df = run_bench(verbose=True)
    df.to_csv("%s.csv" % name, index=False)
    df.to_excel("%s.xlsx" % name, index=False)
    fig, ax = plot_rf_models(df)
    fig.savefig("%s.png" % name)
    plt.show()



.. image-sg:: /gyexamples/images/sphx_glr_plot_opml_random_forest_reg_001.png
   :alt: RandomForestRegressor - ort depth 6 - 30 features  100 estimators 8 jobs, RandomForestRegressor - ort depth 8 - 30 features  100 estimators 8 jobs, RandomForestRegressor - ort depth 10 - 30 features  100 estimators 8 jobs, RandomForestRegressor - ort depth 12 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict depth 6 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict depth 8 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict depth 10 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict depth 12 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict2 depth 6 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict2 depth 8 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict2 depth 10 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict2 depth 12 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict3 depth 6 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict3 depth 8 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict3 depth 10 - 30 features  100 estimators 8 jobs, RandomForestRegressor - mlprodict3 depth 12 - 30 features  100 estimators 8 jobs
   :srcset: /gyexamples/images/sphx_glr_plot_opml_random_forest_reg_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    bench 1 : {'n_obs': 1, 'nfeat': 30, 'max_depth': 6, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.054310696395604235, 'time_ort': 0.0009799725130984658, 'time_mlprodict': 0.002856868270196413, 'time_mlprodict2': 7.442664355039597e-05, 'time_mlprodict3': 7.291554816459354e-05}
    bench 2 : {'n_obs': 10, 'nfeat': 30, 'max_depth': 6, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.054329397303885536, 'time_ort': 0.00046060312735406975, 'time_mlprodict': 0.00038778757382380337, 'time_mlprodict2': 0.0002462290423481088, 'time_mlprodict3': 0.0008822693244407052}
    bench 3 : {'n_obs': 100, 'nfeat': 30, 'max_depth': 6, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.057672866568383246, 'time_ort': 0.0004212578448156516, 'time_mlprodict': 0.004359172036250432, 'time_mlprodict2': 0.0004944632140298685, 'time_mlprodict3': 0.00023161097326212458}
    bench 4 : {'n_obs': 1000, 'nfeat': 30, 'max_depth': 6, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.07788108640278761, 'time_ort': 0.0023497632489754604, 'time_mlprodict': 0.010691116277415019, 'time_mlprodict2': 0.00423903834934418, 'time_mlprodict3': 0.0015111281894720518}
    bench 5 : {'n_obs': 10000, 'nfeat': 30, 'max_depth': 6, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.1037089129909873, 'time_ort': 0.021705812029540538, 'time_mlprodict': 0.06808501379564405, 'time_mlprodict2': 0.014242477528750897, 'time_mlprodict3': 0.014772287011146546}
    bench 6 : {'n_obs': 1, 'nfeat': 30, 'max_depth': 8, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.05392895673254603, 'time_ort': 0.0001004368654991451, 'time_mlprodict': 0.00029528273367568066, 'time_mlprodict2': 7.60376355365703e-05, 'time_mlprodict3': 0.0020518176943848006}
    bench 7 : {'n_obs': 10, 'nfeat': 30, 'max_depth': 8, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.05458387884458429, 'time_ort': 0.0007580416767220748, 'time_mlprodict': 0.0007086194757568208, 'time_mlprodict2': 0.0006702235948882605, 'time_mlprodict3': 0.0008463228219433835}
    bench 8 : {'n_obs': 100, 'nfeat': 30, 'max_depth': 8, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.05801032638798157, 'time_ort': 0.0009405585523280832, 'time_mlprodict': 0.004190822183671925, 'time_mlprodict2': 0.0010487929814391667, 'time_mlprodict3': 0.0003171039538251029}
    bench 9 : {'n_obs': 1000, 'nfeat': 30, 'max_depth': 8, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.07991836914935938, 'time_ort': 0.004052460336914429, 'time_mlprodict': 0.013866107839231308, 'time_mlprodict2': 0.008226184819180232, 'time_mlprodict3': 0.0020790946168395188}
    bench 10 : {'n_obs': 10000, 'nfeat': 30, 'max_depth': 8, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.1033536795526743, 'time_ort': 0.030528668873012067, 'time_mlprodict': 0.10764505192637444, 'time_mlprodict2': 0.024742644652724265, 'time_mlprodict3': 0.019452986679971217}
    bench 11 : {'n_obs': 1, 'nfeat': 30, 'max_depth': 10, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.0545955671879806, 'time_ort': 0.00040970370173454285, 'time_mlprodict': 0.0035599830903505023, 'time_mlprodict2': 8.602807984540337e-05, 'time_mlprodict3': 8.25770395366769e-05}
    bench 12 : {'n_obs': 10, 'nfeat': 30, 'max_depth': 10, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.05583446772976054, 'time_ort': 0.0010166289284825325, 'time_mlprodict': 0.0009623911852637926, 'time_mlprodict2': 0.0011006097516251935, 'time_mlprodict3': 0.0008139221722053157}
    bench 13 : {'n_obs': 100, 'nfeat': 30, 'max_depth': 10, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.06592021777760237, 'time_ort': 0.0017161941505037248, 'time_mlprodict': 0.004956886754371226, 'time_mlprodict2': 0.0017607798799872398, 'time_mlprodict3': 0.0007508278940804303}
    bench 14 : {'n_obs': 1000, 'nfeat': 30, 'max_depth': 10, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.07872378467940368, 'time_ort': 0.006400411375440084, 'time_mlprodict': 0.01718821577154673, 'time_mlprodict2': 0.015267018085488906, 'time_mlprodict3': 0.003201059209039578}
    bench 15 : {'n_obs': 10000, 'nfeat': 30, 'max_depth': 10, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.10572157204151153, 'time_ort': 0.04538082899525762, 'time_mlprodict': 0.141562335845083, 'time_mlprodict2': 0.04221725268289447, 'time_mlprodict3': 0.02622768925502896}
    bench 16 : {'n_obs': 1, 'nfeat': 30, 'max_depth': 12, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.05402866246080712, 'time_ort': 0.00020474053331111608, 'time_mlprodict': 0.003107550995130288, 'time_mlprodict2': 8.909379769312708e-05, 'time_mlprodict3': 8.98580704080431e-05}
    bench 17 : {'n_obs': 10, 'nfeat': 30, 'max_depth': 12, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.0573034742847085, 'time_ort': 0.0012268139463331965, 'time_mlprodict': 0.0012493031616840097, 'time_mlprodict2': 0.0015097427078419262, 'time_mlprodict3': 0.0008426424012415939}
    bench 18 : {'n_obs': 100, 'nfeat': 30, 'max_depth': 12, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.0683972455561161, 'time_ort': 0.001954855707784494, 'time_mlprodict': 0.005650524236261845, 'time_mlprodict2': 0.00254492765913407, 'time_mlprodict3': 0.0011654832710822423}
    bench 19 : {'n_obs': 1000, 'nfeat': 30, 'max_depth': 12, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.08159278261546905, 'time_ort': 0.010641709758112064, 'time_mlprodict': 0.02137490168500405, 'time_mlprodict2': 0.022748094338637132, 'time_mlprodict3': 0.005132422925761113}
    bench 20 : {'n_obs': 10000, 'nfeat': 30, 'max_depth': 12, 'n_estimators': 100, 'method': 'predict', 'n_jobs': 8, 'time_skl': 0.10992405051365495, 'time_ort': 0.08871526904404163, 'time_mlprodict': 0.18674851078540086, 'time_mlprodict2': 0.07625024719163775, 'time_mlprodict3': 0.03817121665924787}
    Total time = 376.545 sec cpu=8

                                15         16         17         18        19
    n_obs                        1         10        100       1000     10000
    nfeat                       30         30         30         30        30
    max_depth                   12         12         12         12        12
    n_estimators               100        100        100        100       100
    method                 predict    predict    predict    predict   predict
    n_jobs                       8          8          8          8         8
    time_skl              0.054029   0.057303   0.068397   0.081593  0.109924
    time_ort              0.000205   0.001227   0.001955   0.010642  0.088715
    time_mlprodict        0.003108   0.001249   0.005651   0.021375  0.186749
    time_mlprodict2       0.000089    0.00151   0.002545   0.022748   0.07625
    time_mlprodict3        0.00009   0.000843   0.001165   0.005132  0.038171
    speedup_ort         263.888452  46.709181  34.988386   7.667263  1.239066
    speedup_mlprodict    17.386251   45.86835  12.104584   3.817224  0.588621
    speedup_mlprodict2  606.424508  37.955788   26.87591   3.586796  1.441622
    speedup_mlprodict3  601.266667  68.004499  58.685738  15.897517  2.879763





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 6 minutes  34.608 seconds)


.. _sphx_glr_download_gyexamples_plot_opml_random_forest_reg.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_opml_random_forest_reg.py <plot_opml_random_forest_reg.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_opml_random_forest_reg.ipynb <plot_opml_random_forest_reg.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
