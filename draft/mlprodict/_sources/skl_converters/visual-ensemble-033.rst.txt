

.. _l-VotingClassifier-m-cl-logreg-noflatten-zipmap:False-o15:

VotingClassifier - m-cl - logreg-noflatten - {'zipmap': False}
==============================================================

Fitted on a problem type *m-cl*
(see :func:`find_suitable_problem
<mlprodict.onnxrt.validate.validate_problems.find_suitable_problem>`),
method `predict_proba` matches output .
Model was converted with additional parameter: ``<class 'sklearn.ensemble._voting.VotingClassifier'>={'zipmap': False}``.

::

        VotingClassifier(estimators=[('lr1', LogisticRegression(solver='liblinear')),
                                 ('lr2',
                                  LogisticRegression(fit_intercept=False,
                                                     solver='liblinear'))],
                     flatten_transform=False, n_jobs=8, voting='soft')

+----------------------------------+----------+
| index                            | 0        |
+==================================+==========+
| skl_nop                          | 3        |
+----------------------------------+----------+
| skl_ncoef                        | 6        |
+----------------------------------+----------+
| skl_nlin                         | 2        |
+----------------------------------+----------+
| onx_size                         | 1496     |
+----------------------------------+----------+
| onx_nnodes                       | 12       |
+----------------------------------+----------+
| onx_ninits                       | 4        |
+----------------------------------+----------+
| onx_doc_string                   |          |
+----------------------------------+----------+
| onx_ir_version                   | 8        |
+----------------------------------+----------+
| onx_domain                       | ai.onnx  |
+----------------------------------+----------+
| onx_model_version                | 0        |
+----------------------------------+----------+
| onx_producer_name                | skl2onnx |
+----------------------------------+----------+
| onx_producer_version             | 1.11     |
+----------------------------------+----------+
| onx_ai.onnx.ml                   | 1        |
+----------------------------------+----------+
| onx_                             | 15       |
+----------------------------------+----------+
| onx_op_Cast                      | 2        |
+----------------------------------+----------+
| onx_op_Reshape                   | 1        |
+----------------------------------+----------+
| onx_size_optim                   | 1470     |
+----------------------------------+----------+
| onx_nnodes_optim                 | 12       |
+----------------------------------+----------+
| onx_ninits_optim                 | 3        |
+----------------------------------+----------+
| fit_classes_.shape               | 3        |
+----------------------------------+----------+
| fit_estimators_.size             | 2        |
+----------------------------------+----------+
| fit_estimators_.coef_.shape      | (3, 4)   |
+----------------------------------+----------+
| fit_estimators_.n_iter_.shape    | 1        |
+----------------------------------+----------+
| fit_estimators_.classes_.shape   | 3        |
+----------------------------------+----------+
| fit_estimators_.intercept_.shape | 3        |
+----------------------------------+----------+


.. gdot::

        digraph{
      nodesep=0.05;
      ranksep=0.25;
      size=7;
      orientation=portrait;

      X [shape=box color=red label="X\nfloat((0, 4))" fontsize=10];

      label [shape=box color=green label="label\nint64((0,))" fontsize=10];
      probabilities [shape=box color=green label="probabilities\nfloat((0, 3))" fontsize=10];

      classes_ind [shape=box label="classes_ind\nint64((1, 3))\n[[0 1 2]]" fontsize=10];
      w0 [shape=box label="w0\nfloat32((1,))\n[0.5]" fontsize=10];
      classes [shape=box label="classes\nint32((3,))\n[0 1 2]" fontsize=10];
      shape_tensor [shape=box label="shape_tensor\nint64((1,))\n[-1]" fontsize=10];

      label_0 [shape=box label="label_0" fontsize=10];
      probability_tensor [shape=box label="probability_tensor" fontsize=10];
      LinearClassifier [shape=box style="filled,rounded" color=orange label="LinearClassifier\n(LinearClassifier)\nclasslabels_ints=[0 1 2]\ncoefficients=[ 0.45876738  1.29...\nintercepts=[ 0.28357968  0.8646...\nmulti_class=1\npost_transform=b'LOGISTIC'" fontsize=10];
      X -> LinearClassifier;
      LinearClassifier -> label_0;
      LinearClassifier -> probability_tensor;

      label_1 [shape=box label="label_1" fontsize=10];
      probability_tensor1 [shape=box label="probability_tensor1" fontsize=10];
      LinearClassifier1 [shape=box style="filled,rounded" color=orange label="LinearClassifier\n(LinearClassifier1)\nclasslabels_ints=[0 1 2]\ncoefficients=[ 0.49765062  1.31...\nintercepts=[0. 0. 0.]\nmulti_class=1\npost_transform=b'LOGISTIC'" fontsize=10];
      X -> LinearClassifier1;
      LinearClassifier1 -> label_1;
      LinearClassifier1 -> probability_tensor1;

      voting_proba_0 [shape=box label="voting_proba_0" fontsize=10];
      Normalizer [shape=box style="filled,rounded" color=orange label="Normalizer\n(Normalizer)\nnorm=b'L1'" fontsize=10];
      probability_tensor -> Normalizer;
      Normalizer -> voting_proba_0;

      voting_proba_1 [shape=box label="voting_proba_1" fontsize=10];
      Normalizer1 [shape=box style="filled,rounded" color=orange label="Normalizer\n(Normalizer1)\nnorm=b'L1'" fontsize=10];
      probability_tensor1 -> Normalizer1;
      Normalizer1 -> voting_proba_1;

      wprob_name1 [shape=box label="wprob_name1" fontsize=10];
      Mul1 [shape=box style="filled,rounded" color=orange label="Mul\n(Mul1)" fontsize=10];
      voting_proba_1 -> Mul1;
      w0 -> Mul1;
      Mul1 -> wprob_name1;

      wprob_name [shape=box label="wprob_name" fontsize=10];
      Mul [shape=box style="filled,rounded" color=orange label="Mul\n(Mul)" fontsize=10];
      voting_proba_0 -> Mul;
      w0 -> Mul;
      Mul -> wprob_name;

      Sum [shape=box style="filled,rounded" color=orange label="Sum\n(Sum)" fontsize=10];
      wprob_name -> Sum;
      wprob_name1 -> Sum;
      Sum -> probabilities;

      label_name [shape=box label="label_name" fontsize=10];
      ArgMax [shape=box style="filled,rounded" color=orange label="ArgMax\n(ArgMax)\naxis=1" fontsize=10];
      probabilities -> ArgMax;
      ArgMax -> label_name;

      array_feature_extractor_result [shape=box label="array_feature_extractor_result" fontsize=10];
      ArrayFeatureExtractor [shape=box style="filled,rounded" color=orange label="ArrayFeatureExtractor\n(ArrayFeatureExtractor)" fontsize=10];
      classes -> ArrayFeatureExtractor;
      label_name -> ArrayFeatureExtractor;
      ArrayFeatureExtractor -> array_feature_extractor_result;

      cast2_result [shape=box label="cast2_result" fontsize=10];
      Cast [shape=box style="filled,rounded" color=orange label="Cast\n(Cast)\nto=1" fontsize=10];
      array_feature_extractor_result -> Cast;
      Cast -> cast2_result;

      reshaped_result [shape=box label="reshaped_result" fontsize=10];
      Reshape [shape=box style="filled,rounded" color=orange label="Reshape\n(Reshape)" fontsize=10];
      cast2_result -> Reshape;
      shape_tensor -> Reshape;
      Reshape -> reshaped_result;

      Cast1 [shape=box style="filled,rounded" color=orange label="Cast\n(Cast1)\nto=7" fontsize=10];
      reshaped_result -> Cast1;
      Cast1 -> label;
    }