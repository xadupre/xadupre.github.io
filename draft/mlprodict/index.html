
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>mlprodict &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/thebelab-helper.js"></script>
    <script src="_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="_static/project_ico.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="#">
  <img src="_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="i_cmd.html">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="i_index.html">
  FAQ, code, â€¦
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <a class="reference external image-reference" href="https://github.com/sdpython/mlprodict/"><img alt="https://github.com/sdpython/mlprodict/blob/master/_doc/sphinxdoc/source/phdoc_static/project_ico.png?raw=true" src="https://github.com/sdpython/mlprodict/blob/master/_doc/sphinxdoc/source/phdoc_static/project_ico.png?raw=true" /></a>
<section id="mlprodict">
<h1>mlprodict<a class="headerlink" href="#mlprodict" title="Permalink to this headline">#</a></h1>
<p><strong>Links:</strong> <a class="reference external" href="https://github.com/sdpython/mlprodict/">github</a>,
<a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/index.html">documentation</a>,
<a class="reference internal" href="README.html#l-readme"><span class="std std-ref">mlprodict</span></a>,
<a class="reference internal" href="blog/main_0000.html#ap-main-0"><span class="std std-ref">blog</span></a></p>
<a class="reference external image-reference" href="https://app.travis-ci.com/github/sdpython/mlprodict/"><img alt="Build status" src="https://travis-ci.com/sdpython/mlprodict.svg?branch=master" /></a>
<a class="reference external image-reference" href="https://ci.appveyor.com/project/sdpython/mlprodict"><img alt="Build Status Windows" src="https://ci.appveyor.com/api/projects/status/g8chk1ufyk1m8uep?svg=true" /></a>
<a class="reference external image-reference" href="https://circleci.com/gh/sdpython/mlprodict/tree/master"><img alt="https://circleci.com/gh/sdpython/mlprodict/tree/master.svg?style=svg" src="https://circleci.com/gh/sdpython/mlprodict/tree/master.svg?style=svg" /></a>
<a class="reference external image-reference" href="https://dev.azure.com/xavierdupre3/mlprodict/"><img alt="https://dev.azure.com/xavierdupre3/mlprodict/_apis/build/status/sdpython.mlprodict" src="https://dev.azure.com/xavierdupre3/mlprodict/_apis/build/status/sdpython.mlprodict" /></a>
<a class="reference external image-reference" href="https://pypi.org/project/mlprodict/"><img alt="https://badge.fury.io/py/mlprodict.svg" src="https://badge.fury.io/py/mlprodict.svg" /></a>
<a class="reference external image-reference" href="http://opensource.org/licenses/MIT"><img alt="MIT License" src="https://img.shields.io/badge/license-MIT-blue.svg" /></a>
<a class="reference external image-reference" href="https://codecov.io/github/sdpython/mlprodict?branch=master"><img alt="https://codecov.io/github/sdpython/mlprodict/coverage.svg?branch=master" src="https://codecov.io/github/sdpython/mlprodict/coverage.svg?branch=master" /></a>
<a class="reference external image-reference" href="https://github.com/sdpython/mlprodict/issues"><img alt="GitHub Issues" src="http://img.shields.io/github/issues/sdpython/mlprodict.png" /></a>
<a class="reference external image-reference" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/all_notebooks_coverage.html"><img alt="Notebook Coverage" src="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/_images/nbcov.png" /></a>
<a class="reference external image-reference" href="https://pypi.org/project/mlprodict/"><img alt="Downloads" src="https://pepy.tech/badge/mlprodict" /></a>
<a class="reference external image-reference" href="https://github.com/sdpython/pyquickhelper/"><img alt="Forks" src="https://img.shields.io/github/forks/sdpython/mlprodict.svg" /></a>
<a class="reference external image-reference" href="https://github.com/sdpython/mlprodict/"><img alt="Stars" src="https://img.shields.io/github/stars/sdpython/mlprodict.svg" /></a>
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/sdpython/mlprodict/master?filepath=_doc%2Fnotebooks"><img alt="https://mybinder.org/badge_logo.svg" src="https://mybinder.org/badge_logo.svg" /></a>
<a class="reference external image-reference" href="https://github.com/sdpython/mlprodict/"><img alt="size" src="https://img.shields.io/github/repo-size/sdpython/mlprodict" /></a>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial/index.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/index.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">ONNX, Runtime, Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_bench.html">scikit-learn Converters and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="i_cmd.html">Command lines</a></li>
<li class="toctree-l1"><a class="reference internal" href="i_ex.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="i_index.html">FAQ, code, â€¦</a></li>
<li class="toctree-l1"><a class="reference internal" href="gyexamples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="all_notebooks.html">Notebook Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="HISTORY.html">History</a></li>
</ul>
</div>
<p><em>mlprodict</em> was initially started to help implementing converters
to <a class="reference external" href="https://onnx.ai/">ONNX</a>. The main feature is a python runtime for
<a class="reference external" href="https://onnx.ai/">ONNX</a>. It gives more feedback than <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a>
when the execution fails.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt</span> <span class="kn">import</span> <span class="n">OnnxInference</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt.validate.validate_difference</span> <span class="kn">import</span> <span class="n">measure_relative_difference</span>
<span class="kn">from</span> <span class="nn">mlprodict</span> <span class="kn">import</span> <span class="n">get_ir_version</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Predictions with scikit-learn.</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span>

<span class="c1"># Conversion into ONNX.</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="n">model_onnx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                     <span class="n">black_op</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;LinearRegressor&#39;</span><span class="p">},</span>
                     <span class="n">target_opset</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ONNX:&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_onnx</span><span class="p">)[:</span><span class="mi">200</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">...&quot;</span><span class="p">)</span>

<span class="c1"># Predictions with onnxruntime</span>
<span class="n">model_onnx</span><span class="o">.</span><span class="n">ir_version</span> <span class="o">=</span> <span class="n">get_ir_version</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="n">oinf</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">model_onnx</span><span class="p">,</span> <span class="n">runtime</span><span class="o">=</span><span class="s1">&#39;onnxruntime1&#39;</span><span class="p">)</span>
<span class="n">ypred</span> <span class="o">=</span> <span class="n">oinf</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ONNX output:&quot;</span><span class="p">,</span> <span class="n">ypred</span><span class="p">)</span>

<span class="c1"># Measuring the maximum difference.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;max abs diff:&quot;</span><span class="p">,</span> <span class="n">measure_relative_difference</span><span class="p">(</span>
    <span class="n">expected</span><span class="p">,</span> <span class="n">ypred</span><span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">]))</span>

<span class="c1"># And the python runtime</span>
<span class="n">oinf</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">model_onnx</span><span class="p">,</span> <span class="n">runtime</span><span class="o">=</span><span class="s1">&#39;python&#39;</span><span class="p">)</span>
<span class="n">ypred</span> <span class="o">=</span> <span class="n">oinf</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)},</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fLOG</span><span class="o">=</span><span class="nb">print</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ONNX output:&quot;</span><span class="p">,</span> <span class="n">ypred</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[</span><span class="mf">0.172</span> <span class="mf">0.343</span> <span class="mf">0.069</span> <span class="mf">0.059</span> <span class="mf">0.034</span><span class="p">]</span>
    <span class="n">ONNX</span><span class="p">:</span> <span class="n">ir_version</span><span class="p">:</span> <span class="mi">8</span>
    <span class="n">producer_name</span><span class="p">:</span> <span class="s2">&quot;skl2onnx&quot;</span>
    <span class="n">producer_version</span><span class="p">:</span> <span class="s2">&quot;1.11.1&quot;</span>
    <span class="n">domain</span><span class="p">:</span> <span class="s2">&quot;ai.onnx&quot;</span>
    <span class="n">model_version</span><span class="p">:</span> <span class="mi">0</span>
    <span class="n">doc_string</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
    <span class="n">graph</span> <span class="p">{</span>
      <span class="n">node</span> <span class="p">{</span>
        <span class="nb">input</span><span class="p">:</span> <span class="s2">&quot;X&quot;</span>
        <span class="nb">input</span><span class="p">:</span> <span class="s2">&quot;coef&quot;</span>
        <span class="n">output</span><span class="p">:</span> <span class="s2">&quot;multiplied&quot;</span>
        <span class="n">name</span>
    <span class="o">...</span>
    <span class="n">ONNX</span> <span class="n">output</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;variable&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([[</span><span class="mf">0.172</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.343</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.069</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.059</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.034</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)}</span>
    <span class="nb">max</span> <span class="nb">abs</span> <span class="n">diff</span><span class="p">:</span> <span class="mf">6.303014714402957e-06</span>
    <span class="o">+</span><span class="n">ki</span><span class="o">=</span><span class="s1">&#39;coef&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">0.637811005115509</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.7347416877746582</span><span class="p">)</span>
    <span class="o">+</span><span class="n">ki</span><span class="o">=</span><span class="s1">&#39;intercept&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">1.3433398008346558</span> <span class="nb">max</span><span class="o">=-</span><span class="mf">1.3433398008346558</span><span class="p">)</span>
    <span class="o">+</span><span class="n">ki</span><span class="o">=</span><span class="s1">&#39;shape_tensor&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,)</span> <span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">int64</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">1</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="o">--</span> <span class="n">OnnxInference</span><span class="p">:</span> <span class="n">run</span> <span class="mi">3</span> <span class="n">nodes</span>
    <span class="n">Onnx</span><span class="o">-</span><span class="n">MatMul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">multiplied</span>    <span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;MatMul&#39;</span><span class="p">)</span>
    <span class="o">+</span><span class="n">kr</span><span class="o">=</span><span class="s1">&#39;multiplied&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1.3775889873504639</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.6868011951446533</span><span class="p">)</span>
    <span class="n">Onnx</span><span class="o">-</span><span class="n">Add</span><span class="p">(</span><span class="n">multiplied</span><span class="p">,</span> <span class="n">intercept</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">resh</span>    <span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Add&#39;</span><span class="p">)</span>
    <span class="o">+</span><span class="n">kr</span><span class="o">=</span><span class="s1">&#39;resh&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.034249186515808105</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.34346139430999756</span><span class="p">)</span>
    <span class="n">Onnx</span><span class="o">-</span><span class="n">Reshape</span><span class="p">(</span><span class="n">resh</span><span class="p">,</span> <span class="n">shape_tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">variable</span>    <span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Reshape&#39;</span><span class="p">)</span>
    <span class="o">+</span><span class="n">kr</span><span class="o">=</span><span class="s1">&#39;variable&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.034249186515808105</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.34346139430999756</span><span class="p">)</span>
    <span class="n">ONNX</span> <span class="n">output</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;variable&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([[</span><span class="mf">0.172</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.343</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.069</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.059</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.034</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)}</span>
</pre></div>
</div>
<p>These predictions are obtained with the
following <a class="reference external" href="https://onnx.ai/">ONNX</a> graph.</p>

    <div id="gdot-139924214609184-cont"><div id="gdot-139924214609184" style="width:100%;height:100%;"></div>
    <script>

    require(['_static/viz.js'], function() { var svgGraph = Viz(" digraph{\n  ranksep=0.25;\n  nodesep=0.05;\n  orientation=portrait;\n  size=7;\n\n  X [shape=box color=red label=\"X\\nfloat((0, 2))\" fontsize=10];\n\n  variable [shape=box color=green label=\"variable\\nfloat((0, 1))\" fontsize=10];\n\n\n  LinearRegressor [shape=box style=\"filled,rounded\" color=orange label=\"LinearRegressor\\n(LinearRegressor)\\ncoefficients=[ 0.735 -0.638]\\nintercepts=[-1.343]\" fontsize=10];\n  X -> LinearRegressor;\n  LinearRegressor -> variable;\n}\n");
    document.getElementById('gdot-139924214609184').innerHTML = svgGraph; });
    
</script>
</div><p>Notebook <a class="reference internal" href="notebooks/onnx_visualization.html#onnxvisualizationrst"><span class="std std-ref">ONNX visualization</span></a>
shows how to visualize an <a class="reference external" href="https://onnx.ai/">ONNX</a> pipeline.
The package also contains a collection of tools
to help converting code to ONNX. A short list of
them:</p>
<ul class="simple">
<li><p><strong>Python runtime for ONNX:</strong>
<code class="xref py py-class docutils literal notranslate"><span class="pre">OnnxInference</span></code>,
it is mostly used to check that an ONNX graph produces the expected output.
If it fails, it fails within a python code and not inside C++ code.
This class can also be used to call <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> by
using <code class="docutils literal notranslate"><span class="pre">runtime=='onnxruntime1'</span></code>. A last runtime
<code class="docutils literal notranslate"><span class="pre">runtime=='python_compiled'</span></code> compiles a python function equivalent
to code calling operator one by one. It makes easier to read the ONNX
graph (see <a class="reference internal" href="tutorial/onnx_runtime.html#l-onnx-tutorial"><span class="std std-ref">Execute ONNX graphs</span></a>).</p></li>
<li><p><strong>Intermediate results:</strong>
the python runtime may display all intermediate results,
their shape if <cite>verbosity == 1</cite>, their value if <cite>verbosity &gt; 10</cite>,
see <a class="reference internal" href="tutorial/onnx_runtime.html#l-onnx-tutorial"><span class="std std-ref">Execute ONNX graphs</span></a>. This cannot be done with <code class="docutils literal notranslate"><span class="pre">runtime=='onnxruntime1'</span></code>
but it is still possible to get the intermediate results
(see <a class="reference internal" href="mlprodict/onnxrt/onnx_inference.html#mlprodict.onnxrt.onnx_inference.OnnxInference.run" title="mlprodict.onnxrt.onnx_inference.OnnxInference.run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">OnnxInference.run</span></code></a>).
The class will build all subgraphs from the inputs to every intermediate
results. If the graph has <em>N</em> operators, the cost of this will be
<img class="math" src="_images/math/c0d6b8be0bc5d3f9a254b7bb1413212ff36916f4.svg" alt="O(N^2)"/>.</p></li>
<li><p><strong>Extract a subpart of an ONNX graph:</strong>
hen an ONNX graph does not load, it is possible to modify, to extract
some subpart to check a tiny part of it. Function
<a class="reference internal" href="mlprodict/onnx_tools/onnx_manipulations.html#mlprodict.onnx_tools.onnx_manipulations.select_model_inputs_outputs" title="mlprodict.onnx_tools.onnx_manipulations.select_model_inputs_outputs"><code class="xref py py-func docutils literal notranslate"><span class="pre">select_model_inputs_outputs</span></code></a>
may be used to change the inputs and/or the outputs.</p></li>
<li><p><strong>Change the opset</strong>: function
<a class="reference internal" href="mlprodict/onnx_tools/onnx_manipulations.html#mlprodict.onnx_tools.onnx_manipulations.overwrite_opset" title="mlprodict.onnx_tools.onnx_manipulations.overwrite_opset"><code class="xref py py-func docutils literal notranslate"><span class="pre">overwrite_opset</span></code></a>
overwrites the opset, it is used to check for which opset (ONNX version)
a graph is valid. â€¦</p></li>
<li><p><strong>Visualization in a notebook</strong>: a magic command to display
small ONNX graph in notebooks <a class="reference internal" href="notebooks/onnx_visualization.html#onnxvisualizationrst"><span class="std std-ref">ONNX visualization</span></a>.</p></li>
<li><p><strong>Text visualization for ONNX:</strong> a way to visualize ONNX graph only
with text <a class="reference internal" href="mlprodict/plotting/text_plot.html#mlprodict.plotting.text_plot.onnx_text_plot" title="mlprodict.plotting.text_plot.onnx_text_plot"><code class="xref py py-func docutils literal notranslate"><span class="pre">onnx_text_plot</span></code></a>.</p></li>
<li><p><strong>Text visualization of TreeEnsemble:</strong> a way to visualize the graph
described by a on operator TreeEnsembleRegressor or TreeEnsembleClassifier,
see <a class="reference internal" href="mlprodict/plotting/text_plot.html#mlprodict.plotting.text_plot.onnx_text_plot_tree" title="mlprodict.plotting.text_plot.onnx_text_plot_tree"><code class="xref py py-func docutils literal notranslate"><span class="pre">onnx_text_plot</span></code></a>.</p></li>
<li><p><strong>Export ONNX graph to numpy:</strong> the numpy code produces the same
results as the ONNX graph (see <a class="reference internal" href="mlprodict/onnx_tools/onnx_export.html#mlprodict.onnx_tools.onnx_export.export2numpy" title="mlprodict.onnx_tools.onnx_export.export2numpy"><code class="xref py py-func docutils literal notranslate"><span class="pre">export2numpy</span></code></a>)</p></li>
<li><p><strong>Export ONNX graph to ONNX API:</strong> this produces a
a code based on ONNX API which replicates the ONNX graph
(see <a class="reference internal" href="mlprodict/onnx_tools/onnx_export.html#mlprodict.onnx_tools.onnx_export.export2onnx" title="mlprodict.onnx_tools.onnx_export.export2onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">export2onnx</span></code></a>)</p></li>
<li><p><strong>Export ONNX graph to</strong> <a class="reference external" href="https://github.com/onnx/tensorflow-onnx">tf2onnx</a>: still a function which
creates an ONNX graph but based on <a class="reference external" href="https://github.com/onnx/tensorflow-onnx">tf2onnx</a> API
(see <a class="reference internal" href="mlprodict/onnx_tools/onnx_export.html#mlprodict.onnx_tools.onnx_export.export2tf2onnx" title="mlprodict.onnx_tools.onnx_export.export2tf2onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">export2tf2onnx</span></code></a>)</p></li>
<li><p><strong>Xop API:</strong> (ONNX operators API), see <a class="reference internal" href="tutorial/xop_api.html#l-xop-api"><span class="std std-ref">Xop API</span></a>,
most of the converting libraries uses <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> to create ONNX graphs.
The API is quite verbose and that is why most of them implement a second
API wrapping the first one. They are not necessarily meant to be used
by users to create ONNX graphs as they are specialized for the training
framework they are developped for.</p></li>
<li><p><strong>Numpy API for ONNX:</strong> many functions doing computation are
written with <a class="reference external" href="https://www.numpy.org/">numpy</a> and converting them to ONNX may take
quite some time for users not familiar with ONNX. This API implements
many functions from <a class="reference external" href="https://www.numpy.org/">numpy</a> with ONNX and allows the user
to combine them. It is as if numpy function where exectued by an
ONNX runtime: <a class="reference internal" href="tutorial/numpy_api_onnx.html#l-numpy-api-for-onnx"><span class="std std-ref">Numpy to ONNX: Create ONNX graphs with an API similar to numpy</span></a>.</p></li>
<li><p><strong>Benchmark scikit-learn models converted into ONNX:</strong> a simple function to
benchmark ONNX against <em>scikit-learn</em> for a simple model:
<a class="reference internal" href="gyexamples/plot_onnx_benchmark.html#l-example-onnx-benchmark"><span class="std std-ref">Measure ONNX runtime performances</span></a></p></li>
<li><p><strong>Accelerate scikit-learn prediction:</strong>,
what if <em>transform</em> or <em>predict</em> is replaced by an implementation
based on ONNX, or a numpy version of it, would it be faster?
<a class="reference internal" href="gyexamples/plot_speedup_pca.html#l-speedup-pca"><span class="std std-ref">Speed up scikit-learn inference with ONNX</span></a></p></li>
<li><p><strong>Profiling onnxruntime:</strong> <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> can memorize the time
spent in each operator. The following notebook shows how to retreive
the results and display them <a class="reference internal" href="notebooks/onnx_profile_ort.html#onnxprofileortrst"><span class="std std-ref">Profiling with onnxruntime</span></a>.</p></li>
</ul>
<p>This package supports ONNX opsets to the latest opset stored
in <cite>mlprodict.__max_supported_opset__</cite> which is:</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlprodict</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlprodict</span><span class="o">.</span><span class="n">__max_supported_opset__</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="mi">15</span>
</pre></div>
</div>
<p>Any opset beyond that value is not supported and could fail.
Thatâ€™s for the main set of ONNX functions or domain.
Converters for <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> requires another domain,
<cite>â€˜ai.onnxmlâ€™</cite> to implement tree. Latest supported options
are defined here:</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">mlprodict</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">mlprodict</span><span class="o">.</span><span class="n">__max_supported_opsets__</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">{</span><span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;ai.onnx.ml&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
</pre></div>
</div>
<table class="table">
<colgroup>
<col style="width: 14%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 15%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="index_module.html#l-modules"><span class="std std-ref">Modules</span></a></p></td>
<td><p><a class="reference internal" href="index_function.html#l-functions"><span class="std std-ref">Functions</span></a></p></td>
<td><p><a class="reference internal" href="index_class.html#l-classes"><span class="std std-ref">Classes</span></a></p></td>
<td><p><a class="reference internal" href="index_method.html#l-methods"><span class="std std-ref">Methods</span></a></p></td>
<td><p><a class="reference internal" href="index_staticmethod.html#l-staticmethods"><span class="std std-ref">Static Methods</span></a></p></td>
<td><p><a class="reference internal" href="index_property.html#l-properties"><span class="std std-ref">Properties</span></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></td>
<td><p><a class="reference internal" href="i_ex.html#l-ex2"><span class="std std-ref">Examples</span></a></p></td>
<td><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></td>
<td><p><a class="reference internal" href="license.html#l-license"><span class="std std-ref">License</span></a></p></td>
<td><p><a class="reference internal" href="filechanges.html#l-changes"><span class="std std-ref">Changes</span></a></p></td>
<td><p><a class="reference internal" href="README.html#l-readme"><span class="std std-ref">mlprodict</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></td>
<td><p><a class="reference internal" href="i_faq.html#l-faq2"><span class="std std-ref">FAQ</span></a></p></td>
<td><p><a class="reference internal" href="all_notebooks.html#l-notebooks"><span class="std std-ref">Notebook Gallery</span></a></p></td>
<td></td>
<td><p><a class="reference internal" href="all_report.html#l-statcode"><span class="std std-ref">Statistics on code</span></a></p></td>
<td><p><a class="reference external" href="coverage/index.html">Unit Test Coverage</a></p></td>
</tr>
</tbody>
</table>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='right-next' id="next-link" href="installation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Installation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier DuprÃ©.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>