
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>2021-05-05 Numpy API for ONNX and scikit-learn (part I) &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="../../_static/project_ico.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2020-11-27 Parallelization of Random Forest predictions" href="../2020/2020-11-27_parallelisation.html" />
    <link rel="prev" title="2021-05-05 Numpy API for ONNX and scikit-learn (part II)" href="2021-05-05_numpyapionnx2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../i_cmd.html">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../i_index.html">
  FAQ, code, …
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../all_indexes.html">
   All indexes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../all_report.html">
   Statistics on code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../filechanges.html">
   Changes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../index_module.html">
   Modules
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../i_faq.html">
   FAQ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../i_nb.html">
   Magic commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../blogindex.html">
   Blog Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../license.html">
   License
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   mlprodict
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="simple visible nav section-nav flex-column">
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="numpy-api-for-onnx-and-scikit-learn-part-i">
<span id="blog-onnx-api-part1"></span><h1>2021-05-05 Numpy API for ONNX and scikit-learn (part I)<a class="headerlink" href="#numpy-api-for-onnx-and-scikit-learn-part-i" title="Permalink to this headline">#</a></h1>
<p>
<script>
function share_url(share) {
    var url = share + encodeURIComponent(window.location.href);
    window.location.href = url;
}

function share_icon(divid, text) {
    var canvas = document.getElementById(divid);
    var context = canvas.getContext('2d');
    var centerX = canvas.width / 2;
    var centerY = canvas.height / 2;
    var radius = centerX;

    context.beginPath();
    context.arc(centerX, centerY, radius, 0, 2 * Math.PI, false);
    context.fillStyle = '#444444';
    context.fill();
    context.font = '' + (centerX*4/3) + 'pt Calibri';
    context.textAlign = 'center';
    context.fillStyle = '#FFFFFF';
    context.fillText(text, centerX, centerY+centerY*16/30);
}
</script>
<a href="#" onclick="share_url('https://www.facebook.com/sharer/sharer.php?u=');return false;"><canvas height="20" id="canvas-f" width="20"/></a><script>share_icon('canvas-f', 'f');</script><a href="#" onclick="share_url('https://www.linkedin.com/shareArticle?mini=true&amp;title=&amp;summary=&amp;source=&amp;url=');return false;"><canvas height="20" id="canvas-in" width="20"/></a><script>share_icon('canvas-in', 'in');</script><a href="#" onclick="share_url('https://twitter.com/home?status=');return false;"><canvas height="20" id="canvas-t" width="20"/></a><script>share_icon('canvas-t', 't');</script></p>
<p><a class="reference external" href="https://github.com/onnx/sklearn-onnx">sklearn-onnx</a> converts most of the pipelines including
numerical preprocessing or predictors but it fails whenever
custom code is involved. That covers the use of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html">FunctionTransformer</a> or a new model
inheriting from <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">BaseEstimator</a>. To be successful,
the conversion needs a way to convert the custom code into ONNX.
The proposed solution here is bypass that complex steps
(rewrite a python function with ONNX operators) by directly writing
the custom code with ONNX operators. However, even though most of
the operator are close to <a class="reference external" href="https://www.numpy.org/">numpy</a> functions, they are not
the same. To avoid spending time looking at them, many <a class="reference external" href="https://www.numpy.org/">numpy</a>
functions were implementing with ONNX operators. The custom function
or predictor can then just be implemented with this API to build
a unique ONNX graph executed with a runtime.</p>
<p>Next sections takes some examples from
<a class="reference internal" href="../../tutorial/numpy_api_onnx.html#l-numpy-api-for-onnx"><span class="std std-ref">Numpy to ONNX: Create ONNX graphs with an API similar to numpy</span></a>.</p>
<p><strong>numpy API for ONNX</strong></p>
<p>Let’s an example with a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html">FunctionTransformer</a>.</p>
<p>The mechanism is similar to what <a class="reference external" href="https://pytorch.org/">pytorch</a> or <a class="reference external" href="https://www.tensorflow.org/">tensorflow</a>
put in place: write a graph assuming every node processes a variable.
Then the user instantiates a variable and executes the graph.
It works the same with ONNX. The following snippet implement the
function <img class="math" src="../../_images/math/e735dc47efe872236d7c13a7c3fba97e9c006c80.svg" alt="log(1 + x)"/>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mlprodict.npy.numpy_onnx_impl</span> <span class="k">as</span> <span class="nn">npnx</span>

<span class="k">def</span> <span class="nf">onnx_log_1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">npnx</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>The list of implemented function is <a class="reference internal" href="../../mlprodict/npy/numpy_onnx_impl.html#f-numpyonnximpl"><span class="std std-ref">module npy.numpy_onnx_impl</span></a>.
ONNX is strongly typed so we need to specified them with annotations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mlprodict.npy</span> <span class="kn">import</span> <span class="n">NDArray</span>
<span class="kn">import</span> <span class="nn">mlprodict.npy.numpy_onnx_impl</span> <span class="k">as</span> <span class="nn">npnx</span>

<span class="k">def</span> <span class="nf">onnx_log_1</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">npnx</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>And finally, this function does not run on a numpy array as every
function expects a variable (see <code class="xref py py-class docutils literal notranslate"><span class="pre">OnnxVariable</span></code>) to define an ONNX graph
which can be executed with a runtime. That’s the purpose of the decorator
<cite>onnxnumpy_default</cite>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mlprodict.npy</span> <span class="kn">import</span> <span class="n">onnxnumpy_default</span><span class="p">,</span> <span class="n">NDArray</span>
<span class="kn">import</span> <span class="nn">mlprodict.npy.numpy_onnx_impl</span> <span class="k">as</span> <span class="nn">npnx</span>


<span class="nd">@onnxnumpy_default</span>
<span class="k">def</span> <span class="nf">onnx_log_1</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">npnx</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">onnx_log_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">onnx_log_1</span><span class="p">))</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [[0.693 1.099]
     [1.386 1.609]]
    &lt;class &#39;mlprodict.npy.onnx_numpy_wrapper.onnxnumpy_onnx_log_1_None_None&#39;&gt;
</pre></div>
</div>
<p><cite>onnx_log_1</cite> is not a function but an instance
of a class which defines operator <cite>__call__</cite> and that class
has a hold on the ONNX graph and all the necessary information
to have <a class="reference external" href="https://github.com/onnx/sklearn-onnx">sklearn-onnx</a> convert any pipeline using it after
a new converter for <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html">FunctionTransformer</a> is registered
to handle this API.</p>
<p>The ONNX graph is created when the function is called for the
first time and loaded by the runtime. That explains why the first
call is much slower and all the other call.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">register_rewritten_operators</span>
<span class="n">register_rewritten_operators</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>The complete example:</strong></p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">mlprodict.npy.numpy_onnx_impl</span> <span class="k">as</span> <span class="nn">npnx</span>
<span class="kn">from</span> <span class="nn">mlprodict.npy</span> <span class="kn">import</span> <span class="n">onnxnumpy_default</span><span class="p">,</span> <span class="n">NDArray</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt</span> <span class="kn">import</span> <span class="n">OnnxInference</span>

<span class="kn">from</span> <span class="nn">skl2onnx</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">register_rewritten_operators</span>
<span class="n">register_rewritten_operators</span><span class="p">()</span>


<span class="nd">@onnxnumpy_default</span>
<span class="k">def</span> <span class="nf">onnx_log_1</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">npnx</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">onnx_log_1</span><span class="p">),</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">2</span><span class="p">]))</span>

<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span>
              <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="n">LogisticRegression</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;zipmap&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}})</span>
<span class="n">oinf</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">oinf</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X_test</span><span class="p">[:</span><span class="mi">2</span><span class="p">]})[</span><span class="s1">&#39;probabilities&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[[</span><span class="mf">9.860e-01</span> <span class="mf">1.396e-02</span> <span class="mf">3.130e-07</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">2.012e-02</span> <span class="mf">8.711e-01</span> <span class="mf">1.088e-01</span><span class="p">]]</span>
    <span class="p">[[</span><span class="mf">9.860e-01</span> <span class="mf">1.396e-02</span> <span class="mf">3.130e-07</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">2.012e-02</span> <span class="mf">8.711e-01</span> <span class="mf">1.088e-01</span><span class="p">]]</span>
</pre></div>
</div>
<p>The decorator has parameter to change the way the function
is converted or executed. ONNX has different version or opset,
it is possible to target a specific opset. The ONNX graph must
be executed with a runtime, this one or <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a>.
This can be defined too. The function is strongly typed but it is
possible to have an implementation which supports multiple types.
An ONNX graph will be created for every distinct type,
like a template in C++.
See <a class="reference internal" href="../../tutorial/numpy_api_onnx.html#l-numpy-api-for-onnx"><span class="std std-ref">Numpy to ONNX: Create ONNX graphs with an API similar to numpy</span></a> for more information.</p>
<p>Next: <a class="reference internal" href="2021-05-05_numpyapionnx2.html#blog-onnx-api-part2"><span class="std std-ref">Numpy API for ONNX and scikit-learn (part II)</span></a>.</p>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="2021-05-05_numpyapionnx2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">2021-05-05 Numpy API for ONNX and scikit-learn (part II)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../2020/2020-11-27_parallelisation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">2020-11-27 Parallelization of Random Forest predictions</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>