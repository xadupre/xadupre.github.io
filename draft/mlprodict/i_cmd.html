
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Command lines &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/thebelab-helper.js"></script>
    <script src="_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="_static/project_ico.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="i_ex.html" />
    <link rel="prev" title="Availability of scikit-learn model for runtime onnxruntime1" href="skl_converters/bench_onnxrt1.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="current reference internal nav-link" href="#">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="i_index.html">
  FAQ, code, â€¦
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="command-lines">
<span id="l-cmd2"></span><h1>Command lines<a class="headerlink" href="#command-lines" title="Permalink to this headline">#</a></h1>
<ol class="simple">
<li><p><a class="reference internal" href="#index-cmdref-0-0">Automatically creates an asv benchmark</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-1">Computes statistics on an ONNX graph</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-2">Converts and compares an ONNX file</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-3">Converts asv results into csv</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-4">Exports an ONNX graph into a python code creating the same graph.</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-5">Investigates whether or not the decomposing einsum is faster.</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-6">Measures model latency</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-7">Measures model latency</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-8">Optimizes an ONNX graph</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-9">Plots an ONNX graph as text</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-10">Replays a benchmark of stored converted models by validate_runtime</a></p></li>
<li><p><a class="reference internal" href="#index-cmdref-0-11">Validates a runtime against scikit-learn</a></p></li>
</ol>
<div class="admonition-cmdref admonition" id="index-cmdref-0-0">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-asv-bench">Automatically creates an asv benchmark</p>
<p>The command creates a benchmark based on asv module.
It does not run it.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">asv_bench</span> <span class="o">--</span><span class="n">models</span> <span class="n">LogisticRegression</span><span class="p">,</span><span class="n">LinearRegression</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">asv_bench</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: asv_bench [-h] [-l LOCATION] [-o OPSET_MIN] [-op OPSET_MAX]
                 [-r RUNTIME] [-m MODELS] [-s SKIP_MODELS] [-e EXTENDED_LIST]
                 [-d DIMS] [-n N_FEATURES] [-dt DTYPE] [-v VERBOSE] [-c CLEAN]
                 [-f FLAT] [-co CONF_PARAMS] [-b BUILD] [-a ADD_PYSPY]
                 [--env ENV] [-ma MATRIX]

Creates an `asv` benchmark in a folder but does not run it.

optional arguments:
  -h, --help            show this help message and exit
  -l LOCATION, --location LOCATION
                        location of the benchmark (default: asvsklonnx)
  -o OPSET_MIN, --opset_min OPSET_MIN
                        tries every conversion from this minimum opset, `-1`
                        to get the current opset defined by module onnx
                        (default: -1)
  -op OPSET_MAX, --opset_max OPSET_MAX
                        tries every conversion up to maximum opset, `-1` to
                        get the current opset defined by module onnx (default:
                        )
  -r RUNTIME, --runtime RUNTIME
                        runtime to check, *scikit-learn*, *python*,
                        *python_compiled* compiles the graph structure and is
                        more efficient when the number of observations is
                        small, *onnxruntime1* to check `onnxruntime`,
                        *onnxruntime2* to check every ONNX node independently
                        with onnxruntime, many runtime can be checked at the
                        same time if the value is a comma separated list
                        (default: scikit-learn,python_compiled)
  -m MODELS, --models MODELS
                        list of models to test or empty string to test them
                        all (default: )
  -s SKIP_MODELS, --skip_models SKIP_MODELS
                        models to skip (default: )
  -e EXTENDED_LIST, --extended_list EXTENDED_LIST
                        extends the list of :epkg:`scikit-learn` converters
                        with converters implemented in this module (default:
                        True)
  -d DIMS, --dims DIMS  number of observations to try (default:
                        1,10,100,1000,10000)
  -n N_FEATURES, --n_features N_FEATURES
                        number of features to try (default: 4,20)
  -dt DTYPE, --dtype DTYPE
                        &#39;32&#39; or &#39;64&#39; or None for both, limits the test to one
                        specific number types (default: )
  -v VERBOSE, --verbose VERBOSE
                        integer from 0 (None) to 2 (full verbose) (default: 1)
  -c CLEAN, --clean CLEAN
                        clean the folder first, otherwise overwrites the
                        content (default: True)
  -f FLAT, --flat FLAT  one folder for all files or subfolders (default:
                        False)
  -co CONF_PARAMS, --conf_params CONF_PARAMS
                        to overwrite some of the configuration parameters,
                        format ``name,value;name2,value2`` (default: )
  -b BUILD, --build BUILD
                        location of the outputs (env, html, results) (default:
                        )
  -a ADD_PYSPY, --add_pyspy ADD_PYSPY
                        add an extra folder with code to profile each
                        configuration (default: False)
  --env ENV             default environment or ``same`` to use the current one
                        (default: )
  -ma MATRIX, --matrix MATRIX
                        specifies versions for a module as a json string,
                        example: ``{&#39;onnxruntime&#39;: [&#39;1.1.1&#39;, &#39;1.1.2&#39;]}``, if a
                        package name starts with `&#39;~&#39;`, the package is removed
                        (default: )

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-0"></span>(<a class="reference internal" href="mlprodict/cli/asv_bench.html#indexcmdref-cmd0">original entry</a> : asv_bench.py:docstring of mlprodict.cli.asv_bench.asv_bench, line 40)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-1">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-onnx-stats">Computes statistics on an ONNX graph</p>
<p>The command computes statistics on an ONNX model.</p>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">onnx_stats</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: onnx_stats [-h] [-n NAME] [-o OPTIM] [-k KIND]

Computes statistics on an ONNX model.

optional arguments:
  -h, --help            show this help message and exit
  -n NAME, --name NAME  filename (default: None)
  -o OPTIM, --optim OPTIM
                        computes statistics before an after optimisation was
                        done (default: False)
  -k KIND, --kind KIND  kind of statistics, if left unknown, prints out the
                        metadata, possible values: * `io`: prints input and
                        output name, type, shapes * `node`: prints the
                        distribution of node types * `text`: printts a text
                        summary (default: )

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd1-0"></span>(<a class="reference internal" href="mlprodict/cli/optimize.html#indexcmdref-cmd1">original entry</a> : optimize.py:docstring of mlprodict.cli.optimize.onnx_stats, line 11)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-2">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-convert-validate">Converts and compares an ONNX file</p>
<p>The command converts and validates a <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> model.
An example to check the prediction of a logistic regression.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">mlprodict.__main__</span> <span class="kn">import</span> <span class="n">main</span>
<span class="kn">from</span> <span class="nn">mlprodict.cli</span> <span class="kn">import</span> <span class="n">convert_validate</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">clr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">clr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;model.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">clr</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
<p>And the command line to check the predictions
using a command line.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">convert_validate</span> <span class="o">--</span><span class="n">pkl</span> <span class="n">model</span><span class="o">.</span><span class="n">pkl</span> <span class="o">--</span><span class="n">data</span> <span class="n">data</span><span class="o">.</span><span class="n">csv</span>
                 <span class="o">--</span><span class="n">method</span> <span class="n">predict</span><span class="p">,</span><span class="n">predict_proba</span>
                 <span class="o">--</span><span class="n">name</span> <span class="n">output_label</span><span class="p">,</span><span class="n">output_probability</span>
                 <span class="o">--</span><span class="n">verbose</span> <span class="mi">1</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">convert_validate</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: convert_validate [-h] [--pkl PKL] [-d DATA] [-s SCHEMA] [-m METHOD]
                        [-n NAME] [-t TARGET_OPSET] [-o OUTONNX] [-r RUNTIME]
                        [-me METRIC] [-u USE_DOUBLE] [-no NOSHAPE] [-op OPTIM]
                        [-re REWRITE_OPS] [-opt OPTIONS] [-v VERBOSE]
                        [-reg REGISTER]

Converts a model stored in *pkl* file and measure the differences between the
model and the ONNX predictions.

optional arguments:
  -h, --help            show this help message and exit
  --pkl PKL             pickle file (default: None)
  -d DATA, --data DATA  data file, loaded with pandas, converted to a single
                        array, the data is used to guess the schema if
                        *schema* not specified (default: )
  -s SCHEMA, --schema SCHEMA
                        initial type of the model (default: )
  -m METHOD, --method METHOD
                        method to call (default: predict)
  -n NAME, --name NAME  output name (default: Y)
  -t TARGET_OPSET, --target_opset TARGET_OPSET
                        target opset (default: )
  -o OUTONNX, --outonnx OUTONNX
                        produced ONNX model (default: model.onnx)
  -r RUNTIME, --runtime RUNTIME
                        runtime to use to compute predictions, &#39;python&#39;,
                        &#39;python_compiled&#39;, &#39;onnxruntime1&#39; or &#39;onnxruntime2&#39;
                        (default: python)
  -me METRIC, --metric METRIC
                        the metric &#39;l1med&#39; is given by function
                        :func:`measure_relative_difference &lt;mlprodict.onnxrt.v
                        alidate.validate_difference.measure_relative_differenc
                        e&gt;` (default: l1med)
  -u USE_DOUBLE, --use_double USE_DOUBLE
                        use double for the runtime if possible, two possible
                        options, ``&quot;float64&quot;`` or ``&#39;switch&#39;``, the first
                        option produces an ONNX file with doubles, the second
                        option loads an ONNX file (float or double) and
                        replaces matrices in ONNX with the matrices coming
                        from the model, this second way is just for testing
                        purposes (default: )
  -no NOSHAPE, --noshape NOSHAPE
                        run the conversion with no shape information (default:
                        False)
  -op OPTIM, --optim OPTIM
                        applies optimisations on the first ONNX graph, use
                        &#39;onnx&#39; to reduce the number of node Identity and
                        redundant subgraphs (default: onnx)
  -re REWRITE_OPS, --rewrite_ops REWRITE_OPS
                        rewrites some converters from :epkg:`sklearn-onnx`
                        (default: True)
  -opt OPTIONS, --options OPTIONS
                        additional options for conversion, dictionary as a
                        string (default: )
  -v VERBOSE, --verbose VERBOSE
                        verbose level (default: 1)
  -reg REGISTER, --register REGISTER
                        registers additional converters implemented by this
                        package (default: True)

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-1"></span>(<a class="reference internal" href="mlprodict/cli/convert_validate.html#indexcmdref-cmd0">original entry</a> : convert_validate.py:docstring of mlprodict.cli.convert_validate.convert_validate, line 37)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-3">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-asv2csv">Converts asv results into csv</p>
<p>The command converts <a class="reference external" href="https://github.com/airspeed-velocity/asv">asv</a> results into <a class="reference external" href="https://en.wikipedia.org/wiki/Comma-separated_values">csv</a>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">asv2csv</span> <span class="o">-</span><span class="n">f</span> <span class="o">&lt;</span><span class="n">folder</span><span class="o">&gt;</span> <span class="o">-</span><span class="n">o</span> <span class="n">result</span><span class="o">.</span><span class="n">csv</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">asv2csv</span><span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Command not found: &#39;asv2csv--help&#39;.

Available commands:

    asv2csv            Converts results produced by :epkg:`asv` into :epkg:`csv`.
    asv_bench          Creates an :epkg:`asv` benchmark in a folder
    benchmark_doc      Runs the benchmark published into the documentation
    benchmark_replay   The command rerun a benchmark if models were stored by
    convert_validate   Converts a model stored in *pkl* file and measure the differences
    dynamic_doc        Generates the documentation for ONNX operators.
    einsum_test        Investigates whether or not the decomposing einsum is faster.
    latency            Measures the latency of a model (python API).
    onnx_code          Exports an ONNX graph into a python code creating
    onnx_optim         Optimizes an ONNX model.
    onnx_stats         Computes statistics on an ONNX model.
    plot_onnx          Plots an ONNX graph on the standard output.
    validate_runtime   Walks through most of :epkg:`scikit-learn` operators
</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-2"></span>(<a class="reference internal" href="mlprodict/cli/asv2csv.html#indexcmdref-cmd0">original entry</a> : asv2csv.py:docstring of mlprodict.cli.asv2csv.asv2csv, line 11)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-4">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-onnx-code">Exports an ONNX graph into a python code creating the same graph.</p>
<p>The command converts an ONNX graph into a python code generating
the same graph. The python code may use onnx syntax, numpy syntax
or tf2onnx syntax.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">onnx_code</span> <span class="o">--</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;something.onnx&quot;</span> <span class="o">--</span><span class="nb">format</span><span class="o">=</span><span class="n">onnx</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">onnx_code</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: onnx_code [-h] [-f FILENAME] [-fo FORMAT] [-o OUTPUT] [-v VERBOSE]
                 [-n NAME] [-op OPSET]

Exports an ONNX graph into a python code creating the same graph.

optional arguments:
  -h, --help            show this help message and exit
  -f FILENAME, --filename FILENAME
                        onnx file (default: None)
  -fo FORMAT, --format FORMAT
                        format to export too (`onnx`, `tf2onnx`, `numpy`)
                        (default: onnx)
  -o OUTPUT, --output OUTPUT
                        output file to produce or None to print it on stdout
                        (default: )
  -v VERBOSE, --verbose VERBOSE
                        verbosity level (default: 0)
  -n NAME, --name NAME  rewrite the graph name (default: )
  -op OPSET, --opset OPSET
                        overwrite the opset (may not works depending on the
                        format) (default: )

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-3"></span>(<a class="reference internal" href="mlprodict/cli/onnx_code.html#indexcmdref-cmd0">original entry</a> : onnx_code.py:docstring of mlprodict.cli.onnx_code.onnx_code, line 12)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-5">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-einsum-test">Investigates whether or not the decomposing einsum is faster.</p>
<p>The command checks whether or not decomposing an einsum function
is faster than einsum implementation.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">einsum_test</span> <span class="o">--</span><span class="n">equation</span><span class="o">=</span><span class="s2">&quot;abc,cd-&gt;abd&quot;</span> <span class="o">--</span><span class="n">output</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">csv</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">einsum_test</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: einsum_test [-h] [-e EQUATION] [-s SHAPE] [-p PERM] [-r RUNTIME]
                   [-v VERBOSE] [-o OUTPUT] [-n NUMBER] [-re REPEAT]

Investigates whether or not the decomposing einsum is faster.

optional arguments:
  -h, --help            show this help message and exit
  -e EQUATION, --equation EQUATION
                        einsum equation to test (default: abc,cd-&gt;abd)
  -s SHAPE, --shape SHAPE
                        an integer (all dimension gets the same size) or a
                        list of shapes in a string separated with `;`) or a
                        list of integer to try out multiple shapes, example:
                        `5`, `(5,5,5),(5,5)`, `5,6` (default: 30)
  -p PERM, --perm PERM  check on permutation or all letter permutations
                        (default: False)
  -r RUNTIME, --runtime RUNTIME
                        `&#39;numpy&#39;`, `&#39;python&#39;`, `&#39;onnxruntime&#39;` (default:
                        python)
  -v VERBOSE, --verbose VERBOSE
                        verbose (default: 1)
  -o OUTPUT, --output OUTPUT
                        output file (usually a csv file or an excel file), it
                        requires pandas (default: )
  -n NUMBER, --number NUMBER
                        usual parameter to measure a function (default: 5)
  -re REPEAT, --repeat REPEAT
                        usual parameter to measure a function (default: 5)

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-4"></span>(<a class="reference internal" href="mlprodict/cli/einsum.html#indexcmdref-cmd0">original entry</a> : einsum.py:docstring of mlprodict.cli.einsum.einsum_test, line 17)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-6">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-latency">Measures model latency</p>
<p>The command generates random inputs and call many times the
model on these inputs. It returns the processing time for one
iteration.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">latency</span> <span class="o">--</span><span class="n">model</span> <span class="s2">&quot;model.onnx&quot;</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">latency</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: latency [-h] [-m MODEL] [--law LAW] [-s SIZE] [-n NUMBER] [-r REPEAT]
               [-ma MAX_TIME] [-ru RUNTIME] [-d DEVICE] [--fmt FMT]
               [-p PROFILING] [-pr PROFILE_OUTPUT]

Measures the latency of a model (python API).

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        ONNX graph (default: None)
  --law LAW             random law used to generate fake inputs (default:
                        normal)
  -s SIZE, --size SIZE  batch size, it replaces the first dimension of every
                        input if it is left unknown (default: 1)
  -n NUMBER, --number NUMBER
                        number of calls to measure (default: 10)
  -r REPEAT, --repeat REPEAT
                        number of times to repeat the experiment (default: 10)
  -ma MAX_TIME, --max_time MAX_TIME
                        if it is &gt; 0, it runs as many time during that period
                        of time (default: 0)
  -ru RUNTIME, --runtime RUNTIME
                        available runtime (default: onnxruntime)
  -d DEVICE, --device DEVICE
                        device, `cpu`, `cuda:0` or a list of providers
                        `CPUExecutionProvider, CUDAExecutionProvider (default:
                        cpu)
  --fmt FMT             None or `csv`, it then returns a string formatted like
                        a csv file (default: )
  -p PROFILING, --profiling PROFILING
                        if True, profile the execution of every node, if can
                        be sorted by name or type, the value for this
                        parameter should e in `(None, &#39;name&#39;, &#39;type&#39;)`
                        (default: )
  -pr PROFILE_OUTPUT, --profile_output PROFILE_OUTPUT
                        output name for the profiling if profiling is
                        specified (default: profiling.csv)

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-5"></span>(<a class="reference internal" href="mlprodict/cli/validate.html#indexcmdref-cmd0">original entry</a> : validate.py:docstring of mlprodict.cli.validate.latency, line 22)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-7">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-latency">Measures model latency</p>
<p>The command generates random inputs and call many times the
model on these inputs. It returns the processing time for one
iteration.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">latency</span> <span class="o">--</span><span class="n">model</span> <span class="s2">&quot;model.onnx&quot;</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">latency</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: latency [-h] [-m MODEL] [--law LAW] [-s SIZE] [-n NUMBER] [-r REPEAT]
               [-ma MAX_TIME] [-ru RUNTIME] [-d DEVICE] [--fmt FMT]
               [-p PROFILING] [-pr PROFILE_OUTPUT]

Measures the latency of a model (python API).

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        ONNX graph (default: None)
  --law LAW             random law used to generate fake inputs (default:
                        normal)
  -s SIZE, --size SIZE  batch size, it replaces the first dimension of every
                        input if it is left unknown (default: 1)
  -n NUMBER, --number NUMBER
                        number of calls to measure (default: 10)
  -r REPEAT, --repeat REPEAT
                        number of times to repeat the experiment (default: 10)
  -ma MAX_TIME, --max_time MAX_TIME
                        if it is &gt; 0, it runs as many time during that period
                        of time (default: 0)
  -ru RUNTIME, --runtime RUNTIME
                        available runtime (default: onnxruntime)
  -d DEVICE, --device DEVICE
                        device, `cpu`, `cuda:0` or a list of providers
                        `CPUExecutionProvider, CUDAExecutionProvider (default:
                        cpu)
  --fmt FMT             None or `csv`, it then returns a string formatted like
                        a csv file (default: )
  -p PROFILING, --profiling PROFILING
                        if True, profile the execution of every node, if can
                        be sorted by name or type, the value for this
                        parameter should e in `(None, &#39;name&#39;, &#39;type&#39;)`
                        (default: )
  -pr PROFILE_OUTPUT, --profile_output PROFILE_OUTPUT
                        output name for the profiling if profiling is
                        specified (default: profiling.csv)

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-6"></span>(<a class="reference internal" href="mlprodict/onnxrt/validate/validate_latency.html#indexcmdref-cmd0">original entry</a> : validate_latency.py:docstring of mlprodict.onnxrt.validate.validate_latency.latency, line 19)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-8">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-onnx-optim">Optimizes an ONNX graph</p>
<p>The command optimizes an ONNX model.</p>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">onnx_optim</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">onnx_optim</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">n</span> <span class="n">NAME</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">o</span> <span class="n">OUTFILE</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">r</span> <span class="n">RECURSIVE</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">op</span> <span class="n">OPTIONS</span><span class="p">]</span>
                  <span class="p">[</span><span class="o">-</span><span class="n">v</span> <span class="n">VERBOSE</span><span class="p">]</span>

<span class="n">Optimizes</span> <span class="n">an</span> <span class="n">ONNX</span> <span class="n">model</span><span class="o">.</span>

<span class="n">optional</span> <span class="n">arguments</span><span class="p">:</span>
  <span class="o">-</span><span class="n">h</span><span class="p">,</span> <span class="o">--</span><span class="n">help</span>            <span class="n">show</span> <span class="n">this</span> <span class="n">help</span> <span class="n">message</span> <span class="ow">and</span> <span class="n">exit</span>
  <span class="o">-</span><span class="n">n</span> <span class="n">NAME</span><span class="p">,</span> <span class="o">--</span><span class="n">name</span> <span class="n">NAME</span>  <span class="n">filename</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
  <span class="o">-</span><span class="n">o</span> <span class="n">OUTFILE</span><span class="p">,</span> <span class="o">--</span><span class="n">outfile</span> <span class="n">OUTFILE</span>
                        <span class="n">output</span> <span class="n">filename</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="p">)</span>
  <span class="o">-</span><span class="n">r</span> <span class="n">RECURSIVE</span><span class="p">,</span> <span class="o">--</span><span class="n">recursive</span> <span class="n">RECURSIVE</span>
                        <span class="n">processes</span> <span class="n">the</span> <span class="n">main</span> <span class="n">graph</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">subgraphs</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span>
                        <span class="kc">True</span><span class="p">)</span>
  <span class="o">-</span><span class="n">op</span> <span class="n">OPTIONS</span><span class="p">,</span> <span class="o">--</span><span class="n">options</span> <span class="n">OPTIONS</span>
                        <span class="n">options</span><span class="p">,</span> <span class="n">kind</span> <span class="n">of</span> <span class="n">optimize</span> <span class="n">to</span> <span class="n">do</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="p">)</span>
  <span class="o">-</span><span class="n">v</span> <span class="n">VERBOSE</span><span class="p">,</span> <span class="o">--</span><span class="n">verbose</span> <span class="n">VERBOSE</span>
                        <span class="n">display</span> <span class="n">statistics</span> <span class="n">before</span> <span class="ow">and</span> <span class="n">after</span> <span class="n">the</span> <span class="n">optimisation</span>
                        <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-7"></span>(<a class="reference internal" href="mlprodict/cli/optimize.html#indexcmdref-cmd0">original entry</a> : optimize.py:docstring of mlprodict.cli.optimize.onnx_optim, line 10)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-9">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-plot-onnx">Plots an ONNX graph as text</p>
<p>The command shows the ONNX graphs as a text on the standard output.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">plot_onnx</span> <span class="o">--</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;something.onnx&quot;</span> <span class="o">--</span><span class="nb">format</span><span class="o">=</span><span class="n">simple</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">plot_onnx</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: plot_onnx [-h] [-f FILENAME] [-fo FORMAT] [-v VERBOSE] [-o OUTPUT]

Plots an ONNX graph on the standard output.

optional arguments:
  -h, --help            show this help message and exit
  -f FILENAME, --filename FILENAME
                        onnx file (default: None)
  -fo FORMAT, --format FORMAT
                        format to export too (`simple`, `tree`, `dot`, `io`,
                        `mat`, `raw`) (default: onnx)
  -v VERBOSE, --verbose VERBOSE
                        verbosity level (default: 0)
  -o OUTPUT, --output OUTPUT
                        output file to produce or None to print it on stdout
                        (default: )

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd1-1"></span>(<a class="reference internal" href="mlprodict/cli/onnx_code.html#indexcmdref-cmd1">original entry</a> : onnx_code.py:docstring of mlprodict.cli.onnx_code.plot_onnx, line 10)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-10">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-benchmark-replay">Replays a benchmark of stored converted models by validate_runtime</p>
<p>The command rerun a benchmark if models were stored by
command line <cite>vaidate_runtime</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">benchmark_replay</span> <span class="o">--</span><span class="n">folder</span> <span class="n">dumped</span> <span class="o">--</span><span class="n">out</span> <span class="n">bench_results</span><span class="o">.</span><span class="n">xlsx</span>
</pre></div>
</div>
<p>Parameter <code class="docutils literal notranslate"><span class="pre">--time_kwargs</span></code> may be used to reduce or increase
bencharmak precisions. The following value tells the function
to run a benchmarks with datasets of 1 or 10 number, to repeat
a given number of time <em>number</em> predictions in one row.
The total time is divided by <img class="math" src="_images/math/b2a8ec412aac147c13883b2524b98a033c85f07f.svg" alt="number \times repeat"/>.
Parameter <code class="docutils literal notranslate"><span class="pre">--time_kwargs_fact</span></code> may be used to increase these
number for some specific models. <code class="docutils literal notranslate"><span class="pre">'lin'</span></code> multiplies
by 10 number when the model is linear.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span><span class="n">t</span> <span class="s2">&quot;{</span><span class="se">\&quot;</span><span class="s2">1</span><span class="se">\&quot;</span><span class="s2">:{</span><span class="se">\&quot;</span><span class="s2">number</span><span class="se">\&quot;</span><span class="s2">:10,</span><span class="se">\&quot;</span><span class="s2">repeat</span><span class="se">\&quot;</span><span class="s2">:10},</span><span class="se">\&quot;</span><span class="s2">10</span><span class="se">\&quot;</span><span class="s2">:{</span><span class="se">\&quot;</span><span class="s2">number</span><span class="se">\&quot;</span><span class="s2">:5,</span><span class="se">\&quot;</span><span class="s2">repeat</span><span class="se">\&quot;</span><span class="s2">:5}}&quot;</span>
</pre></div>
</div>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">benchmark_replay</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: benchmark_replay [-h] [-f FOLDER] [-r RUNTIME] [-t TIME_KWARGS]
                        [-s SKIP_LONG_TEST] [-ti TIME_KWARGS_FACT]
                        [-tim TIME_LIMIT] [--out OUT] [-v VERBOSE]

The command rerun a benchmark if models were stored by command line
`vaidate_runtime`.

optional arguments:
  -h, --help            show this help message and exit
  -f FOLDER, --folder FOLDER
                        where to find pickled files (default: None)
  -r RUNTIME, --runtime RUNTIME
                        runtimes, comma separated list (default: python)
  -t TIME_KWARGS, --time_kwargs TIME_KWARGS
                        a dictionary which defines the number of rows and the
                        parameter *number* and *repeat* when benchmarking a
                        model, the value must follow `json` format (default: )
  -s SKIP_LONG_TEST, --skip_long_test SKIP_LONG_TEST
                        skips tests for high values of N if they seem too long
                        (default: True)
  -ti TIME_KWARGS_FACT, --time_kwargs_fact TIME_KWARGS_FACT
                        to multiply number and repeat in *time_kwargs*
                        depending on the model (see
                        :func:`_multiply_time_kwargs &lt;mlprodict.onnxrt.validat
                        e.validate_helper._multiply_time_kwargs&gt;`) (default: )
  -tim TIME_LIMIT, --time_limit TIME_LIMIT
                        to stop benchmarking after this limit of time
                        (default: 4)
  --out OUT             output raw results into this file (excel format)
                        (default: )
  -v VERBOSE, --verbose VERBOSE
                        integer from 0 (None) to 2 (full verbose) (default: 1)

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd0-8"></span>(<a class="reference internal" href="mlprodict/cli/replay.html#indexcmdref-cmd0">original entry</a> : replay.py:docstring of mlprodict.cli.replay.benchmark_replay, line 19)</p>
<div class="admonition-cmdref admonition" id="index-cmdref-0-11">
<div class="docutils container">
</div>
<p class="admonition-title" id="l-cmd-validate-runtime">Validates a runtime against scikit-learn</p>
<p>The command walks through all scikit-learn operators,
tries to convert them, checks the predictions,
and produces a report.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">validate_runtime</span> <span class="o">--</span><span class="n">models</span> <span class="n">LogisticRegression</span><span class="p">,</span><span class="n">LinearRegression</span>
</pre></div>
</div>
<p>Following example benchmarks models
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/ensemble.RandomForestRegressor.html">sklearn.ensemble.RandomForestRegressor</a>,
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/tree.DecisionTreeRegressor.html">sklearn.tree.DecisionTreeRegressor</a>, it compares
<a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> against <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> for opset 10.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">validate_runtime</span> <span class="o">-</span><span class="n">v</span> <span class="mi">1</span> <span class="o">-</span><span class="n">o</span> <span class="mi">10</span> <span class="o">-</span><span class="n">op</span> <span class="mi">10</span> <span class="o">-</span><span class="n">c</span> <span class="mi">1</span> <span class="o">-</span><span class="n">r</span> <span class="n">onnxruntime1</span>
       <span class="o">-</span><span class="n">m</span> <span class="n">RandomForestRegressor</span><span class="p">,</span><span class="n">DecisionTreeRegressor</span> <span class="o">-</span><span class="n">out</span> <span class="n">bench_onnxruntime</span><span class="o">.</span><span class="n">xlsx</span> <span class="o">-</span><span class="n">b</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Parameter <code class="docutils literal notranslate"><span class="pre">--time_kwargs</span></code> may be used to reduce or increase
bencharmak precisions. The following value tells the function
to run a benchmarks with datasets of 1 or 10 number, to repeat
a given number of time <em>number</em> predictions in one row.
The total time is divided by <img class="math" src="_images/math/b2a8ec412aac147c13883b2524b98a033c85f07f.svg" alt="number \times repeat"/>.
Parameter <code class="docutils literal notranslate"><span class="pre">--time_kwargs_fact</span></code> may be used to increase these
number for some specific models. <code class="docutils literal notranslate"><span class="pre">'lin'</span></code> multiplies
by 10 number when the model is linear.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span><span class="n">t</span> <span class="s2">&quot;{</span><span class="se">\&quot;</span><span class="s2">1</span><span class="se">\&quot;</span><span class="s2">:{</span><span class="se">\&quot;</span><span class="s2">number</span><span class="se">\&quot;</span><span class="s2">:10,</span><span class="se">\&quot;</span><span class="s2">repeat</span><span class="se">\&quot;</span><span class="s2">:10},</span><span class="se">\&quot;</span><span class="s2">10</span><span class="se">\&quot;</span><span class="s2">:{</span><span class="se">\&quot;</span><span class="s2">number</span><span class="se">\&quot;</span><span class="s2">:5,</span><span class="se">\&quot;</span><span class="s2">repeat</span><span class="se">\&quot;</span><span class="s2">:5}}&quot;</span>
</pre></div>
</div>
<p>The following example dumps every model in the list:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">validate_runtime</span> <span class="o">--</span><span class="n">out_raw</span> <span class="n">raw</span><span class="o">.</span><span class="n">csv</span> <span class="o">--</span><span class="n">out_summary</span> <span class="nb">sum</span><span class="o">.</span><span class="n">csv</span>
       <span class="o">--</span><span class="n">models</span> <span class="n">LinearRegression</span><span class="p">,</span><span class="n">LogisticRegression</span><span class="p">,</span><span class="n">DecisionTreeRegressor</span><span class="p">,</span><span class="n">DecisionTreeClassifier</span>
       <span class="o">-</span><span class="n">r</span> <span class="n">python</span><span class="p">,</span><span class="n">onnxruntime1</span> <span class="o">-</span><span class="n">o</span> <span class="mi">10</span> <span class="o">-</span><span class="n">op</span> <span class="mi">10</span> <span class="o">-</span><span class="n">v</span> <span class="mi">1</span> <span class="o">-</span><span class="n">b</span> <span class="mi">1</span> <span class="o">-</span><span class="n">dum</span> <span class="mi">1</span>
       <span class="o">-</span><span class="n">du</span> <span class="n">model_dump</span> <span class="o">-</span><span class="n">n</span> <span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span> <span class="o">--</span><span class="n">out_graph</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">png</span> <span class="o">--</span><span class="n">dtype</span> <span class="mi">32</span>
</pre></div>
</div>
<p>The command line generates a graph produced by function
<code class="xref py py-func docutils literal notranslate"><span class="pre">plot_validate_benchmark</span></code>.</p>
<div class="docutils container">
<p>&lt;&lt;&lt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">mlprodict</span> <span class="n">validate_runtime</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>usage: validate_runtime [-h] [-v VERBOSE] [-o OPSET_MIN] [-op OPSET_MAX]
                        [-c CHECK_RUNTIME] [-r RUNTIME] [-d DEBUG] [-m MODELS]
                        [-ou OUT_RAW] [-out OUT_SUMMARY] [-du DUMP_FOLDER]
                        [-dum DUMP_ALL] [-b BENCHMARK] [-ca CATCH_WARNINGS]
                        [-a ASSUME_FINITE] [-ve VERSIONS] [-s SKIP_MODELS]
                        [-e EXTENDED_LIST] [-se SEPARATE_PROCESS]
                        [-t TIME_KWARGS] [-n N_FEATURES]
                        [--out_graph OUT_GRAPH] [-f FORCE_RETURN] [-dt DTYPE]
                        [-sk SKIP_LONG_TEST] [-nu NUMBER] [-re REPEAT]
                        [-ti TIME_KWARGS_FACT] [-tim TIME_LIMIT] [-n_ N_JOBS]

Walks through most of :epkg:`scikit-learn` operators or model or predictor or
transformer, tries to convert them into `ONNX` and computes the predictions
with a specific runtime.

optional arguments:
  -h, --help            show this help message and exit
  -v VERBOSE, --verbose VERBOSE
                        integer from 0 (None) to 2 (full verbose) (default: 1)
  -o OPSET_MIN, --opset_min OPSET_MIN
                        tries every conversion from this minimum opset, -1 to
                        get the current opset (default: -1)
  -op OPSET_MAX, --opset_max OPSET_MAX
                        tries every conversion up to maximum opset, -1 to get
                        the current opset (default: )
  -c CHECK_RUNTIME, --check_runtime CHECK_RUNTIME
                        to check the runtime and not only the conversion
                        (default: True)
  -r RUNTIME, --runtime RUNTIME
                        runtime to check, python, onnxruntime1 to check
                        `onnxruntime`, onnxruntime2 to check every *ONNX* node
                        independently with onnxruntime, many runtime can be
                        checked at the same time if the value is a comma
                        separated list (default: python)
  -d DEBUG, --debug DEBUG
                        stops whenever an exception is raised, only if
                        *separate_process* is False (default: False)
  -m MODELS, --models MODELS
                        comma separated list of models to test or empty string
                        to test them all (default: )
  -ou OUT_RAW, --out_raw OUT_RAW
                        output raw results into this file (excel format)
                        (default: model_onnx_raw.xlsx)
  -out OUT_SUMMARY, --out_summary OUT_SUMMARY
                        output an aggregated view into this file (excel
                        format) (default: model_onnx_summary.xlsx)
  -du DUMP_FOLDER, --dump_folder DUMP_FOLDER
                        folder where to dump information (pickle) in case of
                        mismatch (default: )
  -dum DUMP_ALL, --dump_all DUMP_ALL
                        dumps all models, not only the failing ones (default:
                        False)
  -b BENCHMARK, --benchmark BENCHMARK
                        run benchmark (default: False)
  -ca CATCH_WARNINGS, --catch_warnings CATCH_WARNINGS
                        catch warnings (default: True)
  -a ASSUME_FINITE, --assume_finite ASSUME_FINITE
                        See `config_context &lt;https://scikit-learn.org/stable/m
                        odules/generated/sklearn.config_context.html&gt;`_, If
                        True, validation for finiteness will be skipped,
                        saving time, but leading to potential crashes. If
                        False, validation for finiteness will be performed,
                        avoiding error. (default: True)
  -ve VERSIONS, --versions VERSIONS
                        add columns with versions of used packages, `numpy`,
                        :epkg:`scikit-learn`, `onnx`, `onnxruntime`,
                        :epkg:`sklearn-onnx` (default: False)
  -s SKIP_MODELS, --skip_models SKIP_MODELS
                        models to skip (default: )
  -e EXTENDED_LIST, --extended_list EXTENDED_LIST
                        extends the list of :epkg:`scikit-learn` converters
                        with converters implemented in this module (default:
                        True)
  -se SEPARATE_PROCESS, --separate_process SEPARATE_PROCESS
                        run every model in a separate process, this option
                        must be used to run all model in one row even if one
                        of them is crashing (default: False)
  -t TIME_KWARGS, --time_kwargs TIME_KWARGS
                        a dictionary which defines the number of rows and the
                        parameter *number* and *repeat* when benchmarking a
                        model, the value must follow `json` format (default: )
  -n N_FEATURES, --n_features N_FEATURES
                        change the default number of features for a specific
                        problem, it can also be a comma separated list
                        (default: )
  --out_graph OUT_GRAPH
                        image name, to output a graph which summarizes a
                        benchmark in case it was run (default: )
  -f FORCE_RETURN, --force_return FORCE_RETURN
                        forces the function to return the results, used when
                        the results are produces through a separate process
                        (default: False)
  -dt DTYPE, --dtype DTYPE
                        &#39;32&#39; or &#39;64&#39; or None for both, limits the test to one
                        specific number types (default: )
  -sk SKIP_LONG_TEST, --skip_long_test SKIP_LONG_TEST
                        skips tests for high values of N if they seem too long
                        (default: False)
  -nu NUMBER, --number NUMBER
                        to multiply number values in *time_kwargs* (default:
                        1)
  -re REPEAT, --repeat REPEAT
                        to multiply repeat values in *time_kwargs* (default:
                        1)
  -ti TIME_KWARGS_FACT, --time_kwargs_fact TIME_KWARGS_FACT
                        to multiply number and repeat in *time_kwargs*
                        depending on the model (see
                        :func:`_multiply_time_kwargs &lt;mlprodict.onnxrt.validat
                        e.validate_helper._multiply_time_kwargs&gt;`) (default:
                        lin)
  -tim TIME_LIMIT, --time_limit TIME_LIMIT
                        to stop benchmarking after this limit of time
                        (default: 4)
  -n_ N_JOBS, --n_jobs N_JOBS
                        force the number of jobs to have this value, by
                        default, it is equal to the number of CPU (default: 0)

</pre></div>
</div>
</div>
</div>
<p class="cmdref-source"><span class="target" id="indexindexcmdref-cmd1-2"></span>(<a class="reference internal" href="mlprodict/cli/validate.html#indexcmdref-cmd1">original entry</a> : validate.py:docstring of mlprodict.cli.validate.validate_runtime, line 66)</p>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="skl_converters/bench_onnxrt1.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Availability of scikit-learn model for runtime onnxruntime1</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="i_ex.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Examples</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier DuprÃ©.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>