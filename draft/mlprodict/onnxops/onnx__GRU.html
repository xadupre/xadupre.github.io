
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>GRU &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="../_static/project_ico.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Gather" href="onnx__Gather.html" />
    <link rel="prev" title="Floor" href="onnx__Floor.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_cmd.html">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_index.html">
  FAQ, code, â€¦
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   ONNX operators
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Abs.html">
     Abs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acos.html">
     Acos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acosh.html">
     Acosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Add.html">
     Add
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__And.html">
     And
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMax.html">
     ArgMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMin.html">
     ArgMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asin.html">
     Asin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asinh.html">
     Asinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atan.html">
     Atan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atanh.html">
     Atanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__AveragePool.html">
     AveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BatchNormalization.html">
     BatchNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Bernoulli.html">
     Bernoulli
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BitShift.html">
     BitShift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cast.html">
     Cast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CastLike.html">
     CastLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Ceil.html">
     Ceil
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Celu.html">
     Celu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Clip.html">
     Clip
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Compress.html">
     Compress
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Concat.html">
     Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConcatFromSequence.html">
     ConcatFromSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Constant.html">
     Constant
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConstantOfShape.html">
     ConstantOfShape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Conv.html">
     Conv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvInteger.html">
     ConvInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvTranspose.html">
     ConvTranspose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cos.html">
     Cos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cosh.html">
     Cosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CumSum.html">
     CumSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DepthToSpace.html">
     DepthToSpace
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DequantizeLinear.html">
     DequantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Det.html">
     Det
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Div.html">
     Div
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Dropout.html">
     Dropout
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
     DynamicQuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Einsum.html">
     Einsum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Elu.html">
     Elu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Equal.html">
     Equal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Erf.html">
     Erf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Exp.html">
     Exp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Expand.html">
     Expand
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__EyeLike.html">
     EyeLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Flatten.html">
     Flatten
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Floor.html">
     Floor
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     GRU
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gather.html">
     Gather
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherElements.html">
     GatherElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherND.html">
     GatherND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gemm.html">
     Gemm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalAveragePool.html">
     GlobalAveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalLpPool.html">
     GlobalLpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalMaxPool.html">
     GlobalMaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Greater.html">
     Greater
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GreaterOrEqual.html">
     GreaterOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GridSample.html">
     GridSample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSigmoid.html">
     HardSigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSwish.html">
     HardSwish
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Hardmax.html">
     Hardmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Identity.html">
     Identity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__If.html">
     If
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__InstanceNormalization.html">
     InstanceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsInf.html">
     IsInf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsNaN.html">
     IsNaN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LRN.html">
     LRN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LSTM.html">
     LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LeakyRelu.html">
     LeakyRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Less.html">
     Less
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LessOrEqual.html">
     LessOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Log.html">
     Log
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LogSoftmax.html">
     LogSoftmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Loop.html">
     Loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpNormalization.html">
     LpNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpPool.html">
     LpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMul.html">
     MatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMulInteger.html">
     MatMulInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Max.html">
     Max
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxPool.html">
     MaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxRoiPool.html">
     MaxRoiPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxUnpool.html">
     MaxUnpool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mean.html">
     Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
     MeanVarianceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Min.html">
     Min
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mod.html">
     Mod
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mul.html">
     Mul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Multinomial.html">
     Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Neg.html">
     Neg
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
     NegativeLogLikelihoodLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonMaxSuppression.html">
     NonMaxSuppression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonZero.html">
     NonZero
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Not.html">
     Not
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OneHot.html">
     OneHot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Optional.html">
     Optional
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalGetElement.html">
     OptionalGetElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalHasElement.html">
     OptionalHasElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Or.html">
     Or
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__PRelu.html">
     PRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pad.html">
     Pad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pow.html">
     Pow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearConv.html">
     QLinearConv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearMatMul.html">
     QLinearMatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QuantizeLinear.html">
     QuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RNN.html">
     RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormal.html">
     RandomNormal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormalLike.html">
     RandomNormalLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniform.html">
     RandomUniform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniformLike.html">
     RandomUniformLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Range.html">
     Range
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reciprocal.html">
     Reciprocal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL1.html">
     ReduceL1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL2.html">
     ReduceL2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSum.html">
     ReduceLogSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSumExp.html">
     ReduceLogSumExp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMax.html">
     ReduceMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMean.html">
     ReduceMean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMin.html">
     ReduceMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceProd.html">
     ReduceProd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSum.html">
     ReduceSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSumSquare.html">
     ReduceSumSquare
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Relu.html">
     Relu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reshape.html">
     Reshape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Resize.html">
     Resize
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReverseSequence.html">
     ReverseSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RoiAlign.html">
     RoiAlign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Round.html">
     Round
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scan.html">
     Scan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scatter.html">
     Scatter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterElements.html">
     ScatterElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterND.html">
     ScatterND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Selu.html">
     Selu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceAt.html">
     SequenceAt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceConstruct.html">
     SequenceConstruct
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceEmpty.html">
     SequenceEmpty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceErase.html">
     SequenceErase
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceInsert.html">
     SequenceInsert
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceLength.html">
     SequenceLength
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shape.html">
     Shape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shrink.html">
     Shrink
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sigmoid.html">
     Sigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sign.html">
     Sign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sin.html">
     Sin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sinh.html">
     Sinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Size.html">
     Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Slice.html">
     Slice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softmax.html">
     Softmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
     SoftmaxCrossEntropyLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softplus.html">
     Softplus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softsign.html">
     Softsign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SpaceToDepth.html">
     SpaceToDepth
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Split.html">
     Split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SplitToSequence.html">
     SplitToSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sqrt.html">
     Sqrt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Squeeze.html">
     Squeeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__StringNormalizer.html">
     StringNormalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sub.html">
     Sub
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sum.html">
     Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tan.html">
     Tan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tanh.html">
     Tanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TfIdfVectorizer.html">
     TfIdfVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ThresholdedRelu.html">
     ThresholdedRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tile.html">
     Tile
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TopK.html">
     TopK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Transpose.html">
     Transpose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Trilu.html">
     Trilu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unique.html">
     Unique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unsqueeze.html">
     Unsqueeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Upsample.html">
     Upsample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Where.html">
     Where
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Xor.html">
     Xor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
     ai.onnx.ml - ArrayFeatureExtractor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
     ai.onnx.ml - Binarizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CastMap.html">
     ai.onnx.ml - CastMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
     ai.onnx.ml - CategoryMapper
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
     ai.onnx.ml - DictVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
     ai.onnx.ml - FeatureVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Imputer.html">
     ai.onnx.ml - Imputer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
     ai.onnx.ml - LabelEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
     ai.onnx.ml - LinearClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
     ai.onnx.ml - LinearRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
     ai.onnx.ml - Normalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
     ai.onnx.ml - OneHotEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
     ai.onnx.ml - SVMClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
     ai.onnx.ml - SVMRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Scaler.html">
     ai.onnx.ml - Scaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
     ai.onnx.ml - TreeEnsembleClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
     ai.onnx.ml - TreeEnsembleRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
     ai.onnx.ml - ZipMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
     ai.onnx.preview.training - Adagrad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
     ai.onnx.preview.training - Adam
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
     ai.onnx.preview.training - Gradient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
     ai.onnx.preview.training - Momentum
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_runtime.html">
   Runtimes for ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../backends/index.html">
   ONNX Backends
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gru-14">
   GRU - 14
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gru-7">
   GRU - 7
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gru-3">
   GRU - 3
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gru-1">
   GRU - 1
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="gru">
<span id="l-onnx-doc-gru"></span><h1>GRU<a class="headerlink" href="#gru" title="Permalink to this headline">#</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#gru-14" id="id13">GRU - 14</a></p></li>
<li><p><a class="reference internal" href="#gru-7" id="id14">GRU - 7</a></p></li>
<li><p><a class="reference internal" href="#gru-3" id="id15">GRU - 3</a></p></li>
<li><p><a class="reference internal" href="#gru-1" id="id16">GRU - 1</a></p></li>
</ul>
</div>
<section id="gru-14">
<span id="l-onnx-op-gru-14"></span><h2><a class="toc-backref" href="#id13">GRU - 14</a><a class="headerlink" href="#gru-14" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU">GRU (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>14</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 14</strong>.</p>
<p><strong>Summary</strong></p>
<p>Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.</p>
<p>Notations:</p>
<p><cite>X</cite> - input tensor</p>
<p><cite>z</cite> - update gate</p>
<p><cite>r</cite> - reset gate</p>
<p><cite>h</cite> - hidden gate</p>
<p><cite>t</cite> - time step (t-1 means previous time step)</p>
<p><cite>W[zrh]</cite> - W parameter weight matrix for update, reset, and hidden gates</p>
<p><cite>R[zrh]</cite> - R recurrence weight matrix for update, reset, and hidden gates</p>
<p><cite>Wb[zrh]</cite> - W bias vectors for update, reset, and hidden gates</p>
<p><cite>Rb[zrh]</cite> - R bias vectors for update, reset, and hidden gates</p>
<p><cite>WB[zrh]</cite> - W parameter weight matrix for backward update, reset, and hidden gates</p>
<p><cite>RB[zrh]</cite> - R recurrence weight matrix for backward update, reset, and hidden gates</p>
<p><cite>WBb[zrh]</cite> - W bias vectors for backward update, reset, and hidden gates</p>
<p><cite>RBb[zrh]</cite> - R bias vectors for backward update, reset, and hidden gates</p>
<p><cite>H</cite> - Hidden state</p>
<p><cite>num_directions</cite> - 2 if direction == bidirectional else 1</p>
<p>Activation functions:</p>
<blockquote>
<div><p>Relu(x)                - max(0, x)</p>
<p>Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</p>
<p>Sigmoid(x)             - 1/(1 + e^{-x})</p>
<p>(NOTE: Below are optional)</p>
<p>Affine(x)              - alpha*x + beta</p>
<p>LeakyRelu(x)           - x if x &gt;= 0 else alpha * x</p>
<p>ThresholdedRelu(x)     - x if x &gt;= alpha else 0</p>
<p>ScaledTanh(x)          - alpha*Tanh(beta*x)</p>
<p>HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</p>
<p>Elu(x)                 - x if x &gt;= 0 else alpha*(e^x - 1)</p>
<p>Softsign(x)            - x/(1 + <a href="#id5"><span class="problematic" id="id6">|x|</span></a>)</p>
<p>Softplus(x)            - log(1 + e^x)</p>
</div></blockquote>
<p>Equations (Default: f=Sigmoid, g=Tanh):</p>
<blockquote>
<div><ul class="simple">
<li><p>zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)</p></li>
<li><p>rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0</p></li>
<li><p>Ht = (1 - zt) (.) ht + zt (.) Ht-1</p></li>
</ul>
</div></blockquote>
<p>This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argumentâ€™s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>activation_alpha</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM. Default values are the same as of
corresponding ONNX operators.For example with LeakyRelu, the default
alpha is 0.01.</p></li>
<li><p><strong>activation_beta</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM. Default values are the same as of
corresponding ONNX operators.</p></li>
<li><p><strong>activations</strong>:
A list of 2 (or 4 if bidirectional) activation functions for update,
reset, and hidden gates. The activation functions must be one of the
activation functions specified above. Optional: See the equations
for default if not specified.</p></li>
<li><p><strong>clip</strong>:
Cell clip threshold. Clipping bounds the elements of a tensor in the
range of [-threshold, +threshold] and is applied to the input of
activations. No clip if not specified.</p></li>
<li><p><strong>direction</strong>:
Specify if the RNN is forward, reverse, or bidirectional. Must be
one of forward (default), reverse, or bidirectional. Default value is <code class="docutils literal notranslate"><span class="pre">'forward'</span></code>.</p></li>
<li><p><strong>hidden_size</strong>:
Number of neurons in the hidden layer</p></li>
<li><p><strong>layout</strong>:
The shape format of inputs X, initial_h and outputs Y, Y_h. If 0,
the following shapes are expected: X.shape = [seq_length,
batch_size, input_size], Y.shape = [seq_length, num_directions,
batch_size, hidden_size], initial_h.shape = Y_h.shape =
[num_directions, batch_size, hidden_size]. If 1, the following
shapes are expected: X.shape = [batch_size, seq_length, input_size],
Y.shape = [batch_size, seq_length, num_directions, hidden_size],
initial_h.shape = Y_h.shape = [batch_size, num_directions,
hidden_size]. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>linear_before_reset</strong>:
When computing the output of the hidden gate, apply the linear
transformation before multiplying by the output of the reset gate. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 3 and 6 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
The input sequences packed (and potentially padded) into one 3-D
tensor with the shape of <cite>[seq_length, batch_size, input_size]</cite>.</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor for the gates. Concatenation of <cite>W[zrh]</cite> and
<cite>WB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, input_size]</cite>.</p></li>
<li><p><strong>R</strong> (heterogeneous) - <strong>T</strong>:
The recurrence weight tensor. Concatenation of <cite>R[zrh]</cite> and
<cite>RB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, hidden_size]</cite>.</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
The bias tensor for the gates. Concatenation of <cite>[Wb[zrh], Rb[zrh]]</cite>
and <cite>[WBb[zrh], RBb[zrh]]</cite> (if bidirectional) along dimension 0.
This tensor has shape <cite>[num_directions, 6*hidden_size]</cite>. Optional:
If not specified - assumed to be 0</p></li>
<li><p><strong>sequence_lens</strong> (optional, heterogeneous) - <strong>T1</strong>:
Optional tensor specifying lengths of the sequences in a batch. If
not specified - assumed all sequences in the batch to have length
<cite>seq_length</cite>. It has shape <cite>[batch_size]</cite>.</p></li>
<li><p><strong>initial_h</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional initial value of the hidden. If not specified - assumed to
be 0. It has shape <cite>[num_directions, batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 0 and 2 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (optional, heterogeneous) - <strong>T</strong>:
A tensor that concats all the intermediate output values of the
hidden. It has shape <cite>[seq_length, num_directions, batch_size,
hidden_size]</cite>.</p></li>
<li><p><strong>Y_h</strong> (optional, heterogeneous) - <strong>T</strong>:
The last output value of the hidden. It has shape <cite>[num_directions,
batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>T1</strong> in (
tensor(int32)
):
Constrain seq_lens to integer tensor.</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>defaults</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">weight_scale</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">number_of_gates</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;GRU&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Y_h&#39;</span><span class="p">],</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span>
<span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">weight_scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">weight_scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">gru</span> <span class="o">=</span> <span class="n">GRU_Helper</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="n">R</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">Y_h</span> <span class="o">=</span> <span class="n">gru</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">Y_h</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_gru_defaults&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>initial_bias</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">weight_scale</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">custom_bias</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">number_of_gates</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;GRU&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Y_h&#39;</span><span class="p">],</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span>
<span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">weight_scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">weight_scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Adding custom bias</span>
<span class="n">W_B</span> <span class="o">=</span> <span class="n">custom_bias</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">R_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">W_B</span><span class="p">,</span> <span class="n">R_B</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">gru</span> <span class="o">=</span> <span class="n">GRU_Helper</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="n">B</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">Y_h</span> <span class="o">=</span> <span class="n">gru</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">Y_h</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_gru_with_initial_bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>seq_length</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]],</span>
                  <span class="p">[[</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">],</span> <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">],</span> <span class="p">[</span><span class="mf">16.</span><span class="p">,</span> <span class="mf">17.</span><span class="p">,</span> <span class="mf">18.</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">number_of_gates</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;GRU&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Y_h&#39;</span><span class="p">],</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span>
<span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Adding custom bias</span>
<span class="n">W_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">R_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">W_B</span><span class="p">,</span> <span class="n">R_B</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">gru</span> <span class="o">=</span> <span class="n">GRU_Helper</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="n">B</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">Y_h</span> <span class="o">=</span> <span class="n">gru</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">Y_h</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_gru_seq_length&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>batchwise</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]],</span> <span class="p">[[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]],</span> <span class="p">[[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">number_of_gates</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">weight_scale</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">layout</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;GRU&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;Y_h&#39;</span><span class="p">],</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="n">layout</span>
<span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">weight_scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">weight_scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">number_of_gates</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">gru</span> <span class="o">=</span> <span class="n">GRU_Helper</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span>
<span class="n">Y</span><span class="p">,</span> <span class="n">Y_h</span> <span class="o">=</span> <span class="n">gru</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">R</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">Y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Y_h</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_gru_batchwise&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Computes an one-layer GRU. This operator is usually supported via some custom</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Computes an one-layer GRU. This operator is usually supported via some custom</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">implementation such as CuDNN.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">implementation such as CuDNN.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Notations:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Notations:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">X - input tensor</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">X - input tensor</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">z - update gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">z - update gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">r - reset gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">r - reset gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">h - hidden gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">h - hidden gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">t - time step (t-1 means previous time step)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">t - time step (t-1 means previous time step)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">W[zrh] - W parameter weight matrix for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">W[zrh] - W parameter weight matrix for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">R[zrh] - R recurrence weight matrix for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">R[zrh] - R recurrence weight matrix for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Wb[zrh] - W bias vectors for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Wb[zrh] - W bias vectors for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Rb[zrh] - R bias vectors for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Rb[zrh] - R bias vectors for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WB[zrh] - W parameter weight matrix for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WB[zrh] - W parameter weight matrix for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RB[zrh] - R recurrence weight matrix for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RB[zrh] - R recurrence weight matrix for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WBb[zrh] - W bias vectors for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WBb[zrh] - W bias vectors for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RBb[zrh] - R bias vectors for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RBb[zrh] - R bias vectors for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">H - Hidden state</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">H - Hidden state</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">num_directions - 2 if direction == bidirectional else 1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">num_directions - 2 if direction == bidirectional else 1</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Activation functions:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Activation functions:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Relu(x)                - max(0, x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Relu(x)                - max(0, x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Sigmoid(x)             - 1/(1 + e^{-x})</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Sigmoid(x)             - 1/(1 + e^{-x})</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (NOTE: Below are optional)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (NOTE: Below are optional)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Affine(x)              - alpha*x + beta</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Affine(x)              - alpha*x + beta</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  LeakyRelu(x)           - x if x >= 0 else alpha * x</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  LeakyRelu(x)           - x if x >= 0 else alpha * x</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ThresholdedRelu(x)     - x if x >= alpha else 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ThresholdedRelu(x)     - x if x >= alpha else 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ScaledTanh(x)          - alpha*Tanh(beta*x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ScaledTanh(x)          - alpha*Tanh(beta*x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softsign(x)            - x/(1 + |x|)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softsign(x)            - x/(1 + |x|)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softplus(x)            - log(1 + e^x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softplus(x)            - log(1 + e^x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Equations (Default: f=Sigmoid, g=Tanh):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Equations (Default: f=Sigmoid, g=Tanh):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - Ht = (1 - zt) (.) ht + zt (.) Ht-1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - Ht = (1 - zt) (.) ht + zt (.) Ht-1</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_alpha**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_alpha**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.For example with LeakyRelu, the default</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.For example with LeakyRelu, the default</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  alpha is 0.01.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  alpha is 0.01.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_beta**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_beta**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activations**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activations**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A list of 2 (or 4 if bidirectional) activation functions for update,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A list of 2 (or 4 if bidirectional) activation functions for update,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  reset, and hidden gates. The activation functions must be one of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  reset, and hidden gates. The activation functions must be one of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activation functions specified above. Optional: See the equations</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activation functions specified above. Optional: See the equations</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  for default if not specified.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  for default if not specified.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **clip**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **clip**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Cell clip threshold. Clipping bounds the elements of a tensor in the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Cell clip threshold. Clipping bounds the elements of a tensor in the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  range of [-threshold, +threshold] and is applied to the input of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  range of [-threshold, +threshold] and is applied to the input of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activations. No clip if not specified.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activations. No clip if not specified.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **direction**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **direction**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specify if the RNN is forward, reverse, or bidirectional. Must be</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specify if the RNN is forward, reverse, or bidirectional. Must be</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  one of forward (default), reverse, or bidirectional. Default value is 'forward'.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  one of forward (default), reverse, or bidirectional. Default value is 'forward'.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **hidden_size**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **hidden_size**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Number of neurons in the hidden layer</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Number of neurons in the hidden layer</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">101</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">* **layout**:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">102</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  The shape format of inputs X, initial_h and outputs Y, Y_h. If 0,</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">103</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  the following shapes are expected: X.shape = [seq_length,</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">104</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  batch_size, input_size], Y.shape = [seq_length, num_directions,</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">105</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  batch_size, hidden_size], initial_h.shape = Y_h.shape =</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">106</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  [num_directions, batch_size, hidden_size]. If 1, the following</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">107</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  shapes are expected: X.shape = [batch_size, seq_length, input_size],</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">108</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  Y.shape = [batch_size, seq_length, num_directions, hidden_size],</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">109</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  initial_h.shape = Y_h.shape = [batch_size, num_directions,</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">110</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  hidden_size]. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">111</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **linear_before_reset**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **linear_before_reset**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">102</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">112</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  When computing the output of the hidden gate, apply the linear</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  When computing the output of the hidden gate, apply the linear</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">103</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">113</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  transformation before multiplying by the output of the reset gate. Default value is 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  transformation before multiplying by the output of the reset gate. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">104</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">114</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">115</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">106</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">116</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">107</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">117</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 3 and 6 inputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 3 and 6 inputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">108</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">118</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">109</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">119</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">110</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">120</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The input sequences packed (and potentially padded) into one 3-D</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The input sequences packed (and potentially padded) into one 3-D</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">111</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">121</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor with the shape of [seq_length, batch_size, input_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor with the shape of [seq_length, batch_size, input_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">112</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">122</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">113</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">123</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor for the gates. Concatenation of W[zrh] and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor for the gates. Concatenation of W[zrh] and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">114</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">124</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  WB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  WB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">115</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">125</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, input_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, input_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">116</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">126</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **R** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **R** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">117</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">127</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The recurrence weight tensor. Concatenation of R[zrh] and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The recurrence weight tensor. Concatenation of R[zrh] and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">118</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">128</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  RB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  RB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">119</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">129</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">120</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">130</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">121</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">131</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias tensor for the gates. Concatenation of [Wb[zrh], Rb[zrh]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias tensor for the gates. Concatenation of [Wb[zrh], Rb[zrh]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">122</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">132</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  and [WBb[zrh], RBb[zrh]] (if bidirectional) along dimension 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  and [WBb[zrh], RBb[zrh]] (if bidirectional) along dimension 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">123</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">133</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  This tensor has shape [num_directions, 6*hidden_size]. Optional:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  This tensor has shape [num_directions, 6*hidden_size]. Optional:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">124</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">134</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If not specified - assumed to be 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If not specified - assumed to be 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">125</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">135</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **sequence_lens** (optional, heterogeneous) - **T1**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **sequence_lens** (optional, heterogeneous) - **T1**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">126</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">136</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional tensor specifying lengths of the sequences in a batch. If</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional tensor specifying lengths of the sequences in a batch. If</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">127</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">137</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  not specified - assumed all sequences in the batch to have length</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  not specified - assumed all sequences in the batch to have length</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">128</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">138</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  seq_length. It has shape [batch_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  seq_length. It has shape [batch_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">129</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">139</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **initial_h** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **initial_h** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">130</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">140</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional initial value of the hidden. If not specified - assumed to</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional initial value of the hidden. If not specified - assumed to</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">131</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">141</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be 0. It has shape [num_directions, batch_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be 0. It has shape [num_directions, batch_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">132</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">142</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">133</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">143</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">134</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">144</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">135</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">145</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 0 and 2 outputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 0 and 2 outputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">136</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">146</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">137</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">147</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">138</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">148</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A tensor that concats all the intermediate output values of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A tensor that concats all the intermediate output values of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">139</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">149</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden. It has shape [seq_length, num_directions, batch_size,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden. It has shape [seq_length, num_directions, batch_size,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">140</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">150</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">141</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">151</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y_h** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y_h** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">142</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">152</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The last output value of the hidden. It has shape [num_directions,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The last output value of the hidden. It has shape [num_directions,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">143</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">153</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  batch_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  batch_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">144</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">154</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">145</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">155</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">146</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">156</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">147</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">157</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">148</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">158</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">149</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">159</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">150</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">160</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">151</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">161</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">152</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">162</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">153</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">163</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T1** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T1** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">154</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">164</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">155</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">165</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">156</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">166</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain seq_lens to integer tensor.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain seq_lens to integer tensor.</code></td></tr>
</table></section>
<section id="gru-7">
<span id="l-onnx-op-gru-7"></span><h2><a class="toc-backref" href="#id14">GRU - 7</a><a class="headerlink" href="#gru-7" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU">GRU (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>7</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 7</strong>.</p>
<p><strong>Summary</strong></p>
<p>Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.</p>
<p>Notations:</p>
<p><cite>X</cite> - input tensor</p>
<p><cite>z</cite> - update gate</p>
<p><cite>r</cite> - reset gate</p>
<p><cite>h</cite> - hidden gate</p>
<p><cite>t</cite> - time step (t-1 means previous time step)</p>
<p><cite>W[zrh]</cite> - W parameter weight matrix for update, reset, and hidden gates</p>
<p><cite>R[zrh]</cite> - R recurrence weight matrix for update, reset, and hidden gates</p>
<p><cite>Wb[zrh]</cite> - W bias vectors for update, reset, and hidden gates</p>
<p><cite>Rb[zrh]</cite> - R bias vectors for update, reset, and hidden gates</p>
<p><cite>WB[zrh]</cite> - W parameter weight matrix for backward update, reset, and hidden gates</p>
<p><cite>RB[zrh]</cite> - R recurrence weight matrix for backward update, reset, and hidden gates</p>
<p><cite>WBb[zrh]</cite> - W bias vectors for backward update, reset, and hidden gates</p>
<p><cite>RBb[zrh]</cite> - R bias vectors for backward update, reset, and hidden gates</p>
<p><cite>H</cite> - Hidden state</p>
<p><cite>num_directions</cite> - 2 if direction == bidirectional else 1</p>
<p>Activation functions:</p>
<blockquote>
<div><p>Relu(x)                - max(0, x)</p>
<p>Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</p>
<p>Sigmoid(x)             - 1/(1 + e^{-x})</p>
<p>(NOTE: Below are optional)</p>
<p>Affine(x)              - alpha*x + beta</p>
<p>LeakyRelu(x)           - x if x &gt;= 0 else alpha * x</p>
<p>ThresholdedRelu(x)     - x if x &gt;= alpha else 0</p>
<p>ScaledTanh(x)          - alpha*Tanh(beta*x)</p>
<p>HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</p>
<p>Elu(x)                 - x if x &gt;= 0 else alpha*(e^x - 1)</p>
<p>Softsign(x)            - x/(1 + <a href="#id7"><span class="problematic" id="id8">|x|</span></a>)</p>
<p>Softplus(x)            - log(1 + e^x)</p>
</div></blockquote>
<p>Equations (Default: f=Sigmoid, g=Tanh):</p>
<blockquote>
<div><ul class="simple">
<li><p>zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)</p></li>
<li><p>rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0</p></li>
<li><p>Ht = (1 - zt) (.) ht + zt (.) Ht-1</p></li>
</ul>
</div></blockquote>
<p>This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argumentâ€™s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>activation_alpha</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM. Default values are the same as of
corresponding ONNX operators.For example with LeakyRelu, the default
alpha is 0.01.</p></li>
<li><p><strong>activation_beta</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM. Default values are the same as of
corresponding ONNX operators.</p></li>
<li><p><strong>activations</strong>:
A list of 2 (or 4 if bidirectional) activation functions for update,
reset, and hidden gates. The activation functions must be one of the
activation functions specified above. Optional: See the equations
for default if not specified.</p></li>
<li><p><strong>clip</strong>:
Cell clip threshold. Clipping bounds the elements of a tensor in the
range of [-threshold, +threshold] and is applied to the input of
activations. No clip if not specified.</p></li>
<li><p><strong>direction</strong>:
Specify if the RNN is forward, reverse, or bidirectional. Must be
one of forward (default), reverse, or bidirectional. Default value is <code class="docutils literal notranslate"><span class="pre">'forward'</span></code>.</p></li>
<li><p><strong>hidden_size</strong>:
Number of neurons in the hidden layer</p></li>
<li><p><strong>linear_before_reset</strong>:
When computing the output of the hidden gate, apply the linear
transformation before multiplying by the output of the reset gate. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 3 and 6 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
The input sequences packed (and potentially padded) into one 3-D
tensor with the shape of <cite>[seq_length, batch_size, input_size]</cite>.</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor for the gates. Concatenation of <cite>W[zrh]</cite> and
<cite>WB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, input_size]</cite>.</p></li>
<li><p><strong>R</strong> (heterogeneous) - <strong>T</strong>:
The recurrence weight tensor. Concatenation of <cite>R[zrh]</cite> and
<cite>RB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, hidden_size]</cite>.</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
The bias tensor for the gates. Concatenation of <cite>[Wb[zrh], Rb[zrh]]</cite>
and <cite>[WBb[zrh], RBb[zrh]]</cite> (if bidirectional) along dimension 0.
This tensor has shape <cite>[num_directions, 6*hidden_size]</cite>. Optional:
If not specified - assumed to be 0</p></li>
<li><p><strong>sequence_lens</strong> (optional, heterogeneous) - <strong>T1</strong>:
Optional tensor specifying lengths of the sequences in a batch. If
not specified - assumed all sequences in the batch to have length
<cite>seq_length</cite>. It has shape <cite>[batch_size]</cite>.</p></li>
<li><p><strong>initial_h</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional initial value of the hidden. If not specified - assumed to
be 0. It has shape <cite>[num_directions, batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 0 and 2 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (optional, heterogeneous) - <strong>T</strong>:
A tensor that concats all the intermediate output values of the
hidden. It has shape <cite>[seq_length, num_directions, batch_size,
hidden_size]</cite>.</p></li>
<li><p><strong>Y_h</strong> (optional, heterogeneous) - <strong>T</strong>:
The last output value of the hidden. It has shape <cite>[num_directions,
batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>T1</strong> in (
tensor(int32)
):
Constrain seq_lens to integer tensor.</p></li>
</ul>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Computes an one-layer GRU. This operator is usually supported via some custom</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Computes an one-layer GRU. This operator is usually supported via some custom</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">implementation such as CuDNN.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">implementation such as CuDNN.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Notations:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Notations:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">X - input tensor</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">X - input tensor</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">z - update gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">z - update gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">r - reset gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">r - reset gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">h - hidden gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">h - hidden gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">t - time step (t-1 means previous time step)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">t - time step (t-1 means previous time step)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">W[zrh] - W parameter weight matrix for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">W[zrh] - W parameter weight matrix for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">R[zrh] - R recurrence weight matrix for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">R[zrh] - R recurrence weight matrix for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Wb[zrh] - W bias vectors for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Wb[zrh] - W bias vectors for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Rb[zrh] - R bias vectors for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Rb[zrh] - R bias vectors for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WB[zrh] - W parameter weight matrix for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WB[zrh] - W parameter weight matrix for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RB[zrh] - R recurrence weight matrix for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RB[zrh] - R recurrence weight matrix for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WBb[zrh] - W bias vectors for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WBb[zrh] - W bias vectors for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RBb[zrh] - R bias vectors for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RBb[zrh] - R bias vectors for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">H - Hidden state</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">H - Hidden state</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">num_directions - 2 if direction == bidirectional else 1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">num_directions - 2 if direction == bidirectional else 1</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Activation functions:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Activation functions:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Relu(x)                - max(0, x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Relu(x)                - max(0, x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Sigmoid(x)             - 1/(1 + e^{-x})</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Sigmoid(x)             - 1/(1 + e^{-x})</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (NOTE: Below are optional)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (NOTE: Below are optional)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Affine(x)              - alpha*x + beta</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Affine(x)              - alpha*x + beta</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  LeakyRelu(x)           - x if x >= 0 else alpha * x</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  LeakyRelu(x)           - x if x >= 0 else alpha * x</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ThresholdedRelu(x)     - x if x >= alpha else 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ThresholdedRelu(x)     - x if x >= alpha else 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ScaledTanh(x)          - alpha*Tanh(beta*x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ScaledTanh(x)          - alpha*Tanh(beta*x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softsign(x)            - x/(1 + |x|)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softsign(x)            - x/(1 + |x|)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softplus(x)            - log(1 + e^x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softplus(x)            - log(1 + e^x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Equations (Default: f=Sigmoid, g=Tanh):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Equations (Default: f=Sigmoid, g=Tanh):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td><code>63</code></td><td><code>63</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  - zt = f(Xt*(Wz^T) + Ht-1*Rz + Wbz + Rbz)</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  - zt = f(Xt*(Wz^T) + Ht-1*<span style="color:#196F3D;">(</span>Rz<span style="color:#196F3D;">^</span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">)</span> + Wbz + Rbz)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td><code>65</code></td><td><code>65</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  - rt = f(Xt*(Wr^T) + Ht-1*Rr + Wbr + Rbr)</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  - rt = f(Xt*(Wr^T) + Ht-1*<span style="color:#196F3D;">(</span>Rr<span style="color:#196F3D;">^</span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">)</span> + Wbr + Rbr)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td><code>67</code></td><td><code>67</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*Rh + Rbh + Wbh) # default, when linear_before_reset = 0</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*<span style="color:#196F3D;">(</span>Rh<span style="color:#196F3D;">^</span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">)</span> + Rbh + Wbh) # default, when linear_before_reset = 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td><code>69</code></td><td><code>69</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*Rh + Rbh) + Wbh) # when linear_before_reset != 0</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*<span style="color:#196F3D;">(</span>Rh<span style="color:#196F3D;">^</span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">)</span> + Rbh)<span style="color:#196F3D;">)</span> + Wbh) # when linear_before_reset != 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">71</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  - Ht = (1 - zt) (.) ht + zt (.) Ht-1</code></td></tr>
<tr style="1px solid black;"><td><code>71</code></td><td><code>72</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">-</span> <span style="color:#BA4A00;">H</span>t <span style="color:#BA4A00;">=</span> <span style="color:#BA4A00;">(</span><span style="color:#BA4A00;">1</span> <span style="color:#BA4A00;">-</span> <span style="color:#BA4A00;">z</span>t<span style="color:#BA4A00;">)</span> <span style="color:#BA4A00;">(</span>.<span style="color:#BA4A00;">)</span> ht <span style="color:#BA4A00;">+</span> <span style="color:#BA4A00;">z</span>t (<span style="color:#BA4A00;">.</span>) <span style="color:#BA4A00;">H</span>t<span style="color:#BA4A00;">-</span><span style="color:#BA4A00;">1</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code><span style="color:#196F3D;">T</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span> <span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span> <span style="color:#196F3D;">h</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">s</span> <span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span>t<span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span> <span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">.</span> <span style="color:#196F3D;">S</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">e</span> <span style="color:#196F3D;">O</span><span style="color:#196F3D;">N</span><span style="color:#196F3D;">N</span><span style="color:#196F3D;">X</span> <span style="color:#196F3D;"><</span><span style="color:#196F3D;">h</span>t<span style="color:#196F3D;">t</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">:</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">x</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">x</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">I</span><span style="color:#196F3D;">R</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">></span><span style="color:#196F3D;">_</span> <span style="color:#196F3D;">f</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span>. <span style="color:#196F3D;">A</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span>h<span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">c</span>t<span style="color:#196F3D;">u</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span> <span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">'</span><span style="color:#196F3D;">s</span> <span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span>t<span style="color:#196F3D;">o</span> <span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span>(<span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">w</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span>) <span style="color:#196F3D;">m</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">i</span>t<span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_alpha**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_alpha**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.For example with LeakyRelu, the default</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.For example with LeakyRelu, the default</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  alpha is 0.01.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  alpha is 0.01.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_beta**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_beta**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  example (f, g, h) in LSTM. Default values are the same as of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding ONNX operators.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activations**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activations**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A list of 2 (or 4 if bidirectional) activation functions for update,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A list of 2 (or 4 if bidirectional) activation functions for update,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  reset, and hidden gates. The activation functions must be one of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  reset, and hidden gates. The activation functions must be one of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activation functions specified above. Optional: See the equations</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activation functions specified above. Optional: See the equations</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  for default if not specified.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  for default if not specified.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **clip**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **clip**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Cell clip threshold. Clipping bounds the elements of a tensor in the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Cell clip threshold. Clipping bounds the elements of a tensor in the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  range of [-threshold, +threshold] and is applied to the input of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  range of [-threshold, +threshold] and is applied to the input of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activations. No clip if not specified.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activations. No clip if not specified.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **direction**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **direction**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specify if the RNN is forward, reverse, or bidirectional. Must be</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specify if the RNN is forward, reverse, or bidirectional. Must be</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  one of forward (default), reverse, or bidirectional. Default value is 'forward'.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  one of forward (default), reverse, or bidirectional. Default value is 'forward'.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **hidden_size**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **hidden_size**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Number of neurons in the hidden layer</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Number of neurons in the hidden layer</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **linear_before_reset**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **linear_before_reset**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">102</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  When computing the output of the hidden gate, apply the linear</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  When computing the output of the hidden gate, apply the linear</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">102</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">103</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  transformation before multiplying by the output of the reset gate. Default value is 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  transformation before multiplying by the output of the reset gate. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">103</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">* **output_sequence**:</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">104</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  The sequence output for the hidden is optional if 0. Default 0. Default value is 0.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">104</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">106</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">107</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">106</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">108</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">107</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 3 and 6 inputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 3 and 6 inputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">109</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">108</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">110</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">109</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">111</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">110</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The input sequences packed (and potentially padded) into one 3-D</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The input sequences packed (and potentially padded) into one 3-D</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">112</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">111</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor with the shape of [seq_length, batch_size, input_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor with the shape of [seq_length, batch_size, input_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">113</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">112</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">114</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">113</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor for the gates. Concatenation of W[zrh] and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor for the gates. Concatenation of W[zrh] and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">115</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">114</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  WB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  WB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">116</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">115</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, input_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, input_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">117</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">116</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **R** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **R** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">118</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">117</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The recurrence weight tensor. Concatenation of R[zrh] and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The recurrence weight tensor. Concatenation of R[zrh] and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">119</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">118</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  RB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  RB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">120</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">119</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">121</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">120</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">122</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">121</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias tensor for the gates. Concatenation of [Wb[zrh], Rb[zrh]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias tensor for the gates. Concatenation of [Wb[zrh], Rb[zrh]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">123</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">122</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  and [WBb[zrh], RBb[zrh]] (if bidirectional) along dimension 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  and [WBb[zrh], RBb[zrh]] (if bidirectional) along dimension 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">124</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">123</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  This tensor has shape [num_directions, 6*hidden_size]. Optional:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  This tensor has shape [num_directions, 6*hidden_size]. Optional:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">125</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">124</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If not specified - assumed to be 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If not specified - assumed to be 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">126</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">125</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **sequence_lens** (optional, heterogeneous) - **T1**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **sequence_lens** (optional, heterogeneous) - **T1**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">127</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">126</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional tensor specifying lengths of the sequences in a batch. If</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional tensor specifying lengths of the sequences in a batch. If</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">128</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">127</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  not specified - assumed all sequences in the batch to have length</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  not specified - assumed all sequences in the batch to have length</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">129</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">128</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  seq_length. It has shape [batch_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  seq_length. It has shape [batch_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">130</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">129</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **initial_h** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **initial_h** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">131</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">130</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional initial value of the hidden. If not specified - assumed to</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional initial value of the hidden. If not specified - assumed to</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">132</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">131</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be 0. It has shape [num_directions, batch_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be 0. It has shape [num_directions, batch_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">133</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">132</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">134</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">133</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">135</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">134</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">136</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">135</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 0 and 2 outputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 0 and 2 outputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">137</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">136</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">138</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">137</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">139</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">138</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A tensor that concats all the intermediate output values of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A tensor that concats all the intermediate output values of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">140</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">139</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden. It has shape [seq_length, num_directions, batch_size,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden. It has shape [seq_length, num_directions, batch_size,</code></td></tr>
<tr style="1px solid black;"><td><code>141</code></td><td><code>140</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  hidden_size].<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">_</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">q</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">0</span><span style="color:#BA4A00;">.</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">142</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">141</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y_h** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y_h** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">143</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">142</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The last output value of the hidden. It has shape [num_directions,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The last output value of the hidden. It has shape [num_directions,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">144</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">143</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  batch_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  batch_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">145</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">144</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">146</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">145</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">147</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">146</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">148</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">147</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">149</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">148</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">150</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">149</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">151</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">150</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">152</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">151</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">153</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">152</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">154</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">153</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T1** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T1** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">155</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">154</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">156</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">155</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">157</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">156</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain seq_lens to integer tensor.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain seq_lens to integer tensor.</code></td></tr>
</table></section>
<section id="gru-3">
<span id="l-onnx-op-gru-3"></span><h2><a class="toc-backref" href="#id15">GRU - 3</a><a class="headerlink" href="#gru-3" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU">GRU (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>3</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 3</strong>.</p>
<p><strong>Summary</strong></p>
<p>Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.</p>
<p>Notations:</p>
<p><cite>X</cite> - input tensor</p>
<p><cite>z</cite> - update gate</p>
<p><cite>r</cite> - reset gate</p>
<p><cite>h</cite> - hidden gate</p>
<p><cite>t</cite> - time step (t-1 means previous time step)</p>
<p><cite>W[zrh]</cite> - W parameter weight matrix for update, reset, and hidden gates</p>
<p><cite>R[zrh]</cite> - R recurrence weight matrix for update, reset, and hidden gates</p>
<p><cite>Wb[zrh]</cite> - W bias vectors for update, reset, and hidden gates</p>
<p><cite>Rb[zrh]</cite> - R bias vectors for update, reset, and hidden gates</p>
<p><cite>WB[zrh]</cite> - W parameter weight matrix for backward update, reset, and hidden gates</p>
<p><cite>RB[zrh]</cite> - R recurrence weight matrix for backward update, reset, and hidden gates</p>
<p><cite>WBb[zrh]</cite> - W bias vectors for backward update, reset, and hidden gates</p>
<p><cite>RBb[zrh]</cite> - R bias vectors for backward update, reset, and hidden gates</p>
<p><cite>H</cite> - Hidden state</p>
<p><cite>num_directions</cite> - 2 if direction == bidirectional else 1</p>
<p>Activation functions:</p>
<blockquote>
<div><p>Relu(x)                - max(0, x)</p>
<p>Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</p>
<p>Sigmoid(x)             - 1/(1 + e^{-x})</p>
<p>(NOTE: Below are optional)</p>
<p>Affine(x)              - alpha*x + beta</p>
<p>LeakyRelu(x)           - x if x &gt;= 0 else alpha * x</p>
<p>ThresholdedRelu(x)     - x if x &gt;= alpha else 0</p>
<p>ScaledTanh(x)          - alpha*Tanh(beta*x)</p>
<p>HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</p>
<p>Elu(x)                 - x if x &gt;= 0 else alpha*(e^x - 1)</p>
<p>Softsign(x)            - x/(1 + <a href="#id9"><span class="problematic" id="id10">|x|</span></a>)</p>
<p>Softplus(x)            - log(1 + e^x)</p>
</div></blockquote>
<p>Equations (Default: f=Sigmoid, g=Tanh):</p>
<blockquote>
<div><ul class="simple">
<li><p>zt = f(Xt*(Wz^T) + Ht-1*Rz + Wbz + Rbz)</p></li>
<li><p>rt = f(Xt*(Wr^T) + Ht-1*Rr + Wbr + Rbr)</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*Rh + Rbh + Wbh) # default, when linear_before_reset = 0</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*Rh + Rbh) + Wbh) # when linear_before_reset != 0</p></li>
<li><p>Ht = (1 - zt) (.) ht + zt (.) Ht-1</p></li>
</ul>
</div></blockquote>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>activation_alpha</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM. Default values are the same as of
corresponding ONNX operators.For example with LeakyRelu, the default
alpha is 0.01.</p></li>
<li><p><strong>activation_beta</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM. Default values are the same as of
corresponding ONNX operators.</p></li>
<li><p><strong>activations</strong>:
A list of 2 (or 4 if bidirectional) activation functions for update,
reset, and hidden gates. The activation functions must be one of the
activation functions specified above. Optional: See the equations
for default if not specified.</p></li>
<li><p><strong>clip</strong>:
Cell clip threshold. Clipping bounds the elements of a tensor in the
range of [-threshold, +threshold] and is applied to the input of
activations. No clip if not specified.</p></li>
<li><p><strong>direction</strong>:
Specify if the RNN is forward, reverse, or bidirectional. Must be
one of forward (default), reverse, or bidirectional. Default value is <code class="docutils literal notranslate"><span class="pre">'forward'</span></code>.</p></li>
<li><p><strong>hidden_size</strong>:
Number of neurons in the hidden layer</p></li>
<li><p><strong>linear_before_reset</strong>:
When computing the output of the hidden gate, apply the linear
transformation before multiplying by the output of the reset gate. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>output_sequence</strong>:
The sequence output for the hidden is optional if 0. Default 0. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 3 and 6 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
The input sequences packed (and potentially padded) into one 3-D
tensor with the shape of <cite>[seq_length, batch_size, input_size]</cite>.</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor for the gates. Concatenation of <cite>W[zrh]</cite> and
<cite>WB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, input_size]</cite>.</p></li>
<li><p><strong>R</strong> (heterogeneous) - <strong>T</strong>:
The recurrence weight tensor. Concatenation of <cite>R[zrh]</cite> and
<cite>RB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, hidden_size]</cite>.</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
The bias tensor for the gates. Concatenation of <cite>[Wb[zrh], Rb[zrh]]</cite>
and <cite>[WBb[zrh], RBb[zrh]]</cite> (if bidirectional) along dimension 0.
This tensor has shape <cite>[num_directions, 6*hidden_size]</cite>. Optional:
If not specified - assumed to be 0</p></li>
<li><p><strong>sequence_lens</strong> (optional, heterogeneous) - <strong>T1</strong>:
Optional tensor specifying lengths of the sequences in a batch. If
not specified - assumed all sequences in the batch to have length
<cite>seq_length</cite>. It has shape <cite>[batch_size]</cite>.</p></li>
<li><p><strong>initial_h</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional initial value of the hidden. If not specified - assumed to
be 0. It has shape <cite>[num_directions, batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 0 and 2 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (optional, heterogeneous) - <strong>T</strong>:
A tensor that concats all the intermediate output values of the
hidden. It has shape <cite>[seq_length, num_directions, batch_size,
hidden_size]</cite>. It is optional if <cite>output_sequence</cite> is 0.</p></li>
<li><p><strong>Y_h</strong> (optional, heterogeneous) - <strong>T</strong>:
The last output value of the hidden. It has shape <cite>[num_directions,
batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>T1</strong> in (
tensor(int32)
):
Constrain seq_lens to integer tensor.</p></li>
</ul>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Computes an one-layer GRU. This operator is usually supported via some custom</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Computes an one-layer GRU. This operator is usually supported via some custom</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">implementation such as CuDNN.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">implementation such as CuDNN.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Notations:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Notations:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">X - input tensor</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">X - input tensor</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">z - update gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">z - update gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">r - reset gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">r - reset gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">h - hidden gate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">h - hidden gate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">t - time step (t-1 means previous time step)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">t - time step (t-1 means previous time step)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">W[zrh] - W parameter weight matrix for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">W[zrh] - W parameter weight matrix for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">R[zrh] - R recurrence weight matrix for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">R[zrh] - R recurrence weight matrix for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Wb[zrh] - W bias vectors for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Wb[zrh] - W bias vectors for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Rb[zrh] - R bias vectors for update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Rb[zrh] - R bias vectors for update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WB[zrh] - W parameter weight matrix for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WB[zrh] - W parameter weight matrix for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RB[zrh] - R recurrence weight matrix for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RB[zrh] - R recurrence weight matrix for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WBb[zrh] - W bias vectors for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">WBb[zrh] - W bias vectors for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RBb[zrh] - R bias vectors for backward update, reset, and hidden gates</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">RBb[zrh] - R bias vectors for backward update, reset, and hidden gates</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">H - Hidden state</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">H - Hidden state</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">num_directions - 2 if direction == bidirectional else 1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">num_directions - 2 if direction == bidirectional else 1</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Activation functions:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Activation functions:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Relu(x)                - max(0, x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Relu(x)                - max(0, x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Sigmoid(x)             - 1/(1 + e^{-x})</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Sigmoid(x)             - 1/(1 + e^{-x})</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (NOTE: Below are optional)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (NOTE: Below are optional)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Affine(x)              - alpha*x + beta</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Affine(x)              - alpha*x + beta</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  LeakyRelu(x)           - x if x >= 0 else alpha * x</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  LeakyRelu(x)           - x if x >= 0 else alpha * x</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ThresholdedRelu(x)     - x if x >= alpha else 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ThresholdedRelu(x)     - x if x >= alpha else 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ScaledTanh(x)          - alpha*Tanh(beta*x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ScaledTanh(x)          - alpha*Tanh(beta*x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softsign(x)            - x/(1 + |x|)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softsign(x)            - x/(1 + |x|)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softplus(x)            - log(1 + e^x)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Softplus(x)            - log(1 + e^x)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Equations (Default: f=Sigmoid, g=Tanh):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Equations (Default: f=Sigmoid, g=Tanh):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - zt = f(Xt*(Wz^T) + Ht-1*Rz + Wbz + Rbz)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - zt = f(Xt*(Wz^T) + Ht-1*Rz + Wbz + Rbz)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - rt = f(Xt*(Wr^T) + Ht-1*Rr + Wbr + Rbr)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - rt = f(Xt*(Wr^T) + Ht-1*Rr + Wbr + Rbr)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*Rh + Rbh + Wbh) # default, when linear_before_reset = 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*Rh + Rbh + Wbh) # default, when linear_before_reset = 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*Rh + Rbh) + Wbh) # when linear_before_reset != 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*Rh + Rbh) + Wbh) # when linear_before_reset != 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - Ht = (1 - zt) (.) ht + zt (.) Ht-1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  - Ht = (1 - zt) (.) ht + zt (.) Ht-1</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_alpha**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_alpha**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td></tr>
<tr style="1px solid black;"><td><code>78</code></td><td><code>78</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  example (f, g, h) in LSTM.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  example (f, g, h) in LSTM.<span style="color:#196F3D;"> </span><span style="color:#196F3D;">D</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">v</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">79</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  corresponding ONNX operators.For example with LeakyRelu, the default</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">80</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  alpha is 0.01.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_beta**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activation_beta**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional scaling values used by some activation functions. The</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are consumed in the order of activation functions, for</code></td></tr>
<tr style="1px solid black;"><td><code>82</code></td><td><code>84</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  example (f, g, h) in LSTM.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  example (f, g, h) in LSTM.<span style="color:#196F3D;"> </span><span style="color:#196F3D;">D</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">v</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">85</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  corresponding ONNX operators.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activations**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **activations**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A list of 2 (or 4 if bidirectional) activation functions for update,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A list of 2 (or 4 if bidirectional) activation functions for update,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  reset, and hidden gates. The activation functions must be one of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  reset, and hidden gates. The activation functions must be one of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activation functions specified above. Optional: See the equations</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activation functions specified above. Optional: See the equations</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  for default if not specified.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  for default if not specified.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **clip**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **clip**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Cell clip threshold. Clipping bounds the elements of a tensor in the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Cell clip threshold. Clipping bounds the elements of a tensor in the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  range of [-threshold, +threshold] and is applied to the input of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  range of [-threshold, +threshold] and is applied to the input of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activations. No clip if not specified.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  activations. No clip if not specified.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **direction**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **direction**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specify if the RNN is forward, reverse, or bidirectional. Must be</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specify if the RNN is forward, reverse, or bidirectional. Must be</code></td></tr>
<tr style="1px solid black;"><td><code>94</code></td><td><code>97</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  one of forward (default), reverse, or bidirectional. Default value is 'foward'.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  one of forward (default), reverse, or bidirectional. Default value is 'fo<span style="color:#196F3D;">r</span>ward'.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **hidden_size**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **hidden_size**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Number of neurons in the hidden layer</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Number of neurons in the hidden layer</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">100</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">* **linear_before_reset**:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">101</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  When computing the output of the hidden gate, apply the linear</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">102</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  transformation before multiplying by the output of the reset gate. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">103</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **output_sequence**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **output_sequence**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">104</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The sequence output for the hidden is optional if 0. Default 0. Default value is 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The sequence output for the hidden is optional if 0. Default 0. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">106</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">107</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">102</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">108</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 3 and 6 inputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 3 and 6 inputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">103</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">109</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">104</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">110</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">111</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The input sequences packed (and potentially padded) into one 3-D</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The input sequences packed (and potentially padded) into one 3-D</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">106</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">112</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor with the shape of [seq_length, batch_size, input_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor with the shape of [seq_length, batch_size, input_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">107</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">113</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">108</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">114</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor for the gates. Concatenation of W[zrh] and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor for the gates. Concatenation of W[zrh] and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">109</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">115</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  WB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  WB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">110</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">116</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, input_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, input_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">111</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">117</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **R** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **R** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">112</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">118</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The recurrence weight tensor. Concatenation of R[zrh] and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The recurrence weight tensor. Concatenation of R[zrh] and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">113</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">119</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  RB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  RB[zrh] (if bidirectional) along dimension 0. This tensor has</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">114</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">120</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape [num_directions, 3*hidden_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">115</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">121</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">116</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">122</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias tensor for the gates. Concatenation of [Wb[zrh], Rb[zrh]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias tensor for the gates. Concatenation of [Wb[zrh], Rb[zrh]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">117</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">123</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  and [WBb[zrh], RBb[zrh]] (if bidirectional) along dimension 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  and [WBb[zrh], RBb[zrh]] (if bidirectional) along dimension 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">118</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">124</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  This tensor has shape [num_directions, 6*hidden_size]. Optional:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  This tensor has shape [num_directions, 6*hidden_size]. Optional:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">119</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">125</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If not specified - assumed to be 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If not specified - assumed to be 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">120</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">126</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **sequence_lens** (optional, heterogeneous) - **T1**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **sequence_lens** (optional, heterogeneous) - **T1**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">121</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">127</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional tensor specifying lengths of the sequences in a batch. If</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional tensor specifying lengths of the sequences in a batch. If</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">122</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">128</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  not specified - assumed all sequences in the batch to have length</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  not specified - assumed all sequences in the batch to have length</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">123</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">129</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  seq_length. It has shape [batch_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  seq_length. It has shape [batch_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">124</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">130</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **initial_h** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **initial_h** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">125</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">131</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional initial value of the hidden. If not specified - assumed to</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional initial value of the hidden. If not specified - assumed to</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">126</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">132</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be 0. It has shape [num_directions, batch_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be 0. It has shape [num_directions, batch_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">127</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">133</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">128</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">134</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">129</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">135</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">136</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">Between 0 and 2 outputs.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">137</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">130</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">138</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">131</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">139</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A tensor that concats all the intermediate output values of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  A tensor that concats all the intermediate output values of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">132</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">140</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden. It has shape [seq_length, num_directions, batch_size,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden. It has shape [seq_length, num_directions, batch_size,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">133</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">141</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden_size]. It is optional if output_sequence is 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  hidden_size]. It is optional if output_sequence is 0.</code></td></tr>
<tr style="1px solid black;"><td><code>134</code></td><td><code>142</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **Y_h** (heterogeneous) - **T**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **Y_h** (<span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">,</span><span style="color:#196F3D;"> </span>heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">135</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">143</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The last output value of the hidden. It has shape [num_directions,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The last output value of the hidden. It has shape [num_directions,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">136</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">144</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  batch_size, hidden_size].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  batch_size, hidden_size].</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">137</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">145</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">138</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">146</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">139</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">147</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">140</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">148</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">141</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">149</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">142</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">150</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">143</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">151</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">144</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">152</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">145</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">153</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">146</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">154</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T1** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T1** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">147</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">155</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">148</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">156</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">149</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">157</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain seq_lens to integer tensor.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain seq_lens to integer tensor.</code></td></tr>
</table></section>
<section id="gru-1">
<span id="l-onnx-op-gru-1"></span><h2><a class="toc-backref" href="#id16">GRU - 1</a><a class="headerlink" href="#gru-1" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU">GRU (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>1</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: False</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<p>Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.</p>
<p>Notations:</p>
<p><cite>X</cite> - input tensor</p>
<p><cite>z</cite> - update gate</p>
<p><cite>r</cite> - reset gate</p>
<p><cite>h</cite> - hidden gate</p>
<p><cite>t</cite> - time step (t-1 means previous time step)</p>
<p><cite>W[zrh]</cite> - W parameter weight matrix for update, reset, and hidden gates</p>
<p><cite>R[zrh]</cite> - R recurrence weight matrix for update, reset, and hidden gates</p>
<p><cite>Wb[zrh]</cite> - W bias vectors for update, reset, and hidden gates</p>
<p><cite>Rb[zrh]</cite> - R bias vectors for update, reset, and hidden gates</p>
<p><cite>WB[zrh]</cite> - W parameter weight matrix for backward update, reset, and hidden gates</p>
<p><cite>RB[zrh]</cite> - R recurrence weight matrix for backward update, reset, and hidden gates</p>
<p><cite>WBb[zrh]</cite> - W bias vectors for backward update, reset, and hidden gates</p>
<p><cite>RBb[zrh]</cite> - R bias vectors for backward update, reset, and hidden gates</p>
<p><cite>H</cite> - Hidden state</p>
<p><cite>num_directions</cite> - 2 if direction == bidirectional else 1</p>
<p>Activation functions:</p>
<blockquote>
<div><p>Relu(x)                - max(0, x)</p>
<p>Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})</p>
<p>Sigmoid(x)             - 1/(1 + e^{-x})</p>
<p>(NOTE: Below are optional)</p>
<p>Affine(x)              - alpha*x + beta</p>
<p>LeakyRelu(x)           - x if x &gt;= 0 else alpha * x</p>
<p>ThresholdedRelu(x)     - x if x &gt;= alpha else 0</p>
<p>ScaledTanh(x)          - alpha*Tanh(beta*x)</p>
<p>HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)</p>
<p>Elu(x)                 - x if x &gt;= 0 else alpha*(e^x - 1)</p>
<p>Softsign(x)            - x/(1 + <a href="#id11"><span class="problematic" id="id12">|x|</span></a>)</p>
<p>Softplus(x)            - log(1 + e^x)</p>
</div></blockquote>
<p>Equations (Default: f=Sigmoid, g=Tanh):</p>
<blockquote>
<div><ul class="simple">
<li><p>zt = f(Xt*(Wz^T) + Ht-1*Rz + Wbz + Rbz)</p></li>
<li><p>rt = f(Xt*(Wr^T) + Ht-1*Rr + Wbr + Rbr)</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*Rh + Rbh + Wbh) # default, when linear_before_reset = 0</p></li>
<li><p>ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*Rh + Rbh) + Wbh) # when linear_before_reset != 0</p></li>
<li><p>Ht = (1 - zt) (.) ht + zt (.) Ht-1</p></li>
</ul>
</div></blockquote>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>activation_alpha</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM.</p></li>
<li><p><strong>activation_beta</strong>:
Optional scaling values used by some activation functions. The
values are consumed in the order of activation functions, for
example (f, g, h) in LSTM.</p></li>
<li><p><strong>activations</strong>:
A list of 2 (or 4 if bidirectional) activation functions for update,
reset, and hidden gates. The activation functions must be one of the
activation functions specified above. Optional: See the equations
for default if not specified.</p></li>
<li><p><strong>clip</strong>:
Cell clip threshold. Clipping bounds the elements of a tensor in the
range of [-threshold, +threshold] and is applied to the input of
activations. No clip if not specified.</p></li>
<li><p><strong>direction</strong>:
Specify if the RNN is forward, reverse, or bidirectional. Must be
one of forward (default), reverse, or bidirectional. Default value is <code class="docutils literal notranslate"><span class="pre">'foward'</span></code>.</p></li>
<li><p><strong>hidden_size</strong>:
Number of neurons in the hidden layer</p></li>
<li><p><strong>output_sequence</strong>:
The sequence output for the hidden is optional if 0. Default 0. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 3 and 6 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
The input sequences packed (and potentially padded) into one 3-D
tensor with the shape of <cite>[seq_length, batch_size, input_size]</cite>.</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor for the gates. Concatenation of <cite>W[zrh]</cite> and
<cite>WB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, input_size]</cite>.</p></li>
<li><p><strong>R</strong> (heterogeneous) - <strong>T</strong>:
The recurrence weight tensor. Concatenation of <cite>R[zrh]</cite> and
<cite>RB[zrh]</cite> (if bidirectional) along dimension 0. This tensor has
shape <cite>[num_directions, 3*hidden_size, hidden_size]</cite>.</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
The bias tensor for the gates. Concatenation of <cite>[Wb[zrh], Rb[zrh]]</cite>
and <cite>[WBb[zrh], RBb[zrh]]</cite> (if bidirectional) along dimension 0.
This tensor has shape <cite>[num_directions, 6*hidden_size]</cite>. Optional:
If not specified - assumed to be 0</p></li>
<li><p><strong>sequence_lens</strong> (optional, heterogeneous) - <strong>T1</strong>:
Optional tensor specifying lengths of the sequences in a batch. If
not specified - assumed all sequences in the batch to have length
<cite>seq_length</cite>. It has shape <cite>[batch_size]</cite>.</p></li>
<li><p><strong>initial_h</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional initial value of the hidden. If not specified - assumed to
be 0. It has shape <cite>[num_directions, batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (optional, heterogeneous) - <strong>T</strong>:
A tensor that concats all the intermediate output values of the
hidden. It has shape <cite>[seq_length, num_directions, batch_size,
hidden_size]</cite>. It is optional if <cite>output_sequence</cite> is 0.</p></li>
<li><p><strong>Y_h</strong> (heterogeneous) - <strong>T</strong>:
The last output value of the hidden. It has shape <cite>[num_directions,
batch_size, hidden_size]</cite>.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>T1</strong> in (
tensor(int32)
):
Constrain seq_lens to integer tensor.</p></li>
</ul>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="onnx__Floor.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Floor</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="onnx__Gather.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Gather</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier DuprÃ©.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>