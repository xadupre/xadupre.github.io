
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>ConvTranspose &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="../_static/project_ico.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cos" href="onnx__Cos.html" />
    <link rel="prev" title="ConvInteger" href="onnx__ConvInteger.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_cmd.html">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_index.html">
  FAQ, code, …
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   ONNX operators
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Abs.html">
     Abs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acos.html">
     Acos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acosh.html">
     Acosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Add.html">
     Add
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__And.html">
     And
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMax.html">
     ArgMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMin.html">
     ArgMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asin.html">
     Asin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asinh.html">
     Asinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atan.html">
     Atan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atanh.html">
     Atanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__AveragePool.html">
     AveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BatchNormalization.html">
     BatchNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Bernoulli.html">
     Bernoulli
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BitShift.html">
     BitShift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cast.html">
     Cast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CastLike.html">
     CastLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Ceil.html">
     Ceil
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Celu.html">
     Celu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Clip.html">
     Clip
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Compress.html">
     Compress
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Concat.html">
     Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConcatFromSequence.html">
     ConcatFromSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Constant.html">
     Constant
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConstantOfShape.html">
     ConstantOfShape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Conv.html">
     Conv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvInteger.html">
     ConvInteger
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     ConvTranspose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cos.html">
     Cos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cosh.html">
     Cosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CumSum.html">
     CumSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DepthToSpace.html">
     DepthToSpace
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DequantizeLinear.html">
     DequantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Det.html">
     Det
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Div.html">
     Div
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Dropout.html">
     Dropout
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
     DynamicQuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Einsum.html">
     Einsum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Elu.html">
     Elu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Equal.html">
     Equal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Erf.html">
     Erf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Exp.html">
     Exp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Expand.html">
     Expand
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__EyeLike.html">
     EyeLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Flatten.html">
     Flatten
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Floor.html">
     Floor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GRU.html">
     GRU
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gather.html">
     Gather
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherElements.html">
     GatherElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherND.html">
     GatherND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gemm.html">
     Gemm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalAveragePool.html">
     GlobalAveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalLpPool.html">
     GlobalLpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalMaxPool.html">
     GlobalMaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Greater.html">
     Greater
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GreaterOrEqual.html">
     GreaterOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GridSample.html">
     GridSample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSigmoid.html">
     HardSigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSwish.html">
     HardSwish
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Hardmax.html">
     Hardmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Identity.html">
     Identity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__If.html">
     If
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__InstanceNormalization.html">
     InstanceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsInf.html">
     IsInf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsNaN.html">
     IsNaN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LRN.html">
     LRN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LSTM.html">
     LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LeakyRelu.html">
     LeakyRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Less.html">
     Less
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LessOrEqual.html">
     LessOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Log.html">
     Log
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LogSoftmax.html">
     LogSoftmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Loop.html">
     Loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpNormalization.html">
     LpNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpPool.html">
     LpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMul.html">
     MatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMulInteger.html">
     MatMulInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Max.html">
     Max
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxPool.html">
     MaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxRoiPool.html">
     MaxRoiPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxUnpool.html">
     MaxUnpool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mean.html">
     Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
     MeanVarianceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Min.html">
     Min
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mod.html">
     Mod
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mul.html">
     Mul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Multinomial.html">
     Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Neg.html">
     Neg
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
     NegativeLogLikelihoodLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonMaxSuppression.html">
     NonMaxSuppression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonZero.html">
     NonZero
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Not.html">
     Not
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OneHot.html">
     OneHot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Optional.html">
     Optional
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalGetElement.html">
     OptionalGetElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalHasElement.html">
     OptionalHasElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Or.html">
     Or
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__PRelu.html">
     PRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pad.html">
     Pad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pow.html">
     Pow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearConv.html">
     QLinearConv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearMatMul.html">
     QLinearMatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QuantizeLinear.html">
     QuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RNN.html">
     RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormal.html">
     RandomNormal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormalLike.html">
     RandomNormalLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniform.html">
     RandomUniform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniformLike.html">
     RandomUniformLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Range.html">
     Range
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reciprocal.html">
     Reciprocal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL1.html">
     ReduceL1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL2.html">
     ReduceL2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSum.html">
     ReduceLogSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSumExp.html">
     ReduceLogSumExp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMax.html">
     ReduceMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMean.html">
     ReduceMean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMin.html">
     ReduceMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceProd.html">
     ReduceProd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSum.html">
     ReduceSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSumSquare.html">
     ReduceSumSquare
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Relu.html">
     Relu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reshape.html">
     Reshape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Resize.html">
     Resize
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReverseSequence.html">
     ReverseSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RoiAlign.html">
     RoiAlign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Round.html">
     Round
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scan.html">
     Scan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scatter.html">
     Scatter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterElements.html">
     ScatterElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterND.html">
     ScatterND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Selu.html">
     Selu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceAt.html">
     SequenceAt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceConstruct.html">
     SequenceConstruct
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceEmpty.html">
     SequenceEmpty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceErase.html">
     SequenceErase
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceInsert.html">
     SequenceInsert
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceLength.html">
     SequenceLength
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shape.html">
     Shape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shrink.html">
     Shrink
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sigmoid.html">
     Sigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sign.html">
     Sign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sin.html">
     Sin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sinh.html">
     Sinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Size.html">
     Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Slice.html">
     Slice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softmax.html">
     Softmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
     SoftmaxCrossEntropyLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softplus.html">
     Softplus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softsign.html">
     Softsign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SpaceToDepth.html">
     SpaceToDepth
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Split.html">
     Split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SplitToSequence.html">
     SplitToSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sqrt.html">
     Sqrt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Squeeze.html">
     Squeeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__StringNormalizer.html">
     StringNormalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sub.html">
     Sub
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sum.html">
     Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tan.html">
     Tan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tanh.html">
     Tanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TfIdfVectorizer.html">
     TfIdfVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ThresholdedRelu.html">
     ThresholdedRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tile.html">
     Tile
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TopK.html">
     TopK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Transpose.html">
     Transpose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Trilu.html">
     Trilu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unique.html">
     Unique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unsqueeze.html">
     Unsqueeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Upsample.html">
     Upsample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Where.html">
     Where
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Xor.html">
     Xor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
     ai.onnx.ml - ArrayFeatureExtractor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
     ai.onnx.ml - Binarizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CastMap.html">
     ai.onnx.ml - CastMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
     ai.onnx.ml - CategoryMapper
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
     ai.onnx.ml - DictVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
     ai.onnx.ml - FeatureVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Imputer.html">
     ai.onnx.ml - Imputer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
     ai.onnx.ml - LabelEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
     ai.onnx.ml - LinearClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
     ai.onnx.ml - LinearRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
     ai.onnx.ml - Normalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
     ai.onnx.ml - OneHotEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
     ai.onnx.ml - SVMClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
     ai.onnx.ml - SVMRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Scaler.html">
     ai.onnx.ml - Scaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
     ai.onnx.ml - TreeEnsembleClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
     ai.onnx.ml - TreeEnsembleRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
     ai.onnx.ml - ZipMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
     ai.onnx.preview.training - Adagrad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
     ai.onnx.preview.training - Adam
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
     ai.onnx.preview.training - Gradient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
     ai.onnx.preview.training - Momentum
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_runtime.html">
   Runtimes for ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../backends/index.html">
   ONNX Backends
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convtranspose-11">
   ConvTranspose - 11
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convtranspose-1">
   ConvTranspose - 1
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="convtranspose">
<span id="l-onnx-doc-convtranspose"></span><h1>ConvTranspose<a class="headerlink" href="#convtranspose" title="Permalink to this headline">#</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#convtranspose-11" id="id2">ConvTranspose - 11</a></p></li>
<li><p><a class="reference internal" href="#convtranspose-1" id="id3">ConvTranspose - 1</a></p></li>
</ul>
</div>
<section id="convtranspose-11">
<span id="l-onnx-op-convtranspose-11"></span><h2><a class="toc-backref" href="#id2">ConvTranspose - 11</a><a class="headerlink" href="#convtranspose-11" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose">ConvTranspose (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>11</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 11</strong>.</p>
<p><strong>Summary</strong></p>
<p>The convolution transpose operator consumes an input tensor and a filter,
and computes the output.</p>
<p>If the pads parameter is provided the shape of the output is calculated via the following equation:</p>
<blockquote>
<div><p>output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]</p>
</div></blockquote>
<p>output_shape can also be explicitly specified in which case pads values are auto generated using these equations:</p>
<blockquote>
<div><p>total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]
If (auto_pads == SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).</p>
</div></blockquote>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>auto_pad</strong>:
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
Where default value is NOTSET, which means explicit padding is used.
SAME_UPPER or SAME_LOWER mean pad the input so that <cite>output_shape[i]
= input_shape[i] * strides[i]</cite> for each axis <cite>i</cite>. The padding is
split between the two sides equally or almost equally (depending on
whether it is even or odd). In case the padding is an odd number,
the extra padding is added at the end for SAME_UPPER and at the
beginning for SAME_LOWER. Default value is <code class="docutils literal notranslate"><span class="pre">'NOTSET'</span></code>.</p></li>
<li><p><strong>dilations</strong>:
dilation value along each spatial axis of the filter. If not
present, the dilation defaults to 1 along each spatial axis.</p></li>
<li><p><strong>group</strong>:
number of groups input channels and output channels are divided
into. Default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>kernel_shape</strong>:
The shape of the convolution kernel. If not present, should be
inferred from input W.</p></li>
<li><p><strong>output_padding</strong>:
Additional elements added to the side with higher coordinate indices
in the output. Each padding value in “output_padding” must be less
than the corresponding stride/dilation dimension. By default, this
attribute is a zero vector. Note that this attribute doesn’t
directly affect the computed output values. It only controls the
selection of the computed values, so changing this attribute only
adds or removes output elements. If “output_shape” is explicitly
provided, “output_padding” does not contribute additional size to
“output_shape” but participates in the computation of the needed
padding amount. This is also called adjs or adjustment in some
frameworks.</p></li>
<li><p><strong>output_shape</strong>:
The shape of the output can be explicitly set which will cause pads
values to be auto generated. If output_shape is specified pads
values are ignored. See doc for details for equations to generate
pads</p></li>
<li><p><strong>pads</strong>:
Padding for the beginning and ending along each spatial axis, it can
take any value greater than or equal to 0. The value represent the
number of pixels added to the beginning and end part of the
corresponding axis. <cite>pads</cite> format should be as follow [x1_begin,
x2_begin…x1_end, x2_end,…], where xi_begin the number of pixels
added at the beginning of axis <cite>i</cite> and xi_end, the number of pixels
added at the end of axis <cite>i</cite>. This attribute cannot be used
simultaneously with auto_pad attribute. If not present, the padding
defaults to 0 along start and end of each spatial axis.</p></li>
<li><p><strong>strides</strong>:
Stride along each spatial axis. If not present, the stride defaults
to 1 along each spatial axis.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from previous layer; has size (N x C x H x W),
where N is the batch size, C is the number of channels, and H and W
are the height and width. Note that this is for the 2D image.
Otherwise the size is (N x C x D1 x D2 … x Dn)</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor that will be used in the convolutions; has size (C
x M/group x kH x kW), where C is the number of channels, and kH and
kW are the height and width of the kernel, and M is the number of
feature maps. For more than 2 dimensions, the weight shape will be
(C x M/group x k1 x k2 x … x kn), where (k1 x k2 x … x kn) is
the dimension of the kernel. The number of channels in the output
should be equal to W.shape[1] * group (assuming zero based indices
of the shape array)</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional 1D bias to be added to the convolution, has size of M.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output data tensor that contains the result of the convolution. The
output dimensions are functions of the kernel size, stride size, pad
lengths and group count. The number of channels in the output should
be equal to W.shape[1] * group (assuming zero based indices of the
shape array)</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>convtranspose_1d</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (1, 1, 3)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>  <span class="c1"># (1, 2, 3)</span>
               <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>  <span class="c1"># (1, 2, 5)</span>
               <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_1d&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>convtranspose_3d</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 4, 5)</span>
                 <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">,</span> <span class="mf">17.</span><span class="p">,</span> <span class="mf">18.</span><span class="p">,</span> <span class="mf">19.</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">20.</span><span class="p">,</span> <span class="mf">21.</span><span class="p">,</span> <span class="mf">22.</span><span class="p">,</span> <span class="mf">23.</span><span class="p">,</span> <span class="mf">24.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">25.</span><span class="p">,</span> <span class="mf">26.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">,</span> <span class="mf">28.</span><span class="p">,</span> <span class="mf">29.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">30.</span><span class="p">,</span> <span class="mf">31.</span><span class="p">,</span> <span class="mf">32.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="mf">34.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">35.</span><span class="p">,</span> <span class="mf">36.</span><span class="p">,</span> <span class="mf">37.</span><span class="p">,</span> <span class="mf">38.</span><span class="p">,</span> <span class="mf">39.</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">40.</span><span class="p">,</span> <span class="mf">41.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">43.</span><span class="p">,</span> <span class="mf">44.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">45.</span><span class="p">,</span> <span class="mf">46.</span><span class="p">,</span> <span class="mf">47.</span><span class="p">,</span> <span class="mf">48.</span><span class="p">,</span> <span class="mf">49.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">50.</span><span class="p">,</span> <span class="mf">51.</span><span class="p">,</span> <span class="mf">52.</span><span class="p">,</span> <span class="mf">53.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">55.</span><span class="p">,</span> <span class="mf">56.</span><span class="p">,</span> <span class="mf">57.</span><span class="p">,</span> <span class="mf">58.</span><span class="p">,</span> <span class="mf">59.</span><span class="p">]]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>  <span class="c1"># (1, 2, 3, 3, 3)</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]],</span>
               <span class="p">[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>  <span class="c1"># (1, 2, 5, 6, 7)</span>
                 <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">,</span> <span class="mf">21.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="mf">24.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">,</span> <span class="mf">63.</span><span class="p">,</span> <span class="mf">72.</span><span class="p">,</span> <span class="mf">51.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">30.</span><span class="p">,</span> <span class="mf">63.</span><span class="p">,</span> <span class="mf">99.</span><span class="p">,</span> <span class="mf">108.</span><span class="p">,</span> <span class="mf">117.</span><span class="p">,</span> <span class="mf">81.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">25.</span><span class="p">,</span> <span class="mf">52.</span><span class="p">,</span> <span class="mf">81.</span><span class="p">,</span> <span class="mf">87.</span><span class="p">,</span> <span class="mf">93.</span><span class="p">,</span> <span class="mf">64.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">31.</span><span class="p">,</span> <span class="mf">48.</span><span class="p">,</span> <span class="mf">51.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">,</span> <span class="mf">37.</span><span class="p">,</span> <span class="mf">19.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">20.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">66.</span><span class="p">,</span> <span class="mf">72.</span><span class="p">,</span> <span class="mf">78.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">,</span> <span class="mf">28.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">50.</span><span class="p">,</span> <span class="mf">104.</span><span class="p">,</span> <span class="mf">162.</span><span class="p">,</span> <span class="mf">174.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">,</span> <span class="mf">128.</span><span class="p">,</span> <span class="mf">66.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">,</span> <span class="mf">288.</span><span class="p">,</span> <span class="mf">306.</span><span class="p">,</span> <span class="mf">324.</span><span class="p">,</span> <span class="mf">222.</span><span class="p">,</span> <span class="mf">114.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">120.</span><span class="p">,</span> <span class="mf">246.</span><span class="p">,</span> <span class="mf">378.</span><span class="p">,</span> <span class="mf">396.</span><span class="p">,</span> <span class="mf">414.</span><span class="p">,</span> <span class="mf">282.</span><span class="p">,</span> <span class="mf">144.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">184.</span><span class="p">,</span> <span class="mf">282.</span><span class="p">,</span> <span class="mf">294.</span><span class="p">,</span> <span class="mf">306.</span><span class="p">,</span> <span class="mf">208.</span><span class="p">,</span> <span class="mf">106.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">50.</span><span class="p">,</span> <span class="mf">102.</span><span class="p">,</span> <span class="mf">156.</span><span class="p">,</span> <span class="mf">162.</span><span class="p">,</span> <span class="mf">168.</span><span class="p">,</span> <span class="mf">114.</span><span class="p">,</span> <span class="mf">58.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">60.</span><span class="p">,</span> <span class="mf">123.</span><span class="p">,</span> <span class="mf">189.</span><span class="p">,</span> <span class="mf">198.</span><span class="p">,</span> <span class="mf">207.</span><span class="p">,</span> <span class="mf">141.</span><span class="p">,</span> <span class="mf">72.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">135.</span><span class="p">,</span> <span class="mf">276.</span><span class="p">,</span> <span class="mf">423.</span><span class="p">,</span> <span class="mf">441.</span><span class="p">,</span> <span class="mf">459.</span><span class="p">,</span> <span class="mf">312.</span><span class="p">,</span> <span class="mf">159.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">225.</span><span class="p">,</span> <span class="mf">459.</span><span class="p">,</span> <span class="mf">702.</span><span class="p">,</span> <span class="mf">729.</span><span class="p">,</span> <span class="mf">756.</span><span class="p">,</span> <span class="mf">513.</span><span class="p">,</span> <span class="mf">261.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">270.</span><span class="p">,</span> <span class="mf">549.</span><span class="p">,</span> <span class="mf">837.</span><span class="p">,</span> <span class="mf">864.</span><span class="p">,</span> <span class="mf">891.</span><span class="p">,</span> <span class="mf">603.</span><span class="p">,</span> <span class="mf">306.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">195.</span><span class="p">,</span> <span class="mf">396.</span><span class="p">,</span> <span class="mf">603.</span><span class="p">,</span> <span class="mf">621.</span><span class="p">,</span> <span class="mf">639.</span><span class="p">,</span> <span class="mf">432.</span><span class="p">,</span> <span class="mf">219.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">105.</span><span class="p">,</span> <span class="mf">213.</span><span class="p">,</span> <span class="mf">324.</span><span class="p">,</span> <span class="mf">333.</span><span class="p">,</span> <span class="mf">342.</span><span class="p">,</span> <span class="mf">231.</span><span class="p">,</span> <span class="mf">117.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">60.</span><span class="p">,</span> <span class="mf">122.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">,</span> <span class="mf">192.</span><span class="p">,</span> <span class="mf">198.</span><span class="p">,</span> <span class="mf">134.</span><span class="p">,</span> <span class="mf">68.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">130.</span><span class="p">,</span> <span class="mf">264.</span><span class="p">,</span> <span class="mf">402.</span><span class="p">,</span> <span class="mf">414.</span><span class="p">,</span> <span class="mf">426.</span><span class="p">,</span> <span class="mf">288.</span><span class="p">,</span> <span class="mf">146.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">210.</span><span class="p">,</span> <span class="mf">426.</span><span class="p">,</span> <span class="mf">648.</span><span class="p">,</span> <span class="mf">666.</span><span class="p">,</span> <span class="mf">684.</span><span class="p">,</span> <span class="mf">462.</span><span class="p">,</span> <span class="mf">234.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">240.</span><span class="p">,</span> <span class="mf">486.</span><span class="p">,</span> <span class="mf">738.</span><span class="p">,</span> <span class="mf">756.</span><span class="p">,</span> <span class="mf">774.</span><span class="p">,</span> <span class="mf">522.</span><span class="p">,</span> <span class="mf">264.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">170.</span><span class="p">,</span> <span class="mf">344.</span><span class="p">,</span> <span class="mf">522.</span><span class="p">,</span> <span class="mf">534.</span><span class="p">,</span> <span class="mf">546.</span><span class="p">,</span> <span class="mf">368.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">182.</span><span class="p">,</span> <span class="mf">276.</span><span class="p">,</span> <span class="mf">282.</span><span class="p">,</span> <span class="mf">288.</span><span class="p">,</span> <span class="mf">194.</span><span class="p">,</span> <span class="mf">98.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">40.</span><span class="p">,</span> <span class="mf">81.</span><span class="p">,</span> <span class="mf">123.</span><span class="p">,</span> <span class="mf">126.</span><span class="p">,</span> <span class="mf">129.</span><span class="p">,</span> <span class="mf">87.</span><span class="p">,</span> <span class="mf">44.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">85.</span><span class="p">,</span> <span class="mf">172.</span><span class="p">,</span> <span class="mf">261.</span><span class="p">,</span> <span class="mf">267.</span><span class="p">,</span> <span class="mf">273.</span><span class="p">,</span> <span class="mf">184.</span><span class="p">,</span> <span class="mf">93.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">135.</span><span class="p">,</span> <span class="mf">273.</span><span class="p">,</span> <span class="mf">414.</span><span class="p">,</span> <span class="mf">423.</span><span class="p">,</span> <span class="mf">432.</span><span class="p">,</span> <span class="mf">291.</span><span class="p">,</span> <span class="mf">147.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">150.</span><span class="p">,</span> <span class="mf">303.</span><span class="p">,</span> <span class="mf">459.</span><span class="p">,</span> <span class="mf">468.</span><span class="p">,</span> <span class="mf">477.</span><span class="p">,</span> <span class="mf">321.</span><span class="p">,</span> <span class="mf">162.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">105.</span><span class="p">,</span> <span class="mf">212.</span><span class="p">,</span> <span class="mf">321.</span><span class="p">,</span> <span class="mf">327.</span><span class="p">,</span> <span class="mf">333.</span><span class="p">,</span> <span class="mf">224.</span><span class="p">,</span> <span class="mf">113.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">55.</span><span class="p">,</span> <span class="mf">111.</span><span class="p">,</span> <span class="mf">168.</span><span class="p">,</span> <span class="mf">171.</span><span class="p">,</span> <span class="mf">174.</span><span class="p">,</span> <span class="mf">117.</span><span class="p">,</span> <span class="mf">59.</span><span class="p">]]],</span>

               <span class="p">[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">,</span> <span class="mf">21.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="mf">24.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">,</span> <span class="mf">63.</span><span class="p">,</span> <span class="mf">72.</span><span class="p">,</span> <span class="mf">51.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">30.</span><span class="p">,</span> <span class="mf">63.</span><span class="p">,</span> <span class="mf">99.</span><span class="p">,</span> <span class="mf">108.</span><span class="p">,</span> <span class="mf">117.</span><span class="p">,</span> <span class="mf">81.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">25.</span><span class="p">,</span> <span class="mf">52.</span><span class="p">,</span> <span class="mf">81.</span><span class="p">,</span> <span class="mf">87.</span><span class="p">,</span> <span class="mf">93.</span><span class="p">,</span> <span class="mf">64.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">31.</span><span class="p">,</span> <span class="mf">48.</span><span class="p">,</span> <span class="mf">51.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">,</span> <span class="mf">37.</span><span class="p">,</span> <span class="mf">19.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">20.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">66.</span><span class="p">,</span> <span class="mf">72.</span><span class="p">,</span> <span class="mf">78.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">,</span> <span class="mf">28.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">50.</span><span class="p">,</span> <span class="mf">104.</span><span class="p">,</span> <span class="mf">162.</span><span class="p">,</span> <span class="mf">174.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">,</span> <span class="mf">128.</span><span class="p">,</span> <span class="mf">66.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">,</span> <span class="mf">288.</span><span class="p">,</span> <span class="mf">306.</span><span class="p">,</span> <span class="mf">324.</span><span class="p">,</span> <span class="mf">222.</span><span class="p">,</span> <span class="mf">114.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">120.</span><span class="p">,</span> <span class="mf">246.</span><span class="p">,</span> <span class="mf">378.</span><span class="p">,</span> <span class="mf">396.</span><span class="p">,</span> <span class="mf">414.</span><span class="p">,</span> <span class="mf">282.</span><span class="p">,</span> <span class="mf">144.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">184.</span><span class="p">,</span> <span class="mf">282.</span><span class="p">,</span> <span class="mf">294.</span><span class="p">,</span> <span class="mf">306.</span><span class="p">,</span> <span class="mf">208.</span><span class="p">,</span> <span class="mf">106.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">50.</span><span class="p">,</span> <span class="mf">102.</span><span class="p">,</span> <span class="mf">156.</span><span class="p">,</span> <span class="mf">162.</span><span class="p">,</span> <span class="mf">168.</span><span class="p">,</span> <span class="mf">114.</span><span class="p">,</span> <span class="mf">58.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">60.</span><span class="p">,</span> <span class="mf">123.</span><span class="p">,</span> <span class="mf">189.</span><span class="p">,</span> <span class="mf">198.</span><span class="p">,</span> <span class="mf">207.</span><span class="p">,</span> <span class="mf">141.</span><span class="p">,</span> <span class="mf">72.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">135.</span><span class="p">,</span> <span class="mf">276.</span><span class="p">,</span> <span class="mf">423.</span><span class="p">,</span> <span class="mf">441.</span><span class="p">,</span> <span class="mf">459.</span><span class="p">,</span> <span class="mf">312.</span><span class="p">,</span> <span class="mf">159.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">225.</span><span class="p">,</span> <span class="mf">459.</span><span class="p">,</span> <span class="mf">702.</span><span class="p">,</span> <span class="mf">729.</span><span class="p">,</span> <span class="mf">756.</span><span class="p">,</span> <span class="mf">513.</span><span class="p">,</span> <span class="mf">261.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">270.</span><span class="p">,</span> <span class="mf">549.</span><span class="p">,</span> <span class="mf">837.</span><span class="p">,</span> <span class="mf">864.</span><span class="p">,</span> <span class="mf">891.</span><span class="p">,</span> <span class="mf">603.</span><span class="p">,</span> <span class="mf">306.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">195.</span><span class="p">,</span> <span class="mf">396.</span><span class="p">,</span> <span class="mf">603.</span><span class="p">,</span> <span class="mf">621.</span><span class="p">,</span> <span class="mf">639.</span><span class="p">,</span> <span class="mf">432.</span><span class="p">,</span> <span class="mf">219.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">105.</span><span class="p">,</span> <span class="mf">213.</span><span class="p">,</span> <span class="mf">324.</span><span class="p">,</span> <span class="mf">333.</span><span class="p">,</span> <span class="mf">342.</span><span class="p">,</span> <span class="mf">231.</span><span class="p">,</span> <span class="mf">117.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">60.</span><span class="p">,</span> <span class="mf">122.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">,</span> <span class="mf">192.</span><span class="p">,</span> <span class="mf">198.</span><span class="p">,</span> <span class="mf">134.</span><span class="p">,</span> <span class="mf">68.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">130.</span><span class="p">,</span> <span class="mf">264.</span><span class="p">,</span> <span class="mf">402.</span><span class="p">,</span> <span class="mf">414.</span><span class="p">,</span> <span class="mf">426.</span><span class="p">,</span> <span class="mf">288.</span><span class="p">,</span> <span class="mf">146.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">210.</span><span class="p">,</span> <span class="mf">426.</span><span class="p">,</span> <span class="mf">648.</span><span class="p">,</span> <span class="mf">666.</span><span class="p">,</span> <span class="mf">684.</span><span class="p">,</span> <span class="mf">462.</span><span class="p">,</span> <span class="mf">234.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">240.</span><span class="p">,</span> <span class="mf">486.</span><span class="p">,</span> <span class="mf">738.</span><span class="p">,</span> <span class="mf">756.</span><span class="p">,</span> <span class="mf">774.</span><span class="p">,</span> <span class="mf">522.</span><span class="p">,</span> <span class="mf">264.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">170.</span><span class="p">,</span> <span class="mf">344.</span><span class="p">,</span> <span class="mf">522.</span><span class="p">,</span> <span class="mf">534.</span><span class="p">,</span> <span class="mf">546.</span><span class="p">,</span> <span class="mf">368.</span><span class="p">,</span> <span class="mf">186.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">182.</span><span class="p">,</span> <span class="mf">276.</span><span class="p">,</span> <span class="mf">282.</span><span class="p">,</span> <span class="mf">288.</span><span class="p">,</span> <span class="mf">194.</span><span class="p">,</span> <span class="mf">98.</span><span class="p">]],</span>

                <span class="p">[[</span><span class="mf">40.</span><span class="p">,</span> <span class="mf">81.</span><span class="p">,</span> <span class="mf">123.</span><span class="p">,</span> <span class="mf">126.</span><span class="p">,</span> <span class="mf">129.</span><span class="p">,</span> <span class="mf">87.</span><span class="p">,</span> <span class="mf">44.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">85.</span><span class="p">,</span> <span class="mf">172.</span><span class="p">,</span> <span class="mf">261.</span><span class="p">,</span> <span class="mf">267.</span><span class="p">,</span> <span class="mf">273.</span><span class="p">,</span> <span class="mf">184.</span><span class="p">,</span> <span class="mf">93.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">135.</span><span class="p">,</span> <span class="mf">273.</span><span class="p">,</span> <span class="mf">414.</span><span class="p">,</span> <span class="mf">423.</span><span class="p">,</span> <span class="mf">432.</span><span class="p">,</span> <span class="mf">291.</span><span class="p">,</span> <span class="mf">147.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">150.</span><span class="p">,</span> <span class="mf">303.</span><span class="p">,</span> <span class="mf">459.</span><span class="p">,</span> <span class="mf">468.</span><span class="p">,</span> <span class="mf">477.</span><span class="p">,</span> <span class="mf">321.</span><span class="p">,</span> <span class="mf">162.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">105.</span><span class="p">,</span> <span class="mf">212.</span><span class="p">,</span> <span class="mf">321.</span><span class="p">,</span> <span class="mf">327.</span><span class="p">,</span> <span class="mf">333.</span><span class="p">,</span> <span class="mf">224.</span><span class="p">,</span> <span class="mf">113.</span><span class="p">],</span>
                 <span class="p">[</span><span class="mf">55.</span><span class="p">,</span> <span class="mf">111.</span><span class="p">,</span> <span class="mf">168.</span><span class="p">,</span> <span class="mf">171.</span><span class="p">,</span> <span class="mf">174.</span><span class="p">,</span> <span class="mf">117.</span><span class="p">,</span> <span class="mf">59.</span><span class="p">]]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_3d&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>convtranspose_attributes</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3)</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>  <span class="c1"># (1, 2, 3, 3)</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
               <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>  <span class="c1"># (1, 2, 10, 8)</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]],</span>

               <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span>
                             <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                             <span class="n">output_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_output_shape&#39;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span>
                             <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                             <span class="n">output_padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_pad&#39;</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;ConvTranspose&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span>
    <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="n">output_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">kernel_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">output_padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span>
       <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_kernel_shape&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>convtranspose_pads</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3)</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>  <span class="c1"># (1, 2, 3, 3)</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
               <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span>
                             <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                             <span class="n">pads</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>  <span class="c1"># (1, 2, 7, 3)</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">]],</span>

               <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_pads&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>convtranspose_dilations</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3)</span>
                <span class="p">[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>  <span class="c1"># (1, 1, 2, 2)</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">dilations</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">21.</span><span class="p">,</span> <span class="mf">56.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>  <span class="c1"># [1, 1, 5, 5]</span>
                <span class="p">[</span><span class="mf">63.</span><span class="p">,</span> <span class="mf">35.</span><span class="p">,</span> <span class="mf">67.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">24.</span><span class="p">,</span> <span class="mf">22.</span><span class="p">,</span> <span class="mf">76.</span><span class="p">,</span> <span class="mf">76.</span><span class="p">,</span> <span class="mf">21.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">88.</span><span class="p">,</span> <span class="mf">45.</span><span class="p">,</span> <span class="mf">63.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="mf">18.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_dilations&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>convtranspose_autopad_same</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>  <span class="c1"># (1, 1, 3, 3)</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>  <span class="c1"># (1, 2, 3, 3)</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
               <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ConvTranspose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;W&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">auto_pad</span><span class="o">=</span><span class="s2">&quot;SAME_UPPER&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span> <span class="mf">24.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]],</span>

               <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span> <span class="mf">24.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">],</span>
                <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_convtranspose_autopad_same&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The convolution transpose operator consumes an input tensor and a filter,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The convolution transpose operator consumes an input tensor and a filter,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">and computes the output.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">and computes the output.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If the pads parameter is provided the shape of the output is calculated via the following equation:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If the pads parameter is provided the shape of the output is calculated via the following equation:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">output_shape can also be explicitly specified in which case pads values are auto generated using these equations:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">output_shape can also be explicitly specified in which case pads values are auto generated using these equations:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]</code></td></tr>
<tr style="1px solid black;"><td><code>10</code></td><td><code>10</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  If (auto_pads <span style="color:#BA4A00;">!</span>= SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  If (auto_pads =<span style="color:#196F3D;">=</span> SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **auto_pad**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **auto_pad**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Where default value is NOTSET, which means explicit padding is used.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Where default value is NOTSET, which means explicit padding is used.</code></td></tr>
<tr style="1px solid black;"><td><code>18</code></td><td><code>18</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  SAME_UPPER or SAME_LOWER mean pad the input so that <span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span>output</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  SAME_UPPER or SAME_LOWER mean pad the input so that output<span style="color:#196F3D;">_</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">[</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">]</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">19</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  spatial size match the input.In case of odd number add the extra</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">19</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  = input_shape[i] * strides[i] for each axis i. The padding is</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">20</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  split between the two sides equally or almost equally (depending on</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">21</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  whether it is even or odd). In case the padding is an odd number,</code></td></tr>
<tr style="1px solid black;"><td><code>20</code></td><td><code>22</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  padding at the end for SAME_UPPER and at the<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">b</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">r</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">x</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;"> </span>padding <span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span>a<span style="color:#196F3D;">d</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span>t the end for SAME_UPPER and at the</code></td></tr>
<tr style="1px solid black;"><td><code>21</code></td><td><code>23</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  SAME_LOWER. <span style="color:#BA4A00;">V</span><span style="color:#BA4A00;">A</span><span style="color:#BA4A00;">L</span><span style="color:#BA4A00;">I</span>D<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">m</span>e<span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">.</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">D</span><span style="color:#BA4A00;">e</span>fault value is 'NOTSET'.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">b</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;"> </span>SAME_LOWER. Default value is 'NOTSET'.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **dilations**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **dilations**:</code></td></tr>
<tr style="1px solid black;"><td><code>23</code></td><td><code>25</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  dilation value along each spatial axis of the filter.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  dilation value along each spatial axis of the filter.<span style="color:#196F3D;"> </span><span style="color:#196F3D;">I</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">t</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">26</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  present, the dilation defaults to 1 along each spatial axis.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **group**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **group**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  number of groups input channels and output channels are divided</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  number of groups input channels and output channels are divided</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  into. Default value is 1.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  into. Default value is 1.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **kernel_shape**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **kernel_shape**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The shape of the convolution kernel. If not present, should be</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The shape of the convolution kernel. If not present, should be</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  inferred from input W.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  inferred from input W.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **output_padding**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **output_padding**:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">34</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  Additional elements added to the side with higher coordinate indices</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">35</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  in the output. Each padding value in "output_padding" must be less</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">36</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  than the corresponding stride/dilation dimension. By default, this</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">37</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  attribute is a zero vector. Note that this attribute doesn't</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">38</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  directly affect the computed output values. It only controls the</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">39</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  selection of the computed values, so changing this attribute only</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">40</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  adds or removes output elements. If "output_shape" is explicitly</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">41</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  provided, "output_padding" does not contribute additional size to</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">42</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  "output_shape" but participates in the computation of the needed</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">43</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  padding amount. This is also called adjs or adjustment in some</code></td></tr>
<tr style="1px solid black;"><td><code>31</code></td><td><code>44</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">T</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">z</span><span style="color:#BA4A00;">e</span>r<span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">-</span><span style="color:#BA4A00;">p</span>a<span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">d</span>e<span style="color:#BA4A00;">d</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span>o<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span>s<span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span>.<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">T</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">o</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">f</span>ra<span style="color:#196F3D;">m</span>e<span style="color:#196F3D;">w</span>o<span style="color:#196F3D;">r</span><span style="color:#196F3D;">k</span>s.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">32</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  called adjs/adjustment in some frameworks.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **output_shape**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **output_shape**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The shape of the output can be explicitly set which will cause pads</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The shape of the output can be explicitly set which will cause pads</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values to be auto generated. If output_shape is specified pads</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values to be auto generated. If output_shape is specified pads</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are ignored. See doc for details for equations to generate</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  values are ignored. See doc for details for equations to generate</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  pads</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  pads</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **pads**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **pads**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Padding for the beginning and ending along each spatial axis, it can</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Padding for the beginning and ending along each spatial axis, it can</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  take any value greater than or equal to 0. The value represent the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  take any value greater than or equal to 0. The value represent the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  number of pixels added to the beginning and end part of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  number of pixels added to the beginning and end part of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding axis. pads format should be as follow [x1_begin,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  corresponding axis. pads format should be as follow [x1_begin,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  added at the beginning of axis i and xi_end, the number of pixels</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  added at the beginning of axis i and xi_end, the number of pixels</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  added at the end of axis i. This attribute cannot be used</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  added at the end of axis i. This attribute cannot be used</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  simultaneously with auto_pad attribute. If not present, the padding</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  simultaneously with auto_pad attribute. If not present, the padding</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  defaults to 0 along start and end of each spatial axis.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  defaults to 0 along start and end of each spatial axis.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **strides**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **strides**:</code></td></tr>
<tr style="1px solid black;"><td><code>49</code></td><td><code>61</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  Stride along each spatial axis.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  Stride along each spatial axis.<span style="color:#196F3D;"> </span><span style="color:#196F3D;">I</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">,</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">62</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  to 1 along each spatial axis.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 2 and 3 inputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 2 and 3 inputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from previous layer; has size (N x C x H x W),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from previous layer; has size (N x C x H x W),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  where N is the batch size, C is the number of channels, and H and W</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  where N is the batch size, C is the number of channels, and H and W</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  are the height and width. Note that this is for the 2D image.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  are the height and width. Note that this is for the 2D image.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Otherwise the size is (N x C x D1 x D2 ... x Dn)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Otherwise the size is (N x C x D1 x D2 ... x Dn)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **W** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor that will be used in the convolutions; has size (C</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The weight tensor that will be used in the convolutions; has size (C</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  x M/group x kH x kW), where C is the number of channels, and kH and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  x M/group x kH x kW), where C is the number of channels, and kH and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  kW are the height and width of the kernel, and M is the number of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  kW are the height and width of the kernel, and M is the number of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  feature maps. For more than 2 dimensions, the weight shape will be</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  feature maps. For more than 2 dimensions, the weight shape will be</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the dimension of the kernel. The number of channels in the output</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the dimension of the kernel. The number of channels in the output</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  should be equal to W.shape[1] * group (assuming zero based indices</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  should be equal to W.shape[1] * group (assuming zero based indices</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of the shape array)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of the shape array)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional 1D bias to be added to the convolution, has size of M.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional 1D bias to be added to the convolution, has size of M.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Output data tensor that contains the result of the convolution. The</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Output data tensor that contains the result of the convolution. The</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output dimensions are functions of the kernel size, stride size, pad</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output dimensions are functions of the kernel size, stride size, pad</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  lengths and group count. The number of channels in the output should</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  lengths and group count. The number of channels in the output should</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be equal to W.shape[1] * group (assuming zero based indices of the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be equal to W.shape[1] * group (assuming zero based indices of the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape array)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  shape array)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
</table></section>
<section id="convtranspose-1">
<span id="l-onnx-op-convtranspose-1"></span><h2><a class="toc-backref" href="#id3">ConvTranspose - 1</a><a class="headerlink" href="#convtranspose-1" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose">ConvTranspose (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>1</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<p>The convolution transpose operator consumes an input tensor and a filter,
and computes the output.</p>
<p>If the pads parameter is provided the shape of the output is calculated via the following equation:</p>
<blockquote>
<div><p>output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]</p>
</div></blockquote>
<p>output_shape can also be explicitly specified in which case pads values are auto generated using these equations:</p>
<blockquote>
<div><p>total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]
If (auto_pads != SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).</p>
</div></blockquote>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>auto_pad</strong>:
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
Where default value is NOTSET, which means explicit padding is used.
SAME_UPPER or SAME_LOWER mean pad the input so that the output
spatial size match the input.In case of odd number add the extra
padding at the end for SAME_UPPER and at the beginning for
SAME_LOWER. VALID mean no padding. Default value is <code class="docutils literal notranslate"><span class="pre">'NOTSET'</span></code>.</p></li>
<li><p><strong>dilations</strong>:
dilation value along each spatial axis of the filter.</p></li>
<li><p><strong>group</strong>:
number of groups input channels and output channels are divided
into. Default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>kernel_shape</strong>:
The shape of the convolution kernel. If not present, should be
inferred from input W.</p></li>
<li><p><strong>output_padding</strong>:
The zero-padding added to one side of the output. This is also
called adjs/adjustment in some frameworks.</p></li>
<li><p><strong>output_shape</strong>:
The shape of the output can be explicitly set which will cause pads
values to be auto generated. If output_shape is specified pads
values are ignored. See doc for details for equations to generate
pads</p></li>
<li><p><strong>pads</strong>:
Padding for the beginning and ending along each spatial axis, it can
take any value greater than or equal to 0. The value represent the
number of pixels added to the beginning and end part of the
corresponding axis. <cite>pads</cite> format should be as follow [x1_begin,
x2_begin…x1_end, x2_end,…], where xi_begin the number of pixels
added at the beginning of axis <cite>i</cite> and xi_end, the number of pixels
added at the end of axis <cite>i</cite>. This attribute cannot be used
simultaneously with auto_pad attribute. If not present, the padding
defaults to 0 along start and end of each spatial axis.</p></li>
<li><p><strong>strides</strong>:
Stride along each spatial axis.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from previous layer; has size (N x C x H x W),
where N is the batch size, C is the number of channels, and H and W
are the height and width. Note that this is for the 2D image.
Otherwise the size is (N x C x D1 x D2 … x Dn)</p></li>
<li><p><strong>W</strong> (heterogeneous) - <strong>T</strong>:
The weight tensor that will be used in the convolutions; has size (C
x M/group x kH x kW), where C is the number of channels, and kH and
kW are the height and width of the kernel, and M is the number of
feature maps. For more than 2 dimensions, the weight shape will be
(C x M/group x k1 x k2 x … x kn), where (k1 x k2 x … x kn) is
the dimension of the kernel. The number of channels in the output
should be equal to W.shape[1] * group (assuming zero based indices
of the shape array)</p></li>
<li><p><strong>B</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional 1D bias to be added to the convolution, has size of M.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
Output data tensor that contains the result of the convolution. The
output dimensions are functions of the kernel size, stride size, pad
lengths and group count. The number of channels in the output should
be equal to W.shape[1] * group (assuming zero based indices of the
shape array)</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="onnx__ConvInteger.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">ConvInteger</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="onnx__Cos.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Cos</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>