
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>NegativeLogLikelihoodLoss &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="../_static/project_ico.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="NonMaxSuppression" href="onnx__NonMaxSuppression.html" />
    <link rel="prev" title="Neg" href="onnx__Neg.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_cmd.html">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_index.html">
  FAQ, code, …
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   ONNX operators
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Abs.html">
     Abs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acos.html">
     Acos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acosh.html">
     Acosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Add.html">
     Add
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__And.html">
     And
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMax.html">
     ArgMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMin.html">
     ArgMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asin.html">
     Asin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asinh.html">
     Asinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atan.html">
     Atan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atanh.html">
     Atanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__AveragePool.html">
     AveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BatchNormalization.html">
     BatchNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Bernoulli.html">
     Bernoulli
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BitShift.html">
     BitShift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cast.html">
     Cast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CastLike.html">
     CastLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Ceil.html">
     Ceil
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Celu.html">
     Celu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Clip.html">
     Clip
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Compress.html">
     Compress
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Concat.html">
     Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConcatFromSequence.html">
     ConcatFromSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Constant.html">
     Constant
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConstantOfShape.html">
     ConstantOfShape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Conv.html">
     Conv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvInteger.html">
     ConvInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvTranspose.html">
     ConvTranspose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cos.html">
     Cos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cosh.html">
     Cosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CumSum.html">
     CumSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DepthToSpace.html">
     DepthToSpace
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DequantizeLinear.html">
     DequantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Det.html">
     Det
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Div.html">
     Div
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Dropout.html">
     Dropout
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
     DynamicQuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Einsum.html">
     Einsum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Elu.html">
     Elu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Equal.html">
     Equal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Erf.html">
     Erf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Exp.html">
     Exp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Expand.html">
     Expand
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__EyeLike.html">
     EyeLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Flatten.html">
     Flatten
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Floor.html">
     Floor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GRU.html">
     GRU
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gather.html">
     Gather
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherElements.html">
     GatherElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherND.html">
     GatherND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gemm.html">
     Gemm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalAveragePool.html">
     GlobalAveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalLpPool.html">
     GlobalLpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalMaxPool.html">
     GlobalMaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Greater.html">
     Greater
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GreaterOrEqual.html">
     GreaterOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GridSample.html">
     GridSample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSigmoid.html">
     HardSigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSwish.html">
     HardSwish
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Hardmax.html">
     Hardmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Identity.html">
     Identity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__If.html">
     If
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__InstanceNormalization.html">
     InstanceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsInf.html">
     IsInf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsNaN.html">
     IsNaN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LRN.html">
     LRN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LSTM.html">
     LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LeakyRelu.html">
     LeakyRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Less.html">
     Less
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LessOrEqual.html">
     LessOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Log.html">
     Log
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LogSoftmax.html">
     LogSoftmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Loop.html">
     Loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpNormalization.html">
     LpNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpPool.html">
     LpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMul.html">
     MatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMulInteger.html">
     MatMulInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Max.html">
     Max
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxPool.html">
     MaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxRoiPool.html">
     MaxRoiPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxUnpool.html">
     MaxUnpool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mean.html">
     Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
     MeanVarianceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Min.html">
     Min
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mod.html">
     Mod
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mul.html">
     Mul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Multinomial.html">
     Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Neg.html">
     Neg
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     NegativeLogLikelihoodLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonMaxSuppression.html">
     NonMaxSuppression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonZero.html">
     NonZero
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Not.html">
     Not
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OneHot.html">
     OneHot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Optional.html">
     Optional
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalGetElement.html">
     OptionalGetElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalHasElement.html">
     OptionalHasElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Or.html">
     Or
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__PRelu.html">
     PRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pad.html">
     Pad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pow.html">
     Pow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearConv.html">
     QLinearConv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearMatMul.html">
     QLinearMatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QuantizeLinear.html">
     QuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RNN.html">
     RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormal.html">
     RandomNormal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormalLike.html">
     RandomNormalLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniform.html">
     RandomUniform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniformLike.html">
     RandomUniformLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Range.html">
     Range
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reciprocal.html">
     Reciprocal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL1.html">
     ReduceL1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL2.html">
     ReduceL2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSum.html">
     ReduceLogSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSumExp.html">
     ReduceLogSumExp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMax.html">
     ReduceMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMean.html">
     ReduceMean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMin.html">
     ReduceMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceProd.html">
     ReduceProd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSum.html">
     ReduceSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSumSquare.html">
     ReduceSumSquare
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Relu.html">
     Relu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reshape.html">
     Reshape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Resize.html">
     Resize
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReverseSequence.html">
     ReverseSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RoiAlign.html">
     RoiAlign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Round.html">
     Round
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scan.html">
     Scan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scatter.html">
     Scatter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterElements.html">
     ScatterElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterND.html">
     ScatterND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Selu.html">
     Selu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceAt.html">
     SequenceAt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceConstruct.html">
     SequenceConstruct
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceEmpty.html">
     SequenceEmpty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceErase.html">
     SequenceErase
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceInsert.html">
     SequenceInsert
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceLength.html">
     SequenceLength
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shape.html">
     Shape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shrink.html">
     Shrink
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sigmoid.html">
     Sigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sign.html">
     Sign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sin.html">
     Sin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sinh.html">
     Sinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Size.html">
     Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Slice.html">
     Slice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softmax.html">
     Softmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
     SoftmaxCrossEntropyLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softplus.html">
     Softplus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softsign.html">
     Softsign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SpaceToDepth.html">
     SpaceToDepth
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Split.html">
     Split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SplitToSequence.html">
     SplitToSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sqrt.html">
     Sqrt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Squeeze.html">
     Squeeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__StringNormalizer.html">
     StringNormalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sub.html">
     Sub
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sum.html">
     Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tan.html">
     Tan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tanh.html">
     Tanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TfIdfVectorizer.html">
     TfIdfVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ThresholdedRelu.html">
     ThresholdedRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tile.html">
     Tile
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TopK.html">
     TopK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Transpose.html">
     Transpose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Trilu.html">
     Trilu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unique.html">
     Unique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unsqueeze.html">
     Unsqueeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Upsample.html">
     Upsample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Where.html">
     Where
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Xor.html">
     Xor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
     ai.onnx.ml - ArrayFeatureExtractor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
     ai.onnx.ml - Binarizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CastMap.html">
     ai.onnx.ml - CastMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
     ai.onnx.ml - CategoryMapper
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
     ai.onnx.ml - DictVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
     ai.onnx.ml - FeatureVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Imputer.html">
     ai.onnx.ml - Imputer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
     ai.onnx.ml - LabelEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
     ai.onnx.ml - LinearClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
     ai.onnx.ml - LinearRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
     ai.onnx.ml - Normalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
     ai.onnx.ml - OneHotEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
     ai.onnx.ml - SVMClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
     ai.onnx.ml - SVMRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Scaler.html">
     ai.onnx.ml - Scaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
     ai.onnx.ml - TreeEnsembleClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
     ai.onnx.ml - TreeEnsembleRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
     ai.onnx.ml - ZipMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
     ai.onnx.preview.training - Adagrad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
     ai.onnx.preview.training - Adam
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
     ai.onnx.preview.training - Gradient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
     ai.onnx.preview.training - Momentum
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_runtime.html">
   Runtimes for ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../backends/index.html">
   ONNX Backends
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#negativeloglikelihoodloss-13">
   NegativeLogLikelihoodLoss - 13
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#negativeloglikelihoodloss-12">
   NegativeLogLikelihoodLoss - 12
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="negativeloglikelihoodloss">
<span id="l-onnx-doc-negativeloglikelihoodloss"></span><h1>NegativeLogLikelihoodLoss<a class="headerlink" href="#negativeloglikelihoodloss" title="Permalink to this headline">#</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#negativeloglikelihoodloss-13" id="id2">NegativeLogLikelihoodLoss - 13</a></p></li>
<li><p><a class="reference internal" href="#negativeloglikelihoodloss-12" id="id3">NegativeLogLikelihoodLoss - 12</a></p></li>
</ul>
</div>
<section id="negativeloglikelihoodloss-13">
<span id="l-onnx-op-negativeloglikelihoodloss-13"></span><h2><a class="toc-backref" href="#id2">NegativeLogLikelihoodLoss - 13</a><a class="headerlink" href="#negativeloglikelihoodloss-13" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#NegativeLogLikelihoodLoss">NegativeLogLikelihoodLoss (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>13</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 13</strong>.</p>
<p><strong>Summary</strong></p>
<p>A NegativeLogLikelihoodLoss operator computes (weighted) negative log likelihood loss.
Its “input” tensor has the shape of (N, C, d1, d2, …, dk) where k &gt;= 0.
The “input” tensor contains log-probabilities for input[n, :, d_1, d_2,…, d_k] being in a class of [0, C).
The operator’s “target” input tensor has the shape of (N, d1, d2, …, dk). It encodes class labels (one of C classes)
or it may contain a special value (indicated by an attribute ignore_index) for N x d1 x d2 x … x dk samples.
The loss value for input[n, :, d_1, d_2,…d_k] being classified as class c = target[n][d_1][d_2]…[d_k] is computed as:</p>
<blockquote>
<div><p>loss[n][d_1][d_2]…[d_k] = -input[n][c][d_1][d_2]…[d_k].</p>
</div></blockquote>
<p>When an optional “weight” is provided, the sample loss is calculated as:</p>
<blockquote>
<div><p>loss[n][d_1][d_2]…[d_k] = -input[n][c][d_1][d_2]…[d_k] * weight[c].</p>
</div></blockquote>
<p>loss is zero for the case when target-value equals ignore_index.</p>
<blockquote>
<div><p>loss[n][d_1][d_2]…[d_k] = 0, when target[n][d_1][d_2]…[d_k] = ignore_index</p>
</div></blockquote>
<p>If “reduction” attribute is set to “none”, the operator’s output will be the above loss with shape (N, d1, d2, …, dk).
If “reduction” attribute is set to “mean” (the default attribute value), the output loss is (weight) averaged:</p>
<blockquote>
<div><p>mean(loss), if “weight” is not provided,</p>
</div></blockquote>
<p>or if weight is provided,</p>
<blockquote>
<div><p>sum(loss) / sum(weight[target[n][d_1][d_2]…[d_k]]]), for all samples.</p>
</div></blockquote>
<dl class="simple">
<dt>If “reduction” attribute is set to “sum”, the output is a scalar:</dt><dd><p>sum(loss).</p>
</dd>
</dl>
<p>See also <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss">https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss</a>.</p>
<p>Example 1:</p>
<blockquote>
<div><p>// negative log likelihood loss, “none” reduction
N, C, d1 = 2, 3, 2
input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</p>
<blockquote>
<div><p>[[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</p>
</div></blockquote>
<p>target = [[2, 1], [0, 2]]</p>
<p>loss = np.zeros((N, d1))
for n in range(N):</p>
<blockquote>
<div><dl class="simple">
<dt>for d_1 in range(d1):</dt><dd><p>c = target[n][d_1]
loss[n][d_1] = -input[n][c][d_1]</p>
</dd>
</dl>
</div></blockquote>
<p>// print(loss)
// [[-3. -2.]
//  [-0. -2.]]</p>
</div></blockquote>
<p>Example 2:</p>
<blockquote>
<div><p>// weighted negative log likelihood loss, sum reduction
N, C, d1 = 2, 3, 2
input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</p>
<blockquote>
<div><p>[[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</p>
</div></blockquote>
<p>target = [[2, 1], [0, 2]]
weight = [0.2, 0.3, 0.1]
loss = np.zeros((N, d1))
for n in range(N):</p>
<blockquote>
<div><dl class="simple">
<dt>for d_1 in range(d1):</dt><dd><p>c = target[n][d_1]
loss[n][d_1] = -input[n][c][d_1] * weight[c]</p>
</dd>
</dl>
</div></blockquote>
<p>loss = np.sum(loss)
// print(loss)
// -1.1</p>
</div></blockquote>
<p>Example 3:</p>
<blockquote>
<div><p>// weighted negative log likelihood loss, mean reduction
N, C, d1 = 2, 3, 2
input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</p>
<blockquote>
<div><p>[[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</p>
</div></blockquote>
<p>target = [[2, 1], [0, 2]]
weight = [0.2, 0.3, 0.1]
loss = np.zeros((N, d1))
weight_total = 0
for n in range(N):</p>
<blockquote>
<div><dl class="simple">
<dt>for d_1 in range(d1):</dt><dd><p>c = target[n][d_1]
loss[n][d_1] = -input[n][c][d_1] * weight[c]
weight_total = weight_total + weight[c]</p>
</dd>
</dl>
</div></blockquote>
<p>loss = np.sum(loss) / weight_total
// print(loss)
// -1.57</p>
</div></blockquote>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>ignore_index</strong>:
Specifies a target value that is ignored and does not contribute to
the input gradient. It’s an optional value.</p></li>
<li><p><strong>reduction</strong>:
Type of reduction to apply to loss: none, sum, mean (default).
‘none’: the output is the loss for each sample. ‘sum’: the output
will be summed. ‘mean’: the sum of the output will be divided by the
sum of applied weights. Default value is <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
Input tensor of shape (N, C) or (N, C, d1, d2, …, dk).</p></li>
<li><p><strong>target</strong> (heterogeneous) - <strong>Tind</strong>:
Target tensor of shape (N) or (N, d1, d2, …, dk). Target element
value shall be in range of [0, C). If ignore_index is specified, it
may have a value outside [0, C) and the target values should either
be in the range [0, C) or have the value ignore_index.</p></li>
<li><p><strong>weight</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional rescaling weight tensor. If given, it has to be a tensor of
size C. Otherwise, it is treated as if having all ones.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>loss</strong> (heterogeneous) - <strong>T</strong>:
The negative log likelihood loss</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input, weight, and output types to floating-point tensors.</p></li>
<li><p><strong>Tind</strong> in (
tensor(int32),
tensor(int64)
):
Constrain target to integer types</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>input_shape_is_NC</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NC&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2_reduction_mean</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2_reduction_mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2_reduction_sum</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2_reduction_sum&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2_with_weight</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2_with_weight&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2_with_weight_reduction_mean</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2_with_weight_reduction_mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2_with_weight_reduction_sum</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2_with_weight_reduction_sum&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2_with_weight_reduction_sum_ii</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2_with_weight_reduction_sum_ii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2_no_weight_reduction_mean_ii</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2_no_weight_reduction_mean_ii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1_weight</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1_weight&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1_ii</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1_ii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1_weight_ii</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span>
<span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">d1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1_weight_ii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2d3d4d5_mean_weight</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">,</span> <span class="n">dim4</span><span class="p">,</span> <span class="n">dim5</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">,</span> <span class="n">dim4</span><span class="p">,</span> <span class="n">dim5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">,</span> <span class="n">dim4</span><span class="p">,</span> <span class="n">dim5</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
                                                                    <span class="n">target</span><span class="p">,</span>
                                                                    <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                                                                    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2d3d4d5_mean_weight&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2d3d4d5_none_no_weight</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">,</span> <span class="n">dim4</span><span class="p">,</span> <span class="n">dim5</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">,</span> <span class="n">dim4</span><span class="p">,</span> <span class="n">dim5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">,</span> <span class="n">dim4</span><span class="p">,</span> <span class="n">dim5</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
                                                                    <span class="n">target</span><span class="p">,</span>
                                                                    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2d3d4d5_none_no_weight&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1_mean_weight_negative_ii</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
                                                                    <span class="n">target</span><span class="p">,</span>
                                                                    <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                                                                    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
                                                                    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1_mean_weight_negative_ii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2d3_none_no_weight_negative_ii</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">dim3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
                                                                    <span class="n">target</span><span class="p">,</span>
                                                                    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
                                                                    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2d3_none_no_weight_negative_ii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>input_shape_is_NCd1d2d3_sum_weight_high_ii</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
    <span class="s1">&#39;NegativeLogLikelihoodLoss&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
<span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">negative_log_likelihood_loss</span> <span class="o">=</span> <span class="n">compute_negative_log_likelihood_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
                                                                    <span class="n">target</span><span class="p">,</span>
                                                                    <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                                                                    <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
                                                                    <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>

<span class="n">expect</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">negative_log_likelihood_loss</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_nllloss_NCd1d2d3_sum_weight_high_ii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">A NegativeLogLikelihoodLoss operator computes (weighted) negative log likelihood loss.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">A NegativeLogLikelihoodLoss operator computes (weighted) negative log likelihood loss.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Its "input" tensor has the shape of (N, C, d1, d2, ..., dk) where k >= 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Its "input" tensor has the shape of (N, C, d1, d2, ..., dk) where k >= 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The "input" tensor contains log-probabilities for input[n, :, d_1, d_2,..., d_k] being in a class of [0, C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The "input" tensor contains log-probabilities for input[n, :, d_1, d_2,..., d_k] being in a class of [0, C).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The operator's "target" input tensor has the shape of (N, d1, d2, ..., dk). It encodes class labels (one of C classes)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The operator's "target" input tensor has the shape of (N, d1, d2, ..., dk). It encodes class labels (one of C classes)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">or it may contain a special value (indicated by an attribute ignore_index) for N x d1 x d2 x ... x dk samples.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">or it may contain a special value (indicated by an attribute ignore_index) for N x d1 x d2 x ... x dk samples.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The loss value for input[n, :, d_1, d_2,...d_k] being classified as class c = target[n][d_1][d_2]...[d_k] is computed as:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The loss value for input[n, :, d_1, d_2,...d_k] being classified as class c = target[n][d_1][d_2]...[d_k] is computed as:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">6</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k].</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">8</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">When an optional "weight" is provided, the sample loss is calculated as:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">When an optional "weight" is provided, the sample loss is calculated as:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">10</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k] * weight[c].</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k] * weight[c].</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">12</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">loss is zero for the case when target-value equals ignore_index.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">loss is zero for the case when target-value equals ignore_index.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss[n][d_1][d_2]...[d_k] = 0, when target[n][d_1][d_2]...[d_k] = ignore_index</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss[n][d_1][d_2]...[d_k] = 0, when target[n][d_1][d_2]...[d_k] = ignore_index</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">16</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If "reduction" attribute is set to "none", the operator's output will be the above loss with shape (N, d1, d2, ..., dk).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If "reduction" attribute is set to "none", the operator's output will be the above loss with shape (N, d1, d2, ..., dk).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If "reduction" attribute is set to "mean" (the default attribute value), the output loss is (weight) averaged:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If "reduction" attribute is set to "mean" (the default attribute value), the output loss is (weight) averaged:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">19</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    mean(loss), if "weight" is not provided,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    mean(loss), if "weight" is not provided,</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">21</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">or if weight is provided,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">or if weight is provided,</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">23</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    sum(loss) / sum(weight[target[n][d_1][d_2]...[d_k]]]), for all samples.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    sum(loss) / sum(weight[target[n][d_1][d_2]...[d_k]]]), for all samples.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">25</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If "reduction" attribute is set to "sum", the output is a scalar:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">If "reduction" attribute is set to "sum", the output is a scalar:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    sum(loss).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    sum(loss).</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">28</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">See also https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">See also https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">30</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Example 1:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Example 1:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">32</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // negative log likelihood loss, "none" reduction</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // negative log likelihood loss, "none" reduction</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    N, C, d1 = 2, 3, 2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    N, C, d1 = 2, 3, 2</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">             [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">             [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    target = [[2, 1], [0, 2]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    target = [[2, 1], [0, 2]]</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">38</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.zeros((N, d1))</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.zeros((N, d1))</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    for n in range(N):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    for n in range(N):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">        for d_1 in range(d1):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">        for d_1 in range(d1):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            c = target[n][d_1]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            c = target[n][d_1]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            loss[n][d_1] = -input[n][c][d_1]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            loss[n][d_1] = -input[n][c][d_1]</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">44</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // print(loss)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // print(loss)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // [[-3. -2.]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // [[-3. -2.]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    //  [-0. -2.]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    //  [-0. -2.]]</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">48</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Example 2:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Example 2:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">50</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // weighted negative log likelihood loss, sum reduction</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // weighted negative log likelihood loss, sum reduction</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    N, C, d1 = 2, 3, 2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    N, C, d1 = 2, 3, 2</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    target = [[2, 1], [0, 2]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    target = [[2, 1], [0, 2]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    weight = [0.2, 0.3, 0.1]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    weight = [0.2, 0.3, 0.1]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.zeros((N, d1))</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.zeros((N, d1))</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    for n in range(N):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    for n in range(N):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">        for d_1 in range(d1):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">        for d_1 in range(d1):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            c = target[n][d_1]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            c = target[n][d_1]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            loss[n][d_1] = -input[n][c][d_1] * weight[c]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            loss[n][d_1] = -input[n][c][d_1] * weight[c]</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">62</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.sum(loss)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.sum(loss)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // print(loss)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // print(loss)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // -1.1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // -1.1</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">66</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Example 3:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Example 3:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">68</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // weighted negative log likelihood loss, mean reduction</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // weighted negative log likelihood loss, mean reduction</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    N, C, d1 = 2, 3, 2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    N, C, d1 = 2, 3, 2</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    target = [[2, 1], [0, 2]]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    target = [[2, 1], [0, 2]]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    weight = [0.2, 0.3, 0.1]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    weight = [0.2, 0.3, 0.1]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.zeros((N, d1))</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.zeros((N, d1))</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    weight_total = 0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    weight_total = 0</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    for n in range(N):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    for n in range(N):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">        for d_1 in range(d1):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">        for d_1 in range(d1):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            c = target[n][d_1]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            c = target[n][d_1]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            loss[n][d_1] = -input[n][c][d_1] * weight[c]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            loss[n][d_1] = -input[n][c][d_1] * weight[c]</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            weight_total = weight_total + weight[c]</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">            weight_total = weight_total + weight[c]</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">82</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.sum(loss) / weight_total</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    loss = np.sum(loss) / weight_total</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // print(loss)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // print(loss)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // -1.57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    // -1.57</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **ignore_index**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **ignore_index**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specifies a target value that is ignored and does not contribute to</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Specifies a target value that is ignored and does not contribute to</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the input gradient. It's an optional value.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the input gradient. It's an optional value.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **reduction**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **reduction**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Type of reduction to apply to loss: none, sum, mean (default).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Type of reduction to apply to loss: none, sum, mean (default).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  'none': the output is the loss for each sample. 'sum': the output</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  'none': the output is the loss for each sample. 'sum': the output</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  will be summed. 'mean': the sum of the output will be divided by the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  will be summed. 'mean': the sum of the output will be divided by the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  sum of applied weights. Default value is 'mean'.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  sum of applied weights. Default value is 'mean'.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">77</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 2 and 3 inputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 2 and 3 inputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">102</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **input** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **input** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">103</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input tensor of shape (N, C) or (N, C, d1, d2, ..., dk).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input tensor of shape (N, C) or (N, C, d1, d2, ..., dk).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">104</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **target** (heterogeneous) - **Tind**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **target** (heterogeneous) - **Tind**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Target tensor of shape (N) or (N, d1, d2, ..., dk). Target element</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Target tensor of shape (N) or (N, d1, d2, ..., dk). Target element</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">106</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  value shall be in range of [0, C). If ignore_index is specified, it</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  value shall be in range of [0, C). If ignore_index is specified, it</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">107</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  may have a value outside [0, C) and the target values should either</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  may have a value outside [0, C) and the target values should either</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">108</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be in the range [0, C) or have the value ignore_index.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  be in the range [0, C) or have the value ignore_index.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">109</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **weight** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **weight** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">110</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional rescaling weight tensor. If given, it has to be a tensor of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Optional rescaling weight tensor. If given, it has to be a tensor of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">111</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  size C. Otherwise, it is treated as if having all ones.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  size C. Otherwise, it is treated as if having all ones.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">112</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">113</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">114</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">115</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **loss** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **loss** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">116</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The negative log likelihood loss</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The negative log likelihood loss</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">97</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">117</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">98</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">118</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">99</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">119</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">100</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">120</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">121</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">102</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">122</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">103</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">123</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">104</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">124</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">125</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input, weight, and output types to floating-point tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input, weight, and output types to floating-point tensors.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">106</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">126</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Tind** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Tind** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">107</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">127</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int32),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">108</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">128</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int64)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(int64)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">109</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">129</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">110</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">130</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain target to integer types</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain target to integer types</code></td></tr>
</table></section>
<section id="negativeloglikelihoodloss-12">
<span id="l-onnx-op-negativeloglikelihoodloss-12"></span><h2><a class="toc-backref" href="#id3">NegativeLogLikelihoodLoss - 12</a><a class="headerlink" href="#negativeloglikelihoodloss-12" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#NegativeLogLikelihoodLoss">NegativeLogLikelihoodLoss (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>12</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 12</strong>.</p>
<p><strong>Summary</strong></p>
<p>A NegativeLogLikelihoodLoss operator computes (weighted) negative log likelihood loss.
Its “input” tensor has the shape of (N, C, d1, d2, …, dk) where k &gt;= 0.
The “input” tensor contains log-probabilities for input[n, :, d_1, d_2,…, d_k] being in a class of [0, C).
The operator’s “target” input tensor has the shape of (N, d1, d2, …, dk). It encodes class labels (one of C classes)
or it may contain a special value (indicated by an attribute ignore_index) for N x d1 x d2 x … x dk samples.
The loss value for input[n, :, d_1, d_2,…d_k] being classified as class c = target[n][d_1][d_2]…[d_k] is computed as:</p>
<blockquote>
<div><p>loss[n][d_1][d_2]…[d_k] = -input[n][c][d_1][d_2]…[d_k].</p>
</div></blockquote>
<dl class="simple">
<dt>When an optional “weight” is provided, the sample loss is calculated as:</dt><dd><p>loss[n][d_1][d_2]…[d_k] = -input[n][c][d_1][d_2]…[d_k] * weight[c].</p>
</dd>
</dl>
<p>loss is zero for the case when target-value equals ignore_index.</p>
<blockquote>
<div><p>loss[n][d_1][d_2]…[d_k] = 0, when target[n][d_1][d_2]…[d_k] = ignore_index</p>
</div></blockquote>
<p>If “reduction” attribute is set to “none”, the operator’s output will be the above loss with shape (N, d1, d2, …, dk).
If “reduction” attribute is set to “mean” (the default attribute value), the output loss is (weight) averaged:</p>
<blockquote>
<div><p>mean(loss), if “weight” is not provided,</p>
</div></blockquote>
<dl class="simple">
<dt>or if weight is provided,</dt><dd><p>sum(loss) / sum(weight[target[n][d_1][d_2]…[d_k]]]), for all samples.</p>
</dd>
<dt>If “reduction” attribute is set to “sum”, the output is a scalar:</dt><dd><p>sum(loss).</p>
</dd>
</dl>
<p>See also <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss">https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss</a>.
Example 1:</p>
<blockquote>
<div><p>// negative log likelihood loss, “none” reduction
N, C, d1 = 2, 3, 2
input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</p>
<blockquote>
<div><p>[[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</p>
</div></blockquote>
<p>target = [[2, 1], [0, 2]]
loss = np.zeros((N, d1))
for n in range(N):</p>
<blockquote>
<div><dl class="simple">
<dt>for d_1 in range(d1):</dt><dd><p>c = target[n][d_1]
loss[n][d_1] = -input[n][c][d_1]</p>
</dd>
</dl>
</div></blockquote>
<p>// print(loss)
// [[-3. -2.]
//  [-0. -2.]]</p>
</div></blockquote>
<dl>
<dt>Example 2:</dt><dd><p>// weighted negative log likelihood loss, sum reduction
N, C, d1 = 2, 3, 2
input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</p>
<blockquote>
<div><p>[[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</p>
</div></blockquote>
<p>target = [[2, 1], [0, 2]]
weight = [0.2, 0.3, 0.1]
loss = np.zeros((N, d1))
for n in range(N):</p>
<blockquote>
<div><dl class="simple">
<dt>for d_1 in range(d1):</dt><dd><p>c = target[n][d_1]
loss[n][d_1] = -input[n][c][d_1] * weight[c]</p>
</dd>
</dl>
</div></blockquote>
<p>loss = np.sum(loss)
// print(loss)
// -1.1</p>
</dd>
<dt>Example 3:</dt><dd><p>// weighted negative log likelihood loss, mean reduction
N, C, d1 = 2, 3, 2
input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],</p>
<blockquote>
<div><p>[[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]</p>
</div></blockquote>
<p>target = [[2, 1], [0, 2]]
weight = [0.2, 0.3, 0.1]
loss = np.zeros((N, d1))
weight_total = 0
for n in range(N):</p>
<blockquote>
<div><dl class="simple">
<dt>for d_1 in range(d1):</dt><dd><p>c = target[n][d_1]
loss[n][d_1] = -input[n][c][d_1] * weight[c]
weight_total = weight_total + weight[c]</p>
</dd>
</dl>
</div></blockquote>
<p>loss = np.sum(loss) / weight_total
// print(loss)
// -1.57</p>
</dd>
</dl>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>ignore_index</strong>:
Specifies a target value that is ignored and does not contribute to
the input gradient. It’s an optional value.</p></li>
<li><p><strong>reduction</strong>:
Type of reduction to apply to loss: none, sum, mean (default).
‘none’: the output is the loss for each sample. ‘sum’: the output
will be summed. ‘mean’: the sum of the output will be divided by the
sum of applied weights. Default value is <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<p>Between 2 and 3 inputs.</p>
<ul class="simple">
<li><p><strong>input</strong> (heterogeneous) - <strong>T</strong>:
Input tensor of shape (N, C) or (N, C, d1, d2, …, dk).</p></li>
<li><p><strong>target</strong> (heterogeneous) - <strong>Tind</strong>:
Target tensor of shape (N) or (N, d1, d2, …, dk). Target element
value shall be in range of [0, C). If ignore_index is specified, it
may have a value outside [0, C) and the target values should either
be in the range [0, C) or have the value ignore_index.</p></li>
<li><p><strong>weight</strong> (optional, heterogeneous) - <strong>T</strong>:
Optional rescaling weight tensor. If given, it has to be a tensor of
size C. Otherwise, it is treated as if having all ones.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p><strong>loss</strong> (heterogeneous) - <strong>T</strong>:
The negative log likelihood loss</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input, weight, and output types to floating-point tensors.</p></li>
<li><p><strong>Tind</strong> in (
tensor(int32),
tensor(int64)
):
Constrain target to integer types</p></li>
</ul>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="onnx__Neg.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Neg</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="onnx__NonMaxSuppression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">NonMaxSuppression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>