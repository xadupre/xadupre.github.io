
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>BatchNormalization &#8212; Python Runtime for ONNX</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="shortcut icon" href="../_static/project_ico.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bernoulli" href="onnx__Bernoulli.html" />
    <link rel="prev" title="AveragePool" href="onnx__AveragePool.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorial/index.html">
  Tutorial
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/index.html">
  API
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../onnx.html">
  ONNX, Runtime, Backends
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../onnx_bench.html">
  scikit-learn Converters and Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_cmd.html">
  Command lines
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_ex.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../i_index.html">
  FAQ, code, â€¦
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../gyexamples/index.html">
  Gallery of examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebook Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../HISTORY.html">
  History
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   ONNX operators
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Abs.html">
     Abs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acos.html">
     Acos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Acosh.html">
     Acosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Add.html">
     Add
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__And.html">
     And
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMax.html">
     ArgMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ArgMin.html">
     ArgMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asin.html">
     Asin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Asinh.html">
     Asinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atan.html">
     Atan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Atanh.html">
     Atanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__AveragePool.html">
     AveragePool
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     BatchNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Bernoulli.html">
     Bernoulli
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__BitShift.html">
     BitShift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cast.html">
     Cast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CastLike.html">
     CastLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Ceil.html">
     Ceil
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Celu.html">
     Celu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Clip.html">
     Clip
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Compress.html">
     Compress
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Concat.html">
     Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConcatFromSequence.html">
     ConcatFromSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Constant.html">
     Constant
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConstantOfShape.html">
     ConstantOfShape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Conv.html">
     Conv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvInteger.html">
     ConvInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ConvTranspose.html">
     ConvTranspose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cos.html">
     Cos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Cosh.html">
     Cosh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__CumSum.html">
     CumSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DepthToSpace.html">
     DepthToSpace
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DequantizeLinear.html">
     DequantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Det.html">
     Det
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Div.html">
     Div
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Dropout.html">
     Dropout
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__DynamicQuantizeLinear.html">
     DynamicQuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Einsum.html">
     Einsum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Elu.html">
     Elu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Equal.html">
     Equal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Erf.html">
     Erf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Exp.html">
     Exp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Expand.html">
     Expand
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__EyeLike.html">
     EyeLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Flatten.html">
     Flatten
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Floor.html">
     Floor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GRU.html">
     GRU
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gather.html">
     Gather
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherElements.html">
     GatherElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GatherND.html">
     GatherND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Gemm.html">
     Gemm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalAveragePool.html">
     GlobalAveragePool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalLpPool.html">
     GlobalLpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GlobalMaxPool.html">
     GlobalMaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Greater.html">
     Greater
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GreaterOrEqual.html">
     GreaterOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__GridSample.html">
     GridSample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSigmoid.html">
     HardSigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__HardSwish.html">
     HardSwish
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Hardmax.html">
     Hardmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Identity.html">
     Identity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__If.html">
     If
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__InstanceNormalization.html">
     InstanceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsInf.html">
     IsInf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__IsNaN.html">
     IsNaN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LRN.html">
     LRN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LSTM.html">
     LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LeakyRelu.html">
     LeakyRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Less.html">
     Less
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LessOrEqual.html">
     LessOrEqual
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Log.html">
     Log
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LogSoftmax.html">
     LogSoftmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Loop.html">
     Loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpNormalization.html">
     LpNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__LpPool.html">
     LpPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMul.html">
     MatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MatMulInteger.html">
     MatMulInteger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Max.html">
     Max
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxPool.html">
     MaxPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxRoiPool.html">
     MaxRoiPool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MaxUnpool.html">
     MaxUnpool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mean.html">
     Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__MeanVarianceNormalization.html">
     MeanVarianceNormalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Min.html">
     Min
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mod.html">
     Mod
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Mul.html">
     Mul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Multinomial.html">
     Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Neg.html">
     Neg
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NegativeLogLikelihoodLoss.html">
     NegativeLogLikelihoodLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonMaxSuppression.html">
     NonMaxSuppression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__NonZero.html">
     NonZero
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Not.html">
     Not
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OneHot.html">
     OneHot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Optional.html">
     Optional
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalGetElement.html">
     OptionalGetElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__OptionalHasElement.html">
     OptionalHasElement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Or.html">
     Or
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__PRelu.html">
     PRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pad.html">
     Pad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Pow.html">
     Pow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearConv.html">
     QLinearConv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QLinearMatMul.html">
     QLinearMatMul
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__QuantizeLinear.html">
     QuantizeLinear
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RNN.html">
     RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormal.html">
     RandomNormal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomNormalLike.html">
     RandomNormalLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniform.html">
     RandomUniform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RandomUniformLike.html">
     RandomUniformLike
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Range.html">
     Range
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reciprocal.html">
     Reciprocal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL1.html">
     ReduceL1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceL2.html">
     ReduceL2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSum.html">
     ReduceLogSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceLogSumExp.html">
     ReduceLogSumExp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMax.html">
     ReduceMax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMean.html">
     ReduceMean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceMin.html">
     ReduceMin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceProd.html">
     ReduceProd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSum.html">
     ReduceSum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReduceSumSquare.html">
     ReduceSumSquare
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Relu.html">
     Relu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Reshape.html">
     Reshape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Resize.html">
     Resize
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ReverseSequence.html">
     ReverseSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__RoiAlign.html">
     RoiAlign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Round.html">
     Round
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scan.html">
     Scan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Scatter.html">
     Scatter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterElements.html">
     ScatterElements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ScatterND.html">
     ScatterND
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Selu.html">
     Selu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceAt.html">
     SequenceAt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceConstruct.html">
     SequenceConstruct
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceEmpty.html">
     SequenceEmpty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceErase.html">
     SequenceErase
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceInsert.html">
     SequenceInsert
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SequenceLength.html">
     SequenceLength
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shape.html">
     Shape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Shrink.html">
     Shrink
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sigmoid.html">
     Sigmoid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sign.html">
     Sign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sin.html">
     Sin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sinh.html">
     Sinh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Size.html">
     Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Slice.html">
     Slice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softmax.html">
     Softmax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SoftmaxCrossEntropyLoss.html">
     SoftmaxCrossEntropyLoss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softplus.html">
     Softplus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Softsign.html">
     Softsign
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SpaceToDepth.html">
     SpaceToDepth
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Split.html">
     Split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__SplitToSequence.html">
     SplitToSequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sqrt.html">
     Sqrt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Squeeze.html">
     Squeeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__StringNormalizer.html">
     StringNormalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sub.html">
     Sub
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Sum.html">
     Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tan.html">
     Tan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tanh.html">
     Tanh
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TfIdfVectorizer.html">
     TfIdfVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__ThresholdedRelu.html">
     ThresholdedRelu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Tile.html">
     Tile
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__TopK.html">
     TopK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Transpose.html">
     Transpose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Trilu.html">
     Trilu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unique.html">
     Unique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Unsqueeze.html">
     Unsqueeze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Upsample.html">
     Upsample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Where.html">
     Where
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx__Xor.html">
     Xor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ArrayFeatureExtractor.html">
     ai.onnx.ml - ArrayFeatureExtractor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Binarizer.html">
     ai.onnx.ml - Binarizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CastMap.html">
     ai.onnx.ml - CastMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_CategoryMapper.html">
     ai.onnx.ml - CategoryMapper
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_DictVectorizer.html">
     ai.onnx.ml - DictVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_FeatureVectorizer.html">
     ai.onnx.ml - FeatureVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Imputer.html">
     ai.onnx.ml - Imputer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LabelEncoder.html">
     ai.onnx.ml - LabelEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearClassifier.html">
     ai.onnx.ml - LinearClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_LinearRegressor.html">
     ai.onnx.ml - LinearRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Normalizer.html">
     ai.onnx.ml - Normalizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_OneHotEncoder.html">
     ai.onnx.ml - OneHotEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMClassifier.html">
     ai.onnx.ml - SVMClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_SVMRegressor.html">
     ai.onnx.ml - SVMRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_Scaler.html">
     ai.onnx.ml - Scaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleClassifier.html">
     ai.onnx.ml - TreeEnsembleClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_TreeEnsembleRegressor.html">
     ai.onnx.ml - TreeEnsembleRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxml_ZipMap.html">
     ai.onnx.ml - ZipMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adagrad.html">
     ai.onnx.preview.training - Adagrad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Adam.html">
     ai.onnx.preview.training - Adam
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Gradient.html">
     ai.onnx.preview.training - Gradient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="onnx_aionnxpreviewtraining_Momentum.html">
     ai.onnx.preview.training - Momentum
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_runtime.html">
   Runtimes for ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../backends/index.html">
   ONNX Backends
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batchnormalization-15">
   BatchNormalization - 15
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batchnormalization-14">
   BatchNormalization - 14
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batchnormalization-9">
   BatchNormalization - 9
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batchnormalization-7">
   BatchNormalization - 7
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batchnormalization-6">
   BatchNormalization - 6
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batchnormalization-1">
   BatchNormalization - 1
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="batchnormalization">
<span id="l-onnx-doc-batchnormalization"></span><h1>BatchNormalization<a class="headerlink" href="#batchnormalization" title="Permalink to this headline">#</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#batchnormalization-15" id="id9">BatchNormalization - 15</a></p></li>
<li><p><a class="reference internal" href="#batchnormalization-14" id="id10">BatchNormalization - 14</a></p></li>
<li><p><a class="reference internal" href="#batchnormalization-9" id="id11">BatchNormalization - 9</a></p></li>
<li><p><a class="reference internal" href="#batchnormalization-7" id="id12">BatchNormalization - 7</a></p></li>
<li><p><a class="reference internal" href="#batchnormalization-6" id="id13">BatchNormalization - 6</a></p></li>
<li><p><a class="reference internal" href="#batchnormalization-1" id="id14">BatchNormalization - 1</a></p></li>
</ul>
</div>
<section id="batchnormalization-15">
<span id="l-onnx-op-batchnormalization-15"></span><h2><a class="toc-backref" href="#id9">BatchNormalization - 15</a><a class="headerlink" href="#batchnormalization-15" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization">BatchNormalization (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>15</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 15</strong>.</p>
<p><strong>Summary</strong></p>
<p>Carries out batch normalization as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>. Depending on the mode it is being run,
There are five required inputs â€˜Xâ€™, â€˜scaleâ€™, â€˜Bâ€™, â€˜input_meanâ€™ and
â€˜input_varâ€™.
Note that â€˜input_meanâ€™ and â€˜input_varâ€™ are expected to be the estimated
statistics in inference mode (training_mode=False, default),
and the running statistics in training mode (training_mode=True).
There are multiple cases for the number of outputs, which we list below:</p>
<p>Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (training_mode=False)</p>
<p>When training_mode=False, extra outputs are invalid.
The outputs are updated as follows when training_mode=True:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">running_mean</span> <span class="o">=</span> <span class="n">input_mean</span> <span class="o">*</span> <span class="n">momentum</span> <span class="o">+</span> <span class="n">current_mean</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span>
<span class="n">running_var</span> <span class="o">=</span> <span class="n">input_var</span> <span class="o">*</span> <span class="n">momentum</span> <span class="o">+</span> <span class="n">current_var</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span>

<span class="n">Y</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">current_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">current_var</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">B</span>

<span class="n">where</span><span class="p">:</span>

<span class="n">current_mean</span> <span class="o">=</span> <span class="n">ReduceMean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">all_except_channel_index</span><span class="p">)</span>
<span class="n">current_var</span> <span class="o">=</span>  <span class="n">ReduceVar</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">all_except_channel_index</span><span class="p">)</span>

<span class="n">Notice</span> <span class="n">that</span> <span class="n">ReduceVar</span> <span class="n">refers</span> <span class="n">to</span> <span class="n">the</span> <span class="n">population</span> <span class="n">variance</span><span class="p">,</span> <span class="ow">and</span> <span class="n">it</span> <span class="n">equals</span> <span class="n">to</span>
<span class="nb">sum</span><span class="p">(</span><span class="n">sqrd</span><span class="p">(</span><span class="n">x_i</span> <span class="o">-</span> <span class="n">x_avg</span><span class="p">))</span> <span class="o">/</span> <span class="n">N</span>
<span class="n">where</span> <span class="n">N</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">population</span> <span class="n">size</span> <span class="p">(</span><span class="n">this</span> <span class="n">formula</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">use</span> <span class="n">sample</span> <span class="n">size</span> <span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<p>The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.</p>
<p>When training_mode=False:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">input_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">input_var</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">B</span>
</pre></div>
</div>
<p>For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C * D1 * D2 * â€¦ * Dn) before a BatchNormalization Op.
This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argumentâ€™s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>epsilon</strong>:
The epsilon value to use to avoid division by zero. Default value is <code class="docutils literal notranslate"><span class="pre">9.999999747378752e-06</span></code>.</p></li>
<li><p><strong>momentum</strong>:
Factor used in computing the running mean and variance.e.g.,
running_mean = running_mean * momentum + mean * (1 - momentum). Default value is <code class="docutils literal notranslate"><span class="pre">0.8999999761581421</span></code>.</p></li>
<li><p><strong>training_mode</strong>:
If set to true, it indicates BatchNormalization is being used for
training, and outputs 1, 2, 3, and 4 would be populated. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from the previous operator; dimensions are in the
form of (N x C x D1 x D2 â€¦ Dn), where N is the batch size, C is
the number of channels. Statistics are computed for every channel of
C over N and D1 to Dn dimensions. For image data, input dimensions
become (N x C x H x W). The op also accepts single dimension input
of size N in which case C is assumed to be 1</p></li>
<li><p><strong>scale</strong> (heterogeneous) - <strong>T1</strong>:
Scale tensor of shape (C).</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T1</strong>:
Bias tensor of shape (C).</p></li>
<li><p><strong>input_mean</strong> (heterogeneous) - <strong>T2</strong>:
running (training) or estimated (testing) mean tensor of shape (C).</p></li>
<li><p><strong>input_var</strong> (heterogeneous) - <strong>T2</strong>:
running (training) or estimated (testing) variance tensor of shape
(C).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 3 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
The output tensor of the same shape as X</p></li>
<li><p><strong>running_mean</strong> (optional, heterogeneous) - <strong>T2</strong>:
The running mean after the BatchNormalization operator.</p></li>
<li><p><strong>running_var</strong> (optional, heterogeneous) - <strong>T2</strong>:
The running variance after the BatchNormalization operator. This op
uses the population size (N) for calculating variance, and not the
sample size N-1.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>T1</strong> in (
tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain scale and bias types to float tensors.</p></li>
<li><p><strong>T2</strong> in (
tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain mean and variance types to float tensors.</p></li>
</ul>
<p><strong>Examples</strong></p>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">There are five required inputs 'X', 'scale', 'B', 'input_mean' and</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">There are five required inputs 'X', 'scale', 'B', 'input_mean' and</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">'input_var'.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">'input_var'.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Note that 'input_mean' and 'input_var' are expected to be the estimated</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Note that 'input_mean' and 'input_var' are expected to be the estimated</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">statistics in inference mode (training_mode=False, default),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">statistics in inference mode (training_mode=False, default),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">and the running statistics in training mode (training_mode=True).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">and the running statistics in training mode (training_mode=True).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">There are multiple cases for the number of outputs, which we list below:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">There are multiple cases for the number of outputs, which we list below:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, running_mean, running_var (training_mode=True)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, running_mean, running_var (training_mode=True)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (training_mode=False)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (training_mode=False)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">When training_mode=False, extra outputs are invalid.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">When training_mode=False, extra outputs are invalid.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The outputs are updated as follows when training_mode=True:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">The outputs are updated as follows when training_mode=True:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">::</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">::</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    running_mean = input_mean * momentum + current_mean * (1 - momentum)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    running_mean = input_mean * momentum + current_mean * (1 - momentum)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    running_var = input_var * momentum + current_var * (1 - momentum)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    running_var = input_var * momentum + current_var * (1 - momentum)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    where:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    where:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    current_mean = ReduceMean(X, axis=all_except_channel_index)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    current_mean = ReduceMean(X, axis=all_except_channel_index)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    current_var =  ReduceVar(X, axis=all_except_channel_index)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    current_var =  ReduceVar(X, axis=all_except_channel_index)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    Notice that ReduceVar refers to the population variance, and it equals to</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    Notice that ReduceVar refers to the population variance, and it equals to</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    sum(sqrd(x_i - x_avg)) / N</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    sum(sqrd(x_i - x_avg)) / N</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    where N is the population size (this formula does not use sample size N - 1).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    where N is the population size (this formula does not use sample size N - 1).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">30</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">31</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">When training_mode=False:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">When training_mode=False:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">::</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">::</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">    Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">For previous (depreciated) non-spatial cases, implementors are suggested</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">For previous (depreciated) non-spatial cases, implementors are suggested</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero. Default value is 9.999999747378752e-06.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero. Default value is 9.999999747378752e-06.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum). Default value is 0.8999999761581421.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum). Default value is 0.8999999761581421.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **training_mode**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **training_mode**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If set to true, it indicates BatchNormalization is being used for</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If set to true, it indicates BatchNormalization is being used for</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  training, and outputs 1, 2, 3, and 4 would be populated. Default value is 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  training, and outputs 1, 2, 3, and 4 would be populated. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from the previous operator; dimensions are in the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from the previous operator; dimensions are in the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the number of channels. Statistics are computed for every channel of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the number of channels. Statistics are computed for every channel of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  C over N and D1 to Dn dimensions. For image data, input dimensions</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  C over N and D1 to Dn dimensions. For image data, input dimensions</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  become (N x C x H x W). The op also accepts single dimension input</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  become (N x C x H x W). The op also accepts single dimension input</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of size N in which case C is assumed to be 1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of size N in which case C is assumed to be 1</code></td></tr>
<tr style="1px solid black;"><td><code>59</code></td><td><code>61</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **scale** (heterogeneous) - **T**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **scale** (heterogeneous) - **T<span style="color:#196F3D;">1</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Scale tensor of shape (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Scale tensor of shape (C).</code></td></tr>
<tr style="1px solid black;"><td><code>61</code></td><td><code>63</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **B** (heterogeneous) - **T**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **B** (heterogeneous) - **T<span style="color:#196F3D;">1</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Bias tensor of shape (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Bias tensor of shape (C).</code></td></tr>
<tr style="1px solid black;"><td><code>63</code></td><td><code>65</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **input_mean** (heterogeneous) - **<span style="color:#BA4A00;">U</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **input_mean** (heterogeneous) - **<span style="color:#196F3D;">T</span><span style="color:#196F3D;">2</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) mean tensor of shape (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) mean tensor of shape (C).</code></td></tr>
<tr style="1px solid black;"><td><code>65</code></td><td><code>67</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **input_var** (heterogeneous) - **<span style="color:#BA4A00;">U</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **input_var** (heterogeneous) - **<span style="color:#196F3D;">T</span><span style="color:#196F3D;">2</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) variance tensor of shape</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) variance tensor of shape</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (C).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 3 outputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 3 outputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">75</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The output tensor of the same shape as X</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The output tensor of the same shape as X</code></td></tr>
<tr style="1px solid black;"><td><code>75</code></td><td><code>77</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **running_mean** (optional, heterogeneous) - **<span style="color:#BA4A00;">U</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **running_mean** (optional, heterogeneous) - **<span style="color:#196F3D;">T</span><span style="color:#196F3D;">2</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator.</code></td></tr>
<tr style="1px solid black;"><td><code>77</code></td><td><code>79</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **running_var** (optional, heterogeneous) - **<span style="color:#BA4A00;">U</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **running_var** (optional, heterogeneous) - **<span style="color:#196F3D;">T</span><span style="color:#196F3D;">2</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">78</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance after the BatchNormalization operator. This op</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance after the BatchNormalization operator. This op</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">79</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  uses the population size (N) for calculating variance, and not the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  uses the population size (N) for calculating variance, and not the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">80</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  sample size N-1.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  sample size N-1.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">81</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">82</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">83</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">84</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">85</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(bfloat16),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(bfloat16),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">86</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">87</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">88</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">89</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">91</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">90</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">93</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">* **T1** in (</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">94</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  tensor(bfloat16),</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">95</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">96</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">97</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">98</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  ):</code></td></tr>
<tr style="1px solid black;"><td><code>91</code></td><td><code>99</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;">*</span> <span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">U</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span> in <span style="color:#BA4A00;">(</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">C</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">a</span>in <span style="color:#196F3D;">s</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">100</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">* **T2** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">92</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">101</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(bfloat16),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(bfloat16),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">102</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">103</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">104</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">105</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td><code>97</code></td><td><code>106</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  Constrain mean and variance types to float tensors.<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">w</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">l</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  Constrain mean and variance types to float tensors.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">98</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  float type for U.</code></td><td></td></tr>
</table></section>
<section id="batchnormalization-14">
<span id="l-onnx-op-batchnormalization-14"></span><h2><a class="toc-backref" href="#id10">BatchNormalization - 14</a><a class="headerlink" href="#batchnormalization-14" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization">BatchNormalization (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>14</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 14</strong>.</p>
<p><strong>Summary</strong></p>
<p>Carries out batch normalization as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>. Depending on the mode it is being run,
There are five required inputs â€˜Xâ€™, â€˜scaleâ€™, â€˜Bâ€™, â€˜input_meanâ€™ and
â€˜input_varâ€™.
Note that â€˜input_meanâ€™ and â€˜input_varâ€™ are expected to be the estimated
statistics in inference mode (training_mode=False, default),
and the running statistics in training mode (training_mode=True).
There are multiple cases for the number of outputs, which we list below:</p>
<p>Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (training_mode=False)</p>
<p>When training_mode=False, extra outputs are invalid.
The outputs are updated as follows when training_mode=True:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">running_mean</span> <span class="o">=</span> <span class="n">input_mean</span> <span class="o">*</span> <span class="n">momentum</span> <span class="o">+</span> <span class="n">current_mean</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span>
<span class="n">running_var</span> <span class="o">=</span> <span class="n">input_var</span> <span class="o">*</span> <span class="n">momentum</span> <span class="o">+</span> <span class="n">current_var</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span>

<span class="n">Y</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">current_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">current_var</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">B</span>

<span class="n">where</span><span class="p">:</span>

<span class="n">current_mean</span> <span class="o">=</span> <span class="n">ReduceMean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">all_except_channel_index</span><span class="p">)</span>
<span class="n">current_var</span> <span class="o">=</span>  <span class="n">ReduceVar</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">all_except_channel_index</span><span class="p">)</span>

<span class="n">Notice</span> <span class="n">that</span> <span class="n">ReduceVar</span> <span class="n">refers</span> <span class="n">to</span> <span class="n">the</span> <span class="n">population</span> <span class="n">variance</span><span class="p">,</span> <span class="ow">and</span> <span class="n">it</span> <span class="n">equals</span> <span class="n">to</span>
<span class="nb">sum</span><span class="p">(</span><span class="n">sqrd</span><span class="p">(</span><span class="n">x_i</span> <span class="o">-</span> <span class="n">x_avg</span><span class="p">))</span> <span class="o">/</span> <span class="n">N</span>
<span class="n">where</span> <span class="n">N</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">population</span> <span class="n">size</span> <span class="p">(</span><span class="n">this</span> <span class="n">formula</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">use</span> <span class="n">sample</span> <span class="n">size</span> <span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<p>When training_mode=False:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">input_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">input_var</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">B</span>
</pre></div>
</div>
<p>For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C * D1 * D2 * â€¦ * Dn) before a BatchNormalization Op.
This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argumentâ€™s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>epsilon</strong>:
The epsilon value to use to avoid division by zero. Default value is <code class="docutils literal notranslate"><span class="pre">9.999999747378752e-06</span></code>.</p></li>
<li><p><strong>momentum</strong>:
Factor used in computing the running mean and variance.e.g.,
running_mean = running_mean * momentum + mean * (1 - momentum). Default value is <code class="docutils literal notranslate"><span class="pre">0.8999999761581421</span></code>.</p></li>
<li><p><strong>training_mode</strong>:
If set to true, it indicates BatchNormalization is being used for
training, and outputs 1, 2, 3, and 4 would be populated. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from the previous operator; dimensions are in the
form of (N x C x D1 x D2 â€¦ Dn), where N is the batch size, C is
the number of channels. Statistics are computed for every channel of
C over N and D1 to Dn dimensions. For image data, input dimensions
become (N x C x H x W). The op also accepts single dimension input
of size N in which case C is assumed to be 1</p></li>
<li><p><strong>scale</strong> (heterogeneous) - <strong>T</strong>:
Scale tensor of shape (C).</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Bias tensor of shape (C).</p></li>
<li><p><strong>input_mean</strong> (heterogeneous) - <strong>U</strong>:
running (training) or estimated (testing) mean tensor of shape (C).</p></li>
<li><p><strong>input_var</strong> (heterogeneous) - <strong>U</strong>:
running (training) or estimated (testing) variance tensor of shape
(C).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 3 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
The output tensor of the same shape as X</p></li>
<li><p><strong>running_mean</strong> (optional, heterogeneous) - <strong>U</strong>:
The running mean after the BatchNormalization operator.</p></li>
<li><p><strong>running_var</strong> (optional, heterogeneous) - <strong>U</strong>:
The running variance after the BatchNormalization operator. This op
uses the population size (N) for calculating variance, and not the
sample size N-1.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
<li><p><strong>U</strong> in (
tensor(bfloat16),
tensor(double),
tensor(float),
tensor(float16)
):
Constrain mean and variance types to float tensors. It allows all
float type for U.</p></li>
</ul>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">2</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">There are five required inputs 'X', 'scale', 'B', 'input_mean' and</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">3</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">'input_var'.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">4</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">Note that 'input_mean' and 'input_var' are expected to be the estimated</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">5</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">statistics in inference mode (training_mode=False, default),</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">6</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">and the running statistics in training mode (training_mode=True).</code></td></tr>
<tr style="1px solid black;"><td><code>2</code></td><td><code>7</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;">t</span>here are multiple cases for the number of outputs, which we list below:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code><span style="color:#196F3D;">T</span>here are multiple cases for the number of outputs, which we list below:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">9</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">Output case #1: Y, running_mean, running_var (training_mode=True)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">10</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">Output case #2: Y (training_mode=False)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">11</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">12</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">When training_mode=False, extra outputs are invalid.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">13</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">The outputs are updated as follows when training_mode=True:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">14</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">::</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">15</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">16</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    running_mean = input_mean * momentum + current_mean * (1 - momentum)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">17</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    running_var = input_var * momentum + current_var * (1 - momentum)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">18</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">19</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">20</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">21</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    where:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">22</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">23</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    current_mean = ReduceMean(X, axis=all_except_channel_index)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">24</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    current_var =  ReduceVar(X, axis=all_except_channel_index)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">25</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">26</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    Notice that ReduceVar refers to the population variance, and it equals to</code></td></tr>
<tr style="1px solid black;"><td><code>4</code></td><td><code>27</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;">O</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span> <span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">e</span> <span style="color:#BA4A00;">#</span><span style="color:#BA4A00;">1</span><span style="color:#BA4A00;">:</span> <span style="color:#BA4A00;">Y</span><span style="color:#BA4A00;">,</span> m<span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">,</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">a</span>r<span style="color:#BA4A00;">,</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">e</span>d_<span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">,</span> <span style="color:#BA4A00;">s</span>av<span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">_</span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">(</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span>g <span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">)</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>    <span style="color:#196F3D;">s</span><span style="color:#196F3D;">u</span>m<span style="color:#196F3D;">(</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">q</span>rd<span style="color:#196F3D;">(</span><span style="color:#196F3D;">x</span>_<span style="color:#196F3D;">i</span> <span style="color:#196F3D;">-</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">x</span><span style="color:#196F3D;">_</span>avg<span style="color:#196F3D;">)</span><span style="color:#196F3D;">)</span> <span style="color:#196F3D;">/</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">N</span></code></td></tr>
<tr style="1px solid black;"><td><code>5</code></td><td><code>28</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;">O</span><span style="color:#BA4A00;">u</span>tput <span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">a</span>se <span style="color:#BA4A00;">#</span><span style="color:#BA4A00;">2</span><span style="color:#BA4A00;">:</span> <span style="color:#BA4A00;">Y</span> <span style="color:#BA4A00;">(</span><span style="color:#BA4A00;">t</span>est m<span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">d</span>e)</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code><span style="color:#196F3D;"> </span><span style="color:#196F3D;"> </span><span style="color:#196F3D;"> </span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">w</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">N</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span>t<span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span>p<span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span>u<span style="color:#196F3D;">l</span><span style="color:#196F3D;">a</span>t<span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span> s<span style="color:#196F3D;">i</span><span style="color:#196F3D;">z</span>e <span style="color:#196F3D;">(</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span> <span style="color:#196F3D;">f</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">a</span> <span style="color:#196F3D;">d</span><span style="color:#196F3D;">o</span>es<span style="color:#196F3D;"> </span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">o</span>t <span style="color:#196F3D;">u</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">a</span>m<span style="color:#196F3D;">p</span><span style="color:#196F3D;">l</span>e<span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">z</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">N</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">-</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">1</span>)<span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">30</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">When training_mode=False:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">31</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">::</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">32</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">33</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">    Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">34</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">For previous (depreciated) non-spatial cases, implementors are suggested</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">For previous (depreciated) non-spatial cases, implementors are suggested</code></td></tr>
<tr style="1px solid black;"><td><code>8</code></td><td><code>36</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>to flatten the input shape to (N x C<span style="color:#196F3D;"> </span>*<span style="color:#196F3D;"> </span>D1<span style="color:#196F3D;"> </span>*<span style="color:#196F3D;"> </span>D2 <span style="color:#196F3D;">*</span><span style="color:#196F3D;"> </span>..<span style="color:#196F3D;">.</span><span style="color:#196F3D;"> </span>*<span style="color:#196F3D;"> </span>Dn) before a BatchNormalization Op.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero. Default value is 9.999999747378752e-06.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero. Default value is 9.999999747378752e-06.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum). Default value is 0.8999999761581421.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum). Default value is 0.8999999761581421.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">46</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">* **training_mode**:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">47</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  If set to true, it indicates BatchNormalization is being used for</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">48</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  training, and outputs 1, 2, 3, and 4 would be populated. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from the previous operator; dimensions are in the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from the previous operator; dimensions are in the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the number of channels. Statistics are computed for every channel of</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  the number of channels. Statistics are computed for every channel of</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  C over N and D1 to Dn dimensions. For image data, input dimensions</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  C over N and D1 to Dn dimensions. For image data, input dimensions</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  become (N x C x H x W). The op also accepts single dimension input</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  become (N x C x H x W). The op also accepts single dimension input</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of size N in which case C is assumed to be 1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of size N in which case C is assumed to be 1</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Scale tensor of shape (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Scale tensor of shape (C).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Bias tensor of shape (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Bias tensor of shape (C).</code></td></tr>
<tr style="1px solid black;"><td><code>32</code></td><td><code>63</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **mean** (heterogeneous) - **<span style="color:#BA4A00;">T</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **<span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">_</span>mean** (heterogeneous) - **<span style="color:#196F3D;">U</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) mean tensor of shape (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) mean tensor of shape (C).</code></td></tr>
<tr style="1px solid black;"><td><code>34</code></td><td><code>65</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **var** (heterogeneous) - **<span style="color:#BA4A00;">T</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **<span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">_</span>var** (heterogeneous) - **<span style="color:#196F3D;">U</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) variance tensor of shape</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running (training) or estimated (testing) variance tensor of shape</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (C).</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  (C).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td><code>40</code></td><td><code>71</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">Between 1 and <span style="color:#BA4A00;">5</span> outputs.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>Between 1 and <span style="color:#196F3D;">3</span> outputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">72</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">73</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">74</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The output tensor of the same shape as X</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The output tensor of the same shape as X</code></td></tr>
<tr style="1px solid black;"><td><code>44</code></td><td><code>75</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **mean** (optional, heterogeneous) - **<span style="color:#BA4A00;">T</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **<span style="color:#196F3D;">r</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">_</span>mean** (optional, heterogeneous) - **<span style="color:#196F3D;">U</span>**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">76</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator.</code></td></tr>
<tr style="1px solid black;"><td><code>46</code></td><td><code>77</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **var** (optional, heterogeneous) - **<span style="color:#BA4A00;">T</span>**:</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **<span style="color:#196F3D;">r</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">_</span>var** (optional, heterogeneous) - **<span style="color:#196F3D;">U</span>**:</code></td></tr>
<tr style="1px solid black;"><td><code>47</code></td><td><code>78</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  The running variance after the BatchNormalization operator.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  The running variance after the BatchNormalization operator.<span style="color:#196F3D;"> </span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">79</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  uses the population size (N) for calculating variance, and not the</code></td></tr>
<tr style="1px solid black;"><td><code>48</code></td><td><code>80</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;">*</span> <span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span>sa<span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">_</span>me<span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span> <span style="color:#BA4A00;">(</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">t</span>i<span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">,</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">h</span>e<span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">)</span> -<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">T</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">:</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code> <span style="color:#196F3D;"> </span>sam<span style="color:#196F3D;">p</span><span style="color:#196F3D;">l</span>e <span style="color:#196F3D;">s</span>i<span style="color:#196F3D;">z</span>e <span style="color:#196F3D;">N</span>-<span style="color:#196F3D;">1</span><span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">81</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td><code>49</code></td><td><code>82</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">S</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">v</span>e<span style="color:#BA4A00;">d</span> <span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">a</span>n<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">u</span>s<span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;"> </span>train<span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;"> </span>t<span style="color:#BA4A00;">o</span><span style="color:#BA4A00;"> </span>s<span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">.</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code><span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;">p</span>e <span style="color:#196F3D;">C</span><span style="color:#196F3D;">o</span>nstraints<span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">83</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">84</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td><code>50</code></td><td><code>85</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;">*</span> <span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span>s<span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">_</span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">a</span>r<span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;"> </span>(o<span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span>a<span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">,</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span>t<span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">s</span>)<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">-</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">T</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">:</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code> <span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span>s<span style="color:#196F3D;">o</span>r(<span style="color:#196F3D;">b</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">l</span>oat<span style="color:#196F3D;">1</span><span style="color:#196F3D;">6</span>)<span style="color:#196F3D;">,</span></code></td></tr>
<tr style="1px solid black;"><td><code>51</code></td><td><code>86</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">S</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">v</span>e<span style="color:#BA4A00;">d</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">a</span>n<span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">u</span>s<span style="color:#BA4A00;">e</span>d<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span>o<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;"> </span>u<span style="color:#BA4A00;">p</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span>e<span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">t</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">t</span>ens<span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">(</span>dou<span style="color:#196F3D;">b</span><span style="color:#196F3D;">l</span>e<span style="color:#196F3D;">)</span><span style="color:#196F3D;">,</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">52</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  computation.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">53</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;"></code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">87</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">88</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">89</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  ):</code></td></tr>
<tr style="1px solid black;"><td><code>54</code></td><td><code>90</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">T</span><span style="color:#BA4A00;">y</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">e</span> Constraints<span style="color:#BA4A00;">*</span><span style="color:#BA4A00;">*</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code> <span style="color:#196F3D;"> </span>Constrain<span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span>t<span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">e</span>s<span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">55</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;"></code></td><td></td></tr>
<tr style="1px solid black;"><td><code>56</code></td><td><code>91</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">* **<span style="color:#BA4A00;">T</span>** in (</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>* **<span style="color:#196F3D;">U</span>** in (</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">92</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  tensor(bfloat16),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">93</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">94</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">95</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">96</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td><code>61</code></td><td><code>97</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  Constrain <span style="color:#BA4A00;">i</span>n<span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span> and <span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">t</span> types to float tensors.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  Constrain <span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">a</span>n and <span style="color:#196F3D;">v</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">e</span> types to float tensors.<span style="color:#196F3D;"> </span><span style="color:#196F3D;">I</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">w</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">l</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">98</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  float type for U.</code></td></tr>
</table></section>
<section id="batchnormalization-9">
<span id="l-onnx-op-batchnormalization-9"></span><h2><a class="toc-backref" href="#id11">BatchNormalization - 9</a><a class="headerlink" href="#batchnormalization-9" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization">BatchNormalization (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>9</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 9</strong>.</p>
<p><strong>Summary</strong></p>
<p>Carries out batch normalization as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>. Depending on the mode it is being run,
there are multiple cases for the number of outputs, which we list below:</p>
<p>Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)</p>
<p>For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argumentâ€™s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>epsilon</strong>:
The epsilon value to use to avoid division by zero. Default value is <code class="docutils literal notranslate"><span class="pre">9.999999747378752e-06</span></code>.</p></li>
<li><p><strong>momentum</strong>:
Factor used in computing the running mean and variance.e.g.,
running_mean = running_mean * momentum + mean * (1 - momentum). Default value is <code class="docutils literal notranslate"><span class="pre">0.8999999761581421</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from the previous operator; dimensions are in the
form of (N x C x D1 x D2 â€¦ Dn), where N is the batch size, C is
the number of channels. Statistics are computed for every channel of
C over N and D1 to Dn dimensions. For image data, input dimensions
become (N x C x H x W). The op also accepts single dimension input
of size N in which case C is assumed to be 1</p></li>
<li><p><strong>scale</strong> (heterogeneous) - <strong>T</strong>:
Scale tensor of shape (C).</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
Bias tensor of shape (C).</p></li>
<li><p><strong>mean</strong> (heterogeneous) - <strong>T</strong>:
running (training) or estimated (testing) mean tensor of shape (C).</p></li>
<li><p><strong>var</strong> (heterogeneous) - <strong>T</strong>:
running (training) or estimated (testing) variance tensor of shape
(C).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 5 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
The output tensor of the same shape as X</p></li>
<li><p><strong>mean</strong> (optional, heterogeneous) - <strong>T</strong>:
The running mean after the BatchNormalization operator.</p></li>
<li><p><strong>var</strong> (optional, heterogeneous) - <strong>T</strong>:
The running variance after the BatchNormalization operator.</p></li>
<li><p><strong>saved_mean</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved mean used during training to speed up gradient computation.</p></li>
<li><p><strong>saved_var</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved variance used during training to speed up gradient
computation.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">there are multiple cases for the number of outputs, which we list below:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">there are multiple cases for the number of outputs, which we list below:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, mean, var, saved_mean, saved_var (training mode)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, mean, var, saved_mean, saved_var (training mode)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (test mode)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (test mode)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">6</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">7</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">For previous (depreciated) non-spatial cases, implementors are suggested</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">8</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.</code></td></tr>
<tr style="1px solid black;"><td><code>6</code></td><td><code>9</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;"> </span>This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>This operator has **optional** inputs/outputs. See ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero. Default value is 9.999999747378752e-06.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero. Default value is 9.999999747378752e-06.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum). Default value is 0.8999999761581421.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum). Default value is 0.8999999761581421.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">15</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">* **spatial**:</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">16</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  If true, compute the mean and variance across per activation. If</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">17</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  false, compute the mean and variance across per feature over each</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">18</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  mini-batch. Default value is 1.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td><code>23</code></td><td><code>22</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  Input data tensor from the previous operator; dimensions <span style="color:#BA4A00;">f</span><span style="color:#BA4A00;">o</span>r i<span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">g</span>e</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  Input data tensor from the previous operator; dimensions <span style="color:#196F3D;">a</span>r<span style="color:#196F3D;">e</span> i<span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span>e</code></td></tr>
<tr style="1px solid black;"><td><code>24</code></td><td><code>23</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">a</span>r<span style="color:#BA4A00;">e</span> (N x C x <span style="color:#BA4A00;">H</span> x <span style="color:#BA4A00;">W</span>), where N is the batch size, C is<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">b</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">r</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">f</span><span style="color:#196F3D;">o</span>r<span style="color:#196F3D;">m</span> <span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span>(N x C x <span style="color:#196F3D;">D</span><span style="color:#196F3D;">1</span> x <span style="color:#196F3D;">D</span><span style="color:#196F3D;">2</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">D</span><span style="color:#196F3D;">n</span>), where N is the batch size, C is</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">25</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  of channels, and H and W are the height and the width of the data.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">26</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  For non image case, the dimensions are in the form of (N x C x D1 x</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">27</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  D2 ... Dn), where N is the batch size.</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">24</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  the number of channels. Statistics are computed for every channel of</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">25</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  C over N and D1 to Dn dimensions. For image data, input dimensions</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">26</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  become (N x C x H x W). The op also accepts single dimension input</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">27</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  of size N in which case C is assumed to be 1</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td><code>29</code></td><td><code>29</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">p</span>a<span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">a</span>l<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">u</span>e<span style="color:#BA4A00;">,</span> t<span style="color:#BA4A00;">h</span>e<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span>ns<span style="color:#BA4A00;">i</span>o<span style="color:#BA4A00;">n</span> of s<span style="color:#BA4A00;">c</span>a<span style="color:#BA4A00;">l</span>e <span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span>(C).<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">S</span><span style="color:#196F3D;">c</span>ale tenso<span style="color:#196F3D;">r</span> of s<span style="color:#196F3D;">h</span>a<span style="color:#196F3D;">p</span>e (C).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">30</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  false, the dimensions of scale are (C x D1 x ... x Dn)</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td><code>32</code></td><td><code>31</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">t</span>ia<span style="color:#BA4A00;">l</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span>s t<span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">u</span>e<span style="color:#BA4A00;">,</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span>ns<span style="color:#BA4A00;">i</span>o<span style="color:#BA4A00;">n</span> of <span style="color:#BA4A00;">b</span><span style="color:#BA4A00;">i</span>a<span style="color:#BA4A00;">s</span> <span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span>(C).<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">B</span>ias tenso<span style="color:#196F3D;">r</span> of <span style="color:#196F3D;">s</span><span style="color:#196F3D;">h</span>a<span style="color:#196F3D;">p</span><span style="color:#196F3D;">e</span> (C).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">33</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  false, the dimensions of bias are (C x D1 x ... x Dn)</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">35</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  If spatial is true, the dimension of the running mean (training) or</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">36</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  the estimated mean (testing) is (C). If spatial is false, the</code></td><td></td></tr>
<tr style="1px solid black;"><td><code>37</code></td><td><code>33</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span>running <span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;"> </span>(training) or <span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">h</span>e<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">e</span>stimated mean</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  running (training) or estimated <span style="color:#196F3D;">(</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">)</span><span style="color:#196F3D;"> </span>mean<span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">(</span><span style="color:#196F3D;">C</span><span style="color:#196F3D;">)</span><span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">38</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  (testing) are (C x D1 x ... x Dn).</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">40</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  If spatial is true, the dimension of the running variance(training)</code></td><td></td></tr>
<tr style="1px solid black;"><td><code>41</code></td><td><code>35</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">o</span>r t<span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">e</span> estimated <span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span>(testing) <span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">(</span><span style="color:#BA4A00;">C</span><span style="color:#BA4A00;">)</span><span style="color:#BA4A00;">.</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">p</span>a<span style="color:#BA4A00;">t</span>ia<span style="color:#BA4A00;">l</span> <span style="color:#BA4A00;">i</span>s f<span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span>s<span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">,</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span>he</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  r<span style="color:#196F3D;">u</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span> <span style="color:#196F3D;">(</span>t<span style="color:#196F3D;">r</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">)</span> <span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;"> </span>estimated (testing) <span style="color:#196F3D;">v</span>a<span style="color:#196F3D;">r</span>ia<span style="color:#196F3D;">n</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">e</span> <span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span>s<span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span> <span style="color:#196F3D;">o</span>f<span style="color:#196F3D;"> </span>sh<span style="color:#196F3D;">a</span><span style="color:#196F3D;">p</span>e</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">42</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  dimensions of the running variance(training) or the estimated</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">43</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  variance (testing) are (C x D1 x ... x Dn).</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">36</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  (C).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 5 outputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 5 outputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The output tensor of the same shape as X</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The output tensor of the same shape as X</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance after the BatchNormalization operator.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance after the BatchNormalization operator.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_mean** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_mean** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved mean used during training to speed up gradient computation.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved mean used during training to speed up gradient computation.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_var** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_var** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved variance used during training to speed up gradient</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved variance used during training to speed up gradient</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  computation.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  computation.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
</table></section>
<section id="batchnormalization-7">
<span id="l-onnx-op-batchnormalization-7"></span><h2><a class="toc-backref" href="#id12">BatchNormalization - 7</a><a class="headerlink" href="#batchnormalization-7" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization">BatchNormalization (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>7</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 7</strong>.</p>
<p><strong>Summary</strong></p>
<p>Carries out batch normalization as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>. Depending on the mode it is being run,
there are multiple cases for the number of outputs, which we list below:</p>
<p>Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)</p>
<blockquote>
<div><p>This operator has <strong>optional</strong> inputs/outputs. See <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/IR.md">ONNX</a> for more details about the representation of optional arguments. An empty string may be used in the place of an actual argumentâ€™s name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.</p>
</div></blockquote>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>epsilon</strong>:
The epsilon value to use to avoid division by zero. Default value is <code class="docutils literal notranslate"><span class="pre">9.999999747378752e-06</span></code>.</p></li>
<li><p><strong>momentum</strong>:
Factor used in computing the running mean and variance.e.g.,
running_mean = running_mean * momentum + mean * (1 - momentum). Default value is <code class="docutils literal notranslate"><span class="pre">0.8999999761581421</span></code>.</p></li>
<li><p><strong>spatial</strong>:
If true, compute the mean and variance across per activation. If
false, compute the mean and variance across per feature over each
mini-batch. Default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from the previous operator; dimensions for image
case are (N x C x H x W), where N is the batch size, C is the number
of channels, and H and W are the height and the width of the data.
For non image case, the dimensions are in the form of (N x C x D1 x
D2 â€¦ Dn), where N is the batch size.</p></li>
<li><p><strong>scale</strong> (heterogeneous) - <strong>T</strong>:
If spatial is true, the dimension of scale is (C). If spatial is
false, the dimensions of scale are (C x D1 x â€¦ x Dn)</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
If spatial is true, the dimension of bias is (C). If spatial is
false, the dimensions of bias are (C x D1 x â€¦ x Dn)</p></li>
<li><p><strong>mean</strong> (heterogeneous) - <strong>T</strong>:
If spatial is true, the dimension of the running mean (training) or
the estimated mean (testing) is (C). If spatial is false, the
dimensions of the running mean (training) or the estimated mean
(testing) are (C x D1 x â€¦ x Dn).</p></li>
<li><p><strong>var</strong> (heterogeneous) - <strong>T</strong>:
If spatial is true, the dimension of the running variance(training)
or the estimated variance (testing) is (C). If spatial is false, the
dimensions of the running variance(training) or the estimated
variance (testing) are (C x D1 x â€¦ x Dn).</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 5 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
The output tensor of the same shape as X</p></li>
<li><p><strong>mean</strong> (optional, heterogeneous) - <strong>T</strong>:
The running mean after the BatchNormalization operator.</p></li>
<li><p><strong>var</strong> (optional, heterogeneous) - <strong>T</strong>:
The running variance after the BatchNormalization operator.</p></li>
<li><p><strong>saved_mean</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved mean used during training to speed up gradient computation.</p></li>
<li><p><strong>saved_var</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved variance used during training to speed up gradient
computation.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">there are multiple cases for the number of outputs, which we list below:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">there are multiple cases for the number of outputs, which we list below:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, mean, var, saved_mean, saved_var (training mode)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, mean, var, saved_mean, saved_var (training mode)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (test mode)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (test mode)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">6</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;"></code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">7</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">**Attributes**</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">8</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;"></code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">9</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">* **epsilon**:</code></td><td></td></tr>
<tr style="1px solid black;"><td><code>10</code></td><td><code>6</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  The epsilo<span style="color:#BA4A00;">n</span> <span style="color:#BA4A00;">v</span>alue to use to a<span style="color:#BA4A00;">v</span>oid <span style="color:#BA4A00;">d</span>i<span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">i</span>sion by <span style="color:#BA4A00;">z</span>ero<span style="color:#BA4A00;">,</span> <span style="color:#BA4A00;">d</span>e<span style="color:#BA4A00;">f</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">u</span>l<span style="color:#BA4A00;">t</span> i<span style="color:#BA4A00;">s</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;"> </span><span style="color:#196F3D;"> </span>Th<span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span>e<span style="color:#196F3D;">r</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span> <span style="color:#196F3D;">h</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">S</span>e<span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">O</span><span style="color:#196F3D;">N</span><span style="color:#196F3D;">N</span><span style="color:#196F3D;">X</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;"><</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">t</span>ps<span style="color:#196F3D;">:</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">g</span>i<span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">x</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">x</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">b</span>lo<span style="color:#196F3D;">b</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">/</span><span style="color:#196F3D;">I</span><span style="color:#196F3D;">R</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">></span><span style="color:#196F3D;">_</span> <span style="color:#196F3D;">f</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">t</span>a<span style="color:#196F3D;">i</span>l<span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">o</span>u<span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span>e <span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span>t<span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span>o<span style="color:#196F3D;">n</span> <span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span>u<span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span>s<span style="color:#196F3D;">.</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">A</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span>e<span style="color:#196F3D;">m</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">y</span> <span style="color:#196F3D;">s</span>t<span style="color:#196F3D;">r</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span>o<span style="color:#196F3D;">f</span> a<span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">'</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span>o<span style="color:#196F3D;"> </span>i<span style="color:#196F3D;">n</span>d<span style="color:#196F3D;">i</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span> <span style="color:#196F3D;">a</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">m</span>is<span style="color:#196F3D;">s</span>i<span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">T</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;"> </span>o<span style="color:#196F3D;">p</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span>n<span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span> <span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">(</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">w</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span>by <span style="color:#196F3D;">a</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">g</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">m</span>e<span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">h</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">p</span>r<span style="color:#196F3D;">e</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">)</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">s</span>o <span style="color:#196F3D;">b</span>e<span style="color:#196F3D;"> </span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">p</span>l<span style="color:#196F3D;">y</span> <span style="color:#196F3D;">o</span><span style="color:#196F3D;">m</span>i<span style="color:#196F3D;">t</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">7</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td><code>11</code></td><td><code>8</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">1</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">-</span><span style="color:#BA4A00;">5</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;">.</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">D</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;">a</span>u<span style="color:#BA4A00;">l</span>t<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">u</span>e<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span>s<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">9</span><span style="color:#BA4A00;">.</span><span style="color:#BA4A00;">9</span><span style="color:#BA4A00;">9</span><span style="color:#BA4A00;">9</span><span style="color:#BA4A00;">9</span><span style="color:#BA4A00;">9</span><span style="color:#BA4A00;">9</span><span style="color:#BA4A00;">7</span><span style="color:#BA4A00;">4</span><span style="color:#BA4A00;">7</span><span style="color:#BA4A00;">3</span><span style="color:#BA4A00;">7</span><span style="color:#BA4A00;">8</span><span style="color:#BA4A00;">7</span><span style="color:#BA4A00;">5</span><span style="color:#BA4A00;">2</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">-</span><span style="color:#BA4A00;">0</span><span style="color:#BA4A00;">6</span><span style="color:#BA4A00;">.</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code><span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">A</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">b</span>utes<span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">12</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">* **is_test**:</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">9</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;"></code></td></tr>
<tr style="1px solid black;"><td><code>13</code></td><td><code>10</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"> <span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">I</span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">s</span>e<span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">z</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">,</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;"> </span>s<span style="color:#BA4A00;">p</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">t</span>i<span style="color:#BA4A00;">a</span>l<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">b</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">n</span>o<span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">z</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">o</span>n<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">,</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code><span style="color:#196F3D;">*</span> <span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span>e<span style="color:#196F3D;">p</span>silon<span style="color:#196F3D;">*</span><span style="color:#196F3D;">*</span><span style="color:#196F3D;">:</span></code></td></tr>
<tr style="1px solid black;"><td><code>14</code></td><td><code>11</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">d</span>e<span style="color:#BA4A00;">f</span>au<span style="color:#BA4A00;">l</span>t is <span style="color:#BA4A00;">0</span>. Default value is 0.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">T</span><span style="color:#196F3D;">h</span>e<span style="color:#196F3D;"> </span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">p</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">v</span>a<span style="color:#196F3D;">l</span>u<span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span>t<span style="color:#196F3D;">o</span> <span style="color:#196F3D;">u</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">v</span><span style="color:#196F3D;">o</span>i<span style="color:#196F3D;">d</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">d</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">v</span><span style="color:#196F3D;">i</span>s<span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span> <span style="color:#196F3D;">b</span><span style="color:#196F3D;">y</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">z</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">r</span><span style="color:#196F3D;">o</span>. Default value is <span style="color:#196F3D;">9</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">7</span><span style="color:#196F3D;">4</span><span style="color:#196F3D;">7</span><span style="color:#196F3D;">3</span><span style="color:#196F3D;">7</span><span style="color:#196F3D;">8</span><span style="color:#196F3D;">7</span><span style="color:#196F3D;">5</span><span style="color:#196F3D;">2</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">-</span>0<span style="color:#196F3D;">6</span>.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td></tr>
<tr style="1px solid black;"><td><code>17</code></td><td><code>14</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  running_mean = running_mean * momentum + mean * (1 - momentum)<span style="color:#BA4A00;">,</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  running_mean = running_mean * momentum + mean * (1 - momentum)<span style="color:#196F3D;">.</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">D</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">v</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">l</span><span style="color:#196F3D;">u</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">0</span><span style="color:#196F3D;">.</span><span style="color:#196F3D;">8</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">9</span><span style="color:#196F3D;">7</span><span style="color:#196F3D;">6</span><span style="color:#196F3D;">1</span><span style="color:#196F3D;">5</span><span style="color:#196F3D;">8</span><span style="color:#196F3D;">1</span><span style="color:#196F3D;">4</span><span style="color:#196F3D;">2</span><span style="color:#196F3D;">1</span><span style="color:#196F3D;">.</span></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">18</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  default is 0.9f. Default value is 0.8999999761581421.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **spatial**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **spatial**:</code></td></tr>
<tr style="1px solid black;"><td><code>20</code></td><td><code>16</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  If true, compute the mean and variance across <span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">l</span> <span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">p</span>atia<span style="color:#BA4A00;">l</span> <span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">s</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  If true, compute the mean and variance across <span style="color:#196F3D;">p</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">r</span> a<span style="color:#196F3D;">c</span>ti<span style="color:#196F3D;">v</span>a<span style="color:#196F3D;">t</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">.</span> <span style="color:#196F3D;">I</span><span style="color:#196F3D;">f</span></code></td></tr>
<tr style="1px solid black;"><td><code>21</code></td><td><code>17</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">I</span>f<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">f</span>alse, compute the mean and variance across per feature<span style="color:#BA4A00;">.</span><span style="color:#BA4A00;">D</span>e<span style="color:#BA4A00;">f</span>a<span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">t</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  false, compute the mean and variance across per feature<span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">v</span>e<span style="color:#196F3D;">r</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">e</span>a<span style="color:#196F3D;">c</span><span style="color:#196F3D;">h</span></code></td></tr>
<tr style="1px solid black;"><td><code>22</code></td><td><code>18</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  i<span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">1</span>. Default value is 1.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">m</span>i<span style="color:#196F3D;">n</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">-</span><span style="color:#196F3D;">b</span><span style="color:#196F3D;">a</span><span style="color:#196F3D;">t</span><span style="color:#196F3D;">c</span><span style="color:#196F3D;">h</span>. Default value is 1.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from the previous operator; dimensions for image</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Input data tensor from the previous operator; dimensions for image</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  case are (N x C x H x W), where N is the batch size, C is the number</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  case are (N x C x H x W), where N is the batch size, C is the number</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">29</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of channels, and H and W are the height and the width of the data.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  of channels, and H and W are the height and the width of the data.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  For non image case, the dimensions are in the form of (N x C x D1 x</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  For non image case, the dimensions are in the form of (N x C x D1 x</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  D2 ... Dn), where N is the batch size.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  D2 ... Dn), where N is the batch size.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">33</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  The scale as a 1-dimensional tensor of size C to be applied to the</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">34</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  output.</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">29</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  If spatial is true, the dimension of scale is (C). If spatial is</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">30</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  false, the dimensions of scale are (C x D1 x ... x Dn)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">36</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  The bias as a 1-dimensional tensor of size C to be applied to the</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">37</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  output.</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">32</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  If spatial is true, the dimension of bias is (C). If spatial is</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">33</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  false, the dimensions of bias are (C x D1 x ... x Dn)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">35</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  If spatial is true, the dimension of the running mean (training) or</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">36</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  the estimated mean (testing) is (C). If spatial is false, the</code></td></tr>
<tr style="1px solid black;"><td><code>39</code></td><td><code>37</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">T</span>he running mean (training) or the estimated mean<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">(</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">)</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">a</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">d</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span>he running mean (training) or the estimated mean</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">40</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  1-dimensional tensor of size C.</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">38</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  (testing) are (C x D1 x ... x Dn).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">40</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  If spatial is true, the dimension of the running variance(training)</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">41</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  or the estimated variance (testing) is (C). If spatial is false, the</code></td></tr>
<tr style="1px solid black;"><td><code>42</code></td><td><code>42</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  <span style="color:#BA4A00;">T</span>he running variance<span style="color:#BA4A00;"> </span>(training) or the estimated<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">v</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">c</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">(</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">)</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  <span style="color:#196F3D;">d</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">m</span><span style="color:#196F3D;">e</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;">i</span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">n</span><span style="color:#196F3D;">s</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">o</span><span style="color:#196F3D;">f</span><span style="color:#196F3D;"> </span><span style="color:#196F3D;">t</span>he running variance(training) or the estimated</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">43</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  as a 1-dimensional tensor of size C.</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">43</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  variance (testing) are (C x D1 x ... x Dn).</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 5 outputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 5 outputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td><code>50</code></td><td><code>50</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  The output tensor of the same shape as X<span style="color:#BA4A00;">.</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  The output tensor of the same shape as X</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td><code>52</code></td><td><code>52</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  The running mean after the BatchNormalization operator.<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">M</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">b</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">-</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  The running mean after the BatchNormalization operator.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">53</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  place with the input mean. Should not be used for testing.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td><code>55</code></td><td><code>54</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  The running variance after the BatchNormalization operator.<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">M</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">b</span><span style="color:#BA4A00;">e</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  The running variance after the BatchNormalization operator.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">56</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  in-place with the input var. Should not be used for testing.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_mean** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_mean** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved mean used during training to speed up gradient computation.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved mean used during training to speed up gradient computation.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">59</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  Should not be used for testing.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_var** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_var** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved variance used during training to speed up gradient</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved variance used during training to speed up gradient</code></td></tr>
<tr style="1px solid black;"><td><code>62</code></td><td><code>59</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  computation.<span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">S</span><span style="color:#BA4A00;">h</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">b</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">u</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">f</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">r</span><span style="color:#BA4A00;"> </span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">t</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">g</span><span style="color:#BA4A00;">.</span></code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  computation.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
</table></section>
<section id="batchnormalization-6">
<span id="l-onnx-op-batchnormalization-6"></span><h2><a class="toc-backref" href="#id13">BatchNormalization - 6</a><a class="headerlink" href="#batchnormalization-6" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization">BatchNormalization (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>6</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: True</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 6</strong>.</p>
<p><strong>Summary</strong></p>
<p>Carries out batch normalization as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>. Depending on the mode it is being run,
there are multiple cases for the number of outputs, which we list below:</p>
<p>Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>epsilon</strong>:
The epsilon value to use to avoid division by zero, default is
1e-5f. Default value is <code class="docutils literal notranslate"><span class="pre">9.999999747378752e-06</span></code>.</p></li>
<li><p><strong>is_test</strong>:
If set to nonzero, run spatial batch normalization in test mode,
default is 0. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>momentum</strong>:
Factor used in computing the running mean and variance.e.g.,
running_mean = running_mean * momentum + mean * (1 - momentum),
default is 0.9f. Default value is <code class="docutils literal notranslate"><span class="pre">0.8999999761581421</span></code>.</p></li>
<li><p><strong>spatial</strong>:
If true, compute the mean and variance across all spatial elements
If false, compute the mean and variance across per feature.Default
is 1. Default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
Input data tensor from the previous operator; dimensions for image
case are (N x C x H x W), where N is the batch size, C is the number
of channels, and H and W are the height and the width of the data.
For non image case, the dimensions are in the form of (N x C x D1 x
D2 â€¦ Dn), where N is the batch size.</p></li>
<li><p><strong>scale</strong> (heterogeneous) - <strong>T</strong>:
The scale as a 1-dimensional tensor of size C to be applied to the
output.</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
The bias as a 1-dimensional tensor of size C to be applied to the
output.</p></li>
<li><p><strong>mean</strong> (heterogeneous) - <strong>T</strong>:
The running mean (training) or the estimated mean (testing) as a
1-dimensional tensor of size C.</p></li>
<li><p><strong>var</strong> (heterogeneous) - <strong>T</strong>:
The running variance (training) or the estimated variance (testing)
as a 1-dimensional tensor of size C.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 5 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
The output tensor of the same shape as X.</p></li>
<li><p><strong>mean</strong> (optional, heterogeneous) - <strong>T</strong>:
The running mean after the BatchNormalization operator. Must be in-
place with the input mean. Should not be used for testing.</p></li>
<li><p><strong>var</strong> (optional, heterogeneous) - <strong>T</strong>:
The running variance after the BatchNormalization operator. Must be
in-place with the input var. Should not be used for testing.</p></li>
<li><p><strong>saved_mean</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved mean used during training to speed up gradient computation.
Should not be used for testing.</p></li>
<li><p><strong>saved_var</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved variance used during training to speed up gradient
computation. Should not be used for testing.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
<p><strong>Differences</strong></p>
<table style="white-space: pre; 1px solid black; font-family:courier; text-align:left !important;">
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">0</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Carries out batch normalization as described in the paper</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">1</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">2</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">there are multiple cases for the number of outputs, which we list below:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">there are multiple cases for the number of outputs, which we list below:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">3</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">4</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, mean, var, saved_mean, saved_var (training mode)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #1: Y, mean, var, saved_mean, saved_var (training mode)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">5</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (test mode)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Output case #2: Y (test mode)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">6</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">7</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Attributes**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">8</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">9</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">* **consumed_inputs** (required):</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">10</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  legacy optimization attribute.</code></td><td></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">9</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **epsilon**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">10</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero, default is</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The epsilon value to use to avoid division by zero, default is</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">11</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  1e-5f. Default value is 9.999999747378752e-06.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  1e-5f. Default value is 9.999999747378752e-06.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">12</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **is_test**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **is_test**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">13</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If set to nonzero, run spatial batch normalization in test mode,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If set to nonzero, run spatial batch normalization in test mode,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">14</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  default is 0. Default value is 0.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  default is 0. Default value is 0.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">15</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **momentum**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">16</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Factor used in computing the running mean and variance.e.g.,</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">17</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  running_mean = running_mean * momentum + mean * (1 - momentum),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">18</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  default is 0.9f. Default value is 0.8999999761581421.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  default is 0.9f. Default value is 0.8999999761581421.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">19</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **spatial**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **spatial**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">20</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If true, compute the mean and variance across all spatial elements</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If true, compute the mean and variance across all spatial elements</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">21</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If false, compute the mean and variance across per feature.Default</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  If false, compute the mean and variance across per feature.Default</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">22</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  is 1. Default value is 1.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  is 1. Default value is 1.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">23</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">24</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Inputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">27</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">25</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">28</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">26</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **X** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#E59866;"><code style="background-color:#E59866;">29</code></td><td></td><td style="background-color:#E59866;"><code style="background-color:#E59866;">  The input 4-dimensional tensor of shape NCHW.</code></td><td></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">27</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  Input data tensor from the previous operator; dimensions for image</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">28</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  case are (N x C x H x W), where N is the batch size, C is the number</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">29</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  of channels, and H and W are the height and the width of the data.</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">30</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  For non image case, the dimensions are in the form of (N x C x D1 x</code></td></tr>
<tr style="1px solid black;"><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">31</code></td><td></td><td style="background-color:#ABEBC6;"><code style="background-color:#ABEBC6;">  D2 ... Dn), where N is the batch size.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">30</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **scale** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">31</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The scale as a 1-dimensional tensor of size C to be applied to the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The scale as a 1-dimensional tensor of size C to be applied to the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">32</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">33</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **B** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">34</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias as a 1-dimensional tensor of size C to be applied to the</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The bias as a 1-dimensional tensor of size C to be applied to the</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">35</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  output.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">36</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">37</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean (training) or the estimated mean (testing) as a</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean (training) or the estimated mean (testing) as a</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">38</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  1-dimensional tensor of size C.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  1-dimensional tensor of size C.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">39</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">40</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance (training) or the estimated variance (testing)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance (training) or the estimated variance (testing)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">41</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  as a 1-dimensional tensor of size C.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  as a 1-dimensional tensor of size C.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">42</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">43</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Outputs**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">44</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">45</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 5 outputs.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">Between 1 and 5 outputs.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">46</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">48</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">47</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **Y** (heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td><code>48</code></td><td><code>50</code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;">  The output <span style="color:#BA4A00;">4</span><span style="color:#BA4A00;">-</span><span style="color:#BA4A00;">d</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">m</span><span style="color:#BA4A00;">e</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">s</span><span style="color:#BA4A00;">i</span><span style="color:#BA4A00;">o</span><span style="color:#BA4A00;">n</span><span style="color:#BA4A00;">a</span><span style="color:#BA4A00;">l</span><span style="color:#BA4A00;"> </span>tensor of the same shape as X.</code></code></td><td style="background-color:#E5E7E9;"><code style="background-color:#E5E7E9;"><code>  The output tensor of the same shape as X.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">49</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **mean** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">50</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator. Must be in-</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running mean after the BatchNormalization operator. Must be in-</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">51</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  place with the input mean. Should not be used for testing.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  place with the input mean. Should not be used for testing.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">52</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **var** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">53</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance after the BatchNormalization operator. Must be</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  The running variance after the BatchNormalization operator. Must be</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">54</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  in-place with the input var. Should not be used for testing.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  in-place with the input var. Should not be used for testing.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">55</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_mean** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_mean** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">56</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved mean used during training to speed up gradient computation.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved mean used during training to speed up gradient computation.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">57</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Should not be used for testing.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Should not be used for testing.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">58</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_var** (optional, heterogeneous) - **T**:</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **saved_var** (optional, heterogeneous) - **T**:</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">59</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved variance used during training to speed up gradient</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Saved variance used during training to speed up gradient</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">60</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  computation. Should not be used for testing.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  computation. Should not be used for testing.</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">61</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">62</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">**Type Constraints**</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">63</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;"></code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">64</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">* **T** in (</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">65</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(double),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">66</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float),</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">67</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  tensor(float16)</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">68</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">70</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  ):</code></td></tr>
<tr style="1px solid black;"><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">69</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">71</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td><td style="background-color:#FFFFFF;"><code style="background-color:#FFFFFF;">  Constrain input and output types to float tensors.</code></td></tr>
</table></section>
<section id="batchnormalization-1">
<span id="l-onnx-op-batchnormalization-1"></span><h2><a class="toc-backref" href="#id14">BatchNormalization - 1</a><a class="headerlink" href="#batchnormalization-1" title="Permalink to this headline">#</a></h2>
<p><strong>Version</strong></p>
<ul class="simple">
<li><p><strong>name</strong>: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization">BatchNormalization (GitHub)</a></p></li>
<li><p><strong>domain</strong>: <strong>main</strong></p></li>
<li><p><strong>since_version</strong>: <strong>1</strong></p></li>
<li><p><strong>function</strong>: False</p></li>
<li><p><strong>support_level</strong>: SupportType.COMMON</p></li>
<li><p><strong>shape inference</strong>: False</p></li>
</ul>
<p>This version of the operator has been available
<strong>since version 1</strong>.</p>
<p><strong>Summary</strong></p>
<p>Carries out batch normalization as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>. Depending on the mode it is being run,
there are multiple cases for the number of outputs, which we list below:</p>
<p>Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)</p>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>consumed_inputs</strong> (required):
legacy optimization attribute.</p></li>
<li><p><strong>epsilon</strong>:
The epsilon value to use to avoid division by zero, default is
1e-5f. Default value is <code class="docutils literal notranslate"><span class="pre">9.999999747378752e-06</span></code>.</p></li>
<li><p><strong>is_test</strong>:
If set to nonzero, run spatial batch normalization in test mode,
default is 0. Default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><strong>momentum</strong>:
Factor used in computing the running mean and variance.e.g.,
running_mean = running_mean * momentum + mean * (1 - momentum),
default is 0.9f. Default value is <code class="docutils literal notranslate"><span class="pre">0.8999999761581421</span></code>.</p></li>
<li><p><strong>spatial</strong>:
If true, compute the mean and variance across all spatial elements
If false, compute the mean and variance across per feature.Default
is 1. Default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
</ul>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (heterogeneous) - <strong>T</strong>:
The input 4-dimensional tensor of shape NCHW.</p></li>
<li><p><strong>scale</strong> (heterogeneous) - <strong>T</strong>:
The scale as a 1-dimensional tensor of size C to be applied to the
output.</p></li>
<li><p><strong>B</strong> (heterogeneous) - <strong>T</strong>:
The bias as a 1-dimensional tensor of size C to be applied to the
output.</p></li>
<li><p><strong>mean</strong> (heterogeneous) - <strong>T</strong>:
The running mean (training) or the estimated mean (testing) as a
1-dimensional tensor of size C.</p></li>
<li><p><strong>var</strong> (heterogeneous) - <strong>T</strong>:
The running variance (training) or the estimated variance (testing)
as a 1-dimensional tensor of size C.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<p>Between 1 and 5 outputs.</p>
<ul class="simple">
<li><p><strong>Y</strong> (heterogeneous) - <strong>T</strong>:
The output 4-dimensional tensor of the same shape as X.</p></li>
<li><p><strong>mean</strong> (optional, heterogeneous) - <strong>T</strong>:
The running mean after the BatchNormalization operator. Must be in-
place with the input mean. Should not be used for testing.</p></li>
<li><p><strong>var</strong> (optional, heterogeneous) - <strong>T</strong>:
The running variance after the BatchNormalization operator. Must be
in-place with the input var. Should not be used for testing.</p></li>
<li><p><strong>saved_mean</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved mean used during training to speed up gradient computation.
Should not be used for testing.</p></li>
<li><p><strong>saved_var</strong> (optional, heterogeneous) - <strong>T</strong>:
Saved variance used during training to speed up gradient
computation. Should not be used for testing.</p></li>
</ul>
<p><strong>Type Constraints</strong></p>
<ul class="simple">
<li><p><strong>T</strong> in (
tensor(double),
tensor(float),
tensor(float16)
):
Constrain input and output types to float tensors.</p></li>
</ul>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="onnx__AveragePool.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">AveragePool</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="onnx__Bernoulli.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bernoulli</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier DuprÃ©.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>