{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compares implementations of Add\n\nThis example compares the addition of *numpy*\nto :epkg:`onnxruntime` implementation.\nFunction :epkg:`numpy:add` is repeated 3 times. This minimizes the cost\nof copying the data from python to an external library.\nIf available, :epkg:`tensorflow` and :epkg:`pytorch` are included as well.\nThe numpy implementation is not the best,\nit allocates more buffers than necessary because parameter *out*\nis not used to reuse buffers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nimport pandas\nimport matplotlib.pyplot as plt\nfrom onnxruntime import InferenceSession\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx.algebra.onnx_ops import OnnxAdd\nfrom cpyquickhelper.numbers import measure_time\nfrom tqdm import tqdm\nfrom mlprodict.testing.experimental_c_impl.experimental_c import code_optimisation\nprint(code_optimisation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add implementations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    from tensorflow.math import add as tf_add\n    from tensorflow import convert_to_tensor\nexcept ImportError:\n    tf_add = None\ntry:\n    from torch import add as torch_add, from_numpy\nexcept ImportError:\n    torch_add = None\n\n\ndef build_ort_add(op_version=12):\n    node1 = OnnxAdd('x', 'y', op_version=op_version)\n    node2 = OnnxAdd(node1, 'y', op_version=op_version)\n    node = OnnxAdd(node2, 'y', op_version=op_version, output_names=['z'])\n    onx = node.to_onnx(inputs=[('x', FloatTensorType()),\n                               ('y', FloatTensorType())],\n                       target_opset=op_version)\n    sess = InferenceSession(onx.SerializeToString())\n    return lambda x, y: sess.run(None, {'x': x, 'y': y})\n\n\ndef loop_fct(fct, xs, ys):\n    for x, y in zip(xs, ys):\n        fct(x, y)\n\n\ndef benchmark_op(repeat=5, number=2, name=\"Add\", shape_fcts=None):\n    if shape_fcts is None:\n        def shape_fct(dim):\n            return (5, dim, dim)\n        shape_fcts = (shape_fct, shape_fct)\n    ort_fct = build_ort_add()\n    res = []\n    for dim in tqdm([8, 16, 32, 64, 100, 128, 200,\n                     256, 400, 512, 1024, 1536, 2048, 2560]):\n        shape1 = shape_fcts[0](dim)\n        shape2 = shape_fcts[1](dim)\n        n_arrays = (16 if dim < 512 else 4) if dim < 2048 else 4\n        if len(shape1) > 3:\n            n_arrays = int(n_arrays / 4)\n        xs = [numpy.random.rand(*shape1).astype(numpy.float32)\n              for _ in range(n_arrays)]\n        ys = [numpy.random.rand(*shape2).astype(numpy.float32)\n              for _ in range(n_arrays)]\n        info = dict(shape1=shape1, shape2=shape2)\n\n        # numpy\n        ctx = dict(\n            xs=xs, ys=ys,\n            fct=lambda x, y: numpy.add(numpy.add(numpy.add(x, y), y), y),\n            loop_fct=loop_fct)\n        obs = measure_time(\n            \"loop_fct(fct, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=repeat, number=number)\n        obs['dim'] = dim\n        obs['fct'] = 'numpy'\n        obs.update(info)\n        res.append(obs)\n\n        # onnxruntime\n        ctx['fct'] = ort_fct\n        obs = measure_time(\n            \"loop_fct(fct, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=repeat, number=number)\n        obs['dim'] = dim\n        obs['fct'] = 'ort'\n        obs.update(info)\n        res.append(obs)\n\n        if tf_add is not None:\n            # tensorflow\n            ctx['fct'] = lambda x, y: tf_add(tf_add(tf_add(x, y), y), y)\n            ctx['xs'] = [convert_to_tensor(x) for x in xs]\n            ctx['ys'] = [convert_to_tensor(y) for y in ys]\n            obs = measure_time(\n                \"loop_fct(fct, xs, ys)\",\n                div_by_number=True, context=ctx, repeat=repeat, number=number)\n            obs['dim'] = dim\n            obs['fct'] = 'tf'\n            obs.update(info)\n            res.append(obs)\n\n        if torch_add is not None:\n            # torch\n            ctx['fct'] = lambda x, y: torch_add(\n                torch_add(torch_add(x, y), y), y)\n            ctx['xs'] = [from_numpy(x) for x in xs]\n            ctx['ys'] = [from_numpy(y) for y in ys]\n            obs = measure_time(\n                \"loop_fct(fct, xs, ys)\",\n                div_by_number=True, context=ctx, repeat=repeat, number=number)\n            obs['dim'] = dim\n            obs['fct'] = 'torch'\n            obs.update(info)\n            res.append(obs)\n\n    # Dataframes\n    shape1_name = str(shape1).replace(str(dim), \"N\")\n    shape2_name = str(shape2).replace(str(dim), \"N\")\n    df = pandas.DataFrame(res)\n    df.columns = [_.replace('dim', 'N') for _ in df.columns]\n    piv = df.pivot('N', 'fct', 'average')\n\n    rs = piv.copy()\n    for c in ['ort', 'torch', 'tf']:\n        if c in rs.columns:\n            rs[c] = rs['numpy'] / rs[c]\n    rs['numpy'] = 1.\n\n    # Graphs.\n    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n    piv.plot(logx=True, logy=True, ax=ax[0],\n             title=\"%s benchmark\\n%s + %s\"\n                   \" lower better\" % (name, shape1_name, shape2_name))\n    ax[0].legend(prop={\"size\": 9})\n    rs.plot(logx=True, logy=True, ax=ax[1],\n            title=\"%s Speedup, baseline=numpy\\n%s + %s\"\n                  \" higher better\" % (name, shape1_name, shape2_name))\n    ax[1].plot([min(rs.index), max(rs.index)], [0.5, 0.5], 'g--')\n    ax[1].plot([min(rs.index), max(rs.index)], [2., 2.], 'g--')\n    ax[1].legend(prop={\"size\": 9})\n    return df, rs, ax\n\n\ndfs = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (5, N, N) + (5, N, N)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df, piv, ax = benchmark_op()\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (5, N, N) + (5, N, 1)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shape_fcts = (lambda dim: (5, dim, dim),\n              lambda dim: (5, dim, 1))\n\ndf, piv, ax = benchmark_op(shape_fcts=shape_fcts)\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (5, N, N) + (5, 1, N)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shape_fcts = (lambda dim: (5, dim, dim),\n              lambda dim: (5, 1, dim))\n\ndf, piv, ax = benchmark_op(shape_fcts=shape_fcts)\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (5, N, 5, N) + (1, N, 1, 1)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shape_fcts = (lambda dim: (5, dim, 5, dim),\n              lambda dim: (1, dim, 1, 1))\n\ndf, piv, ax = benchmark_op(shape_fcts=shape_fcts)\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nIt is difficult to have a final conclusion as the addition\nof two vectors is of the same order of magnitude of a copy\nbetween python and the C++ code of onnxruntime, pytorch or\ntensorflow. numpy is much better of small vectors.\nonnxruntime, pytorch and tensorflow are not optimized\non this case because it is not very common in deep learning.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "merged = pandas.concat(dfs)\nname = \"add\"\nmerged.to_csv(\"plot_%s.csv\" % name, index=False)\nmerged.to_excel(\"plot_%s.xlsx\" % name, index=False)\nplt.savefig(\"plot_%s.png\" % name)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}