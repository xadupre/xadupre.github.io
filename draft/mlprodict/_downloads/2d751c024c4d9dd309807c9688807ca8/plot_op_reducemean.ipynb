{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compares implementations of ReduceMean\n\nThis example compares the *numpy* for the operator *ReduceMean*\nto :epkg:`onnxruntime` implementation.\nIf available, :epkg:`tensorflow` and :epkg:`pytorch` are included as well.\n\n## Available optimisation\n\nThe code shows which parallelisation optimisation could be used,\n*AVX* or *SSE* and the number of available processors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nimport pandas\nimport matplotlib.pyplot as plt\nfrom onnxruntime import InferenceSession\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx.algebra.onnx_ops import OnnxReduceMean\nfrom cpyquickhelper.numbers import measure_time\nfrom tqdm import tqdm\nfrom mlprodict.testing.experimental_c_impl.experimental_c import code_optimisation\nprint(code_optimisation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ReduceMean implementations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    from tensorflow.math import reduce_mean as tf_reduce_mean\n    from tensorflow import convert_to_tensor\nexcept ImportError:\n    tf_reduce_mean = None\ntry:\n    from torch import mean as torch_mean, from_numpy\nexcept ImportError:\n    torch_mean = None\n\n\ndef build_ort_reducemean(axes, op_version=14):  # opset=13, 14, ...\n    node = OnnxReduceMean('x', axes=axes, op_version=op_version,\n                          output_names=['z'])\n    onx = node.to_onnx(inputs=[('x', FloatTensorType())],\n                       target_opset=op_version)\n    sess = InferenceSession(onx.SerializeToString())\n    return lambda x, y: sess.run(None, {'x': x})\n\n\ndef loop_fct(fct, xs, ys):\n    for x, y in zip(xs, ys):\n        fct(x, y)\n\n\ndef benchmark_op(axes, repeat=2, number=5, name=\"ReduceMean\",\n                 shape_fct=None, max_dim=None):\n    if shape_fct is None:\n        def shape_fct(dim):\n            return (3, dim, 1, 128, 64)\n    ort_fct = build_ort_reducemean(axes)\n    res = []\n    for dim in tqdm([4, 8, 16, 32, 64, 100, 128, 200,\n                     256, 400, 512, 1024]):\n        if max_dim is not None and dim > max_dim:\n            continue\n        shape = shape_fct(dim)\n        n_arrays = 10 if dim < 512 else 4\n        xs = [numpy.random.rand(*shape).astype(numpy.float32)\n              for _ in range(n_arrays)]\n        ys = [numpy.array(axes, dtype=numpy.int64)\n              for _ in range(n_arrays)]\n        info = dict(axes=axes, shape=shape)\n\n        # numpy\n        fct = lambda x, y: numpy.mean(x, axis=tuple(y))\n        ctx = dict(\n            xs=xs, ys=ys,\n            loop_fct=loop_fct)\n        obs = measure_time(\n            lambda: loop_fct(fct, xs, ys),\n            div_by_number=True, context=ctx, repeat=repeat, number=number)\n        obs['dim'] = dim\n        obs['fct'] = 'numpy'\n        obs.update(info)\n        res.append(obs)\n\n        # onnxruntime\n        fct = ort_fct\n        obs = measure_time(\n            lambda: loop_fct(fct, xs, ys),\n            div_by_number=True, context=ctx, repeat=repeat, number=number)\n        obs['dim'] = dim\n        obs['fct'] = 'ort'\n        obs.update(info)\n        res.append(obs)\n\n        if tf_reduce_mean is not None:\n            # tensorflow\n            fct = tf_reduce_mean\n            ctx['xs'] = [convert_to_tensor(x) for x in xs]\n            ctx['ys'] = ys\n            obs = measure_time(\n                lambda: loop_fct(fct, ctx['xs'], ctx['ys']),\n                div_by_number=True, context=ctx, repeat=repeat, number=number)\n            obs['dim'] = dim\n            obs['fct'] = 'tf'\n            obs.update(info)\n            res.append(obs)\n\n        if torch_mean is not None:\n            def torch_mean1(x, y):\n                return torch_mean(x, y[0])\n\n            def torch_mean2(x, y):\n                return torch_mean(torch_mean(x, y[1]), y[0])\n\n            # torch\n            fct = torch_mean1 if len(axes) == 1 else torch_mean2\n            ctx['xs'] = [from_numpy(x) for x in xs]\n            ctx['ys'] = ys  # [from_numpy(y) for y in ys]\n            obs = measure_time(\n                lambda: loop_fct(fct, ctx['xs'], ctx['ys']),\n                div_by_number=True, context=ctx, repeat=repeat, number=number)\n            obs['dim'] = dim\n            obs['fct'] = 'torch'\n            obs.update(info)\n            res.append(obs)\n\n    # Dataframes\n    shape_name = str(shape).replace(str(dim), \"N\")\n    df = pandas.DataFrame(res)\n    df.columns = [_.replace('dim', 'N') for _ in df.columns]\n    piv = df.pivot('N', 'fct', 'average')\n\n    rs = piv.copy()\n    for c in ['ort', 'torch', 'tf', 'tf_copy']:\n        if c in rs.columns:\n            rs[c] = rs['numpy'] / rs[c]\n    rs['numpy'] = 1.\n\n    # Graphs.\n    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n    piv.plot(logx=True, logy=True, ax=ax[0],\n             title=\"%s benchmark\\n%r - %r\"\n                   \" lower better\" % (name, shape_name, axes))\n    ax[0].legend(prop={\"size\": 9})\n    rs.plot(logx=True, logy=True, ax=ax[1],\n            title=\"%s Speedup, baseline=numpy\\n%r - %r\"\n                  \" higher better\" % (name, shape_name, axes))\n    ax[1].plot([min(rs.index), max(rs.index)], [0.5, 0.5], 'g--')\n    ax[1].plot([min(rs.index), max(rs.index)], [2., 2.], 'g--')\n    ax[1].legend(prop={\"size\": 9})\n    return df, rs, ax\n\n\ndfs = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reduction on a particular case KR\n\nConsecutive axis not reduced and consecutive reduced\naxis are merged.\nKR means kept axis - reduced axis\n\n### (8, 24, 48, N), axis=(3, )\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = (3, )\ndf, piv, ax = benchmark_op(axes, shape_fct=lambda dim: (8, 24, 48, dim))\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reduction on a particular case RK\n\nConsecutive axis not reduced and consecutive reduced\naxis are merged.\nRK means reduced axis - kept axis\n\n### (8, 24, 48, N), axis=(0, )\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = (0, )\ndf, piv, ax = benchmark_op(axes, shape_fct=lambda dim: (8, 24, 48, dim))\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reduction on a particular case KRK\n\nConsecutive axis not reduced and consecutive reduced\naxis are merged.\nKRK means kept axis - reduced axis - kept axis,\n\n### (8, 24, 48, N), axis=(1, 2)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = (1, 2)\ndf, piv, ax = benchmark_op(axes, shape_fct=lambda dim: (8, 24, 48, dim))\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (8, 24 * 48, N), axis=1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = (1, )\ndf, piv, ax = benchmark_op(axes, shape_fct=lambda dim: (8, 24 * 48, dim))\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (2, 8, 12, 24, 2, N), axis=(2, 3)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = (2, 3)\ndf, piv, ax = benchmark_op(axes, shape_fct=lambda dim: (2, 8, 12, 24, 2, dim))\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reduction on a particular case RKR\n\n### (N, 64, 16, 16), axis=(0, 2, 3)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = (0, 2, 3)\ndf, piv, ax = benchmark_op(\n    axes, shape_fct=lambda dim: (dim, 64, 16, 16))\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reduction on a particular case RKRK\n\n### (8, 24, 48, N), axis=(0, 2)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = (0, 2)\ndf, piv, ax = benchmark_op(axes, shape_fct=lambda dim: (8, 24, 48, dim))\ndfs.append(df)\ndf.pivot(\"fct\", \"N\", \"average\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nSome of the configurations should be investigated.\n`l-reducesum-problem1`. The reduction on tensorflow\nin one dimension seems to be lazy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "merged = pandas.concat(dfs)\nname = \"reducemean\"\nmerged.to_csv(\"plot_%s.csv\" % name, index=False)\nmerged.to_excel(\"plot_%s.xlsx\" % name, index=False)\nplt.savefig(\"plot_%s.png\" % name)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}