{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# When to parallelize?\n\nThat is the question. Parallize computation\ntakes some time to set up, it is not the right\nsolution in every case. The following example studies\nthe parallelism introduced into the runtime of\n*TreeEnsembleRegressor* to see when it is best\nto do it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\nimport numpy\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn import config_context\nfrom sklearn.datasets import make_regression\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom cpyquickhelper.numbers import measure_time\nfrom pyquickhelper.pycode.profiling import profile\nfrom mlprodict.onnx_conv import to_onnx, register_rewritten_operators\nfrom mlprodict.onnxrt import OnnxInference\nfrom mlprodict.tools.model_info import analyze_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Available optimisations on this machine.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mlprodict.testing.experimental_c_impl.experimental_c import code_optimisation\nprint(code_optimisation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and converting a model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = make_regression(50000, 20)\nX, y = data\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nhgb = HistGradientBoostingRegressor(max_iter=100, max_depth=6)\nhgb.fit(X_train, y_train)\nprint(hgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's get more statistics about the model itself.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pprint(analyze_model(hgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And let's convert it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "register_rewritten_operators()\nonx = to_onnx(hgb, X_train[:1].astype(numpy.float32))\noinf = OnnxInference(onx, runtime='python_compiled')\nprint(oinf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The runtime of the forest is in the following object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(oinf.sequence_[0].ops_)\nprint(oinf.sequence_[0].ops_.rt_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the threshold used to start parallelizing\nbased on the number of observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(oinf.sequence_[0].ops_.rt_.omp_N_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Profiling\n\nThis step involves :epkg:`pyinstrument` to measure\nwhere the time is spent. Both :epkg:`scikit-learn`\nand :epkg:`mlprodict` runtime are called so that\nthe prediction times can be compared.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X32 = X_test.astype(numpy.float32)\n\n\ndef runlocal():\n    with config_context(assume_finite=True):\n        for i in range(0, 100):\n            oinf.run({'X': X32[:1000]})\n            hgb.predict(X_test[:1000])\n\n\nprint(\"profiling...\")\ntxt = profile(runlocal, pyinst_format='text')\nprint(txt[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's measure the performance the average\ncomputation time per observations for 2 to 100\nobservations. The runtime implemented in\n:epkg:`mlprodict` parallizes the computation\nafter a given number of observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs = []\nfor N in tqdm(list(range(2, 21))):\n    m = measure_time(\"oinf.run({'X': x})\",\n                     {'oinf': oinf, 'x': X32[:N]},\n                     div_by_number=True,\n                     number=20)\n    m['N'] = N\n    m['RT'] = 'ONNX'\n    obs.append(m)\n\n    with config_context(assume_finite=True):\n        m = measure_time(\"hgb.predict(x)\",\n                         {'hgb': hgb, 'x': X32[:N]},\n                         div_by_number=True,\n                         number=15)\n    m['N'] = N\n    m['RT'] = 'SKL'\n    obs.append(m)\n\ndf = DataFrame(obs)\nnum = ['min_exec', 'average', 'max_exec']\nfor c in num:\n    df[c] /= df['N']\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\ndf[df.RT == 'ONNX'].set_index('N')[num].plot(ax=ax[0])\nax[0].set_title(\"Average ONNX prediction time per observation in a batch.\")\ndf[df.RT == 'SKL'].set_index('N')[num].plot(ax=ax[1])\nax[1].set_title(\n    \"Average scikit-learn prediction time\\nper observation in a batch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gain from parallelization\n\nThere is a clear gap between after and before 10 observations\nwhen it is parallelized. Does this threshold depends on the number\nof trees in the model?\nFor that we compute for each model the average prediction time\nup to 10 and from 10 to 20.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def parallized_gain(df):\n    df = df[df.RT == 'ONNX']\n    df10 = df[df.N <= 10]\n    t10 = sum(df10['average']) / df10.shape[0]\n    df10p = df[df.N > 10]\n    t10p = sum(df10p['average']) / df10p.shape[0]\n    return t10 / t10p\n\n\nprint('gain', parallized_gain(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measures based on the number of trees\n\nWe trained many models with different number\nof trees to see how the parallelization gain\nis moving. One models is trained for every\ndistinct number of trees and then the prediction\ntime is measured for different number of observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tries_set = [2, 5, 8] + list(range(10, 50, 5)) + list(range(50, 101, 10))\ntries = [(nb, N) for N in range(2, 21, 2) for nb in tries_set]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models = {100: (hgb, oinf)}\nfor nb in tqdm(set(_[0] for _ in tries)):\n    if nb not in models:\n        hgb = HistGradientBoostingRegressor(max_iter=nb, max_depth=6)\n        hgb.fit(X_train, y_train)\n        onx = to_onnx(hgb, X_train[:1].astype(numpy.float32))\n        oinf = OnnxInference(onx, runtime='python_compiled')\n        models[nb] = (hgb, oinf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "prediction time\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs = []\n\nfor nb, N in tqdm(tries):\n    hgb, oinf = models[nb]\n    m = measure_time(\"oinf.run({'X': x})\",\n                     {'oinf': oinf, 'x': X32[:N]},\n                     div_by_number=True,\n                     number=50)\n    m['N'] = N\n    m['nb'] = nb\n    m['RT'] = 'ONNX'\n    obs.append(m)\n\ndf = DataFrame(obs)\nnum = ['min_exec', 'average', 'max_exec']\nfor c in num:\n    df[c] /= df['N']\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compute the gains.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gains = []\nfor nb in set(df['nb']):\n    gain = parallized_gain(df[df.nb == nb])\n    gains.append(dict(nb=nb, gain=gain))\n\ndfg = DataFrame(gains)\ndfg = dfg.sort_values('nb').reset_index(drop=True).copy()\ndfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = dfg.set_index('nb').plot()\nax.set_title(\n    \"Parallelization gain depending\\non the number of trees\\n(max_depth=6).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That does not answer the question we are looking for\nas we would like to know the best threshold *th*\nwhich defines the number of observations for which\nwe should parallelized. This number depends on the number\nof trees. A gain > 1 means the parallization should happen\nHere, even two observations is ok.\nLet's check with lighter trees (``max_depth=2``),\nmaybe in that case, the conclusion is different.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models = {100: (hgb, oinf)}\nfor nb in tqdm(set(_[0] for _ in tries)):\n    if nb not in models:\n        hgb = HistGradientBoostingRegressor(max_iter=nb, max_depth=2)\n        hgb.fit(X_train, y_train)\n        onx = to_onnx(hgb, X_train[:1].astype(numpy.float32))\n        oinf = OnnxInference(onx, runtime='python_compiled')\n        models[nb] = (hgb, oinf)\n\nobs = []\nfor nb, N in tqdm(tries):\n    hgb, oinf = models[nb]\n    m = measure_time(\"oinf.run({'X': x})\",\n                     {'oinf': oinf, 'x': X32[:N]},\n                     div_by_number=True,\n                     number=50)\n    m['N'] = N\n    m['nb'] = nb\n    m['RT'] = 'ONNX'\n    obs.append(m)\n\ndf = DataFrame(obs)\nnum = ['min_exec', 'average', 'max_exec']\nfor c in num:\n    df[c] /= df['N']\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Measures.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gains = []\nfor nb in set(df['nb']):\n    gain = parallized_gain(df[df.nb == nb])\n    gains.append(dict(nb=nb, gain=gain))\n\ndfg = DataFrame(gains)\ndfg = dfg.sort_values('nb').reset_index(drop=True).copy()\ndfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = dfg.set_index('nb').plot()\nax.set_title(\n    \"Parallelization gain depending\\non the number of trees\\n(max_depth=3).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The conclusion is somewhat the same but\nit shows that the bigger the number of trees is\nthe bigger the gain is and under the number of\ncores of the processor.\n\n## Moving the theshold\n\nThe last experiment consists in comparing the prediction\ntime with or without parallelization for different\nnumber of observation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hgb = HistGradientBoostingRegressor(max_iter=40, max_depth=6)\nhgb.fit(X_train, y_train)\nonx = to_onnx(hgb, X_train[:1].astype(numpy.float32))\noinf = OnnxInference(onx, runtime='python_compiled')\n\n\nobs = []\nfor N in tqdm(list(range(2, 51))):\n    oinf.sequence_[0].ops_.rt_.omp_N_ = 100\n    m = measure_time(\"oinf.run({'X': x})\",\n                     {'oinf': oinf, 'x': X32[:N]},\n                     div_by_number=True,\n                     number=20)\n    m['N'] = N\n    m['RT'] = 'ONNX'\n    m['PARALLEL'] = False\n    obs.append(m)\n\n    oinf.sequence_[0].ops_.rt_.omp_N_ = 1\n    m = measure_time(\"oinf.run({'X': x})\",\n                     {'oinf': oinf, 'x': X32[:N]},\n                     div_by_number=True,\n                     number=50)\n    m['N'] = N\n    m['RT'] = 'ONNX'\n    m['PARALLEL'] = True\n    obs.append(m)\n\ndf = DataFrame(obs)\nnum = ['min_exec', 'average', 'max_exec']\nfor c in num:\n    df[c] /= df['N']\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "piv = df[['N', 'PARALLEL', 'average']].pivot('N', 'PARALLEL', 'average')\nax = piv.plot(logy=True)\nax.set_title(\"Prediction time with and without parallelization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parallelization is working.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}