{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Measure ONNX runtime performances\n\nThe following example shows how to use the\ncommand line to compare one or two runtimes\nwith :epkg:`scikit-learn`.\nIt relies on function :func:`validate_runtime\n<mlprodict.cli.validate_runtime>` which can be called\nfrom *python* or through a command line\ndescribed in page `l-CMD2`.\n\n## Run the benchmark\n\nThe following line creates a folder used to dump\ninformation about models which failed during the benchmark.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport pandas\nif not os.path.exists(\"dump_errors\"):\n    os.mkdir(\"dump_errors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The benchmark can be run with a python instruction\nor a command line:\n\n::\n\n  python -m mlprodict validate_runtime -v 1 --out_raw data.csv --out_summary summary.csv\n             -b 1 --dump_folder dump_errors --runtime python,onnxruntime1\n             --models LinearRegression,DecisionTreeRegressor\n             --n_features 4,10 --out_graph bench_png\n             -t \"{\\\"1\\\":{\\\"number\\\":10,\\\"repeat\\\":10},\\\"10\\\":{\\\"number\\\":5,\\\"repeat\\\":5}}\"\n\nWe use the python instruction in this example.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mlprodict.cli import validate_runtime\n\nvalidate_runtime(\n    verbose=1,\n    out_raw=\"data.csv\", out_summary=\"summary.csv\",\n    benchmark=True, dump_folder=\"dump_errors\",\n    runtime=['python', 'onnxruntime1'],\n    models=['LinearRegression', 'DecisionTreeRegressor'],\n    n_features=[4, 10], dtype=\"32\",\n    out_graph=\"bench.png\",\n    time_kwargs={\n        1: {\"number\": 100, \"repeat\": 100},\n        10: {\"number\": 50, \"repeat\": 50},\n        100: {\"number\": 40, \"repeat\": 50},\n        1000: {\"number\": 40, \"repeat\": 40},\n        10000: {\"number\": 20, \"repeat\": 20},\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's show the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pandas.read_csv(\"summary.csv\")\ndf.head(n=2).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's display the graph generated by the function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img = mpimg.imread('bench.png')\nfig = plt.imshow(img)\nfig.axes.get_xaxis().set_visible(False)\nfig.axes.get_yaxis().set_visible(False)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}