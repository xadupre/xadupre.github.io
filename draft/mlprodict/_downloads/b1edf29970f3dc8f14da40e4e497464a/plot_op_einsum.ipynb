{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compares implementations of Einsum\n\nThis example compares different equations for function :epkg:`numpy:einsum`.\nIt compares *numpy* implementation to a custom implementation,\n:epkg:`onnxruntime` implementation and :epkg:`opt-einsum` optimisation.\nIf available, :epkg:`tensorflow` and :epkg:`pytorch` are included as well.\nThe custom implementation does not do any transpose.\nIt uses parallelisation and SIMD optimization when the summation\nhappens on the last axis of both matrices. It only implements\nmatrix multiplication. We also measure the improvment made with\nfunction :func:`einsum <mlprodict.testing.einsum.einsum_fct.einsum>`.\n\n## Available optimisation\n\nThe code shows which optimisation is used for the custom\nimplementation, *AVX* or *SSE* and the number of available processors,\nequal to the default number of used threads to parallelize.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nimport pandas\nimport matplotlib.pyplot as plt\nfrom onnxruntime import InferenceSession\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx.algebra.onnx_ops import OnnxEinsum\nfrom cpyquickhelper.numbers import measure_time\nfrom tqdm import tqdm\nfrom opt_einsum import contract\nfrom mlprodict.testing.experimental_c_impl.experimental_c import (\n    custom_einsum_float, code_optimisation)\nfrom mlprodict.testing.einsum.einsum_fct import _einsum\nprint(code_optimisation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Einsum: common code\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    from tensorflow import einsum as tf_einsum, convert_to_tensor\nexcept ImportError:\n    tf_einsum = None\ntry:\n    from torch import einsum as torch_einsum, from_numpy\nexcept ImportError:\n    torch_einsum = None\n\n\ndef build_ort_einsum(equation, op_version=14):  # opset=13, 14, ...\n    node = OnnxEinsum('x', 'y', equation=equation,\n                      op_version=op_version,\n                      output_names=['z'])\n    onx = node.to_onnx(inputs=[('x', FloatTensorType()),\n                               ('y', FloatTensorType())],\n                       target_opset=op_version)\n    sess = InferenceSession(onx.SerializeToString())\n    return lambda x, y: sess.run(None, {'x': x, 'y': y})\n\n\ndef build_ort_decomposed(equation, op_version=14):  # opset=13, 14, ...\n    cache = _einsum(equation, numpy.float32, opset=op_version,\n                    optimize=True, verbose=True, runtime=\"python\")\n    if not hasattr(cache, 'onnx_'):\n        cache.build()\n    sess = InferenceSession(cache.onnx_.SerializeToString())\n    return lambda x, y: sess.run(None, {'X0': x, 'X1': y})\n\n\ndef loop_einsum_eq(fct, equation, xs, ys):\n    for x, y in zip(xs, ys):\n        fct(equation, x, y)\n\n\ndef loop_einsum_eq_th(fct, equation, xs, ys):\n    for x, y in zip(xs, ys):\n        fct(equation, x, y, nthread=-1)\n\n\ndef loop_einsum(fct, xs, ys):\n    for x, y in zip(xs, ys):\n        fct(x, y)\n\n\ndef custom_einsum_float_tr(eq, x, y):\n    if eq == \"bshn,bthn->bnts\":\n        x = x.transpose((0, 1, 3, 2))\n        y = y.transpose((0, 1, 3, 2))\n        return custom_einsum_float(\"bsnh,btnh->bnts\", x, y, nthread=-1)\n    if eq == \"bhsn,bhtn->bnts\":\n        x = x.transpose((0, 2, 3, 1))\n        y = y.transpose((0, 2, 3, 1))\n        return custom_einsum_float(\"bsnh,btnh->bnts\", x, y, nthread=-1)\n    return custom_einsum_float(eq, x, y, nthread=-1)\n\n\ndef benchmark_equation(equation):\n    # equations\n    ort_einsum = build_ort_einsum(equation)\n    ort_einsum_decomposed = build_ort_decomposed(equation)\n    res = []\n    for dim in tqdm([8, 16, 32, 64, 100, 128, 200,\n                     256, 500, 512]):\n        xs = [numpy.random.rand(2, dim, 12, 64).astype(numpy.float32)\n              for _ in range(5)]\n        ys = [numpy.random.rand(2, dim, 12, 64).astype(numpy.float32)\n              for _ in range(5)]\n\n        # numpy\n        ctx = dict(equation=equation, xs=xs, ys=ys, einsum=numpy.einsum,\n                   loop_einsum=loop_einsum, loop_einsum_eq=loop_einsum_eq,\n                   loop_einsum_eq_th=loop_einsum_eq_th)\n        obs = measure_time(\n            \"loop_einsum_eq(einsum, equation, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=5, number=1)\n        obs['dim'] = dim\n        obs['fct'] = 'numpy.einsum'\n        res.append(obs)\n\n        # opt-einsum\n        ctx['einsum'] = contract\n        obs = measure_time(\n            \"loop_einsum_eq(einsum, equation, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=5, number=1)\n        obs['dim'] = dim\n        obs['fct'] = 'opt-einsum'\n        res.append(obs)\n\n        # onnxruntime\n        ctx['einsum'] = ort_einsum\n        obs = measure_time(\n            \"loop_einsum(einsum, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=5, number=1)\n        obs['dim'] = dim\n        obs['fct'] = 'ort_einsum'\n        res.append(obs)\n\n        # onnxruntime decomposed\n        ctx['einsum'] = ort_einsum_decomposed\n        obs = measure_time(\n            \"loop_einsum(einsum, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=5, number=1)\n        obs['dim'] = dim\n        obs['fct'] = 'ort_dec'\n        res.append(obs)\n\n        # custom implementation\n        ctx['einsum'] = custom_einsum_float\n        obs = measure_time(\n            \"loop_einsum_eq_th(einsum, equation, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=5, number=1)\n        obs['dim'] = dim\n        obs['fct'] = 'c_einsum'\n        res.append(obs)\n\n        # transpose + custom implementation\n        ctx['einsum'] = custom_einsum_float_tr\n        obs = measure_time(\n            \"loop_einsum_eq(einsum, equation, xs, ys)\",\n            div_by_number=True, context=ctx, repeat=5, number=1)\n        obs['dim'] = dim\n        obs['fct'] = 'c_einsum_tr'\n        res.append(obs)\n\n        if tf_einsum is not None:\n            # tensorflow\n            ctx['einsum'] = tf_einsum\n            ctx['xs'] = [convert_to_tensor(x) for x in xs]\n            ctx['ys'] = [convert_to_tensor(y) for y in ys]\n            obs = measure_time(\n                \"loop_einsum_eq(einsum, equation, xs, ys)\",\n                div_by_number=True, context=ctx, repeat=5, number=1)\n            obs['dim'] = dim\n            obs['fct'] = 'tf_einsum'\n            res.append(obs)\n\n        if torch_einsum is not None:\n            # torch\n            ctx['einsum'] = torch_einsum\n            ctx['xs'] = [from_numpy(x) for x in xs]\n            ctx['ys'] = [from_numpy(y) for y in ys]\n            obs = measure_time(\n                \"loop_einsum_eq(einsum, equation, xs, ys)\",\n                div_by_number=True, context=ctx, repeat=5, number=1)\n            obs['dim'] = dim\n            obs['fct'] = 'torch_einsum'\n            res.append(obs)\n\n    # Dataframes\n    df = pandas.DataFrame(res)\n    piv = df.pivot('dim', 'fct', 'average')\n\n    rs = piv.copy()\n    rs['c_einsum'] = rs['numpy.einsum'] / rs['c_einsum']\n    rs['ort_einsum'] = rs['numpy.einsum'] / rs['ort_einsum']\n    rs['ort_dec'] = rs['numpy.einsum'] / rs['ort_dec']\n    rs['opt-einsum'] = rs['numpy.einsum'] / rs['opt-einsum']\n    if 'c_einsum_tr' in rs.columns:\n        rs['c_einsum_tr'] = rs['numpy.einsum'] / rs['c_einsum_tr']\n    if 'tf_einsum' in rs.columns:\n        rs['tf_einsum'] = rs['numpy.einsum'] / rs['tf_einsum']\n    if 'torch_einsum' in rs.columns:\n        rs['torch_einsum'] = rs['numpy.einsum'] / rs['torch_einsum']\n    rs['numpy.einsum'] = 1.\n\n    # Graphs.\n    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n    piv.plot(logx=True, logy=True, ax=ax[0],\n             title=\"Einsum benchmark\\n%s -- (2, N, 12, 64)\"\n                   \" lower better\" % equation)\n    ax[0].legend(prop={\"size\": 9})\n    rs.plot(logx=True, logy=True, ax=ax[1],\n            title=\"Einsum Speedup, baseline=numpy\\n%s -- (2, N, 12, 64)\"\n                  \" higher better\" % equation)\n    ax[1].plot([min(rs.index), max(rs.index)], [0.5, 0.5], 'g--')\n    ax[1].plot([min(rs.index), max(rs.index)], [2., 2.], 'g--')\n    ax[1].legend(prop={\"size\": 9})\n\n    return df, rs, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First equation: bsnh,btnh->bnts\n\nThe decomposition of this equation without einsum function gives\nthe following.\n\n .. gdot::\n      :script:\n\n      from mlprodict.testing.einsum import decompose_einsum_equation\n      dec = decompose_einsum_equation(\n          'bsnh,btnh->bnts', strategy='numpy', clean=True)\n      print(dec.to_dot())\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dfs = []\nequation = \"bsnh,btnh->bnts\"\ndf, piv, ax = benchmark_equation(equation)\ndf.pivot(\"fct\", \"dim\", \"average\")\ndfs.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Second equation: bshn,bthn->bnts\n\nThe summation does not happen on the last axis but\non the previous one.\nIs it worth transposing before doing the summation...\nThe decomposition of this equation without einsum function gives\nthe following.\n\n .. gdot::\n      :script:\n\n      from mlprodict.testing.einsum import decompose_einsum_equation\n      dec = decompose_einsum_equation(\n          'bshn,bthn->bnts', strategy='numpy', clean=True)\n      print(dec.to_dot())\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "equation = \"bshn,bthn->bnts\"\ndf, piv, ax = benchmark_equation(equation)\ndf.pivot(\"fct\", \"dim\", \"average\")\ndfs.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Third equation: bhsn,bhtn->bnts\n\nThe summation does not happen on the last axis but\non the second one. It is worth transposing before multiplying.\nThe decomposition of this equation without einsum function gives\nthe following.\n\n .. gdot::\n      :script:\n\n      from mlprodict.testing.einsum import decompose_einsum_equation\n      dec = decompose_einsum_equation(\n          'bhsn,bhtn->bnts', strategy='numpy', clean=True)\n      print(dec.to_dot())\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "equation = \"bhsn,bhtn->bnts\"\ndf, piv, ax = benchmark_equation(equation)\ndf.pivot(\"fct\", \"dim\", \"average\")\ndfs.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\npytorch seems quite efficient on these examples.\nThe custom implementation was a way to investigate\nthe implementation of einsum and find some ways to optimize it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "merged = pandas.concat(dfs)\nname = \"einsum\"\nmerged.to_csv(\"plot_%s.csv\" % name, index=False)\nmerged.to_excel(\"plot_%s.xlsx\" % name, index=False)\nplt.savefig(\"plot_%s.png\" % name)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}