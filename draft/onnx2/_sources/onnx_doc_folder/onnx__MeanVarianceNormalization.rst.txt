
.. _l-onnx-doc-MeanVarianceNormalization:

=========================
MeanVarianceNormalization
=========================

.. contents::
    :local:


.. _l-onnx-op-meanvariancenormalization-13:

MeanVarianceNormalization - 13
==============================

**Version**

* **name**: `MeanVarianceNormalization (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#MeanVarianceNormalization>`_
* **domain**: **main**
* **since_version**: **13**
* **function**: True
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 13**.

**Summary**

A MeanVarianceNormalization Function: Perform mean variance normalization
on the input tensor X using formula: <br/> ``` (X-EX)/sqrt(E(X-EX)^2) ```

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to
  caculate along axes [0,2,3] for calculating mean and variance along
  each channel. Two variables with the same C-coordinate are
  associated with the same mean and variance.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(bfloat16),
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to all numeric tensors.

**Examples**

**default**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        "MeanVarianceNormalization", inputs=["X"], outputs=["Y"]
    )

    input_data = np.array(
        [
            [
                [[0.8439683], [0.5665144], [0.05836735]],
                [[0.02916367], [0.12964272], [0.5060197]],
                [[0.79538304], [0.9411346], [0.9546573]],
            ],
            [
                [[0.17730942], [0.46192095], [0.26480448]],
                [[0.6746842], [0.01665257], [0.62473077]],
                [[0.9240844], [0.9722341], [0.11965699]],
            ],
            [
                [[0.41356155], [0.9129373], [0.59330076]],
                [[0.81929934], [0.7862604], [0.11799799]],
                [[0.69248444], [0.54119414], [0.07513223]],
            ],
        ],
        dtype=np.float32,
    )

    # Calculate expected output data
    data_mean = np.mean(input_data, axis=(0, 2, 3), keepdims=1)
    data_mean_squared = np.power(data_mean, 2)
    data_squared = np.power(input_data, 2)
    data_squared_mean = np.mean(data_squared, axis=(0, 2, 3), keepdims=1)
    std = np.sqrt(data_squared_mean - data_mean_squared)
    expected_output = (input_data - data_mean) / (std + 1e-9)

    expect(node, inputs=[input_data], outputs=[expected_output], name="test_mvn")

.. toctree::
    text_diff_MeanVarianceNormalization_9_13

.. _l-onnx-op-meanvariancenormalization-9:

MeanVarianceNormalization - 9
=============================

**Version**

* **name**: `MeanVarianceNormalization (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#MeanVarianceNormalization>`_
* **domain**: **main**
* **since_version**: **9**
* **function**: True
* **support_level**: SupportType.COMMON
* **shape inference**: False

This version of the operator has been available
**since version 9**.

**Summary**

A MeanVarianceNormalization Function: Perform mean variance normalization
on the input tensor X using formula: <br/> ``` (X-EX)/sqrt(E(X-EX)^2) ```

**Attributes**

* **axes**:
  A list of integers, along which to reduce. The default is to
  caculate along axes [0,2,3] for calculating mean and variance along
  each channel. Two variables with the same C-coordinate are
  associated with the same mean and variance.

**Inputs**

* **X** (heterogeneous) - **T**:
  Input tensor

**Outputs**

* **Y** (heterogeneous) - **T**:
  Output tensor

**Type Constraints**

* **T** in (
  tensor(double),
  tensor(float),
  tensor(float16)
  ):
  Constrain input and output types to all numeric tensors.
