
.. _l-onnx-doccom-ms-internal-nhwc-QLinearConv:

==================================
com.ms.internal.nhwc - QLinearConv
==================================

.. contents::
    :local:


.. _l-onnx-opcom-ms-internal-nhwc-qlinearconv-10:

QLinearConv - 10
================

**Version**

* **name**: `QLinearConv (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#com.ms.internal.nhwc.QLinearConv>`_
* **domain**: **com.ms.internal.nhwc**
* **since_version**: **10**
* **function**:
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 10 of domain com.ms.internal.nhwc**.

**Summary**

**Attributes**

* **auto_pad - STRING** :   auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
  Where default value is NOTSET, which means explicit padding is used.
  SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i]
  = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding
  is split between the two sides equally or almost equally (depending
  on whether it is even or odd). In case the padding is an odd number,
  the extra padding is added at the end for SAME_UPPER and at the
  beginning for SAME_LOWER.
* **dilations - INTS** :   dilation value along each spatial axis of the filter. If not
  present, the dilation defaults to 1 along each spatial axis.
* **group - INT** :   number of groups input channels and output channels are divided
  into. default is 1.
* **kernel_shape - INTS** :   The shape of the convolution kernel. If not present, should be
  inferred from input 'w'.
* **pads - INTS** :   Padding for the beginning and ending along each spatial axis, it can
  take any value greater than or equal to 0.The value represent the
  number of pixels added to the beginning and end part of the
  corresponding axis.`pads` format should be as follow [x1_begin,
  x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels
  added at the beginning of axis `i` and xi_end, the number of pixels
  added at the end of axis `i`.This attribute cannot be used
  simultaneously with auto_pad attribute. If not present, the padding
  defaultsto 0 along start and end of each spatial axis.
* **strides - INTS** :   Stride along each spatial axis. If not present, the stride defaults
  to 1 along each spatial axis.

**Inputs**

Between 8 and 9 inputs.

* **x** (heterogeneous) - **T1**:

* **x_scale** (heterogeneous) - **tensor(float)**:

* **x_zero_point** (heterogeneous) - **T1**:

* **w** (heterogeneous) - **T2**:

* **w_scale** (heterogeneous) - **tensor(float)**:

* **w_zero_point** (heterogeneous) - **T2**:

* **y_scale** (heterogeneous) - **tensor(float)**:

* **y_zero_point** (heterogeneous) - **T3**:

* **B** (optional, heterogeneous) - **T4**:

**Outputs**

* **y** (heterogeneous) - **T3**:

**Type Constraints**

* **T1** in (
  tensor(int8),
  tensor(uint8)
  ):
  Constrain input type to 8-bit integer tensor.
* **T2** in (
  tensor(int8),
  tensor(uint8)
  ):
  Constrain filter type to 8-bit integer tensor.
* **T3** in (
  tensor(int8),
  tensor(uint8)
  ):
  Constrain output type to 8-bit integer tensor.
* **T4** in (
  tensor(int32)
  ):
  Constrain bias type to 32-bit integer tensor.

**Examples**

**default**

::

    import numpy as np
    import onnx

    node = onnx.helper.make_node(
        "QLinearConv",
        inputs=[
            "x",
            "x_scale",
            "x_zero_point",
            "w",
            "w_scale",
            "w_zero_point",
            "y_scale",
            "y_zero_point",
        ],
        outputs=["y"],
    )

    x = np.array(
        [
            [255, 174, 162, 25, 203, 168, 58],
            [15, 59, 237, 95, 129, 0, 64],
            [56, 242, 153, 221, 168, 12, 166],
            [232, 178, 186, 195, 237, 162, 237],
            [188, 39, 124, 77, 80, 102, 43],
            [127, 230, 21, 83, 41, 40, 134],
            [255, 154, 92, 141, 42, 148, 247],
        ],
        dtype=np.uint8,
    ).reshape((1, 1, 7, 7))

    x_scale = np.float32(0.00369204697)
    x_zero_point = np.uint8(132)

    w = np.array([0], dtype=np.uint8).reshape((1, 1, 1, 1))

    w_scale = np.array([0.00172794575], dtype=np.float32)
    w_zero_point = np.array([255], dtype=np.uint8)

    y_scale = np.float32(0.00162681262)
    y_zero_point = np.uint8(123)

    output = np.array(
        [
            [0, 81, 93, 230, 52, 87, 197],
            [240, 196, 18, 160, 126, 255, 191],
            [199, 13, 102, 34, 87, 243, 89],
            [23, 77, 69, 60, 18, 93, 18],
            [67, 216, 131, 178, 175, 153, 212],
            [128, 25, 234, 172, 214, 215, 121],
            [0, 101, 163, 114, 213, 107, 8],
        ],
        dtype=np.uint8,
    ).reshape((1, 1, 7, 7))

    expect(
        node,
        inputs=[
            x,
            x_scale,
            x_zero_point,
            w,
            w_scale,
            w_zero_point,
            y_scale,
            y_zero_point,
        ],
        outputs=[output],
        name="test_qlinearconv",
    )
