
.. _l-onnx-doc-QuantizeLinear:

==============
QuantizeLinear
==============


.. _l-onnx-op-quantizelinear-10:

QuantizeLinear - 10
===================

**Version**

* **name**: `QuantizeLinear (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#QuantizeLinear>`_
* **domain**: **main**
* **since_version**: **10**
* **function**:
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 10**.

**Summary**

**Inputs**

Between 2 and 3 inputs.

* **x** (heterogeneous) - **T1**:

* **y_scale** (heterogeneous) - **tensor(float)**:

* **y_zero_point** (optional, heterogeneous) - **T2**:

**Outputs**

* **y** (heterogeneous) - **T2**:

**Type Constraints**

* **T1** in (
  tensor(float),
  tensor(int32)
  ):
  Constrain 'x' to float or int32 tensor.
* **T2** in (
  tensor(int8),
  tensor(uint8)
  ):
  Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
