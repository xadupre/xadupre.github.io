
.. _l-onnx-doccom-microsoft-DynamicQuantizeMatMul:

=====================================
com.microsoft - DynamicQuantizeMatMul
=====================================

.. contents::
    :local:


.. _l-onnx-opcom-microsoft-dynamicquantizematmul-1:

DynamicQuantizeMatMul - 1
=========================

**Version**

* **name**: `DynamicQuantizeMatMul (GitHub) <https://github.com/onnx/onnx/blob/main/docs/Operators.md#com.microsoft.DynamicQuantizeMatMul>`_
* **domain**: **com.microsoft**
* **since_version**: **1**
* **function**:
* **support_level**: SupportType.COMMON
* **shape inference**: True

This version of the operator has been available
**since version 1 of domain com.microsoft**.

**Summary**

**Inputs**

Between 3 and 5 inputs.

* **A** (heterogeneous) - **T1**:

* **B** (heterogeneous) - **T2**:

* **b_scale** (heterogeneous) - **T1**:

* **b_zero_point** (optional, heterogeneous) - **T2**:

* **bias** (optional, heterogeneous) - **T1**:

**Outputs**

* **Y** (heterogeneous) - **T1**:

**Type Constraints**

* **T1** in (
  tensor(float)
  ):
  Constrain input A, b_scale and output Y data type as float tensor.
* **T2** in (
  tensor(int8),
  tensor(uint8)
  ):
  Constrain input B data type to 8-bit integer tensor.

**Examples**
