
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>module training.sgd_learning_loss &#8212; onnxcustom</title>
    
    <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="module training.sgd_learning_penalty" href="sgd_learning_penalty.html" />
    <link rel="prev" title="module training.ortgradient" href="ortgradient.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../gyexamples/index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../doc.html">
   Agility
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../i_ex.html">
   Short examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../i_faq.html">
   FAQ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../i_cmd.html">
   Command lines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../HISTORY.html">
   History
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   onnxcustom: custom ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../all_indexes.html">
   All indexes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../all_report.html">
   Statistics on code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../filechanges.html">
   Changes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../index_class.html">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../index_function.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../index_method.html">
   Methods
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../index_module.html">
   Modules
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       __init__
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../__main__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       __main__
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cli/profiling.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       cli.profiling
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../plotting/plotting_onnx.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       plotting.plotting_onnx
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="_base.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training._base
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="_base_estimator.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training._base_estimator
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="_base_onnx_function.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training._base_onnx_function
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data_loader.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.data_loader
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="excs.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.excs
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="grad_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.grad_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimizers.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.optimizers
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimizers_partial.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.optimizers_partial
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ortgradient.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.ortgradient
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.sgd_learning_loss
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sgd_learning_penalty.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.sgd_learning_penalty
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sgd_learning_rate.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       training.sgd_learning_rate
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/__init__.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/benchmark.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.benchmark
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/doc_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.doc_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/imagenet_classes.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.imagenet_classes
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/nvprof2json.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.nvprof2json
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/onnx_function.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.onnx_function
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/onnx_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.onnx_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/onnx_rewriter.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.onnx_rewriter
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/onnxruntime_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.onnxruntime_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/orttraining_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.orttraining_helper
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../utils/print_helper.html">
     module
     <code class="docutils literal notranslate">
      <span class="pre">
       utils.print_helper
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../index_staticmethod.html">
   Static Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../blog/blogindex.html">
   Blog Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../license.html">
   License
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#short-summary">
   Short summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classes">
   Classes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#static-methods">
   Static Methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods">
   Methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-onnxcustom.training.sgd_learning_loss">
   Documentation
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="module-training-sgd-learning-loss">
<span id="f-sgdlearningloss"></span><h1>module <code class="docutils literal notranslate"><span class="pre">training.sgd_learning_loss</span></code><a class="headerlink" href="#module-training-sgd-learning-loss" title="Permalink to this headline">¶</a></h1>
<div class="graphviz"><object data="../../_images/inheritance-1650111775daeceb37ed644960c04bdd714e9fcf.svg" type="image/svg+xml" class="inheritance graphviz">
<p class="warning">Inheritance diagram of onnxcustom.training.sgd_learning_loss</p></object></div>
<section id="short-summary">
<h2>Short summary<a class="headerlink" href="#short-summary" title="Permalink to this headline">¶</a></h2>
<p>module <code class="docutils literal notranslate"><span class="pre">onnxcustom.training.sgd_learning_loss</span></code></p>
<p>Helper for <a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a>.</p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L6">source on GitHub</a></p>
</section>
<section id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h2>
<table class="table">
<colgroup>
<col style="width: 39%" />
<col style="width: 61%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>class</p></th>
<th class="head"><p>truncated documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss" title="onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbsoluteLearningLoss</span></code></a></p></td>
<td><p>Implements a square loss <img class="math" src="../../_images/math/bd135635a9a0e36d9d8c7711cbde8ce640af3e73.svg" alt="|Y - Z|"/> where <em>Y</em> is the output and <em>Z</em> the expected output. See <code class="xref py py-func docutils literal notranslate"><span class="pre">_onnx_grad_loss_absolute_error()</span></code> …</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseLearningLoss</span></code></a></p></td>
<td><p>Class handling the loss for class <code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientForwardBackwardOptimizer</span></code>. All classes inheriting from this …</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.ElasticLearningLoss" title="onnxcustom.training.sgd_learning_loss.ElasticLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElasticLearningLoss</span></code></a></p></td>
<td><p>Implements a square loss <img class="math" src="../../_images/math/bb8f2acc6d837f276f8f1496f1d17f69f6ad55d2.svg" alt="(Y - Z)^2 \alpha + |Y - Z| * \beta"/> where <em>Y</em> is the output and <em>Z</em> the expected …</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.NegLogLearningLoss" title="onnxcustom.training.sgd_learning_loss.NegLogLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">NegLogLearningLoss</span></code></a></p></td>
<td><p>Implements a negative log loss <cite>‘log(yt, yp) = -(1-yt)log(1-yp) - ytlog(yp)</cite>, this only works for a binary classification …</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.SquareLearningLoss" title="onnxcustom.training.sgd_learning_loss.SquareLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">SquareLearningLoss</span></code></a></p></td>
<td><p>Implements a square loss <img class="math" src="../../_images/math/220ff2fdeb35e1fb7fb11d4f769a6e235346b32b.svg" alt="(Y - Z)^2"/> where <em>Y</em> is the output and <em>Z</em> the expected output. See <code class="xref py py-func docutils literal notranslate"><span class="pre">_onnx_grad_loss_square_error()</span></code> …</p></td>
</tr>
</tbody>
</table>
</section>
<section id="static-methods">
<h2>Static Methods<a class="headerlink" href="#static-methods" title="Permalink to this headline">¶</a></h2>
<table class="table">
<colgroup>
<col style="width: 59%" />
<col style="width: 41%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>staticmethod</p></th>
<th class="head"><p>truncated documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">select</span></code></p></td>
<td><p>Returns an instance of a given initialized with <em>kwargs</em>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.select" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.select"><code class="xref py py-meth docutils literal notranslate"><span class="pre">select</span></code></a></p></td>
<td><p>Returns an instance of a given initialized with <em>kwargs</em>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">select</span></code></p></td>
<td><p>Returns an instance of a given initialized with <em>kwargs</em>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">select</span></code></p></td>
<td><p>Returns an instance of a given initialized with <em>kwargs</em>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">select</span></code></p></td>
<td><p>Returns an instance of a given initialized with <em>kwargs</em>.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="methods">
<h2>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h2>
<table class="table">
<colgroup>
<col style="width: 52%" />
<col style="width: 48%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>method</p></th>
<th class="head"><p>truncated documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.__init__" title="onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.__init__" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.__init__" title="onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.__init__" title="onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.SquareLearningLoss.__init__" title="onnxcustom.training.sgd_learning_loss.SquareLearningLoss.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">_call_iobinding</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss._call_iobinding" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss._call_iobinding"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_call_iobinding</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">_call_iobinding</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">_call_iobinding</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">_call_iobinding</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.build_onnx_function" title="onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.build_onnx_function"><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_function</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.build_onnx_function" title="onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.build_onnx_function"><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_function</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.build_onnx_function" title="onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.build_onnx_function"><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_function</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.SquareLearningLoss.build_onnx_function" title="onnxcustom.training.sgd_learning_loss.SquareLearningLoss.build_onnx_function"><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_function</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_score_function</span></code></p></td>
<td><p>Assuming the loss function was created. This one takes the onnx graph and generate the onnx graph for the …</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.build_onnx_score_function" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.build_onnx_score_function"><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_score_function</span></code></a></p></td>
<td><p>Assuming the loss function was created. This one takes the onnx graph and generate the onnx graph for the …</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_score_function</span></code></p></td>
<td><p>Assuming the loss function was created. This one takes the onnx graph and generate the onnx graph for the …</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_score_function</span></code></p></td>
<td><p>Assuming the loss function was created. This one takes the onnx graph and generate the onnx graph for the …</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">build_onnx_score_function</span></code></p></td>
<td><p>Assuming the loss function was created. This one takes the onnx graph and generate the onnx graph for the …</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_gradient</span></code></p></td>
<td><p>Returns the loss and the gradient as OrtValue.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_gradient" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_gradient"><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_gradient</span></code></a></p></td>
<td><p>Returns the loss and the gradient as OrtValue.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_gradient</span></code></p></td>
<td><p>Returns the loss and the gradient as OrtValue.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_gradient</span></code></p></td>
<td><p>Returns the loss and the gradient as OrtValue.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_gradient</span></code></p></td>
<td><p>Returns the loss and the gradient as OrtValue.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_scores</span></code></p></td>
<td><p>Returns the weighted loss (or score) for every observation as OrtValue.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_scores" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_scores"><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_scores</span></code></a></p></td>
<td><p>Returns the weighted loss (or score) for every observation as OrtValue.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_scores</span></code></p></td>
<td><p>Returns the weighted loss (or score) for every observation as OrtValue.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_scores</span></code></p></td>
<td><p>Returns the weighted loss (or score) for every observation as OrtValue.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss_scores</span></code></p></td>
<td><p>Returns the weighted loss (or score) for every observation as OrtValue.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-onnxcustom.training.sgd_learning_loss">
<span id="documentation"></span><h2>Documentation<a class="headerlink" href="#module-onnxcustom.training.sgd_learning_loss" title="Permalink to this headline">¶</a></h2>
<p>Helper for <a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a>.</p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L6">source on GitHub</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onnxcustom.training.sgd_learning_loss.</span></span><span class="sig-name descname"><span class="pre">AbsoluteLearningLoss</span></span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">onnxcustom.training.sgd_learning_loss.BaseLearningLoss</span></code></a></p>
<p>Implements a square loss <img class="math" src="../../_images/math/bd135635a9a0e36d9d8c7711cbde8ce640af3e73.svg" alt="|Y - Z|"/>
where <em>Y</em> is the output and <em>Z</em> the expected output.
See <a class="reference internal" href="../utils/onnx_function.html#onnxcustom.utils.onnx_function._onnx_grad_loss_absolute_error" title="onnxcustom.utils.onnx_function._onnx_grad_loss_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">_onnx_grad_loss_absolute_error</span></code></a> for the ONNX
implementation.</p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L178">source on GitHub</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.build_onnx_function">
<span class="sig-name descname"><span class="pre">build_onnx_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss.build_onnx_function" title="Permalink to this definition">¶</a></dt>
<dd><p>This class updates the weights.
It assumes it can do operator on <em>OrtValue</em>.
This can be done through ONNX graph.
This function creates <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a>
which do that.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opset</strong> – opset to use</p></li>
<li><p><strong>device</strong> – <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/api/onnxruntime_python/helpers.html#c-class-ortdevice">C_OrtDevice</a></p></li>
<li><p><strong>args</strong> – additional arguments</p></li>
</ul>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L115">source on GitHub</a></p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.BaseLearningLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onnxcustom.training.sgd_learning_loss.</span></span><span class="sig-name descname"><span class="pre">BaseLearningLoss</span></span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="_base_onnx_function.html#onnxcustom.training._base_onnx_function.BaseLearningOnnx" title="onnxcustom.training._base_onnx_function.BaseLearningOnnx"><code class="xref py py-class docutils literal notranslate"><span class="pre">onnxcustom.training._base_onnx_function.BaseLearningOnnx</span></code></a></p>
<p>Class handling the loss for class
<a class="reference internal" href="optimizers_partial.html#onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer" title="onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientForwardBackwardOptimizer</span></code></a>.
All classes inheriting from this one creates one ONNX function,
returning the loss and the gradient of the loss against the
outputs. Method <cite>loss_gradient</cite> is the main method, it computes
the loss and the gradient defiend by one ONNX graph and
executed by an instance of <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a>.</p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L22">source on GitHub</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.BaseLearningLoss._call_iobinding">
<span class="sig-name descname"><span class="pre">_call_iobinding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sess</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bind</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss._call_iobinding" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.build_onnx_score_function">
<span class="sig-name descname"><span class="pre">build_onnx_score_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.build_onnx_score_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Assuming the loss function was created. This
one takes the onnx graph and generate the onnx graph
for the method <cite>loss_score</cite>.</p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L33">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_gradient">
<span class="sig-name descname"><span class="pre">loss_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the loss and the gradient as OrtValue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> – device where the training takes place</p></li>
<li><p><strong>expected</strong> – expected value</p></li>
<li><p><strong>predicted</strong> – predicted value</p></li>
<li><p><strong>weight</strong> – optional, training weights
(same dimension as expected and predicted tensors)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss and gradient</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L64">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_scores">
<span class="sig-name descname"><span class="pre">loss_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.loss_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the weighted loss (or score)
for every observation as OrtValue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> – device where the training takes place</p></li>
<li><p><strong>expected</strong> – expected value</p></li>
<li><p><strong>predicted</strong> – predicted value</p></li>
<li><p><strong>weight</strong> – optional, training weights
(same dimension as expected and predicted tensors)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a score for every observation</p>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L96">source on GitHub</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.BaseLearningLoss.select">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">select</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">class_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an instance of a given initialized with
<em>kwargs</em>.
:param class_name: an instance of <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseLearningLoss</span></code></a></p>
<blockquote>
<div><p>or a string among the following class names (see below)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>instance of <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseLearningLoss</span></code></a></p>
</dd>
</dl>
<p>Possible values for <em>class_name</em>:
* <cite>‘square_error’</cite>: see <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.SquareLearningLoss" title="onnxcustom.training.sgd_learning_loss.SquareLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">SquareLearningLoss</span></code></a>
* <cite>‘absolute_error’</cite>: see <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss" title="onnxcustom.training.sgd_learning_loss.AbsoluteLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbsoluteLearningLoss</span></code></a>
* <cite>‘elastic_error’</cite>: see <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.ElasticLearningLoss" title="onnxcustom.training.sgd_learning_loss.ElasticLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElasticLearningLoss</span></code></a></p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L128">source on GitHub</a></p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.ElasticLearningLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onnxcustom.training.sgd_learning_loss.</span></span><span class="sig-name descname"><span class="pre">ElasticLearningLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">l1_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.ElasticLearningLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">onnxcustom.training.sgd_learning_loss.BaseLearningLoss</span></code></a></p>
<p>Implements a square loss
<img class="math" src="../../_images/math/bb8f2acc6d837f276f8f1496f1d17f69f6ad55d2.svg" alt="(Y - Z)^2 \alpha + |Y - Z| * \beta"/>
where <em>Y</em> is the output and <em>Z</em> the expected output,
<img class="math" src="../../_images/math/35093c7ccc735c18e6452789bcb7ec50e0cb0c43.svg" alt="\alpha"/> is <em>l2_weight</em> and <img class="math" src="../../_images/math/8fd96498a01957a1ce6cb102fc544d7e32ae2973.svg" alt="\beta"/>
is <em>l1_weight</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>l1_weight</strong> – weight of L1 norm</p></li>
<li><p><strong>l2_weight</strong> – weight of L2 norm</p></li>
</ul>
</dd>
</dl>
<p>See <a class="reference internal" href="../utils/onnx_function.html#onnxcustom.utils.onnx_function._onnx_grad_loss_elastic_error" title="onnxcustom.utils.onnx_function._onnx_grad_loss_elastic_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">_onnx_grad_loss_elastic_error</span></code></a> for the ONNX
implementation.</p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L214">source on GitHub</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">l1_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.build_onnx_function">
<span class="sig-name descname"><span class="pre">build_onnx_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.ElasticLearningLoss.build_onnx_function" title="Permalink to this definition">¶</a></dt>
<dd><p>This class updates the weights.
It assumes it can do operator on <em>OrtValue</em>.
This can be done through ONNX graph.
This function creates <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a>
which do that.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opset</strong> – opset to use</p></li>
<li><p><strong>device</strong> – <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/api/onnxruntime_python/helpers.html#c-class-ortdevice">C_OrtDevice</a></p></li>
<li><p><strong>args</strong> – additional arguments</p></li>
</ul>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L115">source on GitHub</a></p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.NegLogLearningLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onnxcustom.training.sgd_learning_loss.</span></span><span class="sig-name descname"><span class="pre">NegLogLearningLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probability_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sigmoid'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.NegLogLearningLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">onnxcustom.training.sgd_learning_loss.BaseLearningLoss</span></code></a></p>
<p>Implements a negative log loss
<cite>‘log(yt, yp) = -(1-yt)log(1-yp) - ytlog(yp)</cite>,
this only works for a binary classification where <em>yp</em> is the
predicted probability, <em>yt</em> is the expected probability.
<em>yt</em> is expected to be binary, <em>yp</em> is a matrix with two
columns, the sum on every line is 1.
However, this loss is usually applied after a function softmax
and the gradient is directly computed from the loss to the
raw score before they are processed through the softmax function
(see class <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/linear_model/_sgd_fast.pyx#L236">Log</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eps</strong> – clipping value for probabilities,
avoids computing <cite>log(0)</cite></p></li>
<li><p><strong>probability_function</strong> – function to convert
raw scores into probabilities, default value is <cite>sigmoid</cite>
for a logistic regression</p></li>
</ul>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L260">source on GitHub</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probability_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sigmoid'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.build_onnx_function">
<span class="sig-name descname"><span class="pre">build_onnx_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.NegLogLearningLoss.build_onnx_function" title="Permalink to this definition">¶</a></dt>
<dd><p>This class updates the weights.
It assumes it can do operator on <em>OrtValue</em>.
This can be done through ONNX graph.
This function creates <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a>
which do that.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opset</strong> – opset to use</p></li>
<li><p><strong>device</strong> – <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/api/onnxruntime_python/helpers.html#c-class-ortdevice">C_OrtDevice</a></p></li>
<li><p><strong>args</strong> – additional arguments</p></li>
</ul>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L115">source on GitHub</a></p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.SquareLearningLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onnxcustom.training.sgd_learning_loss.</span></span><span class="sig-name descname"><span class="pre">SquareLearningLoss</span></span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.SquareLearningLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onnxcustom.training.sgd_learning_loss.BaseLearningLoss" title="onnxcustom.training.sgd_learning_loss.BaseLearningLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">onnxcustom.training.sgd_learning_loss.BaseLearningLoss</span></code></a></p>
<p>Implements a square loss <img class="math" src="../../_images/math/220ff2fdeb35e1fb7fb11d4f769a6e235346b32b.svg" alt="(Y - Z)^2"/>
where <em>Y</em> is the output and <em>Z</em> the expected output.
See <a class="reference internal" href="../utils/onnx_function.html#onnxcustom.utils.onnx_function._onnx_grad_loss_square_error" title="onnxcustom.utils.onnx_function._onnx_grad_loss_square_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">_onnx_grad_loss_square_error</span></code></a> for the ONNX
implementation.</p>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L149">source on GitHub</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.SquareLearningLoss.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.SquareLearningLoss.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onnxcustom.training.sgd_learning_loss.SquareLearningLoss.build_onnx_function">
<span class="sig-name descname"><span class="pre">build_onnx_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#onnxcustom.training.sgd_learning_loss.SquareLearningLoss.build_onnx_function" title="Permalink to this definition">¶</a></dt>
<dd><p>This class updates the weights.
It assumes it can do operator on <em>OrtValue</em>.
This can be done through ONNX graph.
This function creates <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a>
which do that.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opset</strong> – opset to use</p></li>
<li><p><strong>device</strong> – <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/api/onnxruntime_python/helpers.html#c-class-ortdevice">C_OrtDevice</a></p></li>
<li><p><strong>args</strong> – additional arguments</p></li>
</ul>
</dd>
</dl>
<p><a class="reference external" href="https://github.com/sdpython/onnxcustom/blob/master/onnxcustom/training/sgd_learning_loss.py#L115">source on GitHub</a></p>
</dd></dl>

</dd></dl>

</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ortgradient.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">module <code class="docutils literal notranslate"><span class="pre">training.ortgradient</span></code></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="sgd_learning_penalty.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">module <code class="docutils literal notranslate"><span class="pre">training.sgd_learning_penalty</span></code></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>