
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>ONNX Model Hub &#8212; onnxcustom</title>
    
    <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../gyexamples/index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="IR.html">
   Open Neural Network Exchange Intermediate Representation (ONNX IR) Specification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PythonAPIOverview.html">
   Python API Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="OpConventions.html">
   Operator Conventions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DimensionDenotation.html">
   Dimension Denotation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Broadcasting.html">
   Broadcasting in ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ExternalData.html">
   External Data
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   ONNX Model Hub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_metadata.html">
   Metatdata
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ShapeInference.html">
   ONNX Shape Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CIPipelines.html">
   ONNX CI Pipelines
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Syntax.html">
   Overview
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Versioning.html">
   ONNX Versioning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="VersionConverter.html">
   ONNX Version Converter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Relicensing.html">
   Relicensing MIT to Apache-2.0
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_releases.html">
   Onnx Releases
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_operators.html">
   ONNX Operators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_operators_ml.html">
   ONNX ML Operators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_changelog.html">
   Change Logs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_changelog_ml.html">
   ML Change Logs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_test_coverage.html">
   Test Coverage (Operators)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_test_coverage_ml.html">
   Test Coverage (ML Operators)
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_add_new_op.html">
   Adding a new operator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ImplementingAnOnnxBackend.html">
   Implementing an ONNX backend
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="OnnxBackendTest.html">
   ONNX Backend Test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_managing.html">
   Onnx Releases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ONNXIFI.html">
   ONNX Interface for Framework Integration (ONNXIFI)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ONNXTypes.html">
   Optional Type
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TypeAnnotations.html">
   Type annotations for ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TypeDenotation.html">
   Type Denotation
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="DefineDifferentiability.html">
   A Short Guide on the Differentiability Tag for ONNX Operators
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#install">
   Install
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basic-usage">
   Basic usage
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downloading-a-model-by-name">
     Downloading a model by name:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downloading-from-custom-repositories">
     Downloading from custom repositories:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#listing-and-inspecting-models">
     Listing and inspecting Models:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#local-caching">
   Local Caching
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#default-cache-location">
     Default cache location
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setting-the-cache-location">
     Setting the cache location
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#additional-cache-details">
     Additional cache details
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#architecture">
   Architecture
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-to-the-onnx-model-hub">
   Adding to the ONNX Model Hub
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contributing-an-official-model">
     Contributing an official model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hosting-your-own-onnx-model-hub">
     Hosting your own ONNX Model Hub
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <!--- SPDX-License-Identifier: Apache-2.0 -->
<section id="onnx-model-hub">
<h1>ONNX Model Hub<a class="headerlink" href="#onnx-model-hub" title="Permalink to this headline">¶</a></h1>
<p>The ONNX Model Hub is a simple and fast way to get started with state of the art pre-trained
ONNX models from the <a class="reference external" href="https://github.com/onnx/models">ONNX Model Zoo</a>. Furthermore, this allows researchers and model
developers the opportunity to share their pre-trained models with the broader community.</p>
<section id="install">
<h2>Install<a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h2>
<p>The ONNX Model hub will be included in the <code class="docutils literal notranslate"><span class="pre">onnx</span></code> package from version 1.11 onwards.
To use the hub before the 1.11 release please install from the weekly build:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install -i https://test.pypi.org/simple/ onnx-weekly
</pre></div>
</div>
</section>
<section id="basic-usage">
<h2>Basic usage<a class="headerlink" href="#basic-usage" title="Permalink to this headline">¶</a></h2>
<p>The ONNX Model Hub is capable of downloading, listing, and querying trained models from any git repository,
and defaults to the official <a class="reference external" href="https://github.com/onnx/models">ONNX Model Zoo</a>. In this section we demonstrate some of the basic functionality.</p>
<p>First please import the hub using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">hub</span>
</pre></div>
</div>
<section id="downloading-a-model-by-name">
<h3>Downloading a model by name:<a class="headerlink" href="#downloading-a-model-by-name" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">load</span></code> function will default to searching the model zoo for the latest model with a matching name,
download this model to a local cache, and load the model into a <code class="docutils literal notranslate"><span class="pre">ModelProto</span></code>
object for use with the ONNX runtime.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;resnet50&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="downloading-from-custom-repositories">
<h3>Downloading from custom repositories:<a class="headerlink" href="#downloading-from-custom-repositories" title="Permalink to this headline">¶</a></h3>
<p>Any repository with the proper structure can be a ONNX model hub. To download from other hubs,
or to specify a particular branch or commit on the main model hub one can provide the <code class="docutils literal notranslate"><span class="pre">repo</span></code> parameter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;resnet50&quot;</span><span class="p">,</span> <span class="n">repo</span><span class="o">=</span><span class="s1">&#39;onnx/models:771185265efbdc049fb223bd68ab1aeb1aecde76&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="listing-and-inspecting-models">
<h3>Listing and inspecting Models:<a class="headerlink" href="#listing-and-inspecting-models" title="Permalink to this headline">¶</a></h3>
<p>The model hub provides APIs for querying the model zoo to learn more about available models.
This does not download the models, but rather just returns information about models matching the given arguments</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># List all models in the onnx/models:master repo</span>
<span class="n">all_models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">list_models</span><span class="p">()</span>

<span class="c1"># List all versions/opsets of a specific model</span>
<span class="n">mnist_models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">list_models</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;mnist&quot;</span><span class="p">)</span>

<span class="c1"># List all models matching a given &quot;tag&quot;</span>
<span class="n">vision_models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">list_models</span><span class="p">(</span><span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;vision&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>One can also inspect the metadata of a model prior to download with the <code class="docutils literal notranslate"><span class="pre">get_model_info</span></code> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">hub</span><span class="o">.</span><span class="n">get_model_info</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">opset</span><span class="o">=</span><span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
<p>This will print something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ModelInfo</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">MNIST</span><span class="p">,</span>
    <span class="n">opset</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">path</span><span class="o">=</span><span class="n">vision</span><span class="o">/</span><span class="n">classification</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="n">model</span><span class="o">/</span><span class="n">mnist</span><span class="o">-</span><span class="mf">8.</span><span class="n">onnx</span><span class="p">,</span>
    <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
     <span class="s1">&#39;model_sha&#39;</span><span class="p">:</span> <span class="s1">&#39;2f06e72de813a8635c9bc0397ac447a601bdbfa7df4bebc278723b958831c9bf&#39;</span><span class="p">,</span>
     <span class="s1">&#39;model_bytes&#39;</span><span class="p">:</span> <span class="mi">26454</span><span class="p">,</span>
     <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;vision&#39;</span><span class="p">,</span> <span class="s1">&#39;classification&#39;</span><span class="p">,</span> <span class="s1">&#39;mnist&#39;</span><span class="p">],</span>
     <span class="s1">&#39;io_ports&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Input3&#39;</span><span class="p">,</span> <span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">],</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;tensor(float)&#39;</span><span class="p">}],</span>
        <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Plus214_Output_0&#39;</span><span class="p">,</span> <span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;tensor(float)&#39;</span><span class="p">}]},</span>
     <span class="s1">&#39;model_with_data_path&#39;</span><span class="p">:</span> <span class="s1">&#39;vision/classification/mnist/model/mnist-8.tar.gz&#39;</span><span class="p">,</span>
     <span class="s1">&#39;model_with_data_sha&#39;</span><span class="p">:</span> <span class="s1">&#39;1dd098b0fe8bc750585eefc02013c37be1a1cae2bdba0191ccdb8e8518b3a882&#39;</span><span class="p">,</span>
     <span class="s1">&#39;model_with_data_bytes&#39;</span><span class="p">:</span> <span class="mi">25962</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="local-caching">
<h2>Local Caching<a class="headerlink" href="#local-caching" title="Permalink to this headline">¶</a></h2>
<p>The ONNX Model hub locally caches downloaded models in a configurable location
so that subsequent calls to <code class="docutils literal notranslate"><span class="pre">hub.load</span></code> do not require network connection.</p>
<section id="default-cache-location">
<h3>Default cache location<a class="headerlink" href="#default-cache-location" title="Permalink to this headline">¶</a></h3>
<p>The hub client looks for the following default cache locations in this order:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">$ONNX_HOME/hub</span></code> if the <code class="docutils literal notranslate"><span class="pre">ONNX_HOME</span></code> environment variable is defined</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$XDG_CACHE_HOME/hub</span></code> if the <code class="docutils literal notranslate"><span class="pre">XDG_CACHE_HOME</span></code> environment variable is defined</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">~/.cache/onnx/hub</span></code> where <code class="docutils literal notranslate"><span class="pre">~</span></code> is the user home directory</p></li>
</ol>
</section>
<section id="setting-the-cache-location">
<h3>Setting the cache location<a class="headerlink" href="#setting-the-cache-location" title="Permalink to this headline">¶</a></h3>
<p>To manually set the cache location use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hub</span><span class="o">.</span><span class="n">set_dir</span><span class="p">(</span><span class="s2">&quot;my/cache/directory&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Additionally one can inspect the cache location with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">hub</span><span class="o">.</span><span class="n">get_dir</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="additional-cache-details">
<h3>Additional cache details<a class="headerlink" href="#additional-cache-details" title="Permalink to this headline">¶</a></h3>
<p>To clear the model cache one can simply delete the cache directory using a python utility like <code class="docutils literal notranslate"><span class="pre">shutil</span></code> or <code class="docutils literal notranslate"><span class="pre">os</span></code>.
Furthermore one can choose to override the cached model using the <code class="docutils literal notranslate"><span class="pre">force_reload</span></code> option:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;resnet50&quot;</span><span class="p">,</span> <span class="n">force_reload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>We include this flag for completeness but note that models in the cache are disambiguated with sha256 hashes so
the force_reload flag is not necessary for normal use.
Finally we note that the model cache directory structure will mirror the directory structure
specified by the <code class="docutils literal notranslate"><span class="pre">model_path</span></code> field of the manifest, but with file names disambiguated with model SHA256 Hashes.</p>
<p>This way, the model cache is human readable, can disambiguate between multiple versions of models,
and can re-use cached models across different hubs if they have the same name and hash.</p>
</section>
</section>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline">¶</a></h2>
<p><img alt="ONNX Hub Architecture" src="../../_images/onnx_hub_arch.svg" /></p>
<p>The ONNX Hub consists of two main components, the client and the server.
The client code currently is included in the <code class="docutils literal notranslate"><span class="pre">onnx</span></code> package and can be pointed at a
server in the form of a hosted <code class="docutils literal notranslate"><span class="pre">ONNX_HUB_MANIFEST.json</span></code> within a github repository
such as <a class="reference external" href="https://github.com/onnx/models/blob/master/ONNX_HUB_MANIFEST.json">the one in the ONNX Model Zoo</a>.
This manifest file is a JSON document which lists all models and their metadata
and is designed to be programming language agnostic. An example of a well formed model manifest entry is as follows:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="w"></span>
<span class="w"> </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;BERT-Squad&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w"> </span><span class="nt">&quot;model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text/machine_comprehension/bert-squad/model/bertsquad-8.onnx&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w"> </span><span class="nt">&quot;onnx_version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w"> </span><span class="nt">&quot;opset_version&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"></span>
<span class="w"> </span><span class="nt">&quot;metadata&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;model_sha&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cad65b9807a5e0393e4f84331f9a0c5c844d9cc736e39781a80f9c48ca39447c&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;model_bytes&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">435882893</span><span class="p">,</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;tags&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;machine comprehension&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;bert-squad&quot;</span><span class="p">],</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;io_ports&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;inputs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"></span>
<span class="w">             </span><span class="p">{</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;unique_ids_raw_output___9:0&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;unk__475&quot;</span><span class="p">],</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor(int64)&quot;</span><span class="w"></span>
<span class="w">             </span><span class="p">},</span><span class="w"></span>
<span class="w">             </span><span class="p">{</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;segment_ids:0&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;unk__476&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">],</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor(int64)&quot;</span><span class="w"></span>
<span class="w">             </span><span class="p">},</span><span class="w"></span>
<span class="w">             </span><span class="p">{</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;input_mask:0&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;unk__477&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">],</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor(int64)&quot;</span><span class="w"></span>
<span class="w">             </span><span class="p">},</span><span class="w"></span>
<span class="w">             </span><span class="p">{</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;input_ids:0&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;unk__478&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">],</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor(int64)&quot;</span><span class="w"></span>
<span class="w">             </span><span class="p">}</span><span class="w"></span>
<span class="w">         </span><span class="p">],</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;outputs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"></span>
<span class="w">             </span><span class="p">{</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;unstack:1&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;unk__479&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">],</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor(float)&quot;</span><span class="w"></span>
<span class="w">             </span><span class="p">},</span><span class="w"></span>
<span class="w">             </span><span class="p">{</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;unstack:0&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;unk__480&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">],</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor(float)&quot;</span><span class="w"></span>
<span class="w">             </span><span class="p">},</span><span class="w"></span>
<span class="w">             </span><span class="p">{</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;unique_ids:0&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;shape&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;unk__481&quot;</span><span class="p">],</span><span class="w"></span>
<span class="w">                 </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tensor(int64)&quot;</span><span class="w"></span>
<span class="w">             </span><span class="p">}</span><span class="w"></span>
<span class="w">         </span><span class="p">]</span><span class="w"></span>
<span class="w">     </span><span class="p">},</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;model_with_data_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text/machine_comprehension/bert-squad/model/bertsquad-8.tar.gz&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;model_with_data_sha&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;c8c6c7e0ab9e1333b86e8415a9d990b2570f9374f80be1c1cb72f182d266f666&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;model_with_data_bytes&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">403400046</span><span class="w"></span>
<span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>These important fields are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>: The name of the model used for querying</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_path</span></code>: The relative path of the model stored in Git LFS.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">onnx_version</span></code>: The ONNX version of the model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">opset_version</span></code>: The version of the opset. The client downloads the latest opset if left unspecified.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">metadata/model_sha</span></code>: Optional model sha specification for increased download security</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">metadata/tags</span></code>: Optional high level tags to help users find models by a given type</p></li>
</ul>
<p>All other fields in the <code class="docutils literal notranslate"><span class="pre">metadata</span></code> field are optional for the client but provide important details for users.</p>
</section>
<section id="adding-to-the-onnx-model-hub">
<h2>Adding to the ONNX Model Hub<a class="headerlink" href="#adding-to-the-onnx-model-hub" title="Permalink to this headline">¶</a></h2>
<section id="contributing-an-official-model">
<h3>Contributing an official model<a class="headerlink" href="#contributing-an-official-model" title="Permalink to this headline">¶</a></h3>
<p>The simplest way to add a model to the official <code class="docutils literal notranslate"><span class="pre">onnx/models</span></code> version model hub is to follow
<a class="reference external" href="https://github.com/onnx/models/blob/master/contribute.md">these guidelines</a> to contribute your model. Once contributed,
ensure that your model has a markdown table in its <code class="docutils literal notranslate"><span class="pre">README.md</span></code>
(<a class="reference external" href="https://github.com/onnx/models/tree/master/vision/classification/mobilenet">Example</a>). The model hub
manifest generator will pull information from these markdown tables. To run the generator:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/onnx/models.git
git lfs pull --include<span class="o">=</span><span class="s2">&quot;*&quot;</span> --exclude<span class="o">=</span><span class="s2">&quot;&quot;</span>
<span class="nb">cd</span> models/workflow_scripts
python generate_onnx_hub_manifest.py
</pre></div>
</div>
<p>Once a new manifest is generated add, submit it in a pull request to <code class="docutils literal notranslate"><span class="pre">onnx/models</span></code></p>
</section>
<section id="hosting-your-own-onnx-model-hub">
<h3>Hosting your own ONNX Model Hub<a class="headerlink" href="#hosting-your-own-onnx-model-hub" title="Permalink to this headline">¶</a></h3>
<p>To host your own model hub, add an <code class="docutils literal notranslate"><span class="pre">ONNX_HUB_MANIFEST.json</span></code> to the top level of your github repository
(<a class="reference external" href="https://github.com/onnx/models/blob/master/ONNX_HUB_MANIFEST.json">Example</a>). At a minimum your
manifest entries should include the fields mentioned in
the <span class="xref myst">Architecture Section</span> of this document.
Once committed, check that you can download models
using the “Downloading from custom repositories” section of this doc.</p>
</section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>