
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Open Neural Network Exchange Intermediate Representation (ONNX IR) Specification &#8212; onnxcustom</title>
    
    <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../gyexamples/index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Open Neural Network Exchange Intermediate Representation (ONNX IR) Specification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PythonAPIOverview.html">
   Python API Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="OpConventions.html">
   Operator Conventions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DimensionDenotation.html">
   Dimension Denotation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Broadcasting.html">
   Broadcasting in ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ExternalData.html">
   External Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Hub.html">
   ONNX Model Hub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_metadata.html">
   Metatdata
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ShapeInference.html">
   ONNX Shape Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CIPipelines.html">
   ONNX CI Pipelines
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Syntax.html">
   Overview
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Versioning.html">
   ONNX Versioning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="VersionConverter.html">
   ONNX Version Converter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Relicensing.html">
   Relicensing MIT to Apache-2.0
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_releases.html">
   Onnx Releases
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_operators.html">
   ONNX Operators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_operators_ml.html">
   ONNX ML Operators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_changelog.html">
   Change Logs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_changelog_ml.html">
   ML Change Logs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_test_coverage.html">
   Test Coverage (Operators)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_test_coverage_ml.html">
   Test Coverage (ML Operators)
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_add_new_op.html">
   Adding a new operator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ImplementingAnOnnxBackend.html">
   Implementing an ONNX backend
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="OnnxBackendTest.html">
   ONNX Backend Test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../onnx_managing.html">
   Onnx Releases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ONNXIFI.html">
   ONNX Interface for Framework Integration (ONNXIFI)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ONNXTypes.html">
   Optional Type
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TypeAnnotations.html">
   Type annotations for ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TypeDenotation.html">
   Type Denotation
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="DefineDifferentiability.html">
   A Short Guide on the Differentiability Tag for ONNX Operators
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#components">
   Components
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#runtime-agnostic">
   Runtime Agnostic
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#onnx-versioning">
   ONNX Versioning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extensible-computation-graph-model">
   Extensible computation graph model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#models">
     Models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-semantics">
     Model Semantics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-metadata">
     Optional Metadata
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#operator-sets">
     Operator Sets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#operators">
     Operators
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#graphs">
     Graphs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#names-within-a-graph">
     Names Within a Graph
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nodes">
     Nodes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#input-and-output-values">
       Input and Output Values
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#attributes">
       Attributes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#variadic-inputs-and-outputs">
       Variadic Inputs and Outputs
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#optional-inputs-and-outputs">
       Optional Inputs and Outputs
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#external-tensor-data">
       External Tensor Data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standard-data-types">
   Standard data types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-definition">
     Tensor Definition
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#representation">
       Representation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-element-types">
     Tensor Element Types
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#input-output-data-types">
     Input / Output Data Types
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#static-tensor-shapes">
       Static tensor shapes
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attribute-types">
     Attribute Types
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-related-information">
   Training Related Information
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-specification-documents">
   Other Specification Documents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Operators
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#syntax">
     Syntax
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#versioning-conventions-and-best-practices">
     Versioning Conventions and Best Practices
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <!--- SPDX-License-Identifier: Apache-2.0 -->
<section id="open-neural-network-exchange-intermediate-representation-onnx-ir-specification">
<h1>Open Neural Network Exchange Intermediate Representation (ONNX IR) Specification<a class="headerlink" href="#open-neural-network-exchange-intermediate-representation-onnx-ir-specification" title="Permalink to this headline">¶</a></h1>
<p><strong>Purpose</strong></p>
<p>This document contains the normative specification of the semantics of ONNX.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.proto</span></code> and <code class="docutils literal notranslate"><span class="pre">.proto3</span></code> files found under the <span class="xref myst">onnx folder</span> form the normative specification of its syntax authored in the <a class="reference external" href="https://developers.google.com/protocol-buffers">Protocol Buffers</a> definition language. Commentary found in the <code class="docutils literal notranslate"><span class="pre">.proto</span></code> and <code class="docutils literal notranslate"><span class="pre">.proto3</span></code> files are intended to improve readability of those files, but are not normative if they conflict with this document. Such conflicts should be reported as documentation bugs.</p>
<p><strong>Notes on model validation</strong></p>
<p>A <span class="xref myst">tool</span> is available to perform general validation of models against this specification. It is implemented in C++ with a Python command-line wrapper.</p>
<p><strong>Notes on language in this and all related documents</strong>:</p>
<ol class="arabic simple">
<li><p>The use of SHOULD, MUST, MAY and so on in this document is consistent with <a class="reference external" href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p></li>
<li><p>The use of ‘list’ shall denote an ordered collection of items, ‘set’ shall denote an unordered collection of unique elements, and ‘bag’ an unordered collection of possibly non-unique elements.</p></li>
</ol>
<section id="components">
<h2>Components<a class="headerlink" href="#components" title="Permalink to this headline">¶</a></h2>
<p>ONNX is an open specification that consists of the following components:</p>
<ol class="arabic simple">
<li><p>A definition of an extensible computation graph model.</p></li>
<li><p>Definitions of standard data types.</p></li>
<li><p>Definitions of built-in operators.</p></li>
</ol>
<p>#1 and #2 together make up the ONNX Intermediate Representation, or ‘IR’, specification which is covered herein; the built-in operators are covered in documents listed at the end. Specifically, built-in operators are divided into a set of primitive operators and functions. A function is an operator whose semantics is formally expressed via expansion into a sub-graph (called the function body) using other operators (and functions). Functionality-wise, an ONNX compatible framework or runtime may inline a function body to execute it if it does not have corresponding implementation of the function.</p>
<p>There are two official ONNX variants; the main distinction between the two is found in the default operator sets. <strong>ONNX-ML</strong> extends the <strong>ONNX</strong> operator set with ML algorithms that are not based on neural networks.</p>
<p>Up to IR version 6, the ONNX specification and model format addressed only inference (also known as scoring). Starting from IR version 7, the ONNX specification and model format also support training. An ONNX training model is an extension of the inference-model. An inference-only runtime can consume a training model ignoring the training-related extensions. However, an inference-only model may enable a representation that is more optimal for inference purposes than a training model.</p>
</section>
<section id="runtime-agnostic">
<h2>Runtime Agnostic<a class="headerlink" href="#runtime-agnostic" title="Permalink to this headline">¶</a></h2>
<p>ONNX does not pre-suppose or imply any particular method of runtime implementation.</p>
<p>For example, an implementation may consist of a rich runtime which interprets the model; it may be a code generator that translates the model in its entirety to executable code for some target programming language; it may be a hardware implementation; it may be a combination of two or three of those.</p>
<p>Nothing in this specification should be construed as advocating one implementation approach over any other; any comments on the inner workings of concrete implementations are to be interpreted as examples.</p>
</section>
<section id="onnx-versioning">
<h2>ONNX Versioning<a class="headerlink" href="#onnx-versioning" title="Permalink to this headline">¶</a></h2>
<p>The IR specification, individual models, and operator sets are all versioned. Furthermore, each individual operator indicates which version of its containing operator set it was introduced or stabilized in.</p>
<p>Version numbers can be used as a simple number, or used to encode <a class="reference external" href="https://semver.org/">semantic versions</a>(AKA SemVer). If using semantic versions, the convention is to use the two most significant bytes for the major number, the next two bytes for the minor number, and the least significant four bytes for the patch/build/bugfix number. When using semantic versioning, at least one of the major/minor numbers MUST be non-zero.</p>
<p>The IR specification uses simple monotonically increasing numbers for its versions. The valid IR versions are defined by the <code class="docutils literal notranslate"><span class="pre">onnx.Version</span></code> enumeration in <span class="xref myst">onnx.proto</span>.</p>
<p>Operator sets use a simple version number. Each operator set version represents a snapshot of the set of operators, and their semantics at a particular point in time.</p>
<p>This specification does not provide guidance on what versioning scheme model producers should be using.</p>
<p>More details on conventions and best practices for versioning of IR, operator sets, and models can be found in <a class="reference internal" href="Versioning.html"><span class="doc std std-doc">Versioning</span></a>.</p>
</section>
<section id="extensible-computation-graph-model">
<h2>Extensible computation graph model<a class="headerlink" href="#extensible-computation-graph-model" title="Permalink to this headline">¶</a></h2>
<p>ONNX specifies the portable, serialized format of a computation graph. It does not have to be the form a framework chooses to use internally. For example, an implementation may represent the model differently in memory if it is more efficient to manipulate during optimization passes.</p>
<p>An implementation MAY extend ONNX by adding operators expressing semantics beyond the standard set of operators that all implementations MUST support. The mechanism for this is adding operator sets to the <code class="docutils literal notranslate"><span class="pre">opset_import</span></code> property in a model that depends on the extension operators.</p>
<section id="models">
<h3>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h3>
<p>The top-level ONNX construct is a ‘Model.’, and is represented in protocol buffers as the type <code class="docutils literal notranslate"><span class="pre">onnx.ModelProto</span></code></p>
<p>The main purpose of the model structure is to associate metadata with a graph which contains all the executable elements. The metadata is used when first reading the model file, giving an implementation the information it needs in order to determine whether it will be able to execute the model, generate logging messages, error reports, etc. Further, the metadata is useful to tools, such as IDEs and model galleries, which need it for informing humans about a given model’s purpose and characteristics.</p>
<p>Each model has the following components:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ir_version</p></td>
<td><p>int64</p></td>
<td><p>The ONNX version assumed by the model.</p></td>
</tr>
<tr class="row-odd"><td><p>opset_import</p></td>
<td><p>OperatorSetId</p></td>
<td><p>A collection of operator set identifiers made available to the model. An implementation must support all operators in the set or reject the model.</p></td>
</tr>
<tr class="row-even"><td><p>producer_name</p></td>
<td><p>string</p></td>
<td><p>The name of the tool used to generate the model.</p></td>
</tr>
<tr class="row-odd"><td><p>producer_version</p></td>
<td><p>string</p></td>
<td><p>The version of the generating tool.</p></td>
</tr>
<tr class="row-even"><td><p>domain</p></td>
<td><p>string</p></td>
<td><p>A reverse-DNS name to indicate the model namespace or domain, for example, ‘org.onnx’</p></td>
</tr>
<tr class="row-odd"><td><p>model_version</p></td>
<td><p>int64</p></td>
<td><p>The version of the model itself, encoded in an integer.</p></td>
</tr>
<tr class="row-even"><td><p>doc_string</p></td>
<td><p>string</p></td>
<td><p>Human-readable documentation for this model. Markdown is allowed.</p></td>
</tr>
<tr class="row-odd"><td><p>graph</p></td>
<td><p>Graph</p></td>
<td><p>The parameterized graph that is evaluated to execute the model.</p></td>
</tr>
<tr class="row-even"><td><p>metadata_props</p></td>
<td><p>map&lt;string,string&gt;</p></td>
<td><p>Named metadata values; keys should be distinct.</p></td>
</tr>
<tr class="row-odd"><td><p>training_info</p></td>
<td><p>TrainingInfoProto[]</p></td>
<td><p>An optional extension that contains information for training.</p></td>
</tr>
<tr class="row-even"><td><p>functions</p></td>
<td><p>FunctionProto[]</p></td>
<td><p>An optional list of functions local to the model.</p></td>
</tr>
</tbody>
</table>
<p>Models MUST specify a domain and use reverse domain names based on the responsible organization’s identity, the same convention that is used for <a class="reference external" href="https://docs.oracle.com/javase/tutorial/java/package/namingpkgs.html">naming Java packages</a>.</p>
<p><strong>Note: Exploring an ONNX file</strong></p>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">protoc</span></code> tool that is part of the Protocol Buffers distribution to examine the contents of an ONNX file, you do so like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ protoc --decode=onnx.ModelProto onnx.proto &lt; yourfile.onnx
</pre></div>
</div>
<p>Where <span class="xref myst">onnx.proto</span> is the file that is part of this repository.</p>
<p>Alternatively, you can use a tool like <a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a> to explore the ONNX file.</p>
</section>
<section id="model-semantics">
<h3>Model Semantics<a class="headerlink" href="#model-semantics" title="Permalink to this headline">¶</a></h3>
<p>The semantics of an inference-model is a <em>stateless function</em> (except possibly for the state used for random-number generation). Thus, whenever an inference-model (without random-generator operations) is used to perform inference on the same input, it is expected to produce the same output.</p>
<p>The semantics of a training model is that of a <em>stateful object</em>, with the state consisting of the current values of trained-weights (and any other auxiliary state required, such as momentum, for example, used by the learning algorithm). Specifically, its semantics is captured via three methods: an initialization method (which is used to initialize or reset the values of state variables), a training step method (to train using a batch of input-output pairs), and an inference method to perform inference using the current values of the learned weights. The first two methods update the state of the object, while the third method is side-effect-free.</p>
</section>
<section id="optional-metadata">
<h3>Optional Metadata<a class="headerlink" href="#optional-metadata" title="Permalink to this headline">¶</a></h3>
<p>The ‘metadata_props’ field in the model is available for any kind of optional metadata that a tool or model developer chooses to place there. The following are the defined “standard” optional metadata properties of a model.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Format</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>model_author</p></td>
<td><p>string</p></td>
<td><p>A comma-separated list of names.</p></td>
<td><p>The personal name of the author(s) of the model, and/or their organizations.</p></td>
</tr>
<tr class="row-odd"><td><p>model_license</p></td>
<td><p>string</p></td>
<td><p>Name or URL.</p></td>
<td><p>The well-known name or URL of the license under which the model is made available.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="operator-sets">
<h3>Operator Sets<a class="headerlink" href="#operator-sets" title="Permalink to this headline">¶</a></h3>
<p>Each model MUST explicitly name the operator sets that it relies on for its functionality. Operator sets define the available operators and their version. Each model defines the imported operator sets by their domains. All models implicitly import the default ONNX operator set.</p>
<p>Each operator set SHALL be defined in a separate document, also using protobuf as the serialization format. How operator set documents are found at runtime is implementation-dependent.</p>
<p><strong>Note: As of the publication of this document, no ONNX implementation is known to process operator set documents.</strong></p>
<p>The properties of an operator set are:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>magic</p></td>
<td><p>string</p></td>
<td><p>The value ‘ONNXOPSET’</p></td>
</tr>
<tr class="row-odd"><td><p>ir_version</p></td>
<td><p>int32</p></td>
<td><p>The ONNX version corresponding to the operators.</p></td>
</tr>
<tr class="row-even"><td><p>ir_version_prerelease</p></td>
<td><p>string</p></td>
<td><p>The prerelease component of the SemVer of the IR.</p></td>
</tr>
<tr class="row-odd"><td><p>ir_build_metadata</p></td>
<td><p>string</p></td>
<td><p>The build metadata of this version of the operator set.</p></td>
</tr>
<tr class="row-even"><td><p>domain</p></td>
<td><p>string</p></td>
<td><p>The domain of the operator set. Must be unique among all sets.</p></td>
</tr>
<tr class="row-odd"><td><p>opset_version</p></td>
<td><p>int64</p></td>
<td><p>The version of the operator set.</p></td>
</tr>
<tr class="row-even"><td><p>doc_string</p></td>
<td><p>string</p></td>
<td><p>Human-readable documentation for this operator set. Markdown is allowed.</p></td>
</tr>
<tr class="row-odd"><td><p>operator</p></td>
<td><p>Operator[]</p></td>
<td><p>The operators contained in this operator set.</p></td>
</tr>
</tbody>
</table>
<p>The operator set version is a simple integer value that is monotonically increased as new versions of the operator set are published.</p>
<p>Operator sets other than the default operator set MUST specify a domain and SHOULD use reverse domain names based on the responsible organization’s identity, the same convention that is used for <a class="reference external" href="https://docs.oracle.com/javase/tutorial/java/package/namingpkgs.html">naming Java packages</a>.</p>
</section>
<section id="operators">
<h3>Operators<a class="headerlink" href="#operators" title="Permalink to this headline">¶</a></h3>
<p>Each operator used within a graph MUST be explicitly declared by one of the operator sets imported by the model.</p>
<p>The properties of an operator definition are:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>op_type</p></td>
<td><p>string</p></td>
<td><p>The name of the operator, as used in graph nodes. MUST be unique within the operator set’s domain.</p></td>
</tr>
<tr class="row-odd"><td><p>since_version</p></td>
<td><p>int64</p></td>
<td><p>The version of the operator set when this operator was introduced.</p></td>
</tr>
<tr class="row-even"><td><p>status</p></td>
<td><p>OperatorStatus</p></td>
<td><p>One of ‘EXPERIMENTAL’ or ‘STABLE.’</p></td>
</tr>
<tr class="row-odd"><td><p>doc_string</p></td>
<td><p>string</p></td>
<td><p>A human-readable documentation string for this operator. Markdown is allowed.</p></td>
</tr>
</tbody>
</table>
<p>The version value MUST be the same value as the operator set version when the operator was first published. Subsequent versions of the operator set MUST NOT alter the signature or semantics of the operator once published as STABLE.</p>
<p>The ‘status’ property indicates whether the syntax, semantics, or presence of the operator is in an experimental or stable stage. Once an operator is published as STABLE, it’s syntax and semantics MUST NOT change in subsequent versions of the operator set.</p>
<p>There are two distinct ways to pass information to operators – inputs and attributes. Inputs represent graph inputs or values computed elsewhere in the graph, while attributes are used for values that are constants in the graph. This distinction may be highly relevant to achieving good performance for some implementations, while completely irrelevant to others.</p>
</section>
<section id="graphs">
<h3>Graphs<a class="headerlink" href="#graphs" title="Permalink to this headline">¶</a></h3>
<p>A graph is used to describe a side-effect-free computation (function).
A serialized graph is comprised of a set of metadata fields, a list of model parameters, and a list of computation nodes.</p>
<p>Each computation dataflow graph is structured as a topologically sorted list of nodes that form a graph, which MUST be free of cycles. Each node represents a call to an operator or a model local function. Each node has zero or more inputs and one or more outputs.</p>
<p>Graphs have the following properties:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>name</p></td>
<td><p>string</p></td>
<td><p>The name of the model graph.</p></td>
</tr>
<tr class="row-odd"><td><p>node</p></td>
<td><p>Node[]</p></td>
<td><p>A list of nodes, forming a partially ordered computation graph based on input/output data dependencies. It is in topological order.</p></td>
</tr>
<tr class="row-even"><td><p>initializer</p></td>
<td><p>Tensor[]</p></td>
<td><p>A list of named tensor values. When an initializer has the same name as a graph input, it specifies a default value for that input. When an initializer has a name different from all graph inputs, it specifies a constant value. The order of the list is unspecified.</p></td>
</tr>
<tr class="row-odd"><td><p>doc_string</p></td>
<td><p>string</p></td>
<td><p>Human-readable documentation for this model. Markdown is allowed.</p></td>
</tr>
<tr class="row-even"><td><p>input</p></td>
<td><p>ValueInfo[]</p></td>
<td><p>The input parameters of the graph, possibly initialized by a default value found in ‘initializer.’</p></td>
</tr>
<tr class="row-odd"><td><p>output</p></td>
<td><p>ValueInfo[]</p></td>
<td><p>The output parameters of the graph. Once all output parameters have been written to by a graph execution, the execution is complete.</p></td>
</tr>
<tr class="row-even"><td><p>value_info</p></td>
<td><p>ValueInfo[]</p></td>
<td><p>Used to store the type and shape information of values that are not inputs or outputs.</p></td>
</tr>
</tbody>
</table>
<p>ValueInfo has the following properties:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>name</p></td>
<td><p>string</p></td>
<td><p>The name of the value/parameter.</p></td>
</tr>
<tr class="row-odd"><td><p>type</p></td>
<td><p>Type</p></td>
<td><p>The type of the value <strong>including shape information</strong>.</p></td>
</tr>
<tr class="row-even"><td><p>doc_string</p></td>
<td><p>string</p></td>
<td><p>Human-readable documentation for this value. Markdown is allowed.</p></td>
</tr>
</tbody>
</table>
<p>Each main (top-level) graph MUST define the names, types and shapes of its inputs and outputs, which are specified as ‘value info’ structures. The main graph inputs and outputs are required to have a shape, indicating the rank, even though the exact dimensions need not be specified.</p>
<p>Nested subgraphs (specified as attribute values) MUST define the names of its inputs and outputs
and MAY define the types of its inputs and outputs.</p>
<p>Each graph MUST specify a name.</p>
<p>The graph MUST adhere to single static assignment (SSA) for all node outputs; this means that all node output names MUST be unique within a graph.</p>
<p>Graphs SHOULD be populated with documentation strings, which MAY be interpreted using GitHub-style markdown syntax. HTML and other text-markup languages MAY NOT be used in documentation strings.</p>
</section>
<section id="names-within-a-graph">
<h3>Names Within a Graph<a class="headerlink" href="#names-within-a-graph" title="Permalink to this headline">¶</a></h3>
<p>All names MUST adhere to <a class="reference external" href="https://en.cppreference.com/w/c/language/identifier">C90 identifier syntax rules</a>.</p>
<p>Names of nodes, inputs, outputs, initializers, and attributes are organized into several namespaces. Within a namespace, each name MUST be unique for each given graph. Please see below for further clarification in the case where a graph contains nested subgraphs (as attribute values).</p>
<p>The namespaces are:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Namespace</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Attribute</p></td>
<td><p>The names of attributes of an operator. Unique for each operator.</p></td>
</tr>
<tr class="row-odd"><td><p>Value</p></td>
<td><p>The names of values – node inputs &amp; outputs, tensor values (if named), graph inputs, outputs.</p></td>
</tr>
<tr class="row-even"><td><p>Node</p></td>
<td><p>The names of graph nodes.</p></td>
</tr>
<tr class="row-odd"><td><p>Graph</p></td>
<td><p>The names of graphs within a domain, unique within the model domain.</p></td>
</tr>
<tr class="row-even"><td><p>Operator</p></td>
<td><p>The names of operators within a domain.</p></td>
</tr>
<tr class="row-odd"><td><p>Shape</p></td>
<td><p>The names of tensor shape variables – scoped to the value information records of a graph, which is where shape variables occur.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="nodes">
<h3>Nodes<a class="headerlink" href="#nodes" title="Permalink to this headline">¶</a></h3>
<p>Computation nodes are comprised of a name, the name of an operator that it invokes, a list of named inputs, a list of named outputs, and a list of attributes.</p>
<p>Input and outputs are positionally associated with operator inputs and outputs. Attributes are associated with operator attributes by name.</p>
<p>They have the following properties:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>name</p></td>
<td><p>string</p></td>
<td><p>An optional name of the node, used for diagnostic purposes only.</p></td>
</tr>
<tr class="row-odd"><td><p>input</p></td>
<td><p>string[]</p></td>
<td><p>Names of the values used by the node to propagate input values to the node operator. It must refer to either a graph input, a graph initializer or a node output.</p></td>
</tr>
<tr class="row-even"><td><p>output</p></td>
<td><p>string[]</p></td>
<td><p>Names of the outputs used by the node to capture data from the operator invoked by the node. It either introduces a  value in the graph or refers to a graph output.</p></td>
</tr>
<tr class="row-odd"><td><p>op_type</p></td>
<td><p>string</p></td>
<td><p>The symbolic identifier of the operator to invoke.</p></td>
</tr>
<tr class="row-even"><td><p>domain</p></td>
<td><p>string</p></td>
<td><p>The domain of the operator set that contains the operator named by the op_type.</p></td>
</tr>
<tr class="row-odd"><td><p>attribute</p></td>
<td><p>Attribute[]</p></td>
<td><p>Named attributes, another form of operator parameterization, used for constant values rather than propagated values.</p></td>
</tr>
<tr class="row-even"><td><p>doc_string</p></td>
<td><p>string</p></td>
<td><p>Human-readable documentation for this value. Markdown is allowed.</p></td>
</tr>
</tbody>
</table>
<p>A name belonging to the Value namespace may appear in multiple places, namely as a graph input, a graph initializer, a graph output, a node input, or a node output. The occurrence of a name as a graph input, a graph initializer, or as a node output is said to be a definition and the occurrence of a name as a node input or as a graph output is said to be a use.</p>
<p>A value name used in a graph must have a unique definition, with the exception that the same name MAY appear in both the graph input list and graph initializer list. (Further exceptions apply in the presence of nested subgraphs, as described later.)</p>
<p>When a name appears in both the initializer list and the graph input list, a runtime MAY allow a caller to specify a value for this (input) name overriding the value specified in the initializer and a runtime MAY allow users to omit specifying a value for this (input) name, choosing the value specified in the initializer. Names of constants that are not meant to be overridden by the caller should appear only in the initializer list and not in the graph input list. In models with IR version &gt;= 4, in nested subgraphs used as attribute values, users MUST NOT use the same name as both a subgraph initializer and subgraph input unless the corresponding op’s specification explicitly allows it. In models with IR version &lt;= 3, users MAY use the same name as both a subgraph initializer and subgraph input, but this is restricted to support constants via initializers that are not intended to correspond to any actual inputs passed from the node into the subgraph. In particular, the control-flow operator semantics determines the set of inputs supplied to the execution of the subgraph, and these input names MUST NOT appear as subgraph initializers. Subgraph initializer names must appear in the graph input list <em>after</em> the actual inputs. This allows the actual inputs and formal inputs to be matched positionally.</p>
<p>Edges in the computation graph are established by outputs of one node being referenced by name in the inputs of a subsequent node.</p>
<p>The outputs of a given node introduce new names into the graph. The values of node outputs are computed by the node’s operator. Node inputs MAY refer to node outputs, graph inputs, and graph initializers. When the name of a node output coincides with the name of a graph output, the graph output’s value is the corresponding output value computed by that node. A node input in a nested subgraph MAY refer to names introduced in outer graphs (as node outputs, graph inputs, or graph initializers).</p>
<p>The graph MUST use single static assignment for all node outputs, which means that all node output names MUST be unique within a graph. In the case of a nested subgraph, a node output name MUST be distinct from the names from the outer scopes that are visible in the nested subgraph.</p>
<p>Node dependencies MUST NOT create cycles in the computation graph.</p>
<p>The number of inputs and outputs in a node, their types, the set of attributes specified in a node and their types MUST satisfy the constraints imposed by the signature of the node’s operator.</p>
<p>The list of nodes defining the top-level computation graph MUST be ordered topologically; that is, if node K follows node N in the graph, none of the data inputs of N may refer to outputs of K.</p>
<p>Node attributes are used to pass literal (static) values to operators.</p>
<section id="input-and-output-values">
<h4>Input and Output Values<a class="headerlink" href="#input-and-output-values" title="Permalink to this headline">¶</a></h4>
<p>The representation distinguishes between two kinds of values: attribute values, which are statically known, and input/output values. The types of values permitted in the two cases are different.</p>
<p>Input and output values are found as graph inputs, outputs, and initializers, and as node inputs and outputs. Their values are determined at runtime, either by the code that initiates model execution, or by operators computing output values.</p>
</section>
<section id="attributes">
<h4>Attributes<a class="headerlink" href="#attributes" title="Permalink to this headline">¶</a></h4>
<p>Attribute values are only found in nodes, passed to operators by name association. Attribute values are runtime constants, in that their values are determined when a model graph is constructed and therefore not computed at runtime. A common use for attributes is to represent coefficients established during model training.</p>
<p>Attributes have the following properties:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>name</p></td>
<td><p>string</p></td>
<td><p>The name of the attribute. Must be unique among attributes, inputs, and outputs for any given operator and node.</p></td>
</tr>
<tr class="row-odd"><td><p>doc_string</p></td>
<td><p>string</p></td>
<td><p>Human-readable documentation for this value. Markdown is allowed.</p></td>
</tr>
<tr class="row-even"><td><p>type</p></td>
<td><p>AttributeType</p></td>
<td><p>The type of the attribute, determining which of the remaining fields is used to hold the value of the attribute.</p></td>
</tr>
<tr class="row-odd"><td><p>f</p></td>
<td><p>float</p></td>
<td><p>A 32-bit floating-point value.</p></td>
</tr>
<tr class="row-even"><td><p>i</p></td>
<td><p>int64</p></td>
<td><p>A 64-bit integer value.</p></td>
</tr>
<tr class="row-odd"><td><p>s</p></td>
<td><p>byte[]</p></td>
<td><p>UTF-8 string.</p></td>
</tr>
<tr class="row-even"><td><p>t</p></td>
<td><p>Tensor</p></td>
<td><p>A tensor value.</p></td>
</tr>
<tr class="row-odd"><td><p>g</p></td>
<td><p>Graph</p></td>
<td><p>A graph.</p></td>
</tr>
<tr class="row-even"><td><p>floats</p></td>
<td><p>float[]</p></td>
<td><p>A list of 32-bit floating-point values.</p></td>
</tr>
<tr class="row-odd"><td><p>ints</p></td>
<td><p>int64[]</p></td>
<td><p>A list of 64-bit integer values.</p></td>
</tr>
<tr class="row-even"><td><p>strings</p></td>
<td><p>byte[][]</p></td>
<td><p>A list of UTF-8 strings.</p></td>
</tr>
<tr class="row-odd"><td><p>tensors</p></td>
<td><p>Tensor[]</p></td>
<td><p>A list of tensor values.</p></td>
</tr>
<tr class="row-even"><td><p>graphs</p></td>
<td><p>Graph[]</p></td>
<td><p>A list of graphs.</p></td>
</tr>
</tbody>
</table>
<p>The properties ‘name’ and ‘type’ are required on all attributes, and ‘doc_string’ SHOULD be used on all attributes. An attribute MUST have only one of the value-carrying properties.</p>
</section>
<section id="variadic-inputs-and-outputs">
<h4>Variadic Inputs and Outputs<a class="headerlink" href="#variadic-inputs-and-outputs" title="Permalink to this headline">¶</a></h4>
<p>The last input or output of an operator MAY be marked as variadic. For example, the operator ‘Max()’ can be used to compute the maximum of a varying number of input values. A variadic operator has a minimum arity, which specifies the minimum number of operands that must be specified.</p>
<p>For each variadic operator input, N or more node inputs must be specified where N is the minimum arity of the operator. For each variadic operator output, N or more node outputs must be specified where N is the minimum arity of the operator.</p>
</section>
<section id="optional-inputs-and-outputs">
<h4>Optional Inputs and Outputs<a class="headerlink" href="#optional-inputs-and-outputs" title="Permalink to this headline">¶</a></h4>
<p>Some operators have inputs that are marked as optional, which means that a referring node MAY forgo providing values for such inputs.</p>
<p>Some operators have outputs that are optional. When an actual output parameter of an operator is not specified, the operator implementation MAY forgo computing values for such outputs.</p>
<p>There are two ways to leave an optional input or output unspecified: the first, available only for trailing inputs and outputs, is to simply not provide that input; the second method is to use an empty string in place of an input or output name.</p>
<p>Each node referring to an operator with optional outputs MUST provide a name for each output that is computed and MUST NOT provide names for outputs that are not computed.</p>
</section>
<section id="external-tensor-data">
<h4>External Tensor Data<a class="headerlink" href="#external-tensor-data" title="Permalink to this headline">¶</a></h4>
<p>The raw data for large constant tensors, such as initializers, MAY be serialised in a separate file. In such a case, the tensor MUST provide the filename relative to the model file and MUST NOT use the value fields. It MAY provide a byte offset and length within that file. It MAY also specify a SHA1 digest of the file. One file MAY contain the data for multiple tensors.</p>
<p>More details can be found in <a class="reference internal" href="ExternalData.html"><span class="doc std std-doc">External Data</span></a>.</p>
</section>
</section>
</section>
<section id="standard-data-types">
<h2>Standard data types<a class="headerlink" href="#standard-data-types" title="Permalink to this headline">¶</a></h2>
<p>There are two official ONNX variants; the main distinction between the two is found in the supported types and the supported operators.</p>
<p>With respect to supported types, both <strong>ONNX</strong> and <strong>ONNX-ML</strong> definition recognize tensors, sparse tensors, sequences, maps, and optionals as input and output types. Sequences and maps were supported from the IR version 6 (ONNX 1.6.0 release). Optional type was supported from IR vesion 8 (ONNX 1.10.0 release).</p>
<p>The following data types are supported by ONNX for inputs and outputs of graphs and nodes as well as the initializers of a graph.</p>
<p>Primitive numeric, string, and Boolean types MUST be used as elements of tensors.</p>
<section id="tensor-definition">
<h3>Tensor Definition<a class="headerlink" href="#tensor-definition" title="Permalink to this headline">¶</a></h3>
<p>Tensors are a generalization of vectors and matrices; whereas vectors have one dimension, and matrices two, tensors can have any number of dimensions, including zero. A zero-dimensional tensor is logically equivalent to a scalar value.</p>
<p>Mathematically, a tensor can be defined as a pair of sequences/lists (V, S) where S is the shape of the tensor (a list of non-negative integers) and V is a list of values with length equal to the product of the dimensions in S. Two tensors (V, S) and (V’, S’) are equal if and only if V = V’ and S = S’. The length of S is referred to as the rank.</p>
<ul class="simple">
<li><p>If S has length 0, V must have length 1, since the empty product is defined to be 1. In this case, the tensor represents a scalar.</p></li>
<li><p>S can contain dimensions of value 0. If any dimensions are 0, V must have length 0.</p></li>
<li><p>If S has length 1, V has length equal to the single dimension in S. In this case, the tensor represents a vector.</p></li>
<li><p>A tensor representing a vector of length 1 has shape [1], while a tensor representing a scalar has shape []. They both have a single element, but scalars are <em>not</em> vectors of length 1.</p></li>
</ul>
<p>A tensor’s shape S is a list but can be represented as a tensor with values S and shape [R] where R is the rank of the tensor.</p>
<ul class="simple">
<li><p>For a tensor (V, S), the tensor representing its shape is (S, [R]).</p></li>
<li><p>The shape of a scalar is []. Represented as a tensor, [] has shape [0].</p></li>
</ul>
<section id="representation">
<h4>Representation<a class="headerlink" href="#representation" title="Permalink to this headline">¶</a></h4>
<p>It is common to represent a tensor as a nested list. This generally works fine, but is problematic when zero dimensions are involved. A tensor of shape (5, 0) can be represented as [[], [], [], [], []], but (0, 5) is represented as [] which loses the information that the second dimension is 5.</p>
<ul class="simple">
<li><p>A nested list is not a complete representation of a tensor with dimensions of value zero.</p></li>
</ul>
</section>
</section>
<section id="tensor-element-types">
<h3>Tensor Element Types<a class="headerlink" href="#tensor-element-types" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Group</p></th>
<th class="head"><p>Types</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Floating Point Types</p></td>
<td><p>float16, float32, float64</p></td>
<td><p>Values adhering to the IEEE 754-2008 standard representation of floating-point data.</p></td>
</tr>
<tr class="row-odd"><td><p>Signed Integer Types</p></td>
<td><p>int8, int16, int32, int64</p></td>
<td><p>Signed integers are supported for 8-64 bit widths.</p></td>
</tr>
<tr class="row-even"><td><p>Unsigned Integer Types</p></td>
<td><p>uint8, uint16</p></td>
<td><p>Unsigned integers of 8 or 16 bits are supported.</p></td>
</tr>
<tr class="row-odd"><td><p>Complex Types</p></td>
<td><p>complex64, complex128</p></td>
<td><p>A complex number with either 32- or 64-bit real and imaginary parts.</p></td>
</tr>
<tr class="row-even"><td><p>Other</p></td>
<td><p>string</p></td>
<td><p>Strings represent textual data. All strings are encoded using UTF-8.</p></td>
</tr>
<tr class="row-odd"><td><p>Other</p></td>
<td><p>bool</p></td>
<td><p>Boolean values represent data with only two values, typically true and false.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="input-output-data-types">
<h3>Input / Output Data Types<a class="headerlink" href="#input-output-data-types" title="Permalink to this headline">¶</a></h3>
<p>The following types are used to define the types of graph and node inputs and outputs.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Variant</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ONNX</p></td>
<td><p>dense tensors</p></td>
<td><p>Represents a Tensor. See definition above.</p></td>
</tr>
<tr class="row-odd"><td><p>ONNX</p></td>
<td><p>sequence</p></td>
<td><p>Sequences are dense, ordered, collections of elements that are of homogeneous types.</p></td>
</tr>
<tr class="row-even"><td><p>ONNX</p></td>
<td><p>map</p></td>
<td><p>Maps are associative tables, defined by a key type and a value type.</p></td>
</tr>
<tr class="row-odd"><td><p>ONNX</p></td>
<td><p>optional</p></td>
<td><p>Optionals are wrappers that may contain an element of tensor, sequence, or map type, or may be empty (containing none). <a class="reference internal" href="ONNXTypes.html"><span class="doc std std-doc">Details</span></a></p></td>
</tr>
</tbody>
</table>
<section id="static-tensor-shapes">
<h4>Static tensor shapes<a class="headerlink" href="#static-tensor-shapes" title="Permalink to this headline">¶</a></h4>
<p>In addition to element type, tensor types have a <strong>static</strong> shape. The static shape of a tensor variable is related to, but different from, the runtime (dynamic) shape of a tensor value. A static tensor shape is a list of records that indicates whether the tensor is a vector, a matrix, or a higher-dimensional value. For example, a 100x100 matrix has the shape [100,100].</p>
<p>The static shape is defined by ‘TensorShapeProto’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">message</span> <span class="n">TensorShapeProto</span> <span class="p">{</span>
  <span class="n">message</span> <span class="n">Dimension</span> <span class="p">{</span>
    <span class="n">oneof</span> <span class="n">value</span> <span class="p">{</span>
      <span class="n">int64</span> <span class="n">dim_value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="n">string</span> <span class="n">dim_param</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">};</span>
  <span class="p">};</span>
  <span class="n">repeated</span> <span class="n">Dimension</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Which is referenced by the Tensor type message:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="n">message</span> <span class="n">Tensor</span> <span class="p">{</span>
    <span class="n">optional</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">DataType</span> <span class="n">elem_type</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">optional</span> <span class="n">TensorShapeProto</span> <span class="n">shape</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
  <span class="p">}</span>
</pre></div>
</div>
<p>The empty list of dimension sizes, [], is a valid tensor shape, denoting a zero-dimension (scalar) value. A zero-dimension tensor is distinct from a tensor of unknown dimensionality, which is indicated by an absent ‘shape’ property in the Tensor message. When the shape property is absent in the type of a value (including node input),
it indicates that the corresponding runtime value may have any shape. This sub-section describes how to interpret a missing-shape or a shape with missing dimensions etc. However, specific usage contexts may impose further constraints on a type and shape.
For example, the inputs and outputs of a model (top-level graph) are required to <em>have</em> a shape, indicating the rank of inputs and outputs,
even though the exact dimensions need not be specified.</p>
<p>Each size in the list MAY be expressed as an integral value or as a “dimension variable,” a string denoting that the actual size of the dimension is not statically constrained to a particular number. This is useful for declaring interfaces that care about the number of dimensions, but not the exact size of each dimension. A dimension MAY have neither dim_value nor dim_param set. Such a dimension represents an unknown dimension unrelated to other unknown dimensions.</p>
<p>For example, a NxM matrix would have the shape list [N,M].</p>
<p>The name of each dimension variable MUST adhere to <a class="reference external" href="https://en.cppreference.com/w/c/language/identifier">C90 identifier syntax rules</a>.</p>
<p>Currently, dimension variables are not scoped. A dimension variable “N” represents the same value across the entire graph in a model. For example, if the graph has two inputs X and Y each with shape [“N”], then at runtime the values passed in for X and Y MUST be tensors of rank 1 with the same dimension. Nested sub-graphs currently share the same scope for dimension variables as the main-graph. This allows a model to relate the dimensions of tensors inside the subgraph to the dimensions of tensors in the outer graph.</p>
<p>ONNX supports types such as Sequences of Tensors. The global scoping of dimension variables means that a variable with type “Sequence&lt;Tensor&lt;float, [M,N]&gt;” represents a sequence of tensors that <em>all have the same shape</em>. The dimension variables M or N must be omitted from the above type if that dimension does not have a fixed size across all tensors in the sequence. The entire shape must be omitted from the type if different tensors in the sequence may have different ranks.</p>
<p>For example, a graph that performs matrix cross-product may be defined as taking two inputs of shape [K,M] and [M,N], and producing an output of shape [K,N].</p>
<p>Shapes MAY be defined using a combination of integers and variables.</p>
<p><em>Historical Notes</em>: The following extensions were considered early on, but were never implemented or supported.</p>
<ul class="simple">
<li><p>The use of an empty string (as a dimension variable) to denote an unknown dimension not related to any other dimension. This was discarded in favor of using a Dimension with neither dim_value nor dim_param set.</p></li>
<li><p>The use of the string “*” (as a dimension variable) to denote a sequence of zero or more dimensions of unknown cardinality. This is not supported. In the current implementation, the number of dimensions in a shape MUST represent the rank of the tensor. A tensor of unknown rank is represented using a TypeProto::Tensor object with no shape, which is legal.</p></li>
<li><p>A scoping mechanism to allow dimension variables that are local to a sub-graph (such as the body of a loop) may be useful, but is not currently supported.</p></li>
<li><p>ONNX supports types such as Sequences of Tensors. A scoping mechanism for the dimension variables local to a type may be useful to distinguish between the following two types: a sequence of square matrices (of differing sizes) vs a sequence of square matrices (all of same size). This is not currently supported.</p></li>
</ul>
</section>
</section>
<section id="attribute-types">
<h3>Attribute Types<a class="headerlink" href="#attribute-types" title="Permalink to this headline">¶</a></h3>
<p>The type system used for attributes is related to but slightly different from that used for of inputs and outputs. Attribute values may be a dense tensor, sparse tensor, a scalar numerical value, a string, a graph, or repeated values of one of the above mentioned types.</p>
</section>
</section>
<section id="training-related-information">
<h2>Training Related Information<a class="headerlink" href="#training-related-information" title="Permalink to this headline">¶</a></h2>
<p>Training related information is described by one or more instances of <em>TrainingInfoProto</em> contained in a model. Each TrainingInfoProto contains information describing both an initialization step and a training step.</p>
<p>The initialization step is described using a Graph (TrainingInfoProto.initialization) and an initialization-binding map (TrainingInfoProto.initialization_binding). The initialization step is performed by evaluating the Graph, and assigning the outputs produced by the Graph to the <em>state variables</em> of the training model as specified in the initialization-binding. The initialization-binding is conceptually a map, specified as a list of key-value pairs, where each key is the name of a state variable, and the value is the name of an output of the (initialization) Graph. Each name specified as a key in the binding MUST be the name of an initializer that appears in the main inference graph (i.e., in ModelProto.graph.initializer) or the name of an initializer that appears in TrainingInfoProto.algorithm.initializer. Each name specified as a value in the binding MUST be the name of an output of the TrainingInfoProto.initialization graph. Key values specified in the repeated initialization_binding field MUST be unique.</p>
<p>The training step is similarly described using a Graph (TrainingInfoProto.algorithm) and an update-binding map (TrainingInfoProto.update_binding). The training step is performed by evaluating the Graph and assigning the outputs produced by the Graph to the state variables as specified in the update-binding. The constraints and description presented above for the initialization apply to the training step as well.</p>
<p>Thus, the state variables of the training model consist of a subset of the initializers of the main inference graph (i.e., ModelProto.graph.initializer) and the training-algorithm graph (TrainingInfoProto.algorithm.initializer) as identified by the keys of the bindings (in TrainingInfoProto.initialization_binding and TrainingInfoProto.update_binding). Note that the state variables are not constant values in the context of training. They represent mutable variables shared by multiple graphs (implicitly declared in the top-level training model scope). This implicit declaration of shared mutable variables is used instead of an explicit declaration for purposes of backward compatibility with the inference graph representation.</p>
<p>All state variables are pre-initialized to the value specified in the corresponding initializer. A subsequent call to perform the initialization step (using the appropriate API exposed by a runtime) updates the values of the state variables as described above. If the training model has more than one instance of TrainingInfoProto, the initialization step corresponding to each is performed in order. A TrainingInfoProto.initialization MAY be omitted (only if there are no initialization_bindings). For the training step, a runtime MAY allow users to invoke any one of the TrainingInfoProto.algorithm, allowing the training process to interleave the different algorithms as desired. The order in which the different TrainingProto.algorithms are called affects the training result, and it is the callers responsibility to call them in the correct order.</p>
</section>
<section id="other-specification-documents">
<h2>Other Specification Documents<a class="headerlink" href="#other-specification-documents" title="Permalink to this headline">¶</a></h2>
<p>The ONNX specification is comprised of this document, which defines the semantics of the IR and the standard data types, and the following documents defining standard operator semantics and the IR syntax. The latter is specified as Protobuf v2 and v3 schema files.</p>
<p>See the <a class="reference internal" href="MetadataProps.html"><span class="doc std std-doc">metadata category documentation</span></a> for more details.</p>
<section id="id1">
<h3>Operators<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="Operators.html"><span class="doc std std-doc">Neural Network Operators</span></a></p>
<p><a class="reference internal" href="Operators-ml.html"><span class="doc std std-doc">Classical Machine Learning operators</span></a></p>
</section>
<section id="syntax">
<h3>Syntax<a class="headerlink" href="#syntax" title="Permalink to this headline">¶</a></h3>
<p><span class="xref myst">ONNX Models and Graphs - protobuf v2</span></p>
<p><span class="xref myst">ONNX Models and Graphs - protobuf v3</span></p>
<p><span class="xref myst">ONNX-ML Models and Graphs - protobuf v2</span></p>
<p><span class="xref myst">ONNX-ML Models and Graphs - protobuf v3</span></p>
<p><span class="xref myst">ONNX Operator Sets - protobuf v2</span></p>
<p><span class="xref myst">ONNX Operator Sets - protobuf v3</span></p>
<p><span class="xref myst">ONNX-ML Operator Sets - protobuf v2</span></p>
<p><span class="xref myst">ONNX-ML Operator Sets - protobuf v3</span></p>
</section>
<section id="versioning-conventions-and-best-practices">
<h3>Versioning Conventions and Best Practices<a class="headerlink" href="#versioning-conventions-and-best-practices" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="Versioning.html"><span class="doc std std-doc">Versioning</span></a></p>
</section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>