
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Inference with onnxruntime in Python &#8212; onnxcustom</title>
    
    <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Training with onnxruntime" href="training_ort_api.html" />
    <link rel="prev" title="OrtValue" href="ortvalue_doc.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../gyexamples/index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_onnx/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Introduction to onnxruntime
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="ortvalue_doc.html">
     OrtValue
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Inference with onnxruntime in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="training_ort_api.html">
     Training with onnxruntime
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extensions.html">
     Extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_skl/index.html">
   scikit-learn to ONNX Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_training/index.html">
   Training Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial_bench/index.html">
   Benchmarking and profiling Tutorial
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-case">
   Simple case
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#session-options">
   Session Options
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logging">
     logging
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memory">
     memory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multithreading">
     multithreading
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extensions">
     extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#providers">
   Providers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference-on-a-device-different-from-cpu">
   Inference on a device different from CPU
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-ortvalue">
     C_OrtValue
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iobinding">
     IOBinding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#profiling">
   Profiling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graph-optimisations">
   Graph Optimisations
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="inference-with-onnxruntime-in-python">
<h1>Inference with onnxruntime in Python<a class="headerlink" href="#inference-with-onnxruntime-in-python" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#simple-case" id="id1">Simple case</a></p></li>
<li><p><a class="reference internal" href="#session-options" id="id2">Session Options</a></p>
<ul>
<li><p><a class="reference internal" href="#logging" id="id3">logging</a></p></li>
<li><p><a class="reference internal" href="#memory" id="id4">memory</a></p></li>
<li><p><a class="reference internal" href="#multithreading" id="id5">multithreading</a></p></li>
<li><p><a class="reference internal" href="#extensions" id="id6">extensions</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#providers" id="id7">Providers</a></p></li>
<li><p><a class="reference internal" href="#inference-on-a-device-different-from-cpu" id="id8">Inference on a device different from CPU</a></p>
<ul>
<li><p><a class="reference internal" href="#c-ortvalue" id="id9">C_OrtValue</a></p></li>
<li><p><a class="reference internal" href="#iobinding" id="id10">IOBinding</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#profiling" id="id11">Profiling</a></p></li>
<li><p><a class="reference internal" href="#graph-optimisations" id="id12">Graph Optimisations</a></p></li>
</ul>
</div>
<section id="simple-case">
<h2><a class="toc-backref" href="#id1">Simple case</a><a class="headerlink" href="#simple-case" title="Permalink to this headline">¶</a></h2>
<p>The main class is <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a>. It loads
an ONNX graph executes all the nodes in it.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">skl2onnx</span> <span class="kn">import</span> <span class="n">to_onnx</span>

<span class="c1"># creation of an ONNX graph</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">clr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">clr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model_def</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">clr</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>

<span class="c1"># InferenceSession only accepts a file name or the serialized</span>
<span class="c1"># ONNX graph.</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">model_def</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="c1"># Method run takes two inputs, first one is</span>
<span class="c1"># the list of desired outputs or None for all,</span>
<span class="c1"># second is the input tensors in a dictionary</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">]})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;linreg_model.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">model_def</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">115.467</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">83.46</span> <span class="p">],</span>
           <span class="p">[</span><span class="mf">160.779</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">187.658</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">72.724</span><span class="p">]])]</span>
</pre></div>
</div>
<p>And visually:</p>

    <div id="gdot-140033938749280-cont"><div id="gdot-140033938749280" style="width:100%;height:100%;"></div>
    <script>

    require(['../../_static/viz.js'], function() { var svgGraph = Viz(" digraph{\n  size=7;\n  orientation=portrait;\n  nodesep=0.05;\n  ranksep=0.25;\n\n  X [shape=box color=red label=\"X\\ndouble((0, 10))\" fontsize=10];\n\n  variable [shape=box color=green label=\"variable\\ndouble((0, 1))\" fontsize=10];\n\n  coef [shape=box label=\"coef\\nfloat64((10, 1))\\n[[ -60.222]\\n [-266.459]\\n [ 523.06 ]\\n [ 310.515]\\n [...\" fontsize=10];\n  intercept [shape=box label=\"intercept\\nfloat64((1,))\\n[152.228]\" fontsize=10];\n  shape_tensor [shape=box label=\"shape_tensor\\nint64((2,))\\n[-1  1]\" fontsize=10];\n\n  multiplied [shape=box label=\"multiplied\" fontsize=10];\n  MatMul [shape=box style=\"filled,rounded\" color=orange label=\"MatMul\\n(MatMul)\" fontsize=10];\n  X -> MatMul;\n  coef -> MatMul;\n  MatMul -> multiplied;\n\n  resh [shape=box label=\"resh\" fontsize=10];\n  Add [shape=box style=\"filled,rounded\" color=orange label=\"Add\\n(Add)\" fontsize=10];\n  multiplied -> Add;\n  intercept -> Add;\n  Add -> resh;\n\n  Reshape [shape=box style=\"filled,rounded\" color=orange label=\"Reshape\\n(Reshape)\" fontsize=10];\n  resh -> Reshape;\n  shape_tensor -> Reshape;\n  Reshape -> variable;\n}\n");
    document.getElementById('gdot-140033938749280').innerHTML = svgGraph; });
    
</script>
</div><p>Some informations about the graph can be retrieved
through the class <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a> such as
inputs and outputs.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="s2">&quot;linreg_model.onnx&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">sess</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input:&quot;</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">sess</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output:&quot;</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="nb">input</span><span class="p">:</span> <span class="n">X</span> <span class="n">tensor</span><span class="p">(</span><span class="n">double</span><span class="p">)</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">variable</span> <span class="n">tensor</span><span class="p">(</span><span class="n">double</span><span class="p">)</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>The class <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a> is not pickable.
It must be restored from the ONNX file.
C API is slightly different. The C object is
stored in attribute <cite>_sess</cite>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">RunOptions</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="s2">&quot;linreg_model.onnx&quot;</span><span class="p">)</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="o">.</span><span class="n">outputs_meta</span><span class="p">]</span>
<span class="n">ro</span> <span class="o">=</span> <span class="n">RunOptions</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">},</span> <span class="n">ro</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[</span><span class="n">array</span><span class="p">([[</span>  <span class="mf">19.783</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">549.877</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">1616.714</span><span class="p">],</span>
           <span class="p">[</span><span class="o">-</span><span class="mf">375.734</span><span class="p">],</span>
           <span class="p">[</span><span class="o">-</span><span class="mf">563.955</span><span class="p">]])]</span>
</pre></div>
</div>
</section>
<section id="session-options">
<h2><a class="toc-backref" href="#id2">Session Options</a><a class="headerlink" href="#session-options" title="Permalink to this headline">¶</a></h2>
<p>Many options can change the behaviour of the class during predictions.
First class is <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#sessionoptions">SessionOptions</a>.
Next sections describe some of the members.
This class can also be used to profile the execution or
adjust graph optimization. This will be seen in further sections.
Next sections just give an overview, you should go to classes
<a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#sessionoptions">SessionOptions</a> and <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#runoptions">RunOptions</a> to get the full list.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">SessionOptions</span>
<span class="n">so</span> <span class="o">=</span> <span class="n">SessionOptions</span><span class="p">()</span>
<span class="c1"># so.... =</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="o">....</span><span class="p">,</span> <span class="n">so</span><span class="p">)</span>
</pre></div>
</div>
<section id="logging">
<h3><a class="toc-backref" href="#id3">logging</a><a class="headerlink" href="#logging" title="Permalink to this headline">¶</a></h3>
<p>Parameters <em>log_severity_level</em> and <em>log_verbosity_level</em> may change
the verbosity level when the model is loaded.</p>
<p>The logging during execution can be modified with the same
attributes but in class <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#runoptions">RunOptions</a>. This class is given
to method <cite>run</cite>.</p>
</section>
<section id="memory">
<h3><a class="toc-backref" href="#id4">memory</a><a class="headerlink" href="#memory" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> focuses on efficiency first and memory peaks.
Following what should be the priority, following members
may be changed to trade efficiency against memory usage.</p>
<ul class="simple">
<li><p><em>enable_cpu_mem_arena</em>: Enables the memory arena on CPU.
Arena may pre-allocate memory for future usage.
Set this option to false if you don’t want it.
Default is True.</p></li>
<li><p><em>enable_mem_pattern</em>: Enable the memory pattern optimization.
Default is true.</p></li>
<li><p><em>enable_mem_reuse</em>: Enable the memory reuse optimization.
Default is true.</p></li>
</ul>
</section>
<section id="multithreading">
<h3><a class="toc-backref" href="#id5">multithreading</a><a class="headerlink" href="#multithreading" title="Permalink to this headline">¶</a></h3>
<p>By default, <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> parallelizes the execution
within every node but does not run multiple node at the same time.
But that can be changed.</p>
<ul class="simple">
<li><p><em>inter_op_num_threads</em>: Sets the number of threads used to
parallelize the execution of the graph (across nodes).
Default is 0 to let onnxruntime choose.</p></li>
<li><p><em>intra_op_num_threads</em>:  Sets the number of threads used to
parallelize the execution within nodes.
Default is 0 to let onnxruntime choose.</p></li>
</ul>
</section>
<section id="extensions">
<h3><a class="toc-backref" href="#id6">extensions</a><a class="headerlink" href="#extensions" title="Permalink to this headline">¶</a></h3>
<p>Attribute <cite>register_custom_ops_library</cite> to register an
assembly implementing the runtime for custom nodes.
<a class="reference external" href="https://github.com/microsoft/onnxruntime-extensions">onnxruntime-extensions</a> is one of these extensions
mostly focusing on text processing (tokenizers) or simple
text manipulations. An exemple can be seen in section
<a class="reference internal" href="extensions.html#l-custom-runtime-extensions"><span class="std std-ref">Custom runtime</span></a>.</p>
</section>
</section>
<section id="providers">
<h2><a class="toc-backref" href="#id7">Providers</a><a class="headerlink" href="#providers" title="Permalink to this headline">¶</a></h2>
<p>A provider is usually a list of implementation of ONNX operator
for a specific environment. <cite>CPUExecutionProvider</cite> provides implementations
for all operator on CPU. <cite>CUDAExecutionProvider</cite> does the same for GPU and
the CUDA drivers. The list of all providers depends on the compilation
settings. The list of available providers is a subset which depends on the machine
<a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> is running on.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;all providers&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">get_all_providers</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;available providers&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">get_available_providers</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="nb">all</span> <span class="n">providers</span>
    <span class="p">[</span><span class="s1">&#39;TensorrtExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;CUDAExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;MIGraphXExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;ROCMExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;OpenVINOExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;DnnlExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;NupharExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;TvmExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;VitisAIExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;NnapiExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;CoreMLExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;ArmNNExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;ACLExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;DmlExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;RknpuExecutionProvider&#39;</span><span class="p">,</span>
     <span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">]</span>
    <span class="n">available</span> <span class="n">providers</span>
    <span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p><a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> selects <cite>CPUExecutionProvider</cite> if it is the only one available.
It raises an exception if there are more.
It is possible to select which provider must be used for the execution
by filling argument <cite>providers</cite>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span>
    <span class="o">...</span>
    <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CUDAExecutionProvider&#39;</span><span class="p">,</span>  <span class="c1"># first one takes precedence</span>
               <span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">]</span>
    <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>All operators are not available in all providers, using multiple may improve
the processing time. Switching from one provider to another may mean
moving data from one memory manager to another, like the transition from CPU
to CUDA or the other way.</p>
</section>
<section id="inference-on-a-device-different-from-cpu">
<h2><a class="toc-backref" href="#id8">Inference on a device different from CPU</a><a class="headerlink" href="#inference-on-a-device-different-from-cpu" title="Permalink to this headline">¶</a></h2>
<p>By default, everything happens on CPU.
Next lines show how to do computation on GPU
with <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a>. Method <cite>run</cite> was using numpy arrays,
another method is needed to use another device.
The choice is not unique.
Example <a class="reference internal" href="../../gyexamples/plot_benchmark_ort_api.html#benchmark-ort-api"><span class="std std-ref">Benchmark onnxruntime API: run or …</span></a> shows which API is the fastest.</p>
<section id="c-ortvalue">
<h3><a class="toc-backref" href="#id9">C_OrtValue</a><a class="headerlink" href="#c-ortvalue" title="Permalink to this headline">¶</a></h3>
<p>Method <cite>run_with_ort_values</cite> works the same way as <cite>run</cite>.
Next example shows how to call the API with any OrtValue
whatever the device it is stored on.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">)</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="s2">&quot;linreg_model.onnx&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ort_X</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="o">.</span><span class="n">outputs_meta</span><span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="o">.</span><span class="n">run_with_ort_values</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">ort_X</span><span class="p">},</span> <span class="n">names</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[[</span><span class="o">-</span><span class="mf">1049.626</span><span class="p">]</span>
     <span class="p">[</span><span class="o">-</span><span class="mf">2233.841</span><span class="p">]</span>
     <span class="p">[</span> <span class="o">-</span><span class="mf">156.136</span><span class="p">]</span>
     <span class="p">[</span> <span class="mf">2679.331</span><span class="p">]</span>
     <span class="p">[</span>  <span class="mf">483.144</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<section id="iobinding">
<h3><a class="toc-backref" href="#id10">IOBinding</a><a class="headerlink" href="#iobinding" title="Permalink to this headline">¶</a></h3>
<p>This API is slower than the previous one but is convenient when
not all inputs change between two calls to the API.
It relies on an intermediate structure
<a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/api/onnxruntime_python/inference.html#onnxruntime.capi._pybind_state.SessionIOBinding">SessionIOBinding</a>. The structure is used to bind an array
knowing its shape, its type, its address, to an input name.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">,</span> <span class="n">SessionIOBinding</span><span class="p">)</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="s2">&quot;linreg_model.onnx&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">bind</span> <span class="o">=</span> <span class="n">SessionIOBinding</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Next line binds the array to the input name.</span>
<span class="n">bind</span><span class="o">.</span><span class="n">bind_input</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">X</span><span class="o">.</span><span class="n">__array_interface__</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># This line tells on which device the result should be stored.</span>
<span class="n">bind</span><span class="o">.</span><span class="n">bind_output</span><span class="p">(</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="c1"># Inference.</span>
<span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="o">.</span><span class="n">run_with_iobinding</span><span class="p">(</span><span class="n">bind</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1"># Next line retrieves the outputs as a list of OrtValue.</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">bind</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()</span>

<span class="c1"># Conversion to numpy to see the result.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[[</span><span class="o">-</span><span class="mf">623.62</span> <span class="p">]</span>
     <span class="p">[</span> <span class="o">-</span><span class="mf">71.85</span> <span class="p">]</span>
     <span class="p">[</span> <span class="mf">456.467</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">1256.325</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">1538.541</span><span class="p">]]</span>
</pre></div>
</div>
<p>When the input is an OrtValue, another method is available.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">,</span> <span class="n">SessionIOBinding</span><span class="p">)</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="s2">&quot;linreg_model.onnx&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">bind</span> <span class="o">=</span> <span class="n">SessionIOBinding</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Next line was changed.</span>
<span class="n">ort_X</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">bind</span><span class="o">.</span><span class="n">bind_ortvalue_input</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">ort_X</span><span class="p">)</span>

<span class="n">bind</span><span class="o">.</span><span class="n">bind_output</span><span class="p">(</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="o">.</span><span class="n">run_with_iobinding</span><span class="p">(</span><span class="n">bind</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">bind</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[[</span><span class="o">-</span><span class="mf">1038.512</span><span class="p">]</span>
     <span class="p">[</span>  <span class="mf">939.972</span><span class="p">]</span>
     <span class="p">[</span>  <span class="mf">591.298</span><span class="p">]</span>
     <span class="p">[</span>  <span class="o">-</span><span class="mf">79.648</span><span class="p">]</span>
     <span class="p">[</span>  <span class="mf">431.312</span><span class="p">]]</span>
</pre></div>
</div>
<p>The last example binds the output to avoid a copy of the results.
It gives an existing and allocated OrtValue which receives
this output, as if it was inplace.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span> <span class="nn">onnxruntime.capi._pybind_state</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># pylint: disable=E0611</span>
    <span class="n">OrtDevice</span> <span class="k">as</span> <span class="n">C_OrtDevice</span><span class="p">,</span>
    <span class="n">OrtValue</span> <span class="k">as</span> <span class="n">C_OrtValue</span><span class="p">,</span>
    <span class="n">OrtMemType</span><span class="p">,</span> <span class="n">SessionIOBinding</span><span class="p">)</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="s2">&quot;linreg_model.onnx&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">bind</span> <span class="o">=</span> <span class="n">SessionIOBinding</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">C_OrtDevice</span><span class="p">(</span><span class="n">C_OrtDevice</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">OrtMemType</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ort_X</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">bind</span><span class="o">.</span><span class="n">bind_ortvalue_input</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">ort_X</span><span class="p">)</span>

<span class="c1"># This line tells on which device the result should be stored.</span>
<span class="n">ort_prediction</span> <span class="o">=</span> <span class="n">C_OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">bind</span><span class="o">.</span><span class="n">bind_ortvalue_output</span><span class="p">(</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span> <span class="n">ort_prediction</span><span class="p">)</span>

<span class="c1"># Inference.</span>
<span class="n">sess</span><span class="o">.</span><span class="n">_sess</span><span class="o">.</span><span class="n">run_with_iobinding</span><span class="p">(</span><span class="n">bind</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1"># Result.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[[</span><span class="o">-</span><span class="mf">1055.742</span><span class="p">]</span>
     <span class="p">[</span>  <span class="mf">438.955</span><span class="p">]</span>
     <span class="p">[</span>  <span class="mf">265.055</span><span class="p">]</span>
     <span class="p">[</span>  <span class="mf">204.501</span><span class="p">]</span>
     <span class="p">[</span><span class="o">-</span><span class="mf">1832.247</span><span class="p">]]</span>
</pre></div>
</div>
</section>
</section>
<section id="profiling">
<h2><a class="toc-backref" href="#id11">Profiling</a><a class="headerlink" href="#profiling" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> offers the possibility to profile
the execution of a graph. It measures the time spent
in each operator. The user starts the profiling when
creating an instance of <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a> and stops
it with method <cite>end_profiling</cite>. It stores the results
as a json file whose name is returned by the method.
The end of the example uses a tool to convert the json
into a table.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">RunOptions</span><span class="p">,</span> <span class="n">SessionOptions</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">skl2onnx</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt.ops_whole.session</span> <span class="kn">import</span> <span class="n">OnnxWholeSession</span>

<span class="c1"># creation of an ONNX graph.</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">km</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">km</span><span class="p">,</span> <span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># creation of a session that enables the profiling</span>
<span class="n">so</span> <span class="o">=</span> <span class="n">SessionOptions</span><span class="p">()</span>
<span class="n">so</span><span class="o">.</span><span class="n">enable_profiling</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">so</span><span class="p">)</span>

<span class="c1"># execution</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">111</span><span class="p">):</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)},</span> <span class="p">)</span>

<span class="c1"># profiling ends</span>
<span class="n">prof</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">end_profiling</span><span class="p">()</span>
<span class="c1"># and is collected in that file:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prof</span><span class="p">)</span>

<span class="c1"># what does it look like?</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">prof</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">js</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">js</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>

<span class="c1"># a tool to convert it into a table</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">OnnxWholeSession</span><span class="o">.</span><span class="n">process_profiling</span><span class="p">(</span><span class="n">js</span><span class="p">))</span>

<span class="c1"># it has the following columns</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># and looks this way</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;inference_profiling.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">onnxruntime_profile__2022</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">08_03</span><span class="o">-</span><span class="mi">04</span><span class="o">-</span><span class="mf">40.</span><span class="n">json</span>
    <span class="p">[{</span><span class="s1">&#39;cat&#39;</span><span class="p">:</span> <span class="s1">&#39;Session&#39;</span><span class="p">,</span> <span class="s1">&#39;pid&#39;</span><span class="p">:</span> <span class="mi">17150</span><span class="p">,</span> <span class="s1">&#39;tid&#39;</span><span class="p">:</span> <span class="mi">17150</span><span class="p">,</span> <span class="s1">&#39;dur&#39;</span><span class="p">:</span> <span class="mi">618</span><span class="p">,</span> <span class="s1">&#39;ts&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;ph&#39;</span><span class="p">:</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;model_loading_array&#39;</span><span class="p">,</span> <span class="s1">&#39;args&#39;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span><span class="s1">&#39;cat&#39;</span><span class="p">:</span> <span class="s1">&#39;Session&#39;</span><span class="p">,</span> <span class="s1">&#39;pid&#39;</span><span class="p">:</span> <span class="mi">17150</span><span class="p">,</span> <span class="s1">&#39;tid&#39;</span><span class="p">:</span> <span class="mi">17150</span><span class="p">,</span> <span class="s1">&#39;dur&#39;</span><span class="p">:</span> <span class="mi">3234</span><span class="p">,</span> <span class="s1">&#39;ts&#39;</span><span class="p">:</span> <span class="mi">672</span><span class="p">,</span> <span class="s1">&#39;ph&#39;</span><span class="p">:</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;session_initialization&#39;</span><span class="p">,</span> <span class="s1">&#39;args&#39;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span><span class="s1">&#39;cat&#39;</span><span class="p">:</span> <span class="s1">&#39;Node&#39;</span><span class="p">,</span> <span class="s1">&#39;pid&#39;</span><span class="p">:</span> <span class="mi">17150</span><span class="p">,</span> <span class="s1">&#39;tid&#39;</span><span class="p">:</span> <span class="mi">17150</span><span class="p">,</span> <span class="s1">&#39;dur&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;ts&#39;</span><span class="p">:</span> <span class="mi">8565</span><span class="p">,</span> <span class="s1">&#39;ph&#39;</span><span class="p">:</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Re_ReduceSumSquare_fence_before&#39;</span><span class="p">,</span> <span class="s1">&#39;args&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;op_name&#39;</span><span class="p">:</span> <span class="s1">&#39;ReduceSumSquare&#39;</span><span class="p">}}]</span>
    <span class="n">Index</span><span class="p">([</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;pid&#39;</span><span class="p">,</span> <span class="s1">&#39;tid&#39;</span><span class="p">,</span> <span class="s1">&#39;dur&#39;</span><span class="p">,</span> <span class="s1">&#39;ts&#39;</span><span class="p">,</span> <span class="s1">&#39;ph&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;args_op_name&#39;</span><span class="p">,</span>
           <span class="s1">&#39;args_thread_scheduling_stats&#39;</span><span class="p">,</span> <span class="s1">&#39;args_activation_size&#39;</span><span class="p">,</span>
           <span class="s1">&#39;args_parameter_size&#39;</span><span class="p">,</span> <span class="s1">&#39;args_graph_index&#39;</span><span class="p">,</span> <span class="s1">&#39;args_output_size&#39;</span><span class="p">,</span>
           <span class="s1">&#39;args_provider&#39;</span><span class="p">,</span> <span class="s1">&#39;args_exec_plan_index&#39;</span><span class="p">],</span>
          <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;object&#39;</span><span class="p">)</span>
           <span class="n">cat</span>    <span class="n">pid</span>  <span class="o">...</span>         <span class="n">args_provider</span>  <span class="n">args_exec_plan_index</span>
    <span class="mi">0</span>  <span class="n">Session</span>  <span class="mi">17150</span>  <span class="o">...</span>                   <span class="n">NaN</span>                   <span class="n">NaN</span>
    <span class="mi">1</span>  <span class="n">Session</span>  <span class="mi">17150</span>  <span class="o">...</span>                   <span class="n">NaN</span>                   <span class="n">NaN</span>
    <span class="mi">2</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>                   <span class="n">NaN</span>                   <span class="n">NaN</span>
    <span class="mi">3</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>  <span class="n">CPUExecutionProvider</span>                     <span class="mi">0</span>
    <span class="mi">4</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>                   <span class="n">NaN</span>                   <span class="n">NaN</span>
    <span class="mi">5</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>                   <span class="n">NaN</span>                   <span class="n">NaN</span>
    <span class="mi">6</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>  <span class="n">CPUExecutionProvider</span>                     <span class="mi">1</span>
    <span class="mi">7</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>                   <span class="n">NaN</span>                   <span class="n">NaN</span>
    <span class="mi">8</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>                   <span class="n">NaN</span>                   <span class="n">NaN</span>
    <span class="mi">9</span>     <span class="n">Node</span>  <span class="mi">17150</span>  <span class="o">...</span>  <span class="n">CPUExecutionProvider</span>                     <span class="mi">2</span>
    
    <span class="p">[</span><span class="mi">10</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">15</span> <span class="n">columns</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">full_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;inference_profiling.csv&quot;</span><span class="p">)))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">full_name</span><span class="p">)</span>

<span class="c1"># but a graph is usually better...</span>
<span class="n">gr_dur</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;dur&#39;</span><span class="p">,</span> <span class="s2">&quot;args_op_name&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;args_op_name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;dur&#39;</span><span class="p">)</span>
<span class="n">gr_n</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;dur&#39;</span><span class="p">,</span> <span class="s2">&quot;args_op_name&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;args_op_name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;dur&#39;</span><span class="p">)</span>
<span class="n">gr_n</span> <span class="o">=</span> <span class="n">gr_n</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">gr_dur</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">gr_dur</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">gr_dur</span> <span class="o">/=</span> <span class="n">gr_dur</span><span class="p">[</span><span class="s1">&#39;dur&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">gr_dur</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">gr_n</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;duration&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;proportion&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;n occurences&quot;</span><span class="p">);</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">ax</span><span class="p">:</span>
    <span class="n">a</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Another example can be found in the tutorial:
<a class="reference internal" href="../../gyexamples/plot_profile_ort.html#l-profile-ort-api"><span class="std std-ref">Profile onnxruntime execution</span></a>.</p>
</section>
<section id="graph-optimisations">
<h2><a class="toc-backref" href="#id12">Graph Optimisations</a><a class="headerlink" href="#graph-optimisations" title="Permalink to this headline">¶</a></h2>
<p>By default, <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> optimizes an ONNX graph as much
as it can. It removes every node it can, merges duplicated initializers,
fuses nodes into more complex node but more efficient such
as <em>FusedMatMul</em> which deals with transposition as well.
There are four level of optimization and the final can be saved
on a disk to look at it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">so</span> <span class="o">=</span> <span class="n">SessionOptions</span><span class="p">()</span>
<span class="n">so</span><span class="o">.</span><span class="n">graph_optimization_level</span> <span class="o">=</span> <span class="n">GraphOptimizationLevel</span><span class="o">.</span><span class="n">ORT_DISABLE_ALL</span>
<span class="c1"># or GraphOptimizationLevel.ORT_ENABLE_BASIC</span>
<span class="c1"># or GraphOptimizationLevel.ORT_ENABLE_EXTENDED</span>
<span class="c1"># or GraphOptimizationLevel.ORT_ENABLE_ALL</span>
<span class="n">so</span><span class="o">.</span><span class="n">optimized_model_filepath</span> <span class="o">=</span> <span class="s2">&quot;to_save_the_optimized_onnx_file.onnx&quot;</span>
</pre></div>
</div>
<p>The bigger the graph is, the more efficient optimizations are.
One example shows how to enable or disable optimizations on a simple
graph: <a class="reference internal" href="../../gyexamples/plot_benchmark_graph_opt.html#benchmark-ort-onnx-graph-opt"><span class="std std-ref">Benchmark onnxruntime optimization</span></a>.</p>
<p>Class <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/inference.html#python-wrapper-for-inferencesession">InferenceSession</a> as any other class from
<a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a> cannot be pickled. Everything can
be created again from the ONNX file it loads. It also means
graph optimization are computed again. To speed up
the process, the optimized graph can be saved
and loaded with disabled optimization next time.
It can save the optimization time.</p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ortvalue_doc.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">OrtValue</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="training_ort_api.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Training with onnxruntime</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>