{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Add a parser to handle dataframes\n\n.. index:: parser, dataframe\n\n`l-custom-parser` shows how to add a parser to define\na converter a model which works differently than standard\npredictors of :epkg:`scikit-learn`. In this case,\nthe input is a dataframe and takes an input per column\nof the dataframe. One input is impossible because a dataframe\nmay contain different types.\n\n## A transformer taking a dataframe as input\n\nSome imports...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\nfrom pyquickhelper.helpgen.graphviz_helper import plot_graphviz\nfrom mlprodict.onnxrt import OnnxInference\nimport numpy\nfrom pandas import DataFrame\nfrom onnxruntime import InferenceSession\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.tree import DecisionTreeRegressor\nfrom onnxconverter_common.onnx_ops import apply_cast\nfrom skl2onnx.proto import onnx_proto\nfrom skl2onnx import (\n    update_registered_converter, to_onnx, get_model_alias)\nfrom skl2onnx._parse import _parse_sklearn_simple_model\nfrom skl2onnx.common.data_types import (\n    Int64TensorType, StringTensorType, FloatTensorType,\n    _guess_numpy_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Later a discretizer is needed. The most efficient way\nto represent it in ONNX is to use a tree. We could\ndirectly convert the discretizer or train a decision tree\nto predict the bins. The second approach is followed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DiscretizeTransformer(TransformerMixin, BaseEstimator):\n    def __init__(self, thresholds):\n        BaseEstimator.__init__(self)\n        TransformerMixin.__init__(self)\n        self.thresholds = thresholds\n\n    def fit(self, X, y=None, sample_weights=None):\n        # Does nothing.\n        if len(X.shape) != 2 or X.shape[1]:\n            raise RuntimeError(\"The transformer expects only one columns.\")\n        return self\n\n    def transform(self, X):\n        return numpy.digitize(\n            X, self.thresholds, right=True).reshape((-1, 1))\n\n    def astree(self):\n        \"Converters the discretizer as a tree.\"\n        X = []\n        y = []\n        for i, th in enumerate(self.thresholds):\n            if i == 0:\n                th_ = th - (self.thresholds[1] - th) * 0.1\n                X.append(th_)\n                y.append(i)\n                X.append(th)\n                y.append(i + 1)\n            else:\n                th_ = th - (th - self.thresholds[i - 1]) * 0.1\n                X.append(th_)\n                y.append(i)\n                X.append(th)\n                y.append(i + 1)\n        tree = DecisionTreeRegressor()\n        tree.fit(numpy.array(X).reshape((-1, 1)),\n                 numpy.array(y))\n        # We need to make sure the threshold in three are\n        # exactly the same.\n        for i in range(0, len(tree.tree_.threshold)):\n            if (tree.tree_.children_left[i] > 0 and\n                    tree.tree_.children_right[i] > 0):\n                # not a leave, let's find the closest threshold\n                th = tree.tree_.threshold[i]\n                dist = numpy.abs(self.thresholds - th)\n                arg = numpy.argmin(dist)\n                tree.tree_.threshold[i] = self.thresholds[arg]\n        return tree\n\n\nX = numpy.array([-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n                dtype=numpy.float32).reshape((-1, 1))\nbins = numpy.array([0, 2, 4, 9], numpy.float32)\ndisc = DiscretizeTransformer(bins)\ngot = disc.transform(X)\nprint(got.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now with the tree.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tree = disc.astree()\npred = tree.predict(X)\nprint(pred.ravel().astype(numpy.int64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That works.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class PreprocessDataframeTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"\n    Converts all columns of a dataframe in integers\n    than in floats.\n    \"\"\"\n\n    def __init__(self):\n        BaseEstimator.__init__(self)\n        TransformerMixin.__init__(self)\n\n    def fit(self, X, y=None, sample_weights=None):\n        \"Trains the transformer. Creates the member `args_`.\"\n        if sample_weights is not None:\n            raise NotImplementedError(\n                \"sample_weights != None is not implemented.\")\n        if not isinstance(X, DataFrame):\n            raise TypeError(\"X must be a dataframe.\")\n        self.args_ = []\n        for i, (col, dt) in enumerate(zip(X.columns, X.dtypes)):\n            values = X[col].values\n            if dt in (numpy.float32, numpy.float64):\n                qu = numpy.quantile(values, numpy.arange(4) * 0.25)\n                self.args_.append((i, col, dt, DiscretizeTransformer(qu)))\n            elif dt == 'category':\n                oo = OrdinalEncoder(dtype=numpy.int64)\n                values = values.to_numpy()\n                oo.fit(values.reshape((-1, 1)))\n                self.args_.append((i, col, dt, oo))\n            else:\n                raise RuntimeError(\n                    \"Unable to transform column '{}' type: '{}'.\".format(\n                        col, dt))\n        return self\n\n    def transform(self, X):\n        if not isinstance(X, DataFrame):\n            raise TypeError(\"X must be a dataframe.\")\n        outs = []\n        for i, col, dt, arg in self.args_:\n            if X.columns[i] != col:\n                raise RuntimeError(\n                    \"Unexpected column name '{}' at position {}.\".format(\n                        col, i))\n            if X.dtypes[i] != dt:\n                raise RuntimeError(\n                    \"Unexpected column type '{}' at position {}.\".format(\n                        col, i))\n            values = X[col].values\n            if dt in (numpy.float32, numpy.float64):\n                out = arg.transform(values)\n            elif dt == 'category':\n                values = values.to_numpy()\n                out = arg.transform(values.reshape((-1, 1)))\n            outs.append(out)\n        res = numpy.hstack(outs)\n        return res.astype(numpy.float32)\n\n\ndata = DataFrame([\n    dict(afloat=0.5, anint=4, astring=\"A\"),\n    dict(afloat=0.6, anint=5, astring=\"B\"),\n    dict(afloat=0.7, anint=6, astring=\"C\"),\n    dict(afloat=0.8, anint=5, astring=\"D\"),\n    dict(afloat=0.9, anint=4, astring=\"C\"),\n    dict(afloat=1.0, anint=5, astring=\"B\")])\ndata['afloat'] = data['afloat'].astype(numpy.float32)\ndata['anint'] = data['anint'].astype('category')\ndata['astring'] = data['astring'].astype('category')\n\ndec = PreprocessDataframeTransformer()\ndec.fit(data)\npred = dec.transform(data)\nprint(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion into ONNX\n\nThe transform has multiple inputs but one outputs.\nThis case is not standard and requires a custom parser.\nThe model ingests different types but returns one output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def preprocess_dataframe_transformer_parser(\n        scope, model, inputs, custom_parsers=None):\n    if len(inputs) != len(model.args_):\n        raise RuntimeError(\n            \"Converter expects {} inputs but got {}.\".format(\n                len(model.args_), len(inputs)))\n    transformed_result_names = []\n    for i, col, dt, arg in model.args_:\n        if dt in (numpy.float32, numpy.float64):\n            op = scope.declare_local_operator('CustomDiscretizeTransformer')\n            op.inputs = [inputs[i]]\n            op.raw_operator = arg\n            op_var = scope.declare_local_variable(\n                'output{}'.format(i), Int64TensorType())\n            op.outputs.append(op_var)\n            transformed_result_names.append(op.outputs[0])\n        elif dt == 'category':\n            transformed_result_names.append(\n                _parse_sklearn_simple_model(\n                    scope, arg, [inputs[i]],\n                    custom_parsers=custom_parsers)[0])\n\n    # Create a Concat ONNX node\n    concat_operator = scope.declare_local_operator('SklearnConcat')\n    concat_operator.inputs = transformed_result_names\n    union_name = scope.declare_local_variable(\n        'union', FloatTensorType())\n    concat_operator.outputs.append(union_name)\n    return concat_operator.outputs\n\n\ndef preprocess_dataframe_transformer_shape_calculator(operator):\n    op = operator.raw_operator\n    input_dim = operator.inputs[0].type.shape[0]\n    operator.outputs[0].type = FloatTensorType([input_dim, len(op.args_)])\n\n\ndef preprocess_dataframe_transformer_converter(scope, operator, container):\n    # op = operator.raw_operator\n    # opv = container.target_opset\n    # out = operator.outputs\n    raise NotImplementedError(\n        \"Converter for PreprocessDataframeTransformer is \"\n        \"implemented in the parser.\")\n\n\nupdate_registered_converter(\n    PreprocessDataframeTransformer,\n    \"CustomPreprocessDataframeTransformer\",\n    preprocess_dataframe_transformer_shape_calculator,\n    preprocess_dataframe_transformer_converter,\n    parser=preprocess_dataframe_transformer_parser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def guess_schema_from_data(data):\n    res = []\n    for col, dt in zip(data.columns, data.dtypes):\n        try:\n            is_cat = dt == 'category'\n        except TypeError:\n            is_cat = False\n        if is_cat:\n            if isinstance(dt.categories[0], str):\n                res.append((col, StringTensorType([None, 1])))\n            else:\n                res.append((col, Int64TensorType([None, 1])))\n        else:\n            res.append((col, _guess_numpy_type(dt, [None, 1])))\n    return res\n\n\ninitial_types = guess_schema_from_data(data)\nprint(initial_types)\n\ntry:\n    onx = to_onnx(dec, initial_types=initial_types,\n                  target_opset={'': 14, 'ai.onnx.ml': 2})\nexcept RuntimeError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The converter for alias DiscretizeTransform is not here.\nLet's add it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def discretizer_transformer_shape_calculator(operator):\n    operator.outputs[0].type = operator.inputs[0].type.__class__([None, 1])\n\n\ndef discretizer_transformer_converter(scope, operator, container):\n    op = operator.raw_operator\n\n    # We convert the discretizer into a tree.\n    model = op.astree()\n\n    # We add a placeholder to call the converter for\n    # this model.\n    alias = get_model_alias(type(model))\n    op = scope.declare_local_operator(alias)\n    op.inputs = operator.inputs\n    op.raw_operator = model\n    tree_out = scope.declare_local_variable(\n        'treeout', operator.inputs[0].type.__class__())\n    op.outputs.append(tree_out)\n\n    out_name = operator.outputs[0].full_name\n    apply_cast(scope, tree_out.full_name, out_name, container,\n               to=onnx_proto.TensorProto.INT64)\n\n\nupdate_registered_converter(\n    DiscretizeTransformer,\n    \"CustomDiscretizeTransformer\",\n    discretizer_transformer_shape_calculator,\n    discretizer_transformer_converter)\n\n\ninitial_types = guess_schema_from_data(data)\npprint(initial_types)\nonx = to_onnx(dec, initial_types=initial_types,\n              target_opset={'': 14, 'ai.onnx.ml': 2})\nsess = InferenceSession(onx.SerializeToString(),\n                        providers=['CPUExecutionProvider'])\n\n\ndef cvt_col(values):\n    if hasattr(values, 'to_numpy'):\n        values = values.to_numpy()\n    return values.reshape((-1, 1))\n\n\ninputs = {c: cvt_col(data[c]) for c in data.columns}\n\nexp = dec.transform(data)\nresults = sess.run(None, inputs)\ny = results[0]\n\n\ndef diff(p1, p2):\n    p1 = p1.ravel()\n    p2 = p2.ravel()\n    d = numpy.abs(p2 - p1)\n    return d.max()\n\n\nprint(\"expected\")\nprint(exp)\nprint(\"ONNX\")\nprint(y)\nprint(\"difference\", diff(exp, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oinf = OnnxInference(onx, runtime=\"python_compiled\")\nax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}