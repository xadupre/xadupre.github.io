{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Forward backward on a neural network on GPU\n\nThis example leverages example `l-orttraining-linreg-gpu` to\ntrain a neural network from :epkg:`scikit-learn` on GPU. The code\nuses the same code introduced in `l-orttraining-linreg-fwbw`.\n\n## A neural network with scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nimport numpy\nfrom pandas import DataFrame\nfrom onnxruntime import get_device\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom onnxcustom.plotting.plotting_onnx import plot_onnxs\nfrom mlprodict.onnx_conv import to_onnx\nfrom onnxcustom.utils.orttraining_helper import get_train_initializer\nfrom onnxcustom.utils.onnx_helper import onnx_rename_weights\nfrom onnxcustom.training.optimizers_partial import (\n    OrtGradientForwardBackwardOptimizer)\n\n\nX, y = make_regression(1000, n_features=10, bias=2)\nX = X.astype(numpy.float32)\ny = y.astype(numpy.float32)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nnn = MLPRegressor(hidden_layer_sizes=(10, 10), max_iter=100,\n                  solver='sgd', learning_rate_init=5e-5,\n                  n_iter_no_change=1000, batch_size=10, alpha=0,\n                  momentum=0, nesterovs_momentum=False)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter('ignore')\n    nn.fit(X_train, y_train)\n\nprint(nn.loss_curve_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Score:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"mean_squared_error=%r\" % mean_squared_error(y_test, nn.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion to ONNX\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx = to_onnx(nn, X_train[:1].astype(numpy.float32), target_opset=15)\nplot_onnxs(onx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initializers to train\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weights = list(sorted(get_train_initializer(onx)))\nprint(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training graph with forward backward\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if get_device().upper() == 'GPU' else 'cpu'\n\nprint(\"device=%r get_device()=%r\" % (device, get_device()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training session. The first instructions fails\nfor an odd reason as the class :epkg:`TrainingAgent` expects\nto find the list of weights to train in alphabetical order.\nThat means the list `onx.graph.initializer` must be sorted\nby alphabetical order of their names otherwise the process\ncould crash unless it is caught earlier with the following\nexception.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    train_session = OrtGradientForwardBackwardOptimizer(\n        onx, device=device, verbose=1,\n        warm_start=False, max_iter=100, batch_size=10)\n    train_session.fit(X, y)\nexcept ValueError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function :func:`onnx_rename_weights\n<onnxcustom.utils.onnx_helper.onnx_rename_weights>`\ndoes not change the order of the initializer but renames\nthem. Then class :epkg:`TrainingAgent` may work.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx = onnx_rename_weights(onx)\ntrain_session = OrtGradientForwardBackwardOptimizer(\n    onx, device=device, verbose=1,\n    learning_rate=5e-5, warm_start=False, max_iter=100, batch_size=10)\ntrain_session.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see the weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state_tensors = train_session.get_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the loss.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(train_session.train_losses_)\n\ndf = DataFrame({'ort losses': train_session.train_losses_,\n                'skl losses:': nn.loss_curve_})\ndf.plot(title=\"Train loss against iterations\", logy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The convergence rate is different but both classes\ndo not update the learning the same way.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}