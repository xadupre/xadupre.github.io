{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compares numpy to onnxruntime on simple functions\n\n:epkg:`onnxruntime` can be used a replacement to :epkg:`numpy`.\nIt can be used to implement a training algorithm,\n:epkg:`onnxruntime-training` differentiate an onnx graph and\nruns it to compute the gradient. Simple functions are implemented\nin ONNX and ran with :epkg:`onnxruntime` to update the weights.\n:func:`function_onnx_graph\n<onnxcustom.utils.onnx_function.function_onnx_graph>` returns many\nfunctions used to implement a training algorithm.\nThe following benchmarks compares a couple of implementations:\n\n* `numpy`: an implementation based on numpy, not optimized\n* `sess`: inference through an ONNX graph executed with\n  method `onnxruntime.InferenceSession.run`\n* `bind`: inference through an ONNX graph executed with\n  method `onnxruntime.InferenceSession.run_with_iobinding`\n* `run`: inference through an ONNX graph executed with\n  method `onnxruntime.InferenceSession.run_with_iobinding`\n  but without counting the binding assuming input buffers\n  are reused and do not need binding again\n\n## axpy\n\nThis function implements $Y = f(X1, X2, \\alpha) = \\alpha X1 + X2$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nfrom scipy.special import expit\nimport pandas\nfrom tqdm import tqdm\nfrom cpyquickhelper.numbers.speed_measure import measure_time\nimport matplotlib.pyplot as plt\nfrom onnxruntime import InferenceSession\nfrom onnxruntime.capi._pybind_state import (  # pylint: disable=E0611\n    SessionIOBinding, OrtDevice as C_OrtDevice,\n    OrtValue as C_OrtValue)\nfrom mlprodict.plotting.text_plot import onnx_simple_text_plot\nfrom onnxcustom.utils.onnx_function import function_onnx_graph\n\nfct_onx = function_onnx_graph(\"axpy\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The numpy implementation is the following.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda X1, X2, alpha: X1 * alpha + X2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def reshape(a, dim):\n    if len(a.shape) == 2:\n        return a[:dim].copy()\n    return a\n\n\ndef bind_and_run(sess, bind, names, args, out_names, device):\n    for n, a in zip(names, args):\n        bind.bind_ortvalue_input(n, a)\n    for o in out_names:\n        bind.bind_output(o, device)\n    sess.run_with_iobinding(bind, None)\n    return bind.get_outputs()\n\n\ndef nobind_just_run(sess, bind):\n    sess.run_with_iobinding(bind, None)\n\n\ndef benchmark(name, onx, fct_numpy, *args,\n              dims=(1, 10, 100, 200, 500, 1000, 2000, 10000)):\n    sess = InferenceSession(onx.SerializeToString())\n    device = C_OrtDevice(\n        C_OrtDevice.cpu(), C_OrtDevice.default_memory(), 0)\n    names = [i.name for i in sess.get_inputs()]\n    out_names = [o.name for o in sess.get_outputs()]\n    if len(names) != len(args):\n        raise RuntimeError(\n            \"Size mismatch %d != %d.\" % (len(names), len(args)))\n\n    rows = []\n    for dim in tqdm(dims):\n        new_args = [reshape(a, dim) for a in args]\n        ortvalues = [\n            C_OrtValue.ortvalue_from_numpy(a, device)\n            for a in new_args]\n\n        ms = measure_time(lambda: fct_numpy(*new_args),\n                          repeat=50, number=100)\n        ms.update(dict(name=name, impl='numpy', dim=dim))\n        rows.append(ms)\n\n        inps = {n: a for n, a in zip(names, new_args)}\n        ms = measure_time(lambda: sess.run(None, inps))\n        ms.update(dict(name=name, impl='sess', dim=dim))\n        rows.append(ms)\n\n        bind = SessionIOBinding(sess._sess)\n        ms = measure_time(\n            lambda: bind_and_run(\n                sess._sess, bind, names, ortvalues, out_names, device))\n        ms.update(dict(name=name, impl='bind_run', dim=dim))\n        rows.append(ms)\n\n        ms = measure_time(\n            lambda: nobind_just_run(sess._sess, bind))\n        ms.update(dict(name=name, impl='run', dim=dim))\n        rows.append(ms)\n\n    return rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Back to function axpy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rows = benchmark(\n    'axpy', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.array([0.5], dtype=numpy.float32))\n\nall_rows = []\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## axpyw\n\nIt does $Y, Z = f(X1, X2, G, \\alpha, \\beta) = (Y, Z)$\nwhere $Z = \\beta G + \\alpha X1$ and\n$Y = Z + X2$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"axpyw\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda x1, x2, g, alpha, beta: (\n    x1 * alpha + x2 + beta * g, x1 * alpha + beta * g)\n\nrows = benchmark(\n    'axpyw', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.array([0.5], dtype=numpy.float32),\n    numpy.array([0.5], dtype=numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## axpyw2\n\nIt implements $Y, Z = f(X1, X2, G, \\alpha, \\beta) = (Y, Z)$\nwhere $Z = \\beta G + \\alpha X1$ and\n$Y = \\beta * Z + \\alpha X1 + X2$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"axpyw2\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda x1, x2, g, alpha, beta: (\n    x1 * alpha + x2 + beta * (x1 * alpha + beta * g),\n    x1 * alpha + beta * g)\n\nrows = benchmark(\n    'axpyw2', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.array([0.5], dtype=numpy.float32),\n    numpy.array([0.5], dtype=numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## copy\n\nIt implements a copy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"copy\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda x: x.copy()\n\nrows = benchmark(\n    'copy', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## grad_loss_absolute_error\n\nIt implements $Y = f(X1, X2) = \\lVert X1 - X2 \\rVert$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"grad_loss_absolute_error\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda x1, x2: (\n    numpy.abs(x1 - x2).sum(), numpy.sign(x1 - x2))\n\nrows = benchmark(\n    'grad_loss_absolute_error', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## grad_loss_square_error\n\nIt implements $Y = f(X1, X2) = \\lVert X1 - X2 \\rVert^2$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"grad_loss_square_error\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda x1, x2: (\n    ((x1 - x2) ** 2).sum(), (x1 - x2) * (-2))\n\nrows = benchmark(\n    'grad_loss_square_error', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## grad_loss_elastic_error\n\nIt implements $Y = f(X1, X2) = \\beta \\lVert X1 - X2 \\rVert +\n\\alpha \\lVert X1 - X2 \\rVert^2$ or\n$Y = f(X1, X2) = \\beta \\lVert w(X1 - X2) \\rVert +\n\\alpha \\lVert (\\sqrt{w}(X1 - X2) \\rVert^2$ if\n*weight_name* is not None and its gradient.\n*l1_weight* is $\\beta$ and\n*l2_weight* is $\\alpha$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"grad_loss_elastic_error\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda x1, x2: (\n    numpy.abs(x1 - x2).sum() * 0.1 + ((x1 - x2) ** 2).sum() * 0.9,\n    numpy.sign(x1 - x2) * 0.1 - 2 * 0.9 * (x1 - x2))\n\nrows = benchmark(\n    'grad_loss_elastic_error', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## n_penalty_elastic_error\n\nIt implements $Y = f(W) = \\beta \\lVert W \\rVert +\n\\alpha \\lVert W \\rVert^2$\n*l1_weight* is $\\beta$ and\n*l2_weight* is $\\alpha$.\nIt does that for *n_tensors* and adds all of the results\nto an input loss.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"n_penalty_elastic_error\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda loss, x: numpy.abs(x).sum() * 0.1 + ((x) ** 2).sum() * 0.9\n\nrows = benchmark(\n    'n_penalty_elastic_error', fct_onx, fct_numpy,\n    numpy.array([[0.5]], dtype=numpy.float32),\n    numpy.random.randn(1000, 10).astype(numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## update_penalty_elastic_error\n\nIt implements $Y = f(W) = W - 2 \\beta W - \\alpha sign(W)$\n*l1* is $\\beta$ and\n*l2* is $\\alpha$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"update_penalty_elastic_error\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_numpy = lambda x: numpy.sign(x) * 0.1 + (x * 0.9 * 2)\n\nrows = benchmark(\n    'update_penalty_elastic_error', fct_onx, fct_numpy,\n    numpy.random.randn(1000, 10).astype(numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## grad_sigmoid_neg_log_loss_error\n\nSee :func:`_onnx_grad_sigmoid_neg_log_loss_error\n<onnxcustom.utils.onnx_function._onnx_grad_sigmoid_neg_log_loss_error>`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fct_onx = function_onnx_graph(\"grad_sigmoid_neg_log_loss_error\")\nprint(onnx_simple_text_plot(fct_onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def loss(x1, x2, eps=1e-5):\n    pr = expit(x2)\n    cl = numpy.clip(pr, eps, 1 - eps)\n    lo = - (1 - x1) * numpy.log(1 - cl) - x1 * numpy.log(cl)\n    return lo\n\n\nfct_numpy = lambda x1, x2: (loss(x1, x2).mean(), expit(x2) - x1)\n\nrows = benchmark(\n    'grad_sigmoid_neg_log_loss_error', fct_onx, fct_numpy,\n    (numpy.random.randn(1000, 1) > 0).astype(numpy.int64),\n    numpy.random.randn(1000, 10).astype(numpy.float32))\n\nall_rows.extend(rows)\npiv = pandas.DataFrame(rows).pivot('dim', 'impl', 'average')\npiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "name = rows[0]['name']\nax = piv.plot(logx=True, logy=True)\nax.set_title(name + \"\\nlower is better\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pandas.DataFrame(all_rows)\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pivot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "piv = pandas.pivot_table(\n    df, index=['name', 'impl'], columns='dim', values='average')\npiv\nprint(piv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = None, None\n\n\nfor i, name in enumerate(sorted(set(df['name']))):\n    if fig is None:\n        fig, ax = plt.subplots(2, 2, figsize=(8, 12), sharex=True)\n    x, y = (i % 4) // 2, (i % 4) % 2\n    piv = df[df.name == name].pivot('dim', 'impl', 'average')\n    piv.plot(ax=ax[x, y], logx=True, logy=True)\n    ax[x, y].set_title(name)\n    ax[x, y].xaxis.set_label_text(\"\")\n    if i % 4 == 3:\n        fig.suptitle(\"lower is better\")\n        fig.tight_layout()\n        fig, ax = None, None\n\n\nif fig is not None:\n    fig.suptitle(\"lower is better\")\n    fig.tight_layout()\n\n\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}