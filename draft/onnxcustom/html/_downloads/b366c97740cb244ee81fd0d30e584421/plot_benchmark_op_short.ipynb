{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Benchmark operator Slice\n\nThis short code compares the execution of the operator *Slice*\non CPU and GPU in three configurations.\n\n## A simple example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nfrom numpy.testing import assert_almost_equal\nfrom pandas import DataFrame, pivot_table\nfrom onnxruntime import InferenceSession, get_device\nfrom onnxruntime.capi._pybind_state import (  # pylint: disable=E0611\n    OrtValue as C_OrtValue)\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx.algebra.onnx_ops import OnnxSlice, OnnxAdd, OnnxMul\nfrom cpyquickhelper.numbers.speed_measure import measure_time\nfrom mlprodict.testing.experimental_c_impl.experimental_c import code_optimisation\nfrom mlprodict.onnxrt import OnnxInference\nfrom mlprodict.plotting.plotting_onnx import plot_onnx\nfrom onnxcustom.utils.onnxruntime_helper import get_ort_device\nfrom tqdm import tqdm\n\n\nprint([code_optimisation(), get_device()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The graph to compare.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def build_ort_op(op_version=14, save=None, slices=None):  # opset=13, 14, ...\n    if slices is None:\n        starts = numpy.array([1, 1], dtype=numpy.int64)\n        ends = numpy.array([-1, -1], dtype=numpy.int64)\n        axes = None\n    else:\n        starts, ends = slices\n        if starts[0] is None:\n            indexes = [i for i in range(len(starts)) if starts[i] is not None]\n            starts = numpy.array(\n                [n for n in starts if n is not None], dtype=numpy.int64)\n            ends = numpy.array(\n                [n for n in ends if n is not None], dtype=numpy.int64)\n            axes = numpy.array(indexes, dtype=numpy.int64)\n        else:\n            starts = numpy.array(starts, dtype=numpy.int64)\n            ends = numpy.array(ends, dtype=numpy.int64)\n            axes = None\n\n    if axes is None:\n        node1 = OnnxSlice('X', starts, ends, op_version=op_version)\n    else:\n        node1 = OnnxSlice('X', starts, ends, axes, op_version=op_version)\n    node2 = OnnxAdd(node1, numpy.array([1], dtype=numpy.float32),\n                    op_version=op_version)\n    if axes is None:\n        node3 = OnnxSlice(node2, starts, ends, op_version=op_version)\n    else:\n        node3 = OnnxSlice(node2, starts, ends, axes, op_version=op_version)\n    node4 = OnnxMul(node3, numpy.array([2], dtype=numpy.float32),\n                    op_version=op_version, output_names=['Y'])\n    onx = node4.to_onnx(inputs=[('X', FloatTensorType([None, None]))],\n                        target_opset=op_version)\n    return onx\n\n\nonx = build_ort_op()\nplot_onnx(onx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execution on CPU\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = numpy.random.rand(50, 50).astype(numpy.float32)\n\noinf = OnnxInference(onx)\noinf.run({'X': x}, verbose=1, fLOG=print)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With onnxruntime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = InferenceSession(onx.SerializeToString(),\n                        providers=[\"CPUExecutionProvider\"])\ny_cpu = sess.run(None, {'X': x})[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execution on GPU\n\nIf available...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if get_device().upper() == 'GPU':\n    dev = get_ort_device('cuda:0')\n    try:\n        gx = C_OrtValue.ortvalue_from_numpy(x, dev)\n        cuda = True\n    except RuntimeError as e:\n        print(e)\n        cuda = False\nelse:\n    cuda = False\n\nif cuda:\n    sessg = InferenceSession(onx.SerializeToString(),\n                             providers=[\"CUDAExecutionProvider\"])\n\n    io_binding = sessg.io_binding()._iobinding\n    io_binding.bind_input(\n        'X', dev, numpy.float32, gx.shape(), gx.data_ptr())\n    io_binding.bind_output('Y', dev)\n    sessg._sess.run_with_iobinding(io_binding, None)\n    y_gpu = io_binding.copy_outputs_to_cpu()[0]\n    assert_almost_equal(y_cpu, y_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = []\nshapes = ([(n, n) for n in [10, 100, 1000]] +\n          [(n, 100) for n in [10, 100, 1000, 10000]] +\n          [(100, n) for n in [10, 100, 1000, 10000]])\nslices = [([1, 1], [-1, -1]), ([1], [-1]), ([None, 1], [None, -1])]\nshape_slices = [(sh, sl) for sh in shapes for sl in slices]\n\nfor shape, slices in tqdm(shape_slices):\n    onx = build_ort_op(slices=slices)\n    x = numpy.random.rand(*shape).astype(numpy.float32)\n\n    number = 100\n    if x.size >= 100000:\n        number = 10\n\n    sess = InferenceSession(\n        onx.SerializeToString(),\n        providers=[\"CPUExecutionProvider\"])\n    sess.run(None, {'X': x})\n\n    obs = dict(\n        shape=str(shape).replace(\n            \" \", \"\"), slice=str(slices).replace(\n            \" \", \"\"))\n    r = measure_time(lambda: sess.run(None, {'X': x}),\n                     number=number, div_by_number=True,\n                     context={})\n    obs.update(r)\n    obs['provider'] = 'CPU'\n    data.append(obs)\n\n    if cuda:\n        def sess_run(sess, io_binding, x, dev):\n            io_binding.bind_input(\n                'X', dev, numpy.float32, gx.shape(), gx.data_ptr())\n            io_binding.bind_output('Y', dev)\n            sess._sess.run_with_iobinding(io_binding)\n\n        io_binding = sess.io_binding()._iobinding\n        sess = InferenceSession(\n            onx.SerializeToString(),\n            providers=[\"CUDAExecutionProvider\"])\n        dev = get_ort_device('cuda:0')\n        gx = C_OrtValue.ortvalue_from_numpy(x, dev)\n        sess_run(sess, io_binding, gx, dev)\n        obs = dict(\n            shape=str(shape).replace(\n                \" \", \"\"), slice=str(slices).replace(\n                \" \", \"\"))\n        r = measure_time(\n            lambda: sess_run(sess, io_binding, io_binding, gx, dev),\n            number=number,\n            div_by_number=True,\n            context={\n                'sess': sess, 'gx': gx, 'io_binding': io_binding,\n                'dev': dev, 'sess_run': sess_run})\n        obs.update(r)\n        obs['provider'] = 'GPU'\n        data.append(obs)\n\ndf = DataFrame(data)\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Better display\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "piv = pivot_table(\n    df, index=[\"shape\", \"slice\"], columns=\"provider\", values=\"average\")\nif 'GPU' in piv.columns:\n    piv['ratio'] = piv['GPU'] / piv['CPU']\nprint(piv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graphs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "piv.plot()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}