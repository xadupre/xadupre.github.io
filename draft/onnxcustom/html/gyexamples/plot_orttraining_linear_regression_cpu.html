
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Train a linear regression with onnxruntime-training in details &#8212; onnxcustom</title>
    
    <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Train a linear regression with onnxruntime-training on GPU in details" href="plot_orttraining_linear_regression_gpu.html" />
    <link rel="prev" title="Train a linear regression with onnxruntime-training" href="plot_orttraining_linear_regression.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnx/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnxruntime/index.html">
   Introduction to onnxruntime
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_skl/index.html">
   scikit-learn to ONNX Tutorial
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../tutorials/tutorial_training/index.html">
   Training Tutorial
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training.html">
     Full Training with OrtGradientOptimizer
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_linear_regression.html">
       Train a linear regression with onnxruntime-training
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Train a linear regression with onnxruntime-training in details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_linear_regression_gpu.html">
       Train a linear regression with onnxruntime-training on GPU in details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_nn_gpu.html">
       Train a scikit-learn neural network with onnxruntime-training on GPU
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_benchmark.html">
       Benchmark, comparison scikit-learn - onnxruntime-training
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training_partial.html">
     Partial Training with OrtGradientForwardBackwardOptimizer
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_bench/index.html">
   Benchmarking and profiling Tutorial
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simple-linear-regression-with-scikit-learn">
   A simple linear regression with scikit-learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#an-equivalent-onnx-graph">
   An equivalent ONNX graph.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-with-onnxruntime-training">
   Training with onnxruntime-training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataloader">
   DataLoader
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#first-iterations-of-training">
   First iterations of training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#update-weights-in-an-onnx-graph">
   Update weights in an ONNX graph
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gyexamples-plot-orttraining-linear-regression-cpu-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="train-a-linear-regression-with-onnxruntime-training-in-details">
<span id="l-orttraining-linreg-cpu"></span><span id="sphx-glr-gyexamples-plot-orttraining-linear-regression-cpu-py"></span><h1>Train a linear regression with onnxruntime-training in details<a class="headerlink" href="#train-a-linear-regression-with-onnxruntime-training-in-details" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a> only computes the gradient values.
A gradient descent can then use it to train a model.
This example goes step by step from the gradient computation
to the gradient descent to get a trained linear regression.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#a-simple-linear-regression-with-scikit-learn" id="id3">A simple linear regression with scikit-learn</a></p></li>
<li><p><a class="reference internal" href="#an-equivalent-onnx-graph" id="id4">An equivalent ONNX graph.</a></p></li>
<li><p><a class="reference internal" href="#training-with-onnxruntime-training" id="id5">Training with onnxruntime-training</a></p></li>
<li><p><a class="reference internal" href="#dataloader" id="id6">DataLoader</a></p></li>
<li><p><a class="reference internal" href="#first-iterations-of-training" id="id7">First iterations of training</a></p></li>
<li><p><a class="reference internal" href="#training" id="id8">Training</a></p></li>
<li><p><a class="reference internal" href="#update-weights-in-an-onnx-graph" id="id9">Update weights in an ONNX graph</a></p></li>
</ul>
</div>
<section id="a-simple-linear-regression-with-scikit-learn">
<h2><a class="toc-backref" href="#id3">A simple linear regression with scikit-learn</a><a class="headerlink" href="#a-simple-linear-regression-with-scikit-learn" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">helper</span><span class="p">,</span> <span class="n">numpy_helper</span><span class="p">,</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">ort_version</span><span class="p">,</span>
    <span class="n">TrainingParameters</span><span class="p">,</span> <span class="n">SessionOptions</span><span class="p">,</span> <span class="n">TrainingSession</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">onnxcustom.plotting.plotting_onnx</span> <span class="kn">import</span> <span class="n">plot_onnxs</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[-123.35968   -48.77173    54.596222   76.6724     71.26569 ]
</pre></div>
</div>
</section>
<section id="an-equivalent-onnx-graph">
<h2><a class="toc-backref" href="#id4">An equivalent ONNX graph.</a><a class="headerlink" href="#an-equivalent-onnx-graph" title="Permalink to this headline">¶</a></h2>
<p>This graph can be obtained with <a href="#id1"><span class="problematic" id="id2">*</span></a>sklearn-onnx`
(see <a class="reference internal" href="plot_orttraining_linear_regression.html#l-orttraining-linreg"><span class="std std-ref">Train a linear regression with onnxruntime-training</span></a>).
For clarity, this step is replaced by
next function which builds the exact same graph. It
implements a linear regression <img class="math" src="../_images/math/8ad76441d79ba6ebc7caffdc0bf37b4ed55b1a8f.svg" alt="y = AX + B"/> with onnx operators.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">onnx_linear_regression</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">intercept</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">coefs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="n">coefs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">coefs</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># input and output</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span>
        <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">coefs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span>
        <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">coefs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

    <span class="c1"># inference</span>
    <span class="n">node_matmul</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;coefs&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;y1&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;N1&#39;</span><span class="p">)</span>
    <span class="n">node_add</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;y1&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;N2&#39;</span><span class="p">)</span>

    <span class="c1"># initializer</span>
    <span class="n">init_coefs</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;coefs&quot;</span><span class="p">)</span>
    <span class="n">init_intercept</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;intercept&quot;</span><span class="p">)</span>

    <span class="c1"># graph</span>
    <span class="n">graph_def</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span>
        <span class="p">[</span><span class="n">node_matmul</span><span class="p">,</span> <span class="n">node_add</span><span class="p">],</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">],</span> <span class="p">[</span><span class="n">Y</span><span class="p">],</span>
        <span class="p">[</span><span class="n">init_coefs</span><span class="p">,</span> <span class="n">init_intercept</span><span class="p">])</span>
    <span class="n">model_def</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span>
        <span class="n">graph_def</span><span class="p">,</span> <span class="n">producer_name</span><span class="o">=</span><span class="s1">&#39;orttrainer&#39;</span><span class="p">,</span> <span class="n">ir_version</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
        <span class="n">producer_version</span><span class="o">=</span><span class="n">ort_version</span><span class="p">,</span>
        <span class="n">opset_imports</span><span class="o">=</span><span class="p">[</span><span class="n">helper</span><span class="o">.</span><span class="n">make_operatorsetid</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="mi">14</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">model_def</span>


<span class="n">onx</span> <span class="o">=</span> <span class="n">onnx_linear_regression</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                             <span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</pre></div>
</div>
<p>Let’s visualize it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot_onnxs</span><span class="p">(</span><span class="n">onx</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Linear Regression&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_cpu_001.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_cpu_001.png" alt="Linear Regression" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:title={&#39;center&#39;:&#39;Linear Regression&#39;}&gt;
</pre></div>
</div>
<p>We check it produces the same outputs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                        <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]})[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[[-123.35968 ]
 [ -48.77173 ]
 [  54.596222]
 [  76.6724  ]
 [  71.26569 ]]
</pre></div>
</div>
<p>It works.</p>
</section>
<section id="training-with-onnxruntime-training">
<h2><a class="toc-backref" href="#id5">Training with onnxruntime-training</a><a class="headerlink" href="#training-with-onnxruntime-training" title="Permalink to this headline">¶</a></h2>
<p>The model can be trained with a gradient descent algorithm.
The previous graph only predicts. A new graph needs to be created
to compute the loss as function of the inputs and the expected outputs.
In our case, it is a square loss.
The new graph then requires two inputs, the features and the labels.
It has two outputs, the predicted values and the loss.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">onnx_linear_regression_training</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">intercept</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">coefs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="n">coefs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">coefs</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># input</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span>
        <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">coefs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

    <span class="c1"># expected input</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span>
        <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">coefs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

    <span class="c1"># output</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span>
        <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">coefs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

    <span class="c1"># loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">[])</span>

    <span class="c1"># inference</span>
    <span class="n">node_matmul</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;MatMul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;coefs&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;y1&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;N1&#39;</span><span class="p">)</span>
    <span class="n">node_add</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;y1&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;N2&#39;</span><span class="p">)</span>

    <span class="c1"># loss</span>
    <span class="n">node_diff</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s1">&#39;Sub&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;diff&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;L1&#39;</span><span class="p">)</span>
    <span class="n">node_square</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
        <span class="s1">&#39;Mul&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;diff&#39;</span><span class="p">,</span> <span class="s1">&#39;diff&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;diff2&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">)</span>
    <span class="n">node_square_sum</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
        <span class="s1">&#39;ReduceSum&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;diff2&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;L3&#39;</span><span class="p">)</span>

    <span class="c1"># initializer</span>
    <span class="n">init_coefs</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;coefs&quot;</span><span class="p">)</span>
    <span class="n">init_intercept</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;intercept&quot;</span><span class="p">)</span>

    <span class="c1"># graph</span>
    <span class="n">graph_def</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span>
        <span class="p">[</span><span class="n">node_matmul</span><span class="p">,</span> <span class="n">node_add</span><span class="p">,</span> <span class="n">node_diff</span><span class="p">,</span> <span class="n">node_square</span><span class="p">,</span> <span class="n">node_square_sum</span><span class="p">],</span>
        <span class="s1">&#39;lrt&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">label</span><span class="p">],</span> <span class="p">[</span><span class="n">loss</span><span class="p">,</span> <span class="n">Y</span><span class="p">],</span> <span class="p">[</span><span class="n">init_coefs</span><span class="p">,</span> <span class="n">init_intercept</span><span class="p">])</span>
    <span class="n">model_def</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span>
        <span class="n">graph_def</span><span class="p">,</span> <span class="n">producer_name</span><span class="o">=</span><span class="s1">&#39;orttrainer&#39;</span><span class="p">,</span> <span class="n">ir_version</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
        <span class="n">producer_version</span><span class="o">=</span><span class="n">ort_version</span><span class="p">,</span>
        <span class="n">opset_imports</span><span class="o">=</span><span class="p">[</span><span class="n">helper</span><span class="o">.</span><span class="n">make_operatorsetid</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="mi">14</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">model_def</span>
</pre></div>
</div>
<p>We create a graph with random coefficients.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx_train</span> <span class="o">=</span> <span class="n">onnx_linear_regression_training</span><span class="p">(</span>
    <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
        <span class="o">*</span><span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">plot_onnxs</span><span class="p">(</span><span class="n">onx_train</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Linear Regression with a loss&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_cpu_002.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_cpu_002.png" alt="Linear Regression with a loss" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:title={&#39;center&#39;:&#39;Linear Regression with a loss&#39;}&gt;
</pre></div>
</div>
</section>
<section id="dataloader">
<h2><a class="toc-backref" href="#id6">DataLoader</a><a class="headerlink" href="#dataloader" title="Permalink to this headline">¶</a></h2>
<p>Next class draws consecutive random observations from a dataset
by batch. It iterates over the datasets by drawing <em>n</em> consecutive
observations. This class is equivalent to
<a class="reference internal" href="../onnxcustom/training/data_loader.html#onnxcustom.training.data_loader.OrtDataLoader" title="onnxcustom.training.data_loader.OrtDataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtDataLoader</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DataLoader</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draws consecutive random observations from a dataset</span>
<span class="sd">    by batch. It iterates over the datasets by drawing</span>
<span class="sd">    *batch_size* consecutive observations.</span>

<span class="sd">    :param X: features</span>
<span class="sd">    :param y: labels</span>
<span class="sd">    :param batch_size: batch size (consecutive observations)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Shape mismatch X.shape=</span><span class="si">%r</span><span class="s2">, y.shape=</span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Returns the number of observations.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Iterates over the datasets by drawing</span>
<span class="sd">        *batch_size* consecutive observations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">N</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">b</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">while</span> <span class="n">N</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
            <span class="n">N</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">yield</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">],</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">])</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Returns a tuple of the datasets.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>


<span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>


<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;batch </span><span class="si">%r</span><span class="s2">: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">batch</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>batch 0: (array([[-1.9480568 ,  1.6599144 ],
       [ 0.07494847,  0.04851316]], dtype=float32), array([[-45.48698 ],
       [  9.912355]], dtype=float32))
batch 1: (array([[-0.18353084, -1.5851127 ],
       [ 0.19202179, -1.2771447 ]], dtype=float32), array([[-96.779305],
       [-53.618725]], dtype=float32))
</pre></div>
</div>
</section>
<section id="first-iterations-of-training">
<h2><a class="toc-backref" href="#id7">First iterations of training</a><a class="headerlink" href="#first-iterations-of-training" title="Permalink to this headline">¶</a></h2>
<p>Prediction needs an instance of class <em>InferenceSession</em>,
the training needs an instance of class <em>TrainingSession</em>.
Next function creates this one.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_training_session</span><span class="p">(</span>
        <span class="n">training_onnx</span><span class="p">,</span> <span class="n">weights_to_train</span><span class="p">,</span> <span class="n">loss_output_name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
        <span class="n">training_optimizer_name</span><span class="o">=</span><span class="s1">&#39;SGDOptimizer&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates an instance of class `TrainingSession`.</span>

<span class="sd">    :param training_onnx: ONNX graph used to train</span>
<span class="sd">    :param weights_to_train: names of initializers to be optimized</span>
<span class="sd">    :param loss_output_name: name of the loss output</span>
<span class="sd">    :param training_optimizer_name: optimizer name</span>
<span class="sd">    :return: instance of `TrainingSession`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ort_parameters</span> <span class="o">=</span> <span class="n">TrainingParameters</span><span class="p">()</span>
    <span class="n">ort_parameters</span><span class="o">.</span><span class="n">loss_output_name</span> <span class="o">=</span> <span class="n">loss_output_name</span>

    <span class="n">output_types</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">training_onnx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">:</span>
        <span class="n">output_types</span><span class="p">[</span><span class="n">output</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span>

    <span class="n">ort_parameters</span><span class="o">.</span><span class="n">weights_to_train</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">weights_to_train</span><span class="p">)</span>
    <span class="n">ort_parameters</span><span class="o">.</span><span class="n">training_optimizer_name</span> <span class="o">=</span> <span class="n">training_optimizer_name</span>

    <span class="n">ort_parameters</span><span class="o">.</span><span class="n">optimizer_attributes_map</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">name</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">weights_to_train</span><span class="p">}</span>
    <span class="n">ort_parameters</span><span class="o">.</span><span class="n">optimizer_int_attributes_map</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">name</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">weights_to_train</span><span class="p">}</span>

    <span class="n">session_options</span> <span class="o">=</span> <span class="n">SessionOptions</span><span class="p">()</span>
    <span class="n">session_options</span><span class="o">.</span><span class="n">use_deterministic_compute</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">session</span> <span class="o">=</span> <span class="n">TrainingSession</span><span class="p">(</span>
        <span class="n">training_onnx</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">ort_parameters</span><span class="p">,</span> <span class="n">session_options</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">session</span>


<span class="n">train_session</span> <span class="o">=</span> <span class="n">create_training_session</span><span class="p">(</span><span class="n">onx_train</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;coefs&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_session</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;onnxruntime.capi.training.training_session.TrainingSession object at 0x7f5d7b6977c0&gt;
</pre></div>
</div>
<p>Let’s look into the expected inputs and outputs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;+input: </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">i</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output: </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">o</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">o</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>+input: X (tensor(float)[None, 2])
+input: label (tensor(float)[None, 1])
+input: Learning_Rate (tensor(float)[1])
output: loss (tensor(float)[1, 1])
output: Y (tensor(float)[None, 1])
output: global_gradient_norm (tensor(float)[])
</pre></div>
</div>
<p>A third parameter <cite>Learning_Rate</cite> was automatically added.
The training updates the weight with a gradient multiplied
by this parameter. Let’s see now how to
retrieve the trained coefficients.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">state_tensors</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">state_tensors</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;coefs&#39;: array([[0.20867229],
       [0.28253436]], dtype=float32),
 &#39;intercept&#39;: array([-0.41941592], dtype=float32)}
</pre></div>
</div>
<p>We can now check the coefficients are updated after one iteration.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span>
          <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
          <span class="s1">&#39;Learning_Rate&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.001</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)}</span>

<span class="n">train_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">state_tensors</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">state_tensors</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;coefs&#39;: array([[0.9041854],
       [0.639641 ]], dtype=float32),
 &#39;intercept&#39;: array([-0.04783082], dtype=float32)}
</pre></div>
</div>
<p>They changed. Another iteration to be sure.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span>
          <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
          <span class="s1">&#39;Learning_Rate&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.001</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)}</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">state_tensors</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">state_tensors</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;coefs&#39;: array([[1.5921495],
       [0.9928715]], dtype=float32),
 &#39;intercept&#39;: array([0.31972107], dtype=float32)}
</pre></div>
</div>
<p>It works. The training loss can be obtained by looking into the results.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[array([[33773.598]], dtype=float32),
 array([[2.259293]], dtype=float32),
 array(856.248, dtype=float32)]
</pre></div>
</div>
</section>
<section id="training">
<h2><a class="toc-backref" href="#id8">Training</a><a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h2>
<p>We need to implement a gradient descent.
Let’s wrap this into a class similar following scikit-learn’s API.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CustomTraining</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements a simple :epkg:`Stochastic Gradient Descent`.</span>

<span class="sd">    :param model_onnx: ONNX graph to train</span>
<span class="sd">    :param weights_to_train: list of initializers to train</span>
<span class="sd">    :param loss_output_name: name of output loss</span>
<span class="sd">    :param max_iter: number of training iterations</span>
<span class="sd">    :param training_optimizer_name: optimizing algorithm</span>
<span class="sd">    :param batch_size: batch size (see class *DataLoader*)</span>
<span class="sd">    :param eta0: initial learning rate for the `&#39;constant&#39;`, `&#39;invscaling&#39;`</span>
<span class="sd">        or `&#39;adaptive&#39;` schedules.</span>
<span class="sd">    :param alpha: constant that multiplies the regularization term,</span>
<span class="sd">        the higher the value, the stronger the regularization.</span>
<span class="sd">        Also used to compute the learning rate when set to *learning_rate*</span>
<span class="sd">        is set to `&#39;optimal&#39;`.</span>
<span class="sd">    :param power_t: exponent for inverse scaling learning rate</span>
<span class="sd">    :param learning_rate: learning rate schedule:</span>
<span class="sd">        * `&#39;constant&#39;`: `eta = eta0`</span>
<span class="sd">        * `&#39;optimal&#39;`: `eta = 1.0 / (alpha * (t + t0))` where *t0* is chosen</span>
<span class="sd">            by a heuristic proposed by Leon Bottou.</span>
<span class="sd">        * `&#39;invscaling&#39;`: `eta = eta0 / pow(t, power_t)`</span>
<span class="sd">    :param verbose: use :epkg:`tqdm` to display the training progress</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_onnx</span><span class="p">,</span> <span class="n">weights_to_train</span><span class="p">,</span> <span class="n">loss_output_name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">training_optimizer_name</span><span class="o">=</span><span class="s1">&#39;SGDOptimizer&#39;</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eta0</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
                 <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;invscaling&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="c1"># See https://scikit-learn.org/stable/modules/generated/</span>
        <span class="c1"># sklearn.linear_model.SGDRegressor.html</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_onnx</span> <span class="o">=</span> <span class="n">model_onnx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_to_train</span> <span class="o">=</span> <span class="n">weights_to_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_output_name</span> <span class="o">=</span> <span class="n">loss_output_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_optimizer_name</span> <span class="o">=</span> <span class="n">training_optimizer_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta0</span> <span class="o">=</span> <span class="n">eta0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power_t</span> <span class="o">=</span> <span class="n">power_t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_init_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta0_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">==</span> <span class="s2">&quot;optimal&quot;</span><span class="p">:</span>
            <span class="n">typw</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eta0_</span> <span class="o">=</span> <span class="n">typw</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">typw</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimal_init_</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eta0_</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eta0_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta0_</span>

    <span class="k">def</span> <span class="nf">_update_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">==</span> <span class="s2">&quot;optimal&quot;</span><span class="p">:</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimal_init_</span> <span class="o">+</span> <span class="n">t</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">==</span> <span class="s2">&quot;invscaling&quot;</span><span class="p">:</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta0_</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">power_t</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eta</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the model.</span>
<span class="sd">        :param X: features</span>
<span class="sd">        :param y: expected output</span>
<span class="sd">        :return: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_session_</span> <span class="o">=</span> <span class="n">create_training_session</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_onnx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_to_train</span><span class="p">,</span>
            <span class="n">loss_output_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_output_name</span><span class="p">,</span>
            <span class="n">training_optimizer_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_optimizer_name</span><span class="p">)</span>

        <span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_learning_rate</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_names_</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_session_</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_names_</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">o</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_session_</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_index_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names_</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_output_name</span><span class="p">)</span>

        <span class="n">loop</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="k">else</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">))</span>
        <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">loop</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iteration</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_learning_rate</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loop</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s2">&quot;loss=</span><span class="si">%1.3g</span><span class="s2"> lr=</span><span class="si">%1.3g</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">lr</span><span class="p">))</span>
            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_losses_</span> <span class="o">=</span> <span class="n">train_losses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trained_coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_session_</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Processes one gradient iteration.</span>

<span class="sd">        :param data_lower: instance of class `DataLoader`</span>
<span class="sd">        :return: loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">actual_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">learning_rate</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

            <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_names_</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">data</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">input_names_</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">target</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">input_names_</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">lr</span><span class="p">}</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_session_</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
            <span class="n">actual_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_index_</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actual_losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<p>Let’s now train the model in a very similar way
that it would be done with <em>scikit-learn</em>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">CustomTraining</span><span class="p">(</span><span class="n">onx_train</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;coefs&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept&#39;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;training losses:&quot;</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;iteration&quot;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">)),</span>
                <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;iteration&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Training loss&quot;</span><span class="p">,</span> <span class="n">logy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_cpu_003.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_cpu_003.png" alt="Training loss" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/10 [00:00&lt;?, ?it/s]
100%|##########| 10/10 [00:00&lt;00:00, 312.06it/s]
training losses: [23782.207, 160.85303, 2.2581344, 0.04318724, 0.001682495, 6.3030675e-05, 3.6188994e-06, 2.1655846e-07, 1.609759e-08, 1.8486048e-09]

&lt;AxesSubplot:title={&#39;center&#39;:&#39;Training loss&#39;}, xlabel=&#39;iteration&#39;&gt;
</pre></div>
</div>
<p>Let’s compare scikit-learn trained coefficients and the coefficients
obtained with onnxruntime and check they are very close.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;scikit-learn&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;onnxruntime&quot;</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">trained_coef_</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>scikit-learn [70.51876  54.151943] 2.0000005
onnxruntime {&#39;coefs&#39;: array([[70.51876 ],
       [54.151943]], dtype=float32), &#39;intercept&#39;: array([2.0000045], dtype=float32)}
</pre></div>
</div>
<p>It works. We could stop here or we could update the weights
in the training model or the first model. That requires to
update the constants in an ONNX graph.</p>
</section>
<section id="update-weights-in-an-onnx-graph">
<h2><a class="toc-backref" href="#id9">Update weights in an ONNX graph</a><a class="headerlink" href="#update-weights-in-an-onnx-graph" title="Permalink to this headline">¶</a></h2>
<p>Let’s first check the output of the first model in ONNX.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                        <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>
<span class="n">before</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]})[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">before</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[[-123.35968 ]
 [ -48.77173 ]
 [  54.596222]
 [  76.6724  ]
 [  71.26569 ]]
</pre></div>
</div>
<p>Let’s replace the initializer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_onnx_graph</span><span class="p">(</span><span class="n">model_onnx</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">):</span>
    <span class="n">replace_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">replace_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model_onnx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">new_weights</span><span class="p">:</span>
            <span class="n">replace_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">new_weights</span><span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">name</span><span class="p">],</span> <span class="n">w</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
            <span class="n">replace_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">replace_indices</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">w_i</span> <span class="ow">in</span> <span class="n">replace_indices</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">model_onnx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">[</span><span class="n">w_i</span><span class="p">]</span>
    <span class="n">model_onnx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">replace_weights</span><span class="p">)</span>


<span class="n">update_onnx_graph</span><span class="p">(</span><span class="n">onx</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">trained_coef_</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s compare with the previous output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                        <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>
<span class="n">after</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]})[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">after</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[[-123.35967 ]
 [ -48.771725]
 [  54.596226]
 [  76.67241 ]
 [  71.2657  ]]
</pre></div>
</div>
<p>It looks almost the same but slighly different.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">after</span> <span class="o">-</span> <span class="n">before</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[[7.6293945e-06]
 [3.8146973e-06]
 [3.8146973e-06]
 [7.6293945e-06]
 [7.6293945e-06]]
</pre></div>
</div>
<p>Next example will show how to train a linear regression on GPU:
<a class="reference internal" href="plot_orttraining_linear_regression_gpu.html#l-orttraining-linreg-gpu"><span class="std std-ref">Train a linear regression with onnxruntime-training on GPU in details</span></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import matplotlib.pyplot as plt</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  2.868 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-gyexamples-plot-orttraining-linear-regression-cpu-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/5e57f61ec0bee0058a95310a9d2880fe/plot_orttraining_linear_regression_cpu.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_orttraining_linear_regression_cpu.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/9f09861a158cc46892274587e162bb18/plot_orttraining_linear_regression_cpu.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_orttraining_linear_regression_cpu.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="plot_orttraining_linear_regression.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Train a linear regression with onnxruntime-training</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="plot_orttraining_linear_regression_gpu.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a linear regression with onnxruntime-training on GPU in details</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>