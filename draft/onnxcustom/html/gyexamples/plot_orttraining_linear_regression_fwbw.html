
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Train a linear regression with forward backward &#8212; onnxcustom</title>
    
    <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Forward backward on a neural network on GPU" href="plot_orttraining_nn_gpu_fwbw.html" />
    <link rel="prev" title="Partial Training with OrtGradientForwardBackwardOptimizer" href="../tutorials/tutorial_training/tutorial_6_training_partial.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnx/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnxruntime/index.html">
   Introduction to onnxruntime
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_skl/index.html">
   scikit-learn to ONNX Tutorial
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../tutorials/tutorial_training/index.html">
   Training Tutorial
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training.html">
     Full Training with OrtGradientOptimizer
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training_partial.html">
     Partial Training with OrtGradientForwardBackwardOptimizer
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Train a linear regression with forward backward
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_nn_gpu_fwbw.html">
       Forward backward on a neural network on GPU
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_nn_gpu_fwbw_nesterov.html">
       Forward backward on a neural network on GPU (Nesterov) and penalty
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_benchmark_fwbw.html">
       Benchmark, comparison scikit-learn - forward-backward
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_benchmark_fwbw_cls.html">
       Benchmark, comparison sklearn - forward-backward - classification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_benchmark_onnx_function.html">
       Compares numpy to onnxruntime on simple functions
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_bench/index.html">
   Benchmarking and profiling Tutorial
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simple-linear-regression-with-scikit-learn">
   A simple linear regression with scikit-learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#onnx-graph">
   ONNX graph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weights">
   Weights
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-cpu-or-gpu-if-available">
   Train on CPU or GPU if available
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-gradient-descent">
   Stochastic Gradient Descent
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-graph">
   Gradient Graph
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gyexamples-plot-orttraining-linear-regression-fwbw-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="train-a-linear-regression-with-forward-backward">
<span id="l-orttraining-linreg-fwbw"></span><span id="sphx-glr-gyexamples-plot-orttraining-linear-regression-fwbw-py"></span><h1>Train a linear regression with forward backward<a class="headerlink" href="#train-a-linear-regression-with-forward-backward" title="Permalink to this headline">¶</a></h1>
<p>This example rewrites <a class="reference internal" href="plot_orttraining_linear_regression.html#l-orttraining-linreg"><span class="std std-ref">Train a linear regression with onnxruntime-training</span></a> with another
optimizer <a class="reference internal" href="../onnxcustom/training/optimizers_partial.html#onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer" title="onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientForwardBackwardOptimizer</span></code></a>.
This optimizer relies on class <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/training_partial.html#trainingagent">TrainingAgent</a> from
<a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a>. In this case, the user does not have to
modify the graph to compute the error. The optimizer
builds another graph which returns the gradient of every weights
assuming the gradient on the output is known. Finally, the optimizer
adds the gradients to the weights. To summarize, it starts from the following
graph:</p>
<img alt="../_images/onnxfwbw1.png" src="../_images/onnxfwbw1.png" />
<p>Class <a class="reference internal" href="../onnxcustom/training/optimizers_partial.html#onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer" title="onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientForwardBackwardOptimizer</span></code></a>
builds other ONNX graph to implement a gradient descent algorithm:</p>
<img alt="../_images/onnxfwbw2.png" src="../_images/onnxfwbw2.png" />
<p>The blue node is built by class <a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/training_partial.html#trainingagent">TrainingAgent</a>
(from <a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a>). The green nodes are added by
class <a class="reference internal" href="../onnxcustom/training/optimizers_partial.html#onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer" title="onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientForwardBackwardOptimizer</span></code></a>.
This implementation relies on ONNX to do the computation but it could
be replaced by any other framework such as <a class="reference external" href="https://pytorch.org/">pytorch</a>. This
design gives more freedom to the user to implement his own training
algorithm.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#a-simple-linear-regression-with-scikit-learn" id="id1">A simple linear regression with scikit-learn</a></p></li>
<li><p><a class="reference internal" href="#onnx-graph" id="id2">ONNX graph</a></p></li>
<li><p><a class="reference internal" href="#weights" id="id3">Weights</a></p></li>
<li><p><a class="reference internal" href="#train-on-cpu-or-gpu-if-available" id="id4">Train on CPU or GPU if available</a></p></li>
<li><p><a class="reference internal" href="#stochastic-gradient-descent" id="id5">Stochastic Gradient Descent</a></p></li>
<li><p><a class="reference internal" href="#gradient-graph" id="id6">Gradient Graph</a></p></li>
</ul>
</div>
<section id="a-simple-linear-regression-with-scikit-learn">
<h2><a class="toc-backref" href="#id1">A simple linear regression with scikit-learn</a><a class="headerlink" href="#a-simple-linear-regression-with-scikit-learn" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">get_device</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">onnxcustom.plotting.plotting_onnx</span> <span class="kn">import</span> <span class="n">plot_onnxs</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.orttraining_helper</span> <span class="kn">import</span> <span class="n">get_train_initializer</span>
<span class="kn">from</span> <span class="nn">onnxcustom.training.optimizers_partial</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OrtGradientForwardBackwardOptimizer</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>We use a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neural_network.MLPRegressor</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span>
                  <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                  <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span>
                  <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
                  <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                  <span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/var/lib/jenkins/workspace/onnxcustom/onnxcustom_UT_39_std/_venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
[-1.15975655e+02  7.97680616e-02  9.66523209e+01 -5.34809189e+01
  2.13671280e+02]
</pre></div>
</div>
<p>The trained coefficients are:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;trained coefficients:&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">coefs_</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>trained coefficients: [array([[51.089794],
       [80.767105]], dtype=float32)] [array([1.989909], dtype=float32)]
</pre></div>
</div>
</section>
<section id="onnx-graph">
<h2><a class="toc-backref" href="#id2">ONNX graph</a><a class="headerlink" href="#onnx-graph" title="Permalink to this headline">¶</a></h2>
<p>Training with <a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a> starts with an ONNX
graph which defines the model to learn. It is obtained by simply
converting the previous linear regression into ONNX.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">target_opset</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
              <span class="n">black_op</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;LinearRegressor&#39;</span><span class="p">})</span>

<span class="n">plot_onnxs</span><span class="p">(</span><span class="n">onx</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Linear Regression in ONNX&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_001.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_001.png" alt="Linear Regression in ONNX" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:title={&#39;center&#39;:&#39;Linear Regression in ONNX&#39;}&gt;
</pre></div>
</div>
</section>
<section id="weights">
<h2><a class="toc-backref" href="#id3">Weights</a><a class="headerlink" href="#weights" title="Permalink to this headline">¶</a></h2>
<p>Every initializer is a set of weights which can be trained
and a gradient will be computed for it.
However an initializer used to modify a shape or to
extract a subpart of a tensor does not need training.
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_train_initializer</span></code>
removes them.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">inits</span> <span class="o">=</span> <span class="n">get_train_initializer</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inits</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;shape_tensor&quot;</span><span class="p">}</span>
<span class="n">pprint</span><span class="p">(</span><span class="nb">list</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">weights</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;coefficient&#39;, (2, 1)), (&#39;intercepts&#39;, (1, 1))]
</pre></div>
</div>
</section>
<section id="train-on-cpu-or-gpu-if-available">
<h2><a class="toc-backref" href="#id4">Train on CPU or GPU if available</a><a class="headerlink" href="#train-on-cpu-or-gpu-if-available" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">get_device</span><span class="p">()</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;GPU&#39;</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;device=</span><span class="si">%r</span><span class="s2"> get_device()=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">get_device</span><span class="p">()))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>device=&#39;cpu&#39; get_device()=&#39;CPU&#39;
</pre></div>
</div>
</section>
<section id="stochastic-gradient-descent">
<h2><a class="toc-backref" href="#id5">Stochastic Gradient Descent</a><a class="headerlink" href="#stochastic-gradient-descent" title="Permalink to this headline">¶</a></h2>
<p>The training logic is hidden in class
<a class="reference internal" href="../onnxcustom/training/optimizers_partial.html#onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer" title="onnxcustom.training.optimizers_partial.OrtGradientForwardBackwardOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientForwardBackwardOptimizer</span></code></a>
It follows <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> API (see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html">SGDRegressor</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_session</span> <span class="o">=</span> <span class="n">OrtGradientForwardBackwardOptimizer</span><span class="p">(</span>
    <span class="n">onx</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">train_session</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/200 [00:00&lt;?, ?it/s]
  6%|5         | 11/200 [00:00&lt;00:01, 109.73it/s]
 12%|#1        | 23/200 [00:00&lt;00:01, 110.04it/s]
 18%|#7        | 35/200 [00:00&lt;00:01, 110.24it/s]
 24%|##3       | 47/200 [00:00&lt;00:01, 110.19it/s]
 30%|##9       | 59/200 [00:00&lt;00:01, 110.23it/s]
 36%|###5      | 71/200 [00:00&lt;00:01, 110.29it/s]
 42%|####1     | 83/200 [00:00&lt;00:01, 110.24it/s]
 48%|####7     | 95/200 [00:00&lt;00:00, 110.29it/s]
 54%|#####3    | 107/200 [00:00&lt;00:00, 110.31it/s]
 60%|#####9    | 119/200 [00:01&lt;00:00, 110.24it/s]
 66%|######5   | 131/200 [00:01&lt;00:00, 110.15it/s]
 72%|#######1  | 143/200 [00:01&lt;00:00, 110.12it/s]
 78%|#######7  | 155/200 [00:01&lt;00:00, 110.07it/s]
 84%|########3 | 167/200 [00:01&lt;00:00, 110.02it/s]
 90%|########9 | 179/200 [00:01&lt;00:00, 109.97it/s]
 95%|#########5| 190/200 [00:01&lt;00:00, 109.96it/s]
100%|##########| 200/200 [00:01&lt;00:00, 110.09it/s]

OrtGradientForwardBackwardOptimizer(model_onnx=&#39;ir_version...&#39;, weights_to_train=[&#39;coefficient&#39;, &#39;intercepts&#39;], loss_output_name=&#39;loss&#39;, max_iter=200, training_optimizer_name=&#39;SGDOptimizer&#39;, batch_size=10, learning_rate=LearningRateSGD(eta0=0.01, alpha=0.0001, power_t=0.25, learning_rate=&#39;invscaling&#39;), value=0.0026591479484724943, device=&#39;cpu&#39;, warm_start=False, verbose=1, validation_every=20, learning_loss=SquareLearningLoss(), enable_logging=False, weight_name=None, learning_penalty=NoLearningPenalty(), exc=True)
</pre></div>
</div>
<p>And the trained coefficients are…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">state_tensors</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<span class="n">pprint</span><span class="p">([</span><span class="s2">&quot;trained coefficients:&quot;</span><span class="p">,</span> <span class="n">state_tensors</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;last_losses:&quot;</span><span class="p">,</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:])</span>

<span class="n">min_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;ort losses&#39;</span><span class="p">:</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">[:</span><span class="n">min_length</span><span class="p">],</span>
                <span class="s1">&#39;skl losses&#39;</span><span class="p">:</span> <span class="n">lr</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">[:</span><span class="n">min_length</span><span class="p">]})</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Train loss against iterations&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_002.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_002.png" alt="Train loss against iterations" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;trained coefficients:&#39;,
 [&lt;onnxruntime.capi.onnxruntime_pybind11_state.OrtValue object at 0x7f5cde096ab0&gt;,
  &lt;onnxruntime.capi.onnxruntime_pybind11_state.OrtValue object at 0x7f5cde096530&gt;]]
last_losses: [0.005264026, 0.007569605, 0.0053504906, 0.0039015156, 0.004138238]

&lt;AxesSubplot:title={&#39;center&#39;:&#39;Train loss against iterations&#39;}&gt;
</pre></div>
</div>
<p>The convergence speed is almost the same.</p>
</section>
<section id="gradient-graph">
<h2><a class="toc-backref" href="#id6">Gradient Graph</a><a class="headerlink" href="#gradient-graph" title="Permalink to this headline">¶</a></h2>
<p>As mentioned in this introduction, the computation relies
on a few more graphs than the initial graph.
When the loss is needed but not the gradient, class
<a class="reference external" href="http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/onnxmd/onnxruntime_python/training_partial.html#trainingagent">TrainingAgent</a> creates another graph, faster,
with the trained initializers as additional inputs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx_loss</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_session_</span><span class="o">.</span><span class="n">cls_type_</span><span class="o">.</span><span class="n">_optimized_pre_grad_model</span>

<span class="n">plot_onnxs</span><span class="p">(</span><span class="n">onx</span><span class="p">,</span> <span class="n">onx_loss</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_003.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_003.png" alt="regression, loss" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>array([&lt;AxesSubplot:title={&#39;center&#39;:&#39;regression&#39;}&gt;,
       &lt;AxesSubplot:title={&#39;center&#39;:&#39;loss&#39;}&gt;], dtype=object)
</pre></div>
</div>
<p>And the gradient.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx_gradient</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_session_</span><span class="o">.</span><span class="n">cls_type_</span><span class="o">.</span><span class="n">_trained_onnx</span>

<span class="n">plot_onnxs</span><span class="p">(</span><span class="n">onx_loss</span><span class="p">,</span> <span class="n">onx_gradient</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="s1">&#39;gradient + loss&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_004.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_004.png" alt="loss, gradient + loss" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>array([&lt;AxesSubplot:title={&#39;center&#39;:&#39;loss&#39;}&gt;,
       &lt;AxesSubplot:title={&#39;center&#39;:&#39;gradient + loss&#39;}&gt;], dtype=object)
</pre></div>
</div>
<p>The last ONNX graphs are used to compute the gradient <em>dE/dY</em>
and to update the weights. The first graph takes the labels and the
expected labels and returns the square loss and its gradient.
The second graph takes the weights and the learning rate as inputs
and returns the updated weights. This graph works on tensors of any shape
but with the same element type.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot_onnxs</span><span class="p">(</span><span class="n">train_session</span><span class="o">.</span><span class="n">learning_loss</span><span class="o">.</span><span class="n">loss_grad_onnx_</span><span class="p">,</span>
           <span class="n">train_session</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">.</span><span class="n">axpy_onnx_</span><span class="p">,</span>
           <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;error gradient + loss&#39;</span><span class="p">,</span> <span class="s1">&#39;gradient update&#39;</span><span class="p">])</span>

<span class="c1"># import matplotlib.pyplot as plt</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_005.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_fwbw_005.png" alt="error gradient + loss, gradient update" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>array([&lt;AxesSubplot:title={&#39;center&#39;:&#39;error gradient + loss&#39;}&gt;,
       &lt;AxesSubplot:title={&#39;center&#39;:&#39;gradient update&#39;}&gt;], dtype=object)
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  10.627 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-gyexamples-plot-orttraining-linear-regression-fwbw-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/1808fdec9011bae20bb8e280f8048ea4/plot_orttraining_linear_regression_fwbw.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_orttraining_linear_regression_fwbw.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/8374c77540d02d631ed77ceaedcaf825/plot_orttraining_linear_regression_fwbw.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_orttraining_linear_regression_fwbw.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../tutorials/tutorial_training/tutorial_6_training_partial.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Partial Training with OrtGradientForwardBackwardOptimizer</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="plot_orttraining_nn_gpu_fwbw.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Forward backward on a neural network on GPU</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>