
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Train a linear regression with onnxruntime-training &#8212; onnxcustom</title>
    
    <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Train a linear regression with onnxruntime-training in details" href="plot_orttraining_linear_regression_cpu.html" />
    <link rel="prev" title="Full Training with OrtGradientOptimizer" href="../tutorials/tutorial_training/tutorial_6_training.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnx/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnxruntime/index.html">
   Introduction to onnxruntime
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_skl/index.html">
   scikit-learn to ONNX Tutorial
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../tutorials/tutorial_training/index.html">
   Training Tutorial
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training.html">
     Full Training with OrtGradientOptimizer
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Train a linear regression with onnxruntime-training
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_linear_regression_cpu.html">
       Train a linear regression with onnxruntime-training in details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_linear_regression_gpu.html">
       Train a linear regression with onnxruntime-training on GPU in details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_nn_gpu.html">
       Train a scikit-learn neural network with onnxruntime-training on GPU
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_benchmark.html">
       Benchmark, comparison scikit-learn - onnxruntime-training
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training_partial.html">
     Partial Training with OrtGradientForwardBackwardOptimizer
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_bench/index.html">
   Benchmarking and profiling Tutorial
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simple-linear-regression-with-scikit-learn">
   A simple linear regression with scikit-learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#onnx-graph">
   ONNX graph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#choosing-a-loss">
   Choosing a loss
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weights">
   Weights
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-cpu-or-gpu-if-available">
   Train on CPU or GPU if available
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-gradient-descent">
   Stochastic Gradient Descent
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gyexamples-plot-orttraining-linear-regression-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="train-a-linear-regression-with-onnxruntime-training">
<span id="l-orttraining-linreg"></span><span id="sphx-glr-gyexamples-plot-orttraining-linear-regression-py"></span><h1>Train a linear regression with onnxruntime-training<a class="headerlink" href="#train-a-linear-regression-with-onnxruntime-training" title="Permalink to this headline">¶</a></h1>
<p>This example explores how <a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a> can be used to
train a simple linear regression using a gradient descent.
It compares the results with those obtained by
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.linear_model.SGDRegressor</span></code></a></p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#a-simple-linear-regression-with-scikit-learn" id="id1">A simple linear regression with scikit-learn</a></p></li>
<li><p><a class="reference internal" href="#onnx-graph" id="id2">ONNX graph</a></p></li>
<li><p><a class="reference internal" href="#choosing-a-loss" id="id3">Choosing a loss</a></p></li>
<li><p><a class="reference internal" href="#weights" id="id4">Weights</a></p></li>
<li><p><a class="reference internal" href="#train-on-cpu-or-gpu-if-available" id="id5">Train on CPU or GPU if available</a></p></li>
<li><p><a class="reference internal" href="#stochastic-gradient-descent" id="id6">Stochastic Gradient Descent</a></p></li>
</ul>
</div>
<section id="a-simple-linear-regression-with-scikit-learn">
<h2><a class="toc-backref" href="#id1">A simple linear regression with scikit-learn</a><a class="headerlink" href="#a-simple-linear-regression-with-scikit-learn" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">get_device</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">onnxcustom.plotting.plotting_onnx</span> <span class="kn">import</span> <span class="n">plot_onnxs</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.orttraining_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">add_loss_output</span><span class="p">,</span> <span class="n">get_train_initializer</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnxcustom.training.optimizers</span> <span class="kn">import</span> <span class="n">OrtGradientOptimizer</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">SGDRegressor</span><span class="p">(</span><span class="n">l1_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">eta0</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[ 73.16733311 -60.81267975  31.04422129 -75.08078784 -71.43513636]
</pre></div>
</div>
<p>The trained coefficients are:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;trained coefficients:&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>trained coefficients: [58.45234203 48.92038649] [2.0011031]
</pre></div>
</div>
<p>However this model does not show the training curve.
We switch to a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neural_network.MLPRegressor</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span>
                  <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                  <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span>
                  <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
                  <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                  <span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/var/lib/jenkins/workspace/onnxcustom/onnxcustom_UT_39_std/_venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
[ 73.173676 -60.81919   31.047342 -75.08743  -71.443665]
</pre></div>
</div>
<p>The trained coefficients are:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;trained coefficients:&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">coefs_</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>trained coefficients: [array([[58.45749],
       [48.92646]], dtype=float32)] [array([2.0000165], dtype=float32)]
</pre></div>
</div>
</section>
<section id="onnx-graph">
<h2><a class="toc-backref" href="#id2">ONNX graph</a><a class="headerlink" href="#onnx-graph" title="Permalink to this headline">¶</a></h2>
<p>Training with <a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a> starts with an ONNX
graph which defines the model to learn. It is obtained by simply
converting the previous linear regression into ONNX.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">target_opset</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
              <span class="n">black_op</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;LinearRegressor&#39;</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section id="choosing-a-loss">
<h2><a class="toc-backref" href="#id3">Choosing a loss</a><a class="headerlink" href="#choosing-a-loss" title="Permalink to this headline">¶</a></h2>
<p>The training requires a loss function. By default, it
is the square function but it could be the absolute error or
include regularization. Function
<a class="reference internal" href="../onnxcustom/utils/orttraining_helper.html#onnxcustom.utils.orttraining_helper.add_loss_output" title="onnxcustom.utils.orttraining_helper.add_loss_output"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_loss_output</span></code></a>
appends the loss function to the ONNX graph.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx_train</span> <span class="o">=</span> <span class="n">add_loss_output</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>

<span class="n">plot_onnxs</span><span class="p">(</span><span class="n">onx</span><span class="p">,</span> <span class="n">onx_train</span><span class="p">,</span>
           <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;Linear Regression + Loss with ONNX&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_001.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_001.png" alt="Linear Regression, Linear Regression + Loss with ONNX" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>array([&lt;AxesSubplot:title={&#39;center&#39;:&#39;Linear Regression&#39;}&gt;,
       &lt;AxesSubplot:title={&#39;center&#39;:&#39;Linear Regression + Loss with ONNX&#39;}&gt;],
      dtype=object)
</pre></div>
</div>
<p>Let’s check inference is working.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx_train</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                        <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X_test</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;onnx loss=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>onnx loss=7.404760822282696e-09
</pre></div>
</div>
</section>
<section id="weights">
<h2><a class="toc-backref" href="#id4">Weights</a><a class="headerlink" href="#weights" title="Permalink to this headline">¶</a></h2>
<p>Every initializer is a set of weights which can be trained
and a gradient will be computed for it.
However an initializer used to modify a shape or to
extract a subpart of a tensor does not need training.
Let’s remove them from the list of initializer to train.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">inits</span> <span class="o">=</span> <span class="n">get_train_initializer</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inits</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;shape_tensor&quot;</span><span class="p">}</span>
<span class="n">pprint</span><span class="p">(</span><span class="nb">list</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">weights</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;coefficient&#39;, (2, 1)), (&#39;intercepts&#39;, (1, 1))]
</pre></div>
</div>
</section>
<section id="train-on-cpu-or-gpu-if-available">
<h2><a class="toc-backref" href="#id5">Train on CPU or GPU if available</a><a class="headerlink" href="#train-on-cpu-or-gpu-if-available" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">get_device</span><span class="p">()</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;GPU&#39;</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;device=</span><span class="si">%r</span><span class="s2"> get_device()=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">get_device</span><span class="p">()))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>device=&#39;cpu&#39; get_device()=&#39;CPU&#39;
</pre></div>
</div>
</section>
<section id="stochastic-gradient-descent">
<h2><a class="toc-backref" href="#id6">Stochastic Gradient Descent</a><a class="headerlink" href="#stochastic-gradient-descent" title="Permalink to this headline">¶</a></h2>
<p>The training logic is hidden in class
<a class="reference internal" href="../onnxcustom/training/optimizers.html#onnxcustom.training.optimizers.OrtGradientOptimizer" title="onnxcustom.training.optimizers.OrtGradientOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientOptimizer</span></code></a>.
It follows <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> API (see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html">SGDRegressor</a>.
The gradient graph is not available at this stage.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_session</span> <span class="o">=</span> <span class="n">OrtGradientOptimizer</span><span class="p">(</span>
    <span class="n">onx_train</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">saved_gradient</span><span class="o">=</span><span class="s2">&quot;saved_gradient.onnx&quot;</span><span class="p">)</span>

<span class="n">train_session</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/200 [00:00&lt;?, ?it/s]
 15%|#5        | 30/200 [00:00&lt;00:00, 295.23it/s]
 30%|###       | 60/200 [00:00&lt;00:00, 289.43it/s]
 45%|####5     | 90/200 [00:00&lt;00:00, 291.87it/s]
 60%|######    | 120/200 [00:00&lt;00:00, 293.14it/s]
 75%|#######5  | 150/200 [00:00&lt;00:00, 293.96it/s]
 90%|######### | 180/200 [00:00&lt;00:00, 294.35it/s]
100%|##########| 200/200 [00:00&lt;00:00, 293.35it/s]

OrtGradientOptimizer(model_onnx=&#39;ir_version...&#39;, weights_to_train=[&#39;coefficient&#39;, &#39;intercepts&#39;], loss_output_name=&#39;loss&#39;, max_iter=200, training_optimizer_name=&#39;SGDOptimizer&#39;, batch_size=10, learning_rate=LearningRateSGD(eta0=0.01, alpha=0.0001, power_t=0.25, learning_rate=&#39;invscaling&#39;), value=0.0026591479484724943, device=&#39;cpu&#39;, warm_start=False, verbose=1, validation_every=20, saved_gradient=&#39;saved_gradient.onnx&#39;, sample_weight_name=&#39;weight&#39;)
</pre></div>
</div>
<p>And the trained coefficient are…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">state_tensors</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<span class="n">pprint</span><span class="p">([</span><span class="s2">&quot;trained coefficients:&quot;</span><span class="p">,</span> <span class="n">state_tensors</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;last_losses:&quot;</span><span class="p">,</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:])</span>

<span class="n">min_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;ort losses&#39;</span><span class="p">:</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">[:</span><span class="n">min_length</span><span class="p">],</span>
                <span class="s1">&#39;skl losses&#39;</span><span class="p">:</span> <span class="n">lr</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">[:</span><span class="n">min_length</span><span class="p">]})</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Train loss against iterations&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_002.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_002.png" alt="Train loss against iterations" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;trained coefficients:&#39;,
 {&#39;coefficient&#39;: array([[58.457428],
       [48.926197]], dtype=float32),
  &#39;intercepts&#39;: array([[2.000249]], dtype=float32)}]
last_losses: [2.3780319e-07, 1.973037e-07, 2.3141999e-07, 1.8104748e-07, 1.8059363e-07]

&lt;AxesSubplot:title={&#39;center&#39;:&#39;Train loss against iterations&#39;}&gt;
</pre></div>
</div>
<p>the training graph looks like the following…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;saved_gradient.onnx.training.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">inode</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;&#39;</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;n</span><span class="si">%d</span><span class="s2">-</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">inode</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

<span class="n">plot_onnxs</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Training graph&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_linear_regression_003.png" srcset="../_images/sphx_glr_plot_orttraining_linear_regression_003.png" alt="Training graph" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:title={&#39;center&#39;:&#39;Training graph&#39;}&gt;
</pre></div>
</div>
<p>The convergence speed is not the same but both gradient descents
do not update the gradient multiplier the same way.
<a class="reference external" href="https://github.com/microsoft/onnxruntime/tree/master/orttraining">onnxruntime-training</a> does not implement any gradient descent,
it just computes the gradient.
That’s the purpose of <a class="reference internal" href="../onnxcustom/training/optimizers.html#onnxcustom.training.optimizers.OrtGradientOptimizer" title="onnxcustom.training.optimizers.OrtGradientOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrtGradientOptimizer</span></code></a>. Next example
digs into the implementation details.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import matplotlib.pyplot as plt</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.182 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-gyexamples-plot-orttraining-linear-regression-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/54b186a9bf1ff7fe8cfe3296a0b68079/plot_orttraining_linear_regression.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_orttraining_linear_regression.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ba6f9a5ee23f5552d9ddc6ab01e077d6/plot_orttraining_linear_regression.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_orttraining_linear_regression.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../tutorials/tutorial_training/tutorial_6_training.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Full Training with OrtGradientOptimizer</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="plot_orttraining_linear_regression_cpu.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a linear regression with onnxruntime-training in details</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>