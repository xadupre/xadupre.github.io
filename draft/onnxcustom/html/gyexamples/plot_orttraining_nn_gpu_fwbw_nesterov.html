
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Forward backward on a neural network on GPU (Nesterov) and penalty &#8212; onnxcustom</title>
    
    <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Benchmark, comparison scikit-learn - forward-backward" href="plot_orttraining_benchmark_fwbw.html" />
    <link rel="prev" title="Forward backward on a neural network on GPU" href="plot_orttraining_nn_gpu_fwbw.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnx/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnxruntime/index.html">
   Introduction to onnxruntime
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_skl/index.html">
   scikit-learn to ONNX Tutorial
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../tutorials/tutorial_training/index.html">
   Training Tutorial
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training.html">
     Full Training with OrtGradientOptimizer
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../tutorials/tutorial_training/tutorial_6_training_partial.html">
     Partial Training with OrtGradientForwardBackwardOptimizer
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_linear_regression_fwbw.html">
       Train a linear regression with forward backward
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_nn_gpu_fwbw.html">
       Forward backward on a neural network on GPU
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Forward backward on a neural network on GPU (Nesterov) and penalty
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_benchmark_fwbw.html">
       Benchmark, comparison scikit-learn - forward-backward
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_orttraining_benchmark_fwbw_cls.html">
       Benchmark, comparison sklearn - forward-backward - classification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_benchmark_onnx_function.html">
       Compares numpy to onnxruntime on simple functions
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_bench/index.html">
   Benchmarking and profiling Tutorial
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-neural-network-with-scikit-learn">
   A neural network with scikit-learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conversion-to-onnx">
   Conversion to ONNX
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-graph-with-forward-backward">
   Training graph with forward backward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularization">
   Regularization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#all-onnx-graphs">
   All ONNX graphs
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gyexamples-plot-orttraining-nn-gpu-fwbw-nesterov-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="forward-backward-on-a-neural-network-on-gpu-nesterov-and-penalty">
<span id="l-orttraining-nn-gpu-fwbw-nesterov"></span><span id="sphx-glr-gyexamples-plot-orttraining-nn-gpu-fwbw-nesterov-py"></span><h1>Forward backward on a neural network on GPU (Nesterov) and penalty<a class="headerlink" href="#forward-backward-on-a-neural-network-on-gpu-nesterov-and-penalty" title="Permalink to this headline">¶</a></h1>
<p>This example does the same as <a class="reference internal" href="plot_orttraining_nn_gpu_fwbw.html#l-orttraining-nn-gpu-fwbw"><span class="std std-ref">Forward backward on a neural network on GPU</span></a>
but updates the weights using <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum">Nesterov momentum</a>.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#a-neural-network-with-scikit-learn" id="id1">A neural network with scikit-learn</a></p></li>
<li><p><a class="reference internal" href="#conversion-to-onnx" id="id2">Conversion to ONNX</a></p></li>
<li><p><a class="reference internal" href="#training-graph-with-forward-backward" id="id3">Training graph with forward backward</a></p></li>
<li><p><a class="reference internal" href="#regularization" id="id4">Regularization</a></p></li>
<li><p><a class="reference internal" href="#all-onnx-graphs" id="id5">All ONNX graphs</a></p></li>
</ul>
</div>
<section id="a-neural-network-with-scikit-learn">
<h2><a class="toc-backref" href="#id1">A neural network with scikit-learn</a><a class="headerlink" href="#a-neural-network-with-scikit-learn" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">get_device</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">onnxcustom.plotting.plotting_onnx</span> <span class="kn">import</span> <span class="n">plot_onnxs</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">mlprodict.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.orttraining_helper</span> <span class="kn">import</span> <span class="n">get_train_initializer</span>
<span class="kn">from</span> <span class="nn">onnxcustom.utils.onnx_helper</span> <span class="kn">import</span> <span class="n">onnx_rename_weights</span>
<span class="kn">from</span> <span class="nn">onnxcustom.training.optimizers_partial</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OrtGradientForwardBackwardOptimizer</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">onnxcustom.training.sgd_learning_rate</span> <span class="kn">import</span> <span class="n">LearningRateSGDNesterov</span>
<span class="kn">from</span> <span class="nn">onnxcustom.training.sgd_learning_penalty</span> <span class="kn">import</span> <span class="n">ElasticLearningPenalty</span>


<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">nn</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                  <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
                  <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                  <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[12142.376850585937, 208.52571149190268, 10.635795823733012, 4.1625566299756365, 2.545690587759018, 1.9989628366629282, 1.5532766801118851, 1.253973110516866, 1.0992915083964665, 0.9226496937870979, 0.8337377693255742, 0.7372933038075765, 0.6420993973811467, 0.6062411475181579, 0.5141608527302742, 0.44477628618478776, 0.44327159454425175, 0.4196765069166819, 0.38307343701521557, 0.3546647993723551, 0.31182308614253995, 0.28883073697487516, 0.2859936295946439, 0.251798144976298, 0.23397356274227302, 0.22059242899219195, 0.2115067273378372, 0.1964540594443679, 0.18915611331661542, 0.17627958372235297, 0.17006373253961404, 0.16114117577672005, 0.15046576759467523, 0.15615677376588186, 0.13722270044187704, 0.13354423951978484, 0.1283668660124143, 0.12381672006100417, 0.11649736418078344, 0.10932136800140142, 0.10336004480719567, 0.10255347618212303, 0.09427588980644941, 0.09865071880320708, 0.09097820652027924, 0.09452121757591764, 0.08985137553264698, 0.08327294170856475, 0.0841425225759546, 0.07678079857180516, 0.07622131654371818, 0.07334446835021179, 0.07204858547697465, 0.0708627612516284, 0.06683499027043581, 0.06581077723453442, 0.06399082435294985, 0.06368227748200297, 0.061796805610259374, 0.06035637442022562, 0.05991592526435852, 0.05721309230973323, 0.05518428727673987, 0.05742139232655366, 0.05565398583188653, 0.05081921972955267, 0.05157470373436809, 0.05034799471497536, 0.049603180922567845, 0.050919087901711464, 0.05095796532308062, 0.049858448108037315, 0.045207385222117105, 0.044612640428046385, 0.04721543467914065, 0.04417784827450911, 0.044271371169015764, 0.04416281206222872, 0.044387510418891905, 0.04164197822411855, 0.041849804955224196, 0.040676024689649544, 0.03856285390133659, 0.04186660434119403, 0.03931069366323451, 0.03893013951058189, 0.03758479594563444, 0.03779271937906742, 0.035520137647787726, 0.03582555818681916, 0.03626670505230625, 0.03448854520296057, 0.03782571161165833, 0.03696222162495057, 0.03296316178205112, 0.03370304711163044, 0.034189842287451026, 0.03165586076055964, 0.03171007619549831, 0.03209064475260675]
</pre></div>
</div>
<p>Score:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mean_squared_error=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>mean_squared_error=0.17486624
</pre></div>
</div>
</section>
<section id="conversion-to-onnx">
<h2><a class="toc-backref" href="#id2">Conversion to ONNX</a><a class="headerlink" href="#conversion-to-onnx" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">target_opset</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plot_onnxs</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>

<span class="n">weights</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">get_train_initializer</span><span class="p">(</span><span class="n">onx</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_nn_gpu_fwbw_nesterov_001.png" srcset="../_images/sphx_glr_plot_orttraining_nn_gpu_fwbw_nesterov_001.png" alt="plot orttraining nn gpu fwbw nesterov" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;coefficient&#39;, &#39;coefficient1&#39;, &#39;coefficient2&#39;, &#39;intercepts&#39;, &#39;intercepts1&#39;, &#39;intercepts2&#39;]
</pre></div>
</div>
</section>
<section id="training-graph-with-forward-backward">
<h2><a class="toc-backref" href="#id3">Training graph with forward backward</a><a class="headerlink" href="#training-graph-with-forward-backward" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">get_device</span><span class="p">()</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;GPU&#39;</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;device=</span><span class="si">%r</span><span class="s2"> get_device()=</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">get_device</span><span class="p">()))</span>

<span class="n">onx</span> <span class="o">=</span> <span class="n">onnx_rename_weights</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>
<span class="n">train_session</span> <span class="o">=</span> <span class="n">OrtGradientForwardBackwardOptimizer</span><span class="p">(</span>
    <span class="n">onx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LearningRateSGDNesterov</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">train_session</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>device=&#39;cpu&#39; get_device()=&#39;CPU&#39;

  0%|          | 0/100 [00:00&lt;?, ?it/s]
  1%|1         | 1/100 [00:00&lt;00:20,  4.81it/s]
  2%|2         | 2/100 [00:00&lt;00:20,  4.80it/s]
  3%|3         | 3/100 [00:00&lt;00:20,  4.79it/s]
  4%|4         | 4/100 [00:00&lt;00:19,  4.80it/s]
  5%|5         | 5/100 [00:01&lt;00:19,  4.80it/s]
  6%|6         | 6/100 [00:01&lt;00:19,  4.80it/s]
  7%|7         | 7/100 [00:01&lt;00:19,  4.80it/s]
  8%|8         | 8/100 [00:01&lt;00:19,  4.80it/s]
  9%|9         | 9/100 [00:01&lt;00:18,  4.80it/s]
 10%|#         | 10/100 [00:02&lt;00:18,  4.80it/s]
 11%|#1        | 11/100 [00:02&lt;00:18,  4.80it/s]
 12%|#2        | 12/100 [00:02&lt;00:18,  4.80it/s]
 13%|#3        | 13/100 [00:02&lt;00:18,  4.80it/s]
 14%|#4        | 14/100 [00:02&lt;00:17,  4.80it/s]
 15%|#5        | 15/100 [00:03&lt;00:17,  4.79it/s]
 16%|#6        | 16/100 [00:03&lt;00:17,  4.78it/s]
 17%|#7        | 17/100 [00:03&lt;00:17,  4.78it/s]
 18%|#8        | 18/100 [00:03&lt;00:17,  4.78it/s]
 19%|#9        | 19/100 [00:03&lt;00:16,  4.78it/s]
 20%|##        | 20/100 [00:04&lt;00:16,  4.79it/s]
 21%|##1       | 21/100 [00:04&lt;00:16,  4.79it/s]
 22%|##2       | 22/100 [00:04&lt;00:16,  4.79it/s]
 23%|##3       | 23/100 [00:04&lt;00:16,  4.79it/s]
 24%|##4       | 24/100 [00:05&lt;00:15,  4.80it/s]
 25%|##5       | 25/100 [00:05&lt;00:15,  4.79it/s]
 26%|##6       | 26/100 [00:05&lt;00:15,  4.80it/s]
 27%|##7       | 27/100 [00:05&lt;00:15,  4.80it/s]
 28%|##8       | 28/100 [00:05&lt;00:15,  4.80it/s]
 29%|##9       | 29/100 [00:06&lt;00:14,  4.80it/s]
 30%|###       | 30/100 [00:06&lt;00:14,  4.80it/s]
 31%|###1      | 31/100 [00:06&lt;00:14,  4.80it/s]
 32%|###2      | 32/100 [00:06&lt;00:14,  4.80it/s]
 33%|###3      | 33/100 [00:06&lt;00:13,  4.79it/s]
 34%|###4      | 34/100 [00:07&lt;00:13,  4.79it/s]
 35%|###5      | 35/100 [00:07&lt;00:13,  4.79it/s]
 36%|###6      | 36/100 [00:07&lt;00:13,  4.78it/s]
 37%|###7      | 37/100 [00:07&lt;00:13,  4.78it/s]
 38%|###8      | 38/100 [00:07&lt;00:12,  4.78it/s]
 39%|###9      | 39/100 [00:08&lt;00:12,  4.78it/s]
 40%|####      | 40/100 [00:08&lt;00:12,  4.78it/s]
 41%|####1     | 41/100 [00:08&lt;00:12,  4.78it/s]
 42%|####2     | 42/100 [00:08&lt;00:12,  4.78it/s]
 43%|####3     | 43/100 [00:08&lt;00:11,  4.78it/s]
 44%|####4     | 44/100 [00:09&lt;00:11,  4.78it/s]
 45%|####5     | 45/100 [00:09&lt;00:11,  4.78it/s]
 46%|####6     | 46/100 [00:09&lt;00:11,  4.78it/s]
 47%|####6     | 47/100 [00:09&lt;00:11,  4.79it/s]
 48%|####8     | 48/100 [00:10&lt;00:10,  4.79it/s]
 49%|####9     | 49/100 [00:10&lt;00:10,  4.78it/s]
 50%|#####     | 50/100 [00:10&lt;00:10,  4.78it/s]
 51%|#####1    | 51/100 [00:10&lt;00:10,  4.78it/s]
 52%|#####2    | 52/100 [00:10&lt;00:10,  4.77it/s]
 53%|#####3    | 53/100 [00:11&lt;00:09,  4.77it/s]
 54%|#####4    | 54/100 [00:11&lt;00:09,  4.77it/s]
 55%|#####5    | 55/100 [00:11&lt;00:09,  4.77it/s]
 56%|#####6    | 56/100 [00:11&lt;00:09,  4.78it/s]
 57%|#####6    | 57/100 [00:11&lt;00:09,  4.77it/s]
 58%|#####8    | 58/100 [00:12&lt;00:08,  4.77it/s]
 59%|#####8    | 59/100 [00:12&lt;00:08,  4.77it/s]
 60%|######    | 60/100 [00:12&lt;00:08,  4.77it/s]
 61%|######1   | 61/100 [00:12&lt;00:08,  4.77it/s]
 62%|######2   | 62/100 [00:12&lt;00:07,  4.77it/s]
 63%|######3   | 63/100 [00:13&lt;00:07,  4.77it/s]
 64%|######4   | 64/100 [00:13&lt;00:07,  4.77it/s]
 65%|######5   | 65/100 [00:13&lt;00:07,  4.77it/s]
 66%|######6   | 66/100 [00:13&lt;00:07,  4.77it/s]
 67%|######7   | 67/100 [00:14&lt;00:06,  4.77it/s]
 68%|######8   | 68/100 [00:14&lt;00:06,  4.77it/s]
 69%|######9   | 69/100 [00:14&lt;00:06,  4.77it/s]
 70%|#######   | 70/100 [00:14&lt;00:06,  4.77it/s]
 71%|#######1  | 71/100 [00:14&lt;00:06,  4.77it/s]
 72%|#######2  | 72/100 [00:15&lt;00:05,  4.77it/s]
 73%|#######3  | 73/100 [00:15&lt;00:05,  4.77it/s]
 74%|#######4  | 74/100 [00:15&lt;00:05,  4.77it/s]
 75%|#######5  | 75/100 [00:15&lt;00:05,  4.77it/s]
 76%|#######6  | 76/100 [00:15&lt;00:05,  4.77it/s]
 77%|#######7  | 77/100 [00:16&lt;00:04,  4.76it/s]
 78%|#######8  | 78/100 [00:16&lt;00:04,  4.76it/s]
 79%|#######9  | 79/100 [00:16&lt;00:04,  4.76it/s]
 80%|########  | 80/100 [00:16&lt;00:04,  4.76it/s]
 81%|########1 | 81/100 [00:16&lt;00:03,  4.76it/s]
 82%|########2 | 82/100 [00:17&lt;00:03,  4.76it/s]
 83%|########2 | 83/100 [00:17&lt;00:03,  4.77it/s]
 84%|########4 | 84/100 [00:17&lt;00:03,  4.76it/s]
 85%|########5 | 85/100 [00:17&lt;00:03,  4.77it/s]
 86%|########6 | 86/100 [00:17&lt;00:02,  4.77it/s]
 87%|########7 | 87/100 [00:18&lt;00:02,  4.77it/s]
 88%|########8 | 88/100 [00:18&lt;00:02,  4.77it/s]
 89%|########9 | 89/100 [00:18&lt;00:02,  4.77it/s]
 90%|######### | 90/100 [00:18&lt;00:02,  4.77it/s]
 91%|#########1| 91/100 [00:19&lt;00:01,  4.77it/s]
 92%|#########2| 92/100 [00:19&lt;00:01,  4.77it/s]
 93%|#########3| 93/100 [00:19&lt;00:01,  4.76it/s]
 94%|#########3| 94/100 [00:19&lt;00:01,  4.76it/s]
 95%|#########5| 95/100 [00:19&lt;00:01,  4.76it/s]
 96%|#########6| 96/100 [00:20&lt;00:00,  4.76it/s]
 97%|#########7| 97/100 [00:20&lt;00:00,  4.76it/s]
 98%|#########8| 98/100 [00:20&lt;00:00,  4.76it/s]
 99%|#########9| 99/100 [00:20&lt;00:00,  4.76it/s]
100%|##########| 100/100 [00:20&lt;00:00,  4.76it/s]
100%|##########| 100/100 [00:20&lt;00:00,  4.78it/s]

OrtGradientForwardBackwardOptimizer(model_onnx=&#39;ir_version...&#39;, weights_to_train=&quot;[&#39;I0_coeff...&quot;, loss_output_name=&#39;loss&#39;, max_iter=100, training_optimizer_name=&#39;SGDOptimizer&#39;, batch_size=10, learning_rate=LearningRateSGDNesterov(eta0=0.0001, alpha=0.0001, power_t=0.25, learning_rate=&#39;invscaling&#39;, momentum=0.9, nesterov=True), value=3.1622776601683795e-05, device=&#39;cpu&#39;, warm_start=False, verbose=1, validation_every=10, learning_loss=SquareLearningLoss(), enable_logging=False, weight_name=None, learning_penalty=NoLearningPenalty(), exc=True)
</pre></div>
</div>
<p>Let’s see the weights.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">state_tensors</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
</pre></div>
</div>
<p>And the loss.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;ort losses&#39;</span><span class="p">:</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">,</span>
                <span class="s1">&#39;skl losses:&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Train loss against iterations (Nesterov)&quot;</span><span class="p">,</span> <span class="n">logy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_nn_gpu_fwbw_nesterov_002.png" srcset="../_images/sphx_glr_plot_orttraining_nn_gpu_fwbw_nesterov_002.png" alt="Train loss against iterations (Nesterov)" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[2258.1738, 26.342966, 9.936302, 5.147777, 3.2953956, 2.8015616, 2.0468345, 1.743872, 1.343944, 1.3889159, 1.1101127, 0.98755026, 0.90764016, 0.7749563, 0.66308135, 0.73497695, 0.6427221, 0.5525322, 0.5237125, 0.62061363, 0.46638852, 0.5113034, 0.40196434, 0.3591859, 0.49574584, 0.34535193, 0.4361959, 0.39837873, 0.38860977, 0.38707742, 0.3307107, 0.28549117, 0.32713687, 0.4017986, 0.3796233, 0.33476147, 0.21781337, 0.30370104, 0.32311404, 0.28576297, 0.24571778, 0.28465894, 0.24558789, 0.21089275, 0.2831703, 0.25513417, 0.23211785, 0.25994626, 0.2551794, 0.25311303, 0.22698905, 0.2027645, 0.23341805, 0.20787859, 0.22074765, 0.20912045, 0.23379944, 0.18521471, 0.18057354, 0.23292427, 0.15141475, 0.19741966, 0.15918921, 0.18584923, 0.14298472, 0.14691725, 0.28181884, 0.1636774, 0.17148694, 0.14742981, 0.11548183, 0.15906177, 0.15372595, 0.12606488, 0.17675255, 0.16583428, 0.16700117, 0.15778151, 0.1406626, 0.1633339, 0.14795175, 0.17505321, 0.19927153, 0.13015547, 0.15346076, 0.11843845, 0.14645901, 0.15687111, 0.124431096, 0.20296392, 0.107760936, 0.13928299, 0.14325543, 0.106979266, 0.09940349, 0.14283879, 0.14309952, 0.1127268, 0.1405759, 0.11075577]

&lt;AxesSubplot:title={&#39;center&#39;:&#39;Train loss against iterations (Nesterov)&#39;}&gt;
</pre></div>
</div>
<p>The convergence rate is different but both classes
do not update the learning exactly the same way.</p>
</section>
<section id="regularization">
<h2><a class="toc-backref" href="#id4">Regularization</a><a class="headerlink" href="#regularization" title="Permalink to this headline">¶</a></h2>
<p>Default parameters for MLPRegressor suggest to penalize weights
during training: <cite>alpha=1e-4</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                  <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
                  <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
                  <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[10287.22519014488, 114.30391664686144, 4.428802581263733, 2.2294384981979367, 1.5061151267471942, 1.0660096135118482, 0.9013473236577829, 0.6927708104238349, 0.6072377480045318, 0.5131283271757443, 0.44050787021721993, 0.3971774471186558, 0.3805070497757753, 0.350709212971592, 0.3160200295091788, 0.2866447259530703, 0.2678877657233954, 0.2624037469550847, 0.2646896001451651, 0.22975923892503577, 0.2235425944488446, 0.20868258862121097, 0.21262072222343276, 0.1918363877769391, 0.1817688411685188, 0.18029508261725902, 0.16713803397329252, 0.15096519545116424, 0.15579957813555, 0.14022681212632657, 0.1335865062277913, 0.13066095226773022, 0.12465744209192994, 0.11612236702070239, 0.11650939311578667, 0.10377068048932547, 0.09965911698656081, 0.09569806834505992, 0.09555516442207891, 0.08785860989701748, 0.08413557989854219, 0.08588188749337594, 0.07946141101812917, 0.07406683651229344, 0.07536813826996087, 0.07404707255665657, 0.06886945094286999, 0.06640573891913693, 0.06959184916854301, 0.0610276720985154, 0.06053264404808283, 0.05765451917141079, 0.05497423387708463, 0.05292999011297026, 0.053558166335922495, 0.051363563591797154, 0.05082045451762675, 0.049323814527793206, 0.04954291654862861, 0.04663594919974508, 0.04639400097087621, 0.045110241577425596, 0.04267538147623937, 0.04201486460911432, 0.041236927045960214, 0.040728190061660605, 0.03991805001185438, 0.03878842797073423, 0.03985737019779681, 0.03783477265487363, 0.03624473010996182, 0.035857376220913735, 0.034874257704518234, 0.03527559812203397, 0.034284848736864826, 0.03344557415381272, 0.03267718306214213, 0.0336423159529845, 0.03282535581768255, 0.032049191349957894, 0.03134248187396525, 0.03107644581406613, 0.029861127178698287, 0.029881794314117735, 0.030867609095594294, 0.028551491866825016, 0.029164035577879357, 0.028555548553245765, 0.027525101808546986, 0.02741220280134081, 0.027476729826804994, 0.02733537836576602, 0.025846304840237408, 0.026733439335417743, 0.024720744558956235, 0.02609910241108065, 0.02529742046883305, 0.025844847096701467, 0.024001264599111175, 0.024748266170668606]
</pre></div>
</div>
<p>Let’s do the same with onnxruntime.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_session</span> <span class="o">=</span> <span class="n">OrtGradientForwardBackwardOptimizer</span><span class="p">(</span>
    <span class="n">onx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LearningRateSGDNesterov</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="n">learning_penalty</span><span class="o">=</span><span class="n">ElasticLearningPenalty</span><span class="p">(</span><span class="n">l1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">),</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">train_session</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/100 [00:00&lt;?, ?it/s]
  1%|1         | 1/100 [00:00&lt;00:28,  3.45it/s]
  2%|2         | 2/100 [00:00&lt;00:28,  3.43it/s]
  3%|3         | 3/100 [00:00&lt;00:28,  3.42it/s]
  4%|4         | 4/100 [00:01&lt;00:28,  3.42it/s]
  5%|5         | 5/100 [00:01&lt;00:27,  3.42it/s]
  6%|6         | 6/100 [00:01&lt;00:27,  3.41it/s]
  7%|7         | 7/100 [00:02&lt;00:27,  3.41it/s]
  8%|8         | 8/100 [00:02&lt;00:26,  3.41it/s]
  9%|9         | 9/100 [00:02&lt;00:26,  3.41it/s]
 10%|#         | 10/100 [00:02&lt;00:26,  3.41it/s]
 11%|#1        | 11/100 [00:03&lt;00:26,  3.41it/s]
 12%|#2        | 12/100 [00:03&lt;00:25,  3.41it/s]
 13%|#3        | 13/100 [00:03&lt;00:25,  3.42it/s]
 14%|#4        | 14/100 [00:04&lt;00:25,  3.42it/s]
 15%|#5        | 15/100 [00:04&lt;00:24,  3.41it/s]
 16%|#6        | 16/100 [00:04&lt;00:24,  3.42it/s]
 17%|#7        | 17/100 [00:04&lt;00:24,  3.42it/s]
 18%|#8        | 18/100 [00:05&lt;00:24,  3.42it/s]
 19%|#9        | 19/100 [00:05&lt;00:23,  3.42it/s]
 20%|##        | 20/100 [00:05&lt;00:23,  3.41it/s]
 21%|##1       | 21/100 [00:06&lt;00:23,  3.41it/s]
 22%|##2       | 22/100 [00:06&lt;00:22,  3.41it/s]
 23%|##3       | 23/100 [00:06&lt;00:22,  3.41it/s]
 24%|##4       | 24/100 [00:07&lt;00:22,  3.41it/s]
 25%|##5       | 25/100 [00:07&lt;00:21,  3.41it/s]
 26%|##6       | 26/100 [00:07&lt;00:21,  3.41it/s]
 27%|##7       | 27/100 [00:07&lt;00:21,  3.41it/s]
 28%|##8       | 28/100 [00:08&lt;00:21,  3.41it/s]
 29%|##9       | 29/100 [00:08&lt;00:20,  3.42it/s]
 30%|###       | 30/100 [00:08&lt;00:20,  3.42it/s]
 31%|###1      | 31/100 [00:09&lt;00:20,  3.42it/s]
 32%|###2      | 32/100 [00:09&lt;00:19,  3.42it/s]
 33%|###3      | 33/100 [00:09&lt;00:19,  3.42it/s]
 34%|###4      | 34/100 [00:09&lt;00:19,  3.42it/s]
 35%|###5      | 35/100 [00:10&lt;00:18,  3.42it/s]
 36%|###6      | 36/100 [00:10&lt;00:18,  3.42it/s]
 37%|###7      | 37/100 [00:10&lt;00:18,  3.42it/s]
 38%|###8      | 38/100 [00:11&lt;00:18,  3.42it/s]
 39%|###9      | 39/100 [00:11&lt;00:17,  3.42it/s]
 40%|####      | 40/100 [00:11&lt;00:17,  3.42it/s]
 41%|####1     | 41/100 [00:12&lt;00:17,  3.42it/s]
 42%|####2     | 42/100 [00:12&lt;00:16,  3.42it/s]
 43%|####3     | 43/100 [00:12&lt;00:16,  3.42it/s]
 44%|####4     | 44/100 [00:12&lt;00:16,  3.42it/s]
 45%|####5     | 45/100 [00:13&lt;00:16,  3.42it/s]
 46%|####6     | 46/100 [00:13&lt;00:15,  3.42it/s]
 47%|####6     | 47/100 [00:13&lt;00:15,  3.42it/s]
 48%|####8     | 48/100 [00:14&lt;00:15,  3.42it/s]
 49%|####9     | 49/100 [00:14&lt;00:14,  3.42it/s]
 50%|#####     | 50/100 [00:14&lt;00:14,  3.42it/s]
 51%|#####1    | 51/100 [00:14&lt;00:14,  3.42it/s]
 52%|#####2    | 52/100 [00:15&lt;00:14,  3.42it/s]
 53%|#####3    | 53/100 [00:15&lt;00:13,  3.42it/s]
 54%|#####4    | 54/100 [00:15&lt;00:13,  3.42it/s]
 55%|#####5    | 55/100 [00:16&lt;00:13,  3.42it/s]
 56%|#####6    | 56/100 [00:16&lt;00:12,  3.41it/s]
 57%|#####6    | 57/100 [00:16&lt;00:12,  3.41it/s]
 58%|#####8    | 58/100 [00:16&lt;00:12,  3.41it/s]
 59%|#####8    | 59/100 [00:17&lt;00:12,  3.41it/s]
 60%|######    | 60/100 [00:17&lt;00:11,  3.42it/s]
 61%|######1   | 61/100 [00:17&lt;00:11,  3.42it/s]
 62%|######2   | 62/100 [00:18&lt;00:11,  3.42it/s]
 63%|######3   | 63/100 [00:18&lt;00:10,  3.42it/s]
 64%|######4   | 64/100 [00:18&lt;00:10,  3.42it/s]
 65%|######5   | 65/100 [00:19&lt;00:10,  3.41it/s]
 66%|######6   | 66/100 [00:19&lt;00:09,  3.41it/s]
 67%|######7   | 67/100 [00:19&lt;00:09,  3.41it/s]
 68%|######8   | 68/100 [00:19&lt;00:09,  3.41it/s]
 69%|######9   | 69/100 [00:20&lt;00:09,  3.41it/s]
 70%|#######   | 70/100 [00:20&lt;00:08,  3.41it/s]
 71%|#######1  | 71/100 [00:20&lt;00:08,  3.41it/s]
 72%|#######2  | 72/100 [00:21&lt;00:08,  3.41it/s]
 73%|#######3  | 73/100 [00:21&lt;00:07,  3.41it/s]
 74%|#######4  | 74/100 [00:21&lt;00:07,  3.41it/s]
 75%|#######5  | 75/100 [00:21&lt;00:07,  3.41it/s]
 76%|#######6  | 76/100 [00:22&lt;00:07,  3.41it/s]
 77%|#######7  | 77/100 [00:22&lt;00:06,  3.41it/s]
 78%|#######8  | 78/100 [00:22&lt;00:06,  3.41it/s]
 79%|#######9  | 79/100 [00:23&lt;00:06,  3.41it/s]
 80%|########  | 80/100 [00:23&lt;00:05,  3.41it/s]
 81%|########1 | 81/100 [00:23&lt;00:05,  3.41it/s]
 82%|########2 | 82/100 [00:24&lt;00:05,  3.41it/s]
 83%|########2 | 83/100 [00:24&lt;00:04,  3.41it/s]
 84%|########4 | 84/100 [00:24&lt;00:04,  3.41it/s]
 85%|########5 | 85/100 [00:24&lt;00:04,  3.41it/s]
 86%|########6 | 86/100 [00:25&lt;00:04,  3.41it/s]
 87%|########7 | 87/100 [00:25&lt;00:03,  3.41it/s]
 88%|########8 | 88/100 [00:25&lt;00:03,  3.41it/s]
 89%|########9 | 89/100 [00:26&lt;00:03,  3.41it/s]
 90%|######### | 90/100 [00:26&lt;00:02,  3.41it/s]
 91%|#########1| 91/100 [00:26&lt;00:02,  3.42it/s]
 92%|#########2| 92/100 [00:26&lt;00:02,  3.42it/s]
 93%|#########3| 93/100 [00:27&lt;00:02,  3.42it/s]
 94%|#########3| 94/100 [00:27&lt;00:01,  3.42it/s]
 95%|#########5| 95/100 [00:27&lt;00:01,  3.42it/s]
 96%|#########6| 96/100 [00:28&lt;00:01,  3.41it/s]
 97%|#########7| 97/100 [00:28&lt;00:00,  3.41it/s]
 98%|#########8| 98/100 [00:28&lt;00:00,  3.41it/s]
 99%|#########9| 99/100 [00:28&lt;00:00,  3.41it/s]
100%|##########| 100/100 [00:29&lt;00:00,  3.41it/s]
100%|##########| 100/100 [00:29&lt;00:00,  3.41it/s]

OrtGradientForwardBackwardOptimizer(model_onnx=&#39;ir_version...&#39;, weights_to_train=&quot;[&#39;I0_coeff...&quot;, loss_output_name=&#39;loss&#39;, max_iter=100, training_optimizer_name=&#39;SGDOptimizer&#39;, batch_size=10, learning_rate=LearningRateSGDNesterov(eta0=0.0001, alpha=0.0001, power_t=0.25, learning_rate=&#39;invscaling&#39;, momentum=0.9, nesterov=True), value=3.1622776601683795e-05, device=&#39;cpu&#39;, warm_start=False, verbose=1, validation_every=10, learning_loss=SquareLearningLoss(), enable_logging=False, weight_name=None, learning_penalty=ElasticLearningPenalty(l1=0, l2=0.0001), exc=True)
</pre></div>
</div>
<p>Let’s see the weights.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">state_tensors</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
</pre></div>
</div>
<p>And the loss.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;ort losses&#39;</span><span class="p">:</span> <span class="n">train_session</span><span class="o">.</span><span class="n">train_losses_</span><span class="p">,</span>
                <span class="s1">&#39;skl losses:&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss_curve_</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Train loss against iterations (Nesterov + penalty)&quot;</span><span class="p">,</span> <span class="n">logy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_orttraining_nn_gpu_fwbw_nesterov_003.png" srcset="../_images/sphx_glr_plot_orttraining_nn_gpu_fwbw_nesterov_003.png" alt="Train loss against iterations (Nesterov + penalty)" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[4861.449, 25.046307, 11.008789, 7.74074, 5.1028852, 3.2229476, 3.2113922, 2.9235556, 2.1449852, 2.3559413, 1.8511151, 1.9164665, 1.435327, 1.4132812, 1.2099515, 1.1310208, 1.206428, 0.8012704, 0.8482481, 1.0125045, 0.76332545, 0.8698208, 0.8912954, 0.7267333, 0.83761984, 0.675399, 0.6764955, 0.5540964, 0.58731264, 0.6209444, 0.55011517, 0.4272984, 0.50298077, 0.42416194, 0.49143714, 0.4930766, 0.41217956, 0.4411206, 0.4109722, 0.34561297, 0.42141122, 0.32779393, 0.36398593, 0.37045026, 0.2863156, 0.28487918, 0.262511, 0.29033896, 0.27661306, 0.27709922, 0.22183947, 0.25974074, 0.2349325, 0.31290713, 0.24561325, 0.29334575, 0.23535314, 0.24226215, 0.2292589, 0.23041001, 0.2390392, 0.23469613, 0.2020327, 0.19836996, 0.2151799, 0.19205719, 0.1804088, 0.2004037, 0.1584917, 0.18252498, 0.16962215, 0.14306745, 0.158388, 0.1560865, 0.107742354, 0.15685132, 0.14094299, 0.13749506, 0.15084405, 0.13492058, 0.14775337, 0.12560132, 0.13170843, 0.13348602, 0.1418273, 0.1413577, 0.13540213, 0.14798613, 0.1299366, 0.1215678, 0.14300115, 0.13453592, 0.14070058, 0.13080919, 0.11906525, 0.15257156, 0.13933863, 0.14258417, 0.13619626, 0.13876237]

&lt;AxesSubplot:title={&#39;center&#39;:&#39;Train loss against iterations (Nesterov + penalty)&#39;}&gt;
</pre></div>
</div>
</section>
<section id="all-onnx-graphs">
<h2><a class="toc-backref" href="#id5">All ONNX graphs</a><a class="headerlink" href="#all-onnx-graphs" title="Permalink to this headline">¶</a></h2>
<p>Method Method <a class="reference internal" href="../onnxcustom/training/_base.html#onnxcustom.training._base.BaseOnnxClass.save_onnx_graph" title="onnxcustom.training._base.BaseOnnxClass.save_onnx_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_onnx_graph</span></code></a>
can export all the ONNX graph used by the model on disk.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_graph</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">print_graph</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">++++++&quot;</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">onnx_simple_text_plot</span><span class="p">(</span><span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)))</span>


<span class="n">all_files</span> <span class="o">=</span> <span class="n">train_session</span><span class="o">.</span><span class="n">save_onnx_graph</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">print_graph</span><span class="p">(</span><span class="n">all_files</span><span class="p">)</span>


<span class="c1"># import matplotlib.pyplot as plt</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>++++++ ./SquareLLoss.learning_loss.loss_grad_onnx_.onnx

opset: domain=&#39;&#39; version=14
input: name=&#39;X1&#39; type=dtype(&#39;float32&#39;) shape=(0, 0)
input: name=&#39;X2&#39; type=dtype(&#39;float32&#39;) shape=(0, 0)
init: name=&#39;Mu_Mulcst&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([0.5], dtype=float32)
init: name=&#39;Re_Reshapecst&#39; type=dtype(&#39;int64&#39;) shape=(1,) -- array([-1])
init: name=&#39;Mu_Mulcst1&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([-1.], dtype=float32)
Sub(X1, X2) -&gt; Su_C0
  Mul(Su_C0, Mu_Mulcst1) -&gt; Y_grad
ReduceSumSquare(Su_C0) -&gt; Re_reduced0
  Mul(Re_reduced0, Mu_Mulcst) -&gt; Mu_C0
    Reshape(Mu_C0, Re_Reshapecst) -&gt; Y
output: name=&#39;Y&#39; type=dtype(&#39;float32&#39;) shape=()
output: name=&#39;Y_grad&#39; type=dtype(&#39;float32&#39;) shape=()

++++++ ./SquareLLoss.learning_loss.loss_score_onnx_.onnx

opset: domain=&#39;&#39; version=14
input: name=&#39;X1&#39; type=dtype(&#39;float32&#39;) shape=(0, 0)
input: name=&#39;X2&#39; type=dtype(&#39;float32&#39;) shape=(0, 0)
Sub(X1, X2) -&gt; Su_C0
  Mul(Su_C0, Su_C0) -&gt; Y
output: name=&#39;Y&#39; type=dtype(&#39;float32&#39;) shape=(0, 1)

++++++ ./ElasticLPenalty.learning_penalty.penalty_grad_onnx_.onnx

opset: domain=&#39;&#39; version=14
input: name=&#39;X&#39; type=dtype(&#39;float32&#39;) shape=()
init: name=&#39;Mu_Mulcst&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([0.9998], dtype=float32)
init: name=&#39;Mu_Mulcst1&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([0.], dtype=float32)
Mul(X, Mu_Mulcst) -&gt; Mu_C0
Sign(X) -&gt; Si_output0
  Mul(Si_output0, Mu_Mulcst1) -&gt; Mu_C02
  Sub(Mu_C0, Mu_C02) -&gt; Y
output: name=&#39;Y&#39; type=dtype(&#39;float32&#39;) shape=()

++++++ ./ElasticLPenalty.learning_penalty.penalty_onnx_.onnx

opset: domain=&#39;&#39; version=14
input: name=&#39;loss&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;W0&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;W1&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;W2&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;W3&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;W4&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;W5&#39; type=dtype(&#39;float32&#39;) shape=()
init: name=&#39;Mu_Mulcst&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([0.], dtype=float32)
init: name=&#39;Mu_Mulcst1&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([1.e-04], dtype=float32)
init: name=&#39;Re_Reshapecst&#39; type=dtype(&#39;int64&#39;) shape=(1,) -- array([-1])
Abs(W0) -&gt; Ab_Y0
  ReduceSum(Ab_Y0) -&gt; Re_reduced0
    Mul(Re_reduced0, Mu_Mulcst) -&gt; Mu_C0
Abs(W3) -&gt; Ab_Y04
  ReduceSum(Ab_Y04) -&gt; Re_reduced07
ReduceSumSquare(W5) -&gt; Re_reduced012
ReduceSumSquare(W3) -&gt; Re_reduced08
Identity(Mu_Mulcst) -&gt; Mu_Mulcst6
  Mul(Re_reduced07, Mu_Mulcst6) -&gt; Mu_C07
ReduceSumSquare(W4) -&gt; Re_reduced010
Identity(Mu_Mulcst1) -&gt; Mu_Mulcst7
  Mul(Re_reduced08, Mu_Mulcst7) -&gt; Mu_C08
    Add(Mu_C07, Mu_C08) -&gt; Ad_C09
Abs(W4) -&gt; Ab_Y05
  ReduceSum(Ab_Y05) -&gt; Re_reduced09
Identity(Mu_Mulcst) -&gt; Mu_Mulcst8
  Mul(Re_reduced09, Mu_Mulcst8) -&gt; Mu_C09
Identity(Mu_Mulcst1) -&gt; Mu_Mulcst9
  Mul(Re_reduced010, Mu_Mulcst9) -&gt; Mu_C010
    Add(Mu_C09, Mu_C010) -&gt; Ad_C010
Abs(W5) -&gt; Ab_Y06
  ReduceSum(Ab_Y06) -&gt; Re_reduced011
Identity(Mu_Mulcst) -&gt; Mu_Mulcst10
  Mul(Re_reduced011, Mu_Mulcst10) -&gt; Mu_C011
Identity(Mu_Mulcst1) -&gt; Mu_Mulcst11
  Mul(Re_reduced012, Mu_Mulcst11) -&gt; Mu_C012
    Add(Mu_C011, Mu_C012) -&gt; Ad_C011
Identity(Mu_Mulcst1) -&gt; Mu_Mulcst3
ReduceSumSquare(W0) -&gt; Re_reduced02
  Mul(Re_reduced02, Mu_Mulcst1) -&gt; Mu_C02
    Add(Mu_C0, Mu_C02) -&gt; Ad_C06
Identity(Mu_Mulcst) -&gt; Mu_Mulcst4
Abs(W2) -&gt; Ab_Y03
  ReduceSum(Ab_Y03) -&gt; Re_reduced05
  Mul(Re_reduced05, Mu_Mulcst4) -&gt; Mu_C05
ReduceSumSquare(W1) -&gt; Re_reduced04
  Mul(Re_reduced04, Mu_Mulcst3) -&gt; Mu_C04
ReduceSumSquare(W2) -&gt; Re_reduced06
Identity(Mu_Mulcst1) -&gt; Mu_Mulcst5
  Mul(Re_reduced06, Mu_Mulcst5) -&gt; Mu_C06
    Add(Mu_C05, Mu_C06) -&gt; Ad_C08
Identity(Mu_Mulcst) -&gt; Mu_Mulcst2
Abs(W1) -&gt; Ab_Y02
  ReduceSum(Ab_Y02) -&gt; Re_reduced03
  Mul(Re_reduced03, Mu_Mulcst2) -&gt; Mu_C03
    Add(Mu_C03, Mu_C04) -&gt; Ad_C07
      Add(Ad_C06, Ad_C07) -&gt; Ad_C05
      Add(Ad_C05, Ad_C08) -&gt; Ad_C04
      Add(Ad_C04, Ad_C09) -&gt; Ad_C03
      Add(Ad_C03, Ad_C010) -&gt; Ad_C02
      Add(Ad_C02, Ad_C011) -&gt; Ad_C01
        Add(loss, Ad_C01) -&gt; Ad_C0
          Reshape(Ad_C0, Re_Reshapecst) -&gt; Y
output: name=&#39;Y&#39; type=dtype(&#39;float32&#39;) shape=(0,)

++++++ ./LRateSGDNesterov.learning_rate.axpyw_onnx_.onnx

opset: domain=&#39;&#39; version=14
input: name=&#39;X1&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;X2&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;G&#39; type=dtype(&#39;float32&#39;) shape=()
input: name=&#39;alpha&#39; type=dtype(&#39;float32&#39;) shape=(1,)
input: name=&#39;beta&#39; type=dtype(&#39;float32&#39;) shape=(1,)
Mul(X1, alpha) -&gt; Mu_C0
Mul(G, beta) -&gt; Mu_C03
  Add(Mu_C0, Mu_C03) -&gt; Z
    Mul(Z, beta) -&gt; Mu_C02
  Add(Mu_C0, Mu_C02) -&gt; Ad_C0
    Add(Ad_C0, X2) -&gt; Y
output: name=&#39;Y&#39; type=dtype(&#39;float32&#39;) shape=()
output: name=&#39;Z&#39; type=dtype(&#39;float32&#39;) shape=()

++++++ ./GradFBOptimizer.model_onnx.onnx

opset: domain=&#39;&#39; version=14
input: name=&#39;X&#39; type=dtype(&#39;float32&#39;) shape=(0, 10)
init: name=&#39;I0_coefficient&#39; type=dtype(&#39;float32&#39;) shape=(100,)
init: name=&#39;I1_intercepts&#39; type=dtype(&#39;float32&#39;) shape=(10,)
init: name=&#39;I2_coefficient1&#39; type=dtype(&#39;float32&#39;) shape=(100,)
init: name=&#39;I3_intercepts1&#39; type=dtype(&#39;float32&#39;) shape=(10,)
init: name=&#39;I4_coefficient2&#39; type=dtype(&#39;float32&#39;) shape=(10,)
init: name=&#39;I5_intercepts2&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([0.14376946], dtype=float32)
init: name=&#39;I6_shape_tensor&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1,  1])
Cast(X, to=1) -&gt; r0
  MatMul(r0, I0_coefficient) -&gt; r1
    Add(r1, I1_intercepts) -&gt; r2
      Relu(r2) -&gt; r3
        MatMul(r3, I2_coefficient1) -&gt; r4
          Add(r4, I3_intercepts1) -&gt; r5
            Relu(r5) -&gt; r6
              MatMul(r6, I4_coefficient2) -&gt; r7
                Add(r7, I5_intercepts2) -&gt; r8
                  Reshape(r8, I6_shape_tensor) -&gt; variable
output: name=&#39;variable&#39; type=dtype(&#39;float32&#39;) shape=(0, 1)

++++++ ./OrtGradientForwardBackwardFunction_140036806160976.train_function_._optimized_pre_grad_model.onnx

opset: domain=&#39;&#39; version=14
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;com.ms.internal.nhwc&#39; version=1
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.ml&#39; version=2
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;X&#39; type=dtype(&#39;float32&#39;) shape=(0, 10)
input: name=&#39;I0_coefficient&#39; type=dtype(&#39;float32&#39;) shape=(10, 10)
input: name=&#39;I1_intercepts&#39; type=dtype(&#39;float32&#39;) shape=(1, 10)
input: name=&#39;I2_coefficient1&#39; type=dtype(&#39;float32&#39;) shape=(10, 10)
input: name=&#39;I3_intercepts1&#39; type=dtype(&#39;float32&#39;) shape=(1, 10)
input: name=&#39;I4_coefficient2&#39; type=dtype(&#39;float32&#39;) shape=(10, 1)
input: name=&#39;I5_intercepts2&#39; type=dtype(&#39;float32&#39;) shape=(1, 1)
init: name=&#39;I6_shape_tensor&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1,  1])
MatMul(X, I0_coefficient) -&gt; r1
  Add(r1, I1_intercepts) -&gt; r2
    Relu(r2) -&gt; r3
      MatMul(r3, I2_coefficient1) -&gt; r4
        Add(r4, I3_intercepts1) -&gt; r5
          Relu(r5) -&gt; r6
            MatMul(r6, I4_coefficient2) -&gt; r7
              Add(r7, I5_intercepts2) -&gt; r8
                Reshape(r8, I6_shape_tensor, allowzero=0) -&gt; variable
output: name=&#39;variable&#39; type=dtype(&#39;float32&#39;) shape=(0, 1)

++++++ ./OrtGradientForwardBackwardFunction_140036806160976.train_function_._trained_onnx.onnx

opset: domain=&#39;&#39; version=14
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;com.ms.internal.nhwc&#39; version=1
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.ml&#39; version=2
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;X&#39; type=dtype(&#39;float32&#39;) shape=(0, 10)
input: name=&#39;I0_coefficient&#39; type=dtype(&#39;float32&#39;) shape=(10, 10)
input: name=&#39;I1_intercepts&#39; type=dtype(&#39;float32&#39;) shape=(1, 10)
input: name=&#39;I2_coefficient1&#39; type=dtype(&#39;float32&#39;) shape=(10, 10)
input: name=&#39;I3_intercepts1&#39; type=dtype(&#39;float32&#39;) shape=(1, 10)
input: name=&#39;I4_coefficient2&#39; type=dtype(&#39;float32&#39;) shape=(10, 1)
input: name=&#39;I5_intercepts2&#39; type=dtype(&#39;float32&#39;) shape=(1, 1)
init: name=&#39;I6_shape_tensor&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1,  1])
init: name=&#39;n1_Grad/A_target_shape&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1, 10])
init: name=&#39;n1_Grad/dY_target_shape&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1, 10])
init: name=&#39;n4_Grad/A_target_shape&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1, 10])
init: name=&#39;n4_Grad/dY_target_shape&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1, 10])
init: name=&#39;n7_Grad/A_target_shape&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1, 10])
init: name=&#39;n7_Grad/dY_target_shape&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([-1,  1])
MatMul(X, I0_coefficient) -&gt; r1
  Add(r1, I1_intercepts) -&gt; r2
    Relu(r2) -&gt; r3
      MatMul(r3, I2_coefficient1) -&gt; r4
        Add(r4, I3_intercepts1) -&gt; r5
          Relu(r5) -&gt; r6
            MatMul(r6, I4_coefficient2) -&gt; r7
              Add(r7, I5_intercepts2) -&gt; r8
                Reshape(r8, I6_shape_tensor, allowzero=0) -&gt; variable
                  YieldOp(variable) -&gt; variable_grad
                Shape(r8) -&gt; n9_Grad/x_shape
                  Reshape(variable_grad, n9_Grad/x_shape, allowzero=0) -&gt; r8_grad
Shape(I5_intercepts2) -&gt; n8_Grad/Shape_I5_intercepts2
Shape(r7) -&gt; n8_Grad/Shape_r7
  BroadcastGradientArgs(n8_Grad/Shape_r7, n8_Grad/Shape_I5_intercepts2) -&gt; n8_Grad/ReduceAxes_r7, n8_Grad/ReduceAxes_I5_intercepts2
    ReduceSum(r8_grad, n8_Grad/ReduceAxes_I5_intercepts2, noop_with_empty_axes=1, keepdims=1) -&gt; n8_Grad/ReduceSum_r8_grad_for_I5_intercepts2
  Reshape(n8_Grad/ReduceSum_r8_grad_for_I5_intercepts2, n8_Grad/Shape_I5_intercepts2, allowzero=0) -&gt; I5_intercepts2_grad
ReduceSum(r8_grad, n8_Grad/ReduceAxes_r7, noop_with_empty_axes=1, keepdims=1) -&gt; n8_Grad/ReduceSum_r8_grad_for_r7
  Reshape(n8_Grad/ReduceSum_r8_grad_for_r7, n8_Grad/Shape_r7, allowzero=0) -&gt; r7_grad
    Reshape(r7_grad, n7_Grad/dY_target_shape, allowzero=0) -&gt; n7_Grad/dY_reshape_2d
Reshape(r6, n7_Grad/A_target_shape, allowzero=0) -&gt; n7_Grad/A_reshape_2d
  Gemm(n7_Grad/A_reshape_2d, n7_Grad/dY_reshape_2d, beta=1.00, transB=0, transA=1, alpha=1.00) -&gt; I4_coefficient2_grad
FusedMatMul(r7_grad, I4_coefficient2, transB=1, alpha=1.00, transA=0) -&gt; n7_Grad/PreReduceGrad0
  Shape(n7_Grad/PreReduceGrad0) -&gt; n7_Grad/Shape_n7_Grad/PreReduceGrad0
Shape(r6) -&gt; n7_Grad/Shape_r6
  BroadcastGradientArgs(n7_Grad/Shape_r6, n7_Grad/Shape_n7_Grad/PreReduceGrad0) -&gt; n7_Grad/ReduceAxes_r6_for_r6,
  ReduceSum(n7_Grad/PreReduceGrad0, n7_Grad/ReduceAxes_r6_for_r6, noop_with_empty_axes=1, keepdims=1) -&gt; n7_Grad/ReduceSum_n7_Grad/PreReduceGrad0_for_r6
  Reshape(n7_Grad/ReduceSum_n7_Grad/PreReduceGrad0_for_r6, n7_Grad/Shape_r6, allowzero=0) -&gt; r6_grad
    ReluGrad(r6_grad, r6) -&gt; r5_grad
Shape(I3_intercepts1) -&gt; n5_Grad/Shape_I3_intercepts1
Shape(r4) -&gt; n5_Grad/Shape_r4
  BroadcastGradientArgs(n5_Grad/Shape_r4, n5_Grad/Shape_I3_intercepts1) -&gt; n5_Grad/ReduceAxes_r4, n5_Grad/ReduceAxes_I3_intercepts1
    ReduceSum(r5_grad, n5_Grad/ReduceAxes_I3_intercepts1, noop_with_empty_axes=1, keepdims=1) -&gt; n5_Grad/ReduceSum_r5_grad_for_I3_intercepts1
  Reshape(n5_Grad/ReduceSum_r5_grad_for_I3_intercepts1, n5_Grad/Shape_I3_intercepts1, allowzero=0) -&gt; I3_intercepts1_grad
ReduceSum(r5_grad, n5_Grad/ReduceAxes_r4, noop_with_empty_axes=1, keepdims=1) -&gt; n5_Grad/ReduceSum_r5_grad_for_r4
  Reshape(n5_Grad/ReduceSum_r5_grad_for_r4, n5_Grad/Shape_r4, allowzero=0) -&gt; r4_grad
    Reshape(r4_grad, n4_Grad/dY_target_shape, allowzero=0) -&gt; n4_Grad/dY_reshape_2d
Reshape(r3, n4_Grad/A_target_shape, allowzero=0) -&gt; n4_Grad/A_reshape_2d
  Gemm(n4_Grad/A_reshape_2d, n4_Grad/dY_reshape_2d, beta=1.00, transB=0, transA=1, alpha=1.00) -&gt; I2_coefficient1_grad
FusedMatMul(r4_grad, I2_coefficient1, transB=1, alpha=1.00, transA=0) -&gt; n4_Grad/PreReduceGrad0
  Shape(n4_Grad/PreReduceGrad0) -&gt; n4_Grad/Shape_n4_Grad/PreReduceGrad0
Shape(r3) -&gt; n4_Grad/Shape_r3
  BroadcastGradientArgs(n4_Grad/Shape_r3, n4_Grad/Shape_n4_Grad/PreReduceGrad0) -&gt; n4_Grad/ReduceAxes_r3_for_r3,
  ReduceSum(n4_Grad/PreReduceGrad0, n4_Grad/ReduceAxes_r3_for_r3, noop_with_empty_axes=1, keepdims=1) -&gt; n4_Grad/ReduceSum_n4_Grad/PreReduceGrad0_for_r3
  Reshape(n4_Grad/ReduceSum_n4_Grad/PreReduceGrad0_for_r3, n4_Grad/Shape_r3, allowzero=0) -&gt; r3_grad
    ReluGrad(r3_grad, r3) -&gt; r2_grad
Shape(I1_intercepts) -&gt; n2_Grad/Shape_I1_intercepts
Shape(r1) -&gt; n2_Grad/Shape_r1
  BroadcastGradientArgs(n2_Grad/Shape_r1, n2_Grad/Shape_I1_intercepts) -&gt; n2_Grad/ReduceAxes_r1, n2_Grad/ReduceAxes_I1_intercepts
    ReduceSum(r2_grad, n2_Grad/ReduceAxes_I1_intercepts, noop_with_empty_axes=1, keepdims=1) -&gt; n2_Grad/ReduceSum_r2_grad_for_I1_intercepts
  Reshape(n2_Grad/ReduceSum_r2_grad_for_I1_intercepts, n2_Grad/Shape_I1_intercepts, allowzero=0) -&gt; I1_intercepts_grad
ReduceSum(r2_grad, n2_Grad/ReduceAxes_r1, noop_with_empty_axes=1, keepdims=1) -&gt; n2_Grad/ReduceSum_r2_grad_for_r1
  Reshape(n2_Grad/ReduceSum_r2_grad_for_r1, n2_Grad/Shape_r1, allowzero=0) -&gt; r1_grad
    Reshape(r1_grad, n1_Grad/dY_target_shape, allowzero=0) -&gt; n1_Grad/dY_reshape_2d
Reshape(X, n1_Grad/A_target_shape, allowzero=0) -&gt; n1_Grad/A_reshape_2d
  Gemm(n1_Grad/A_reshape_2d, n1_Grad/dY_reshape_2d, beta=1.00, transB=0, transA=1, alpha=1.00) -&gt; I0_coefficient_grad
FusedMatMul(r1_grad, I0_coefficient, transB=1, alpha=1.00, transA=0) -&gt; n1_Grad/PreReduceGrad0
  Shape(n1_Grad/PreReduceGrad0) -&gt; n1_Grad/Shape_n1_Grad/PreReduceGrad0
Shape(X) -&gt; n1_Grad/Shape_X
  BroadcastGradientArgs(n1_Grad/Shape_X, n1_Grad/Shape_n1_Grad/PreReduceGrad0) -&gt; n1_Grad/ReduceAxes_X_for_X,
  ReduceSum(n1_Grad/PreReduceGrad0, n1_Grad/ReduceAxes_X_for_X, noop_with_empty_axes=1, keepdims=1) -&gt; n1_Grad/ReduceSum_n1_Grad/PreReduceGrad0_for_X
  Reshape(n1_Grad/ReduceSum_n1_Grad/PreReduceGrad0_for_X, n1_Grad/Shape_X, allowzero=0) -&gt; X_grad
output: name=&#39;X_grad&#39; type=dtype(&#39;float32&#39;) shape=(0, 10)
output: name=&#39;I0_coefficient_grad&#39; type=dtype(&#39;float32&#39;) shape=(10, 10)
output: name=&#39;I1_intercepts_grad&#39; type=dtype(&#39;float32&#39;) shape=(1, 10)
output: name=&#39;I2_coefficient1_grad&#39; type=dtype(&#39;float32&#39;) shape=(10, 10)
output: name=&#39;I3_intercepts1_grad&#39; type=dtype(&#39;float32&#39;) shape=(1, 10)
output: name=&#39;I4_coefficient2_grad&#39; type=dtype(&#39;float32&#39;) shape=(10, 1)
output: name=&#39;I5_intercepts2_grad&#39; type=dtype(&#39;float32&#39;) shape=(1, 1)

++++++ ./GradFBOptimizer.zero_onnx_.onnx

opset: domain=&#39;&#39; version=14
input: name=&#39;X&#39; type=dtype(&#39;float32&#39;) shape=()
init: name=&#39;Mu_Mulcst&#39; type=dtype(&#39;float32&#39;) shape=(1,) -- array([0.], dtype=float32)
Mul(X, Mu_Mulcst) -&gt; Y
output: name=&#39;Y&#39; type=dtype(&#39;float32&#39;) shape=()
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  23.585 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-gyexamples-plot-orttraining-nn-gpu-fwbw-nesterov-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/f74275a6a7748b69c1ad94eaf0a0bd19/plot_orttraining_nn_gpu_fwbw_nesterov.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_orttraining_nn_gpu_fwbw_nesterov.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/799fd9bcbadb995d0151c6a3449b685e/plot_orttraining_nn_gpu_fwbw_nesterov.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_orttraining_nn_gpu_fwbw_nesterov.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="plot_orttraining_nn_gpu_fwbw.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Forward backward on a neural network on GPU</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="plot_orttraining_benchmark_fwbw.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Benchmark, comparison scikit-learn - forward-backward</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>