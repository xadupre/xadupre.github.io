
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Background &#8212; onnxcustom</title>
    
    <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/thebelab-helper.js"></script>
    <script src="../../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../index.html">
  <img src="../../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../gyexamples/index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Background
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ultimate-goal-and-challenges">
   Ultimate Goal and Challenges
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standard-recurrent-network-constructs">
   Standard Recurrent Network Constructs
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generic-control-flow">
   Generic Control Flow
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#end-to-end-example-seq2seq-with-attention">
   End-to-end Example : seq2seq with attention
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-challenges">
   Further Challenges
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <!--- SPDX-License-Identifier: Apache-2.0 -->
<section id="background">
<h1>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h1>
<p>Modern NLP (Natural Language Processing) is an important domain in which deep learning is applied. In addition, modern NLP networks are often non-trivial to implement and even more difficult to transfer between frameworks. These networks are handled fairly non-uniformly across the landscape of frameworks. The ability for ONNX to interchange these networks can be a very compelling feature.</p>
<p>NLP networks, including recurrent networks, are often built on dynamic control structures. Standardizing the handling of these structures can lead to better collaboration with backends to expose network semantics and achieve better performance. A tradition has developed within the Computer Vision field for optimizing hardware backends for canonical vision models, such as ResNet-50. There is not really such as tradition in the NLP field, however. Through standardizing the representation of NLP networks, we can give vendors a common representation and push forward the performance of NLP models.</p>
</section>
<section id="ultimate-goal-and-challenges">
<h1>Ultimate Goal and Challenges<a class="headerlink" href="#ultimate-goal-and-challenges" title="Permalink to this headline">¶</a></h1>
<p>We should work toward being able to represent major classes of NLP model architectures. One example of such an architecture is the seq2seq with attention model (e.g. https://arxiv.org/abs/1409.0473). This architecture is used for many use cases, including neural machine translation, speech processing, summarization, dialog systems, image captioning, and syntax parsing, among many others. At the same time, seq2seq with attention is sufficiently complex that supporting it will push forward the state of the art in ONNX, but not so complex that we’d need to define a full programming language.</p>
<p>seq2seq with attention can roughly be broken down into these constituent parts:</p>
<ul class="simple">
<li><p>An Encoder network</p>
<ul>
<li><p>This network takes a sequence of tokens and yields a sequence of embeddings representing the context found at each time-step</p></li>
<li><p>Major classes of encoders: recurrent network (e.g. LSTM[1]), convolutional[2], attention[3].</p></li>
<li><p>Requirements from an ONNX representation</p>
<ul>
<li><p>Recurrent network - general recurrent network structures preserving outputs at every timestep. Handling of padding and hidden states for batches with different sequence lengths).</p></li>
<li><p>Convolutional - 1d convolution, position embeddings</p></li>
<li><p>Attention - sinusoid position encodings, layer normalization</p></li>
</ul>
</li>
</ul>
</li>
<li><p>A Decoder network</p>
<ul>
<li><p>This network generates a sequence token by token, parameterized by the context provided from the encoder.</p></li>
<li><p>Yields a probability distribution over possible tokens given previous context and encoder context.</p></li>
<li><p>Major classes of decoders: recurrent network (e.g. LSTM), convolutional (causal, temporal for generation), attention.</p></li>
<li><p>Generation requires dynamic control flow. Often, this is done as a beam search, so this is distinct from regular recurrent networks.</p></li>
<li><p>Model-specific requirements</p>
<ul>
<li><p>Recurrent network - Recurrent network cell that can be used within the context of beam search</p></li>
<li><p>Convolutional - 1d causal convolution (only see previous timesteps)</p></li>
<li><p>Attention - sinusoid position encodings, masking along diagonal</p></li>
</ul>
</li>
</ul>
</li>
<li><p>An Attention mechanism</p>
<ul>
<li><p>This network weights the Encoder contexts based on the Decoder’s generation state, and provides a focused Encoder context to the decoder. The Decoder “focuses” on a certain part of the input sequence at each timestep via this mechanism.</p></li>
<li><p>Many classes of attention mechanism: some examples are here https://arxiv.org/pdf/1508.04025.pdf</p></li>
</ul>
</li>
</ul>
<p>Vanilla seq2seq with attention and non-backtracking beam search does NOT include things such as auxiliary data-structures (e.g. stacks), thus it does not require us to implement the full semantics of a programming language. It is an architecture that we can break down into incremental improvements to ONNX without compromising ONNX’s fundamental goal.</p>
<p>[1] https://arxiv.org/abs/1409.0473
[2] https://arxiv.org/abs/1705.03122
[3] https://arxiv.org/abs/1706.03762</p>
</section>
<section id="standard-recurrent-network-constructs">
<h1>Standard Recurrent Network Constructs<a class="headerlink" href="#standard-recurrent-network-constructs" title="Permalink to this headline">¶</a></h1>
<p>Standard recurrent network architectures such as LSTM or GRU are very common, and we can get very far supporting these. We already have the <span class="xref myst">LSTM</span> and <span class="xref myst">GRU</span> operators, which execute the standard LSTM and GRU[4] operations over a sequence of inputs. These high-level operators are great, since they give backends a semantic view of the computation to be performed, and thus backends can make informed decisions about optimization. Many NLP use cases can get away with using just these operators.</p>
<p>[4] http://colah.github.io/posts/2015-08-Understanding-LSTMs/</p>
</section>
<section id="generic-control-flow">
<h1>Generic Control Flow<a class="headerlink" href="#generic-control-flow" title="Permalink to this headline">¶</a></h1>
<p>Once we move beyond the domain of standard LSTM and GRU operations, we need a more generic abstraction onto which we can map NLP architectures. A simple example is how one can implement Multiplicative Integration LSTM (https://arxiv.org/pdf/1606.06630.pdf) in ONNX. We can expose a standard LSTMCell via the proposed Function abstraction (https://github.com/onnx/onnx/issues/481). Building on top of this, we can construct a MI-LSTM by applying the required second-order transformations to the inputs to the LSTMCell. Once we have this aggregated implementation, we can use the generic control flow operators (https://github.com/onnx/onnx/pull/436) to apply this “composite” MI-LSTM cell over a sequence.</p>
<p>Of course, the dynamic control flow constructs can be used for more general use cases. For example, consider the <a class="reference external" href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> used often in NLP for sequence generation. This algorithm has several tricky aspects: a (potentially) dynamic stopping condition, a desired maximum trip count (so we don’t fall into an infinite loop), loop-carried dependencies, and the desire to preserve the outputs at every time-step, not just the final time-step. Inherently, this is an imperative algorithm that operates on mutable state. The proposed control flow operators in ONNX, however, fulfill all of these requirements, and thus we can represent many instances of sequence generation in ONNX graphs.</p>
<p>Note that there are more general forms of beam search, such as those including backtracking, but we are not considering these forms for this focused proposal.</p>
</section>
<section id="end-to-end-example-seq2seq-with-attention">
<h1>End-to-end Example : seq2seq with attention<a class="headerlink" href="#end-to-end-example-seq2seq-with-attention" title="Permalink to this headline">¶</a></h1>
<p>We should endeavor to have full support for seq2seq with attention models in ONNX. Facebook is currently working on this internally and creating a pytorch→ONNX→caffe2 pathway. An example of such a model we’d like to represent in ONNX is <a class="reference external" href="https://github.com/facebookresearch/fairseq-py">fairseq-py</a>. We would love to engage with the community and collaborate on anything that will help make this a reality. Additionally, if the community has any other suggestions for prominent NLP models we should be able to represent, we would love to hear your ideas.</p>
</section>
<section id="further-challenges">
<h1>Further Challenges<a class="headerlink" href="#further-challenges" title="Permalink to this headline">¶</a></h1>
<p>Beyond the constructs used in seq2seq with attention, there are NLP models that exist today that contain more non-trivial features, such as mutable data structures that are manipulated at runtime. Examples of this include back-tracking beam search and parser models such as RNNG (https://arxiv.org/abs/1602.07776). These will present further challenges for ONNX, and the representation of these models will likely remain tied to application code for the time being. We may want to revisit this class of models in the future.</p>
<p>Another thing we should consider is how to handle preprocessing and postprocessing routines for NLP models. For example, do we defer tokenization, normalization, and index lookup to application code? And how do we, for example, distribute dictionaries that map tokens to indices. Initially this will probably remain out of the scope of ONNX unless there is a good story for standardizing text processing.</p>
</section>
<section id="conclusion">
<h1>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h1>
<p>We have presented a proposal for a strategy for representing NLP models in ONNX, using seq2seq with attention as a canonical example that covers many use cases. We would like to hear your thoughts about this proposal and to explore opportunities for collaboration with the ONNX community for making ONNX a pleasure to use for NLP. Please feel free to voice your opinions!</p>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>