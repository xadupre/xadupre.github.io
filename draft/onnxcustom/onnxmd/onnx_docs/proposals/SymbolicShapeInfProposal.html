
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Proposal - Symbolic Shape Inference And Partial Data Propagation &#8212; onnxcustom</title>
    
    <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/thebelab-helper.js"></script>
    <script src="../../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../index.html">
  <img src="../../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../gyexamples/index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#current-onnx-shape-inference-limitations-pre-onnx-1-10">
   Current onnx shape inference limitations (Pre ONNX 1.10)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goals-and-non-goals">
   Goals and Non-Goals
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#non-goals">
     Non-goals
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terminology">
   Terminology
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#proposal">
   Proposal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extend-shape-inference">
   Extend shape inference
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#symbol-generation-and-propagation">
     Symbol generation and propagation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partial-data-computation-and-propagation">
     Partial data computation and propagation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#special-cases">
   Special Cases
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#broadcasting-with-symbolic-dims">
     Broadcasting with symbolic dims
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inferred-shape-does-not-match-output-shape">
     Inferred shape does not match output shape
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#handling-symbolic-dimensions-with-data-propagation">
     Handling symbolic dimensions with data propagation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#output-shape-is-dependent-on-input-data">
     Output shape is dependent on input data
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="proposal-symbolic-shape-inference-and-partial-data-propagation">
<h1>Proposal - Symbolic Shape Inference And Partial Data Propagation<a class="headerlink" href="#proposal-symbolic-shape-inference-and-partial-data-propagation" title="Permalink to this headline">¶</a></h1>
<p><em>Note: This proposal was accepted and implemented in ONNX 1.10. Following PRs implemented this proposal: 3518, 3551, 3593, 3580</em></p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>ONNX provides an implementation of shape inference on ONNX graphs. Shape inference is computed using the operator level shape inference functions. The inferred shape of an operator is used to get the shape information without having to launch the model in a session. Such static shape inference can be used to catch obvious errors before runtime, eliminate run-time checks which are otherwise guaranteed to pass, improve static memory planning and improve model visualization experience. For pytorch exporter and compiler-based execution providers like Nuphar, shape inference is required (rank inference is minimum requirement), and they cannot work with unknown shapes.</p>
<p>This document explains the limitations of shape inference and lays out a proposal for addressing these limitations.</p>
</section>
<section id="current-onnx-shape-inference-limitations-pre-onnx-1-10">
<h2>Current onnx shape inference limitations (Pre ONNX 1.10)<a class="headerlink" href="#current-onnx-shape-inference-limitations-pre-onnx-1-10" title="Permalink to this headline">¶</a></h2>
<p>Today, ONNX shape inference is not guaranteed to be complete. Wherever possible we fall back to rank inference however, there are scenarios when rank inference is not possible either. Here are the various limitations which block the completion of shape inference:</p>
<ol class="arabic simple">
<li><p>Some dynamic behaviors block the flow of shape inference, and the shape inference stops. For example, reshape to a dynamically computed shape.</p></li>
<li><p>Shape inference works only with constants and simple variables. It does not support arithmetic expressions containing variables nor does it support symbol generation. For example, concatenation on tensors of shapes (5, 2) and (7, 2) can be inferred to produce a result of shape (12, 2), but concatenation on tensors of shapes (5, 2) and (N, 2) will simply produce (?, 2), where “?” represents a dimension with neither dim value nor dim param, rather than containing a representation of N+5 or generating a new symbol (M, 2). In such scenarios shape propagation stops.</p></li>
<li><p>All operators are not required to have a shape inference implementation. When such an op is encountered the shape inference stops. There are also cases when rank inference is not done as a fallback mechanism. (Note: We are working on an ongoing basis to identify and fix such issues. The current document does not focus on this limitation)</p></li>
</ol>
</section>
<section id="goals-and-non-goals">
<h2>Goals and Non-Goals<a class="headerlink" href="#goals-and-non-goals" title="Permalink to this headline">¶</a></h2>
<p>Our <strong>goal</strong> is to fix the shape inference gap in scenarios where:</p>
<ul class="simple">
<li><p>Shape computations are done in branches (refer to limitation 1)</p></li>
<li><p>Symbolic dimensions are present (refer to limitation 2)</p></li>
</ul>
<p>By fixing these gaps we aim to:</p>
<ul class="simple">
<li><p>Unblock pytorch exporter from exporting models when exporting stops because of absence of shape information.</p></li>
<li><p>Improve static memory planning in the runtimes.</p></li>
<li><p>Enable pre-allocating output buffers outside of the runtimes so that its lifetime can be managed by the caller itself.</p></li>
</ul>
<section id="non-goals">
<h3>Non-goals<a class="headerlink" href="#non-goals" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Add symbolic expressions to ONNX standard: This is not necessary for accomplishing our goals. There are advantages to having this capability, for example this can significantly reduce the number of symbols introduced and it can also provide more deterministic shape calculations in certain special cases. However, the tradeoff is the added complexity. So, at this point we are not considering it. This can be considered in future iterations.</p></li>
<li><p>Enable data computation and propagation for older operator sets. (details in the proposal section)</p></li>
</ul>
<p>Note: This work will benefit Nuphar as well but right now there is no plan to move Nuphar to use this solution.</p>
</section>
</section>
<section id="terminology">
<h2>Terminology<a class="headerlink" href="#terminology" title="Permalink to this headline">¶</a></h2>
<p>Shape inference can be broken into 2 parts:</p>
<ul class="simple">
<li><p>Node level shape inference: This refers to operator specific shape inference functions. They are defined with the operator schema itself.</p></li>
<li><p>Graph-level shape inference: This refers to the higher-level logic which walks through the entire graph, gets the inferred shape from node level shape inference functions and then makes decisions on merging these inferred shapes with existing shapes so that they are available for downstream nodes.</p></li>
</ul>
</section>
<section id="proposal">
<h2>Proposal<a class="headerlink" href="#proposal" title="Permalink to this headline">¶</a></h2>
<p>Extend current shape inference to allow:</p>
<ul class="simple">
<li><p>Symbol generation and propagation</p></li>
<li><p>Partial data computation and propagation</p></li>
<li><p>Extend shape op to generate slice of the shape to facilitate simplifying shape computations.</p></li>
</ul>
</section>
<section id="extend-shape-inference">
<h2>Extend shape inference<a class="headerlink" href="#extend-shape-inference" title="Permalink to this headline">¶</a></h2>
<section id="symbol-generation-and-propagation">
<h3>Symbol generation and propagation<a class="headerlink" href="#symbol-generation-and-propagation" title="Permalink to this headline">¶</a></h3>
<p>Extend graph level shape inference to maintain a graph level view of symbols and generate new symbols where necessary. This will enable us to continue the shape inference of the downstream nodes.</p>
<p>Example:</p>
<p>For an op like “Concat” if its inputs have shapes “[M]” and “[N]” current shape-inference returns “[?]” where “?” is to indicate a dimension with neither dim-value nor dim-param set. Now, suppose the output X of “Concat” is input to a unary-op Op1() whose output Y is then input to another unary-op Op2() whose output is Z, etc. The shape “[?]” is propagated further. We infer that Y and Z have shape “[?]”. However, we do not infer that X, Y, and Z have the same shape because two “?” cannot be considered equal.</p>
<p>Per the current proposal, “[?]” in inferred shapes will be replaced by a new unique symbol by the graph level shape inference so the downstream nodes can use the symbolic shapes to carry out shape inference. In the current example, “Concat” will produce “[?]” as the shape which will then be replaced by “[K]”, then subsequent shape inference will infer that X, Y, and Z all have the same shape “[K]”. Runtimes can use this information to reuse memory for these tensors.</p>
</section>
<section id="partial-data-computation-and-propagation">
<h3>Partial data computation and propagation<a class="headerlink" href="#partial-data-computation-and-propagation" title="Permalink to this headline">¶</a></h3>
<p>When shape inputs are computed dynamically, shape inference post a reshape node stops. This can be prevented by making this data available to the reshape node during shape inference. We propose computation and propagation of data for operators which are used in shape computation.</p>
<p>It is called “partial” data computation and propagation because this will only be done for shape computations. It is not meant to be a full-fledged kernel for the operator. For the same reasons data computations will be implemented for a limited set of operators. While we will increase the coverage in the future iterations it is important to note that for some operators like LSTM, convolution ops, pooling ops etc. data propagation function will never be added because such ops are not used in shape computations.</p>
<p>The following operators will be picked in the first phase. (These operators are generally used for shape computations.)</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Ops</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Add</p></td>
</tr>
<tr class="row-odd"><td><p>Sub</p></td>
</tr>
<tr class="row-even"><td><p>Mul</p></td>
</tr>
<tr class="row-odd"><td><p>Cast</p></td>
</tr>
<tr class="row-even"><td><p>Concat</p></td>
</tr>
<tr class="row-odd"><td><p>Gather</p></td>
</tr>
<tr class="row-even"><td><p>Reshape</p></td>
</tr>
<tr class="row-odd"><td><p>Shape</p></td>
</tr>
<tr class="row-even"><td><p>Slice</p></td>
</tr>
<tr class="row-odd"><td><p>Size</p></td>
</tr>
<tr class="row-even"><td><p>Squeeze</p></td>
</tr>
<tr class="row-odd"><td><p>UnSqueeze</p></td>
</tr>
</tbody>
</table>
<p>The OpSchema class will be extended to include an optional “PartialDataPropagationFunction” like the existing TypeAndShapeInferenceFunction. This function will provide data computation for the operators which will then be propagated to the downstream operators by the graph level shape inference. PartialDataPropagationFunction will be called by the graph level shape inference after TypeAndShapeInference runs for the node because the output shape is required for partial data computation.</p>
<p>A new interface “DataPropagationContext” will be added to allow  PartialDataPropagationFunction to access all the information required to propagate shape data for the given node and allow writing of the computed data.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>using DataPropagationFunction = std::function&lt;void(DataPropagationContext&amp;)&gt;

class OpSchema final {

 public:
  .
  .
  .

  OpSchema&amp; PartialDataPropagationFunction(DataPropagationFunction dataPropagationFunction)  {
    partial_data_propagation_function_ = std::move(dataPropagationFunction);
    return *this;
  }

  DataPropagationFunction GetDataPropagationFunction() const {
    return partial_data_propagation_function_ ? partial_data_propagation_function_ : dummyDataPropogator;
  }
}

// Operator schema example
ONNX_OPERATOR_SET_SCHEMA(
    Shape,
    13,
    OpSchema()
        .SetDoc(“”)
        .Input(0, &quot;data&quot;, &quot;An input tensor.&quot;, &quot;T&quot;, . . .)
        .Output(0, &quot;shape&quot;, &quot;Shape of the input tensor&quot;, &quot;T1&quot;, . . .)
        .TypeConstraint(&quot;T&quot;, OpSchema::all_tensor_types())
        .TypeConstraint(&quot;T1&quot;, {&quot;tensor(int64)&quot;})
        .TypeAndShapeInferenceFunction([](InferenceContext&amp; ctx) {
        . . .
        })

        .PartialDataPropagationFunction([](DataPropagationContext&amp; ctx) {
          TensorShapeProto tp;
          // compute output data for shape operator
          // add computed data to DataPropagationContext for propagating it downstream
          ctx.addOutputData(0, std::move(tp));
        }));
</pre></div>
</div>
<p>The symbol generation will happen at the graph level shape inference, therefore all the models (older opsets as well as the latest opset versions) can benefit from this enhancement. However, the data computation and propagation are tied to the OpScehma and will happen at node level. To begin with these functions will only be added to the latest op schemas. Older schemas can be extended to support data computation later, on a case by case basis to support some high priority scenarios. What this means is that older opset models will not benefit from shape inference improvements because of this enhancement.</p>
</section>
</section>
<section id="special-cases">
<h2>Special Cases<a class="headerlink" href="#special-cases" title="Permalink to this headline">¶</a></h2>
<p>This section considers some edge cases and proposes a solution to handle them.</p>
<section id="broadcasting-with-symbolic-dims">
<h3>Broadcasting with symbolic dims<a class="headerlink" href="#broadcasting-with-symbolic-dims" title="Permalink to this headline">¶</a></h3>
<p>If we have a broadcast between two unknown dimensions “M” and “N” we cannot infer that both M and N should have the same value. The runtime semantics allows for one of the two symbols to have the value 1 and the other to have a value different from 1. So, merging M and N and treating them as the same value is potentially unsound. In this case, a new symbol will be generated for the output shape and the shape inference will continue.</p>
</section>
<section id="inferred-shape-does-not-match-output-shape">
<h3>Inferred shape does not match output shape<a class="headerlink" href="#inferred-shape-does-not-match-output-shape" title="Permalink to this headline">¶</a></h3>
<p>Inferred and existing shapes can be mismatched. Although failing shape inference in such cases seems like the correct approach it may not always be practical. By default, shape inference will fail when such a case is encountered however callers will have an option to override existing types with inferred types. When this option is enabled, shape inference will continue with the inferred type.</p>
</section>
<section id="handling-symbolic-dimensions-with-data-propagation">
<h3>Handling symbolic dimensions with data propagation<a class="headerlink" href="#handling-symbolic-dimensions-with-data-propagation" title="Permalink to this headline">¶</a></h3>
<p>When the shape contains symbolic dimensions, we try and propagate them downstream, however in cases where some arithmetic operations are performed on these symbolic dims we create new symbols and propagate them instead.</p>
</section>
<section id="output-shape-is-dependent-on-input-data">
<h3>Output shape is dependent on input data<a class="headerlink" href="#output-shape-is-dependent-on-input-data" title="Permalink to this headline">¶</a></h3>
<p>There are certain nodes like NonZero where the output shape depends on the input data. In this case it is not possible to infer the shape completely hence a new symbolic shape will be created using the inferred rank and shape inference will continue.</p>
</section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>