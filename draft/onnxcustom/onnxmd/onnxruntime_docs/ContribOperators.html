
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Contrib Operator Schemas &#8212; onnxcustom</title>
    
    <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../gyexamples/index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Roadmap.html">
   ONNX Runtime Roadmap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Privacy.html">
   Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Server.html">
   Build ONNX Runtime Server on Linux
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ONNX_Runtime_Server_Usage.html">
   How to Use build ONNX Runtime Server for Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FAQ.html">
   FAQ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="OperatorKernels.html">
   Supported Operators and Data Types
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Versioning.html">
   Versioning
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Coding_Conventions_and_Standards.html">
   ONNX Runtime coding conventions and standards
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ABI_Dev_Notes.html">
   Global Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PR_Guidelines.html">
   Guidelines for creating a good pull request
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Model_Test.html">
   Get the test data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NotesOnThreading.html">
   Notes on Threading in ORT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_Dev_Notes.html">
   Python Dev Notes
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="C_API_Guidelines.html">
   ORT API Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cmake_guideline.html">
   Scope the impact to minimal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="onnxruntime_extensions.html">
   ONNXRuntime Extensions
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Contrib Operator Schemas
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Android_testing.html">
   Testing Android Changes using the Emulator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ORTMobilePackageOperatorTypeSupport.html">
   ONNX Runtime Mobile Pre-Built Package Operator and Type Support
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="WinML_principles.html">
   Contributing to Windows ML
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Reduced_Operator_Kernel_build.html">
   ONNX Runtime Reduced Operator Kernel build
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ReleaseManagement.html">
   Release Management
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Contrib Operator Schemas
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#com-microsoft">
   com.microsoft
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-attention-a-a-name-com-microsoft-attention-com-microsoft-attention-a">
     <a name="com.microsoft.Attention">
     </a>
     <a name="com.microsoft.attention">
      <strong>
       com.microsoft.Attention
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#version">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#attributes">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-3-6">
       Inputs (3 - 6)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#outputs-1-2">
       Outputs (1 - 2)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#type-constraints">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-attnlstm-a-a-name-com-microsoft-attnlstm-com-microsoft-attnlstm-a">
     <a name="com.microsoft.AttnLSTM">
     </a>
     <a name="com.microsoft.attnlstm">
      <strong>
       com.microsoft.AttnLSTM
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-3-14">
       Inputs (3 - 14)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#outputs-0-3">
       Outputs (0 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-beamsearch-a-a-name-com-microsoft-beamsearch-com-microsoft-beamsearch-a">
     <a name="com.microsoft.BeamSearch">
     </a>
     <a name="com.microsoft.beamsearch">
      <strong>
       com.microsoft.BeamSearch
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-6-9">
       Inputs (6 - 9)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#outputs-1-3">
       Outputs (1 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-biasdropout-a-a-name-com-microsoft-biasdropout-com-microsoft-biasdropout-a">
     <a name="com.microsoft.BiasDropout">
     </a>
     <a name="com.microsoft.biasdropout">
      <strong>
       com.microsoft.BiasDropout
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-2-5">
       Inputs (2 - 5)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       Outputs (1 - 2)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-biasgelu-a-a-name-com-microsoft-biasgelu-com-microsoft-biasgelu-a">
     <a name="com.microsoft.BiasGelu">
     </a>
     <a name="com.microsoft.biasgelu">
      <strong>
       com.microsoft.BiasGelu
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#outputs">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id12">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-biassoftmax-a-a-name-com-microsoft-biassoftmax-com-microsoft-biassoftmax-a">
     <a name="com.microsoft.BiasSoftmax">
     </a>
     <a name="com.microsoft.biassoftmax">
      <strong>
       com.microsoft.BiasSoftmax
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id13">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id14">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id15">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id16">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id17">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-bifurcationdetector-a-a-name-com-microsoft-bifurcationdetector-com-microsoft-bifurcationdetector-a">
     <a name="com.microsoft.BifurcationDetector">
     </a>
     <a name="com.microsoft.bifurcationdetector">
      <strong>
       com.microsoft.BifurcationDetector
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id18">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id19">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-3-4">
       Inputs (3 - 4)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id20">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id21">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-cdist-a-a-name-com-microsoft-cdist-com-microsoft-cdist-a">
     <a name="com.microsoft.CDist">
     </a>
     <a name="com.microsoft.cdist">
      <strong>
       com.microsoft.CDist
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id22">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id23">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id24">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id25">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id26">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-complexmul-a-a-name-com-microsoft-complexmul-com-microsoft-complexmul-a">
     <a name="com.microsoft.ComplexMul">
     </a>
     <a name="com.microsoft.complexmul">
      <strong>
       com.microsoft.ComplexMul
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id27">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id28">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id29">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id30">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-complexmulconj-a-a-name-com-microsoft-complexmulconj-com-microsoft-complexmulconj-a">
     <a name="com.microsoft.ComplexMulConj">
     </a>
     <a name="com.microsoft.complexmulconj">
      <strong>
       com.microsoft.ComplexMulConj
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id31">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id32">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id33">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id34">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-convtransposewithdynamicpads-a-a-name-com-microsoft-convtransposewithdynamicpads-com-microsoft-convtransposewithdynamicpads-a">
     <a name="com.microsoft.ConvTransposeWithDynamicPads">
     </a>
     <a name="com.microsoft.convtransposewithdynamicpads">
      <strong>
       com.microsoft.ConvTransposeWithDynamicPads
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id35">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id36">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-2-4">
       Inputs (2 - 4)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id37">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id38">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-cropandresize-a-a-name-com-microsoft-cropandresize-com-microsoft-cropandresize-a">
     <a name="com.microsoft.CropAndResize">
     </a>
     <a name="com.microsoft.cropandresize">
      <strong>
       com.microsoft.CropAndResize
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id39">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id40">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id41">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id42">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id43">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-decoderattention-a-a-name-com-microsoft-decoderattention-com-microsoft-decoderattention-a">
     <a name="com.microsoft.DecoderAttention">
     </a>
     <a name="com.microsoft.decoderattention">
      <strong>
       com.microsoft.DecoderAttention
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id44">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id45">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id46">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id47">
       Outputs (1 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id48">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-dequantizelinear-a-a-name-com-microsoft-dequantizelinear-com-microsoft-dequantizelinear-a">
     <a name="com.microsoft.DequantizeLinear">
     </a>
     <a name="com.microsoft.dequantizelinear">
      <strong>
       com.microsoft.DequantizeLinear
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id49">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id50">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id51">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id52">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id53">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-dynamicquantizelstm-a-a-name-com-microsoft-dynamicquantizelstm-com-microsoft-dynamicquantizelstm-a">
     <a name="com.microsoft.DynamicQuantizeLSTM">
     </a>
     <a name="com.microsoft.dynamicquantizelstm">
      <strong>
       com.microsoft.DynamicQuantizeLSTM
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id54">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id55">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id56">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id57">
       Outputs (0 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id58">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-dynamicquantizematmul-a-a-name-com-microsoft-dynamicquantizematmul-com-microsoft-dynamicquantizematmul-a">
     <a name="com.microsoft.DynamicQuantizeMatMul">
     </a>
     <a name="com.microsoft.dynamicquantizematmul">
      <strong>
       com.microsoft.DynamicQuantizeMatMul
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id59">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-3-5">
       Inputs (3 - 5)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id60">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id61">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-embedlayernormalization-a-a-name-com-microsoft-embedlayernormalization-com-microsoft-embedlayernormalization-a">
     <a name="com.microsoft.EmbedLayerNormalization">
     </a>
     <a name="com.microsoft.embedlayernormalization">
      <strong>
       com.microsoft.EmbedLayerNormalization
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id62">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id63">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-7-9">
       Inputs (7 - 9)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#outputs-2-3">
       Outputs (2 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id64">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-expanddims-a-a-name-com-microsoft-expanddims-com-microsoft-expanddims-a">
     <a name="com.microsoft.ExpandDims">
     </a>
     <a name="com.microsoft.expanddims">
      <strong>
       com.microsoft.ExpandDims
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id65">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id66">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id67">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id68">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-fastgelu-a-a-name-com-microsoft-fastgelu-com-microsoft-fastgelu-a">
     <a name="com.microsoft.FastGelu">
     </a>
     <a name="com.microsoft.fastgelu">
      <strong>
       com.microsoft.FastGelu
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id69">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-1-2">
       Inputs (1 - 2)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id70">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id71">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-fusedconv-a-a-name-com-microsoft-fusedconv-com-microsoft-fusedconv-a">
     <a name="com.microsoft.FusedConv">
     </a>
     <a name="com.microsoft.fusedconv">
      <strong>
       com.microsoft.FusedConv
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id72">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id73">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id74">
       Inputs (2 - 4)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id75">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id76">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-fusedgemm-a-a-name-com-microsoft-fusedgemm-com-microsoft-fusedgemm-a">
     <a name="com.microsoft.FusedGemm">
     </a>
     <a name="com.microsoft.fusedgemm">
      <strong>
       com.microsoft.FusedGemm
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id77">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id78">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id79">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id80">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id81">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-fusedmatmul-a-a-name-com-microsoft-fusedmatmul-com-microsoft-fusedmatmul-a">
     <a name="com.microsoft.FusedMatMul">
     </a>
     <a name="com.microsoft.fusedmatmul">
      <strong>
       com.microsoft.FusedMatMul
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id82">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id83">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id84">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id85">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id86">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-gathernd-a-a-name-com-microsoft-gathernd-com-microsoft-gathernd-a">
     <a name="com.microsoft.GatherND">
     </a>
     <a name="com.microsoft.gathernd">
      <strong>
       com.microsoft.GatherND
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id87">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id88">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id89">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id90">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-gelu-a-a-name-com-microsoft-gelu-com-microsoft-gelu-a">
     <a name="com.microsoft.Gelu">
     </a>
     <a name="com.microsoft.gelu">
      <strong>
       com.microsoft.Gelu
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id91">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id92">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id93">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id94">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-gridsample-a-a-name-com-microsoft-gridsample-com-microsoft-gridsample-a">
     <a name="com.microsoft.GridSample">
     </a>
     <a name="com.microsoft.gridsample">
      <strong>
       com.microsoft.GridSample
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id95">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id96">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id97">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id98">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id99">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-inverse-a-a-name-com-microsoft-inverse-com-microsoft-inverse-a">
     <a name="com.microsoft.Inverse">
     </a>
     <a name="com.microsoft.inverse">
      <strong>
       com.microsoft.Inverse
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id100">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id101">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id102">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id103">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-irfft-a-a-name-com-microsoft-irfft-com-microsoft-irfft-a">
     <a name="com.microsoft.Irfft">
     </a>
     <a name="com.microsoft.irfft">
      <strong>
       com.microsoft.Irfft
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id104">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id105">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id106">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id107">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id108">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-longformerattention-a-a-name-com-microsoft-longformerattention-com-microsoft-longformerattention-a">
     <a name="com.microsoft.LongformerAttention">
     </a>
     <a name="com.microsoft.longformerattention">
      <strong>
       com.microsoft.LongformerAttention
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id109">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id110">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id111">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id112">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id113">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-matmulinteger16-a-a-name-com-microsoft-matmulinteger16-com-microsoft-matmulinteger16-a">
     <a name="com.microsoft.MatMulInteger16">
     </a>
     <a name="com.microsoft.matmulinteger16">
      <strong>
       com.microsoft.MatMulInteger16
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id114">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id115">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id116">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id117">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-matmulintegertofloat-a-a-name-com-microsoft-matmulintegertofloat-com-microsoft-matmulintegertofloat-a">
     <a name="com.microsoft.MatMulIntegerToFloat">
     </a>
     <a name="com.microsoft.matmulintegertofloat">
      <strong>
       com.microsoft.MatMulIntegerToFloat
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id118">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-4-7">
       Inputs (4 - 7)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id119">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id120">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-maxpoolwithmask-a-a-name-com-microsoft-maxpoolwithmask-com-microsoft-maxpoolwithmask-a">
     <a name="com.microsoft.MaxpoolWithMask">
     </a>
     <a name="com.microsoft.maxpoolwithmask">
      <strong>
       com.microsoft.MaxpoolWithMask
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id121">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id122">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id123">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id124">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id125">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-mulinteger-a-a-name-com-microsoft-mulinteger-com-microsoft-mulinteger-a">
     <a name="com.microsoft.MulInteger">
     </a>
     <a name="com.microsoft.mulinteger">
      <strong>
       com.microsoft.MulInteger
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id126">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id127">
       Inputs (3 - 4)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id128">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id129">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-murmurhash3-a-a-name-com-microsoft-murmurhash3-com-microsoft-murmurhash3-a">
     <a name="com.microsoft.MurmurHash3">
     </a>
     <a name="com.microsoft.murmurhash3">
      <strong>
       com.microsoft.MurmurHash3
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id130">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id131">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id132">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id133">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id134">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-ngramrepeatblock-a-a-name-com-microsoft-ngramrepeatblock-com-microsoft-ngramrepeatblock-a">
     <a name="com.microsoft.NGramRepeatBlock">
     </a>
     <a name="com.microsoft.ngramrepeatblock">
      <strong>
       com.microsoft.NGramRepeatBlock
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id135">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id136">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id137">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id138">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id139">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-nhwcmaxpool-a-a-name-com-microsoft-nhwcmaxpool-com-microsoft-nhwcmaxpool-a">
     <a name="com.microsoft.NhwcMaxPool">
     </a>
     <a name="com.microsoft.nhwcmaxpool">
      <strong>
       com.microsoft.NhwcMaxPool
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id140">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id141">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id142">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id143">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id144">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-pad-a-a-name-com-microsoft-pad-com-microsoft-pad-a">
     <a name="com.microsoft.Pad">
     </a>
     <a name="com.microsoft.pad">
      <strong>
       com.microsoft.Pad
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id145">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id146">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-2-3">
       Inputs (2 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id147">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id148">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qattention-a-a-name-com-microsoft-qattention-com-microsoft-qattention-a">
     <a name="com.microsoft.QAttention">
     </a>
     <a name="com.microsoft.qattention">
      <strong>
       com.microsoft.QAttention
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id149">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id150">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-5-9">
       Inputs (5 - 9)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id151">
       Outputs (1 - 2)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id152">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qgemm-a-a-name-com-microsoft-qgemm-com-microsoft-qgemm-a">
     <a name="com.microsoft.QGemm">
     </a>
     <a name="com.microsoft.qgemm">
      <strong>
       com.microsoft.QGemm
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id153">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id154">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id155">
       Inputs (6 - 9)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id156">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id157">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearadd-a-a-name-com-microsoft-qlinearadd-com-microsoft-qlinearadd-a">
     <a name="com.microsoft.QLinearAdd">
     </a>
     <a name="com.microsoft.qlinearadd">
      <strong>
       com.microsoft.QLinearAdd
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id158">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-7-8">
       Inputs (7 - 8)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id159">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id160">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearaveragepool-a-a-name-com-microsoft-qlinearaveragepool-com-microsoft-qlinearaveragepool-a">
     <a name="com.microsoft.QLinearAveragePool">
     </a>
     <a name="com.microsoft.qlinearaveragepool">
      <strong>
       com.microsoft.QLinearAveragePool
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id161">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id162">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-4-5">
       Inputs (4 - 5)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id163">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id164">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearconcat-a-a-name-com-microsoft-qlinearconcat-com-microsoft-qlinearconcat-a">
     <a name="com.microsoft.QLinearConcat">
     </a>
     <a name="com.microsoft.qlinearconcat">
      <strong>
       com.microsoft.QLinearConcat
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id165">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id166">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-3">
       Inputs (3 - )
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id167">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id168">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearconv-a-a-name-com-microsoft-qlinearconv-com-microsoft-qlinearconv-a">
     <a name="com.microsoft.QLinearConv">
     </a>
     <a name="com.microsoft.qlinearconv">
      <strong>
       com.microsoft.QLinearConv
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id169">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id170">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-8-9">
       Inputs (8 - 9)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id171">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id172">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearglobalaveragepool-a-a-name-com-microsoft-qlinearglobalaveragepool-com-microsoft-qlinearglobalaveragepool-a">
     <a name="com.microsoft.QLinearGlobalAveragePool">
     </a>
     <a name="com.microsoft.qlinearglobalaveragepool">
      <strong>
       com.microsoft.QLinearGlobalAveragePool
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id173">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id174">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id175">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id176">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id177">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearleakyrelu-a-a-name-com-microsoft-qlinearleakyrelu-com-microsoft-qlinearleakyrelu-a">
     <a name="com.microsoft.QLinearLeakyRelu">
     </a>
     <a name="com.microsoft.qlinearleakyrelu">
      <strong>
       com.microsoft.QLinearLeakyRelu
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id178">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id179">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id180">
       Inputs (4 - 5)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id181">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id182">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearmul-a-a-name-com-microsoft-qlinearmul-com-microsoft-qlinearmul-a">
     <a name="com.microsoft.QLinearMul">
     </a>
     <a name="com.microsoft.qlinearmul">
      <strong>
       com.microsoft.QLinearMul
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id183">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id184">
       Inputs (7 - 8)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id185">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id186">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearreducemean-a-a-name-com-microsoft-qlinearreducemean-com-microsoft-qlinearreducemean-a">
     <a name="com.microsoft.QLinearReduceMean">
     </a>
     <a name="com.microsoft.qlinearreducemean">
      <strong>
       com.microsoft.QLinearReduceMean
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id187">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id188">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id189">
       Inputs (4 - 5)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id190">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id191">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-qlinearsigmoid-a-a-name-com-microsoft-qlinearsigmoid-com-microsoft-qlinearsigmoid-a">
     <a name="com.microsoft.QLinearSigmoid">
     </a>
     <a name="com.microsoft.qlinearsigmoid">
      <strong>
       com.microsoft.QLinearSigmoid
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id192">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id193">
       Inputs (4 - 5)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id194">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id195">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-quantizelinear-a-a-name-com-microsoft-quantizelinear-com-microsoft-quantizelinear-a">
     <a name="com.microsoft.QuantizeLinear">
     </a>
     <a name="com.microsoft.quantizelinear">
      <strong>
       com.microsoft.QuantizeLinear
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id196">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id197">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id198">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id199">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id200">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-range-a-a-name-com-microsoft-range-com-microsoft-range-a">
     <a name="com.microsoft.Range">
     </a>
     <a name="com.microsoft.range">
      <strong>
       com.microsoft.Range
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id201">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id202">
       Inputs (2 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id203">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id204">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-reducesuminteger-a-a-name-com-microsoft-reducesuminteger-com-microsoft-reducesuminteger-a">
     <a name="com.microsoft.ReduceSumInteger">
     </a>
     <a name="com.microsoft.reducesuminteger">
      <strong>
       com.microsoft.ReduceSumInteger
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id205">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id206">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id207">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id208">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id209">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-rfft-a-a-name-com-microsoft-rfft-com-microsoft-rfft-a">
     <a name="com.microsoft.Rfft">
     </a>
     <a name="com.microsoft.rfft">
      <strong>
       com.microsoft.Rfft
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id210">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id211">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id212">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id213">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id214">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-sampleop-a-a-name-com-microsoft-sampleop-com-microsoft-sampleop-a">
     <a name="com.microsoft.SampleOp">
     </a>
     <a name="com.microsoft.sampleop">
      <strong>
       com.microsoft.SampleOp
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id215">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id216">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id217">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id218">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-skiplayernormalization-a-a-name-com-microsoft-skiplayernormalization-com-microsoft-skiplayernormalization-a">
     <a name="com.microsoft.SkipLayerNormalization">
     </a>
     <a name="com.microsoft.skiplayernormalization">
      <strong>
       com.microsoft.SkipLayerNormalization
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id219">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id220">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id221">
       Inputs (3 - 5)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id222">
       Outputs (1 - 3)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id223">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-sparsetodensematmul-a-a-name-com-microsoft-sparsetodensematmul-com-microsoft-sparsetodensematmul-a">
     <a name="com.microsoft.SparseToDenseMatMul">
     </a>
     <a name="com.microsoft.sparsetodensematmul">
      <strong>
       com.microsoft.SparseToDenseMatMul
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id224">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id225">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id226">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id227">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id228">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-tokenizer-a-a-name-com-microsoft-tokenizer-com-microsoft-tokenizer-a">
     <a name="com.microsoft.Tokenizer">
     </a>
     <a name="com.microsoft.tokenizer">
      <strong>
       com.microsoft.Tokenizer
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id229">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id230">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id231">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id232">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id233">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-torchembedding-a-a-name-com-microsoft-torchembedding-com-microsoft-torchembedding-a">
     <a name="com.microsoft.TorchEmbedding">
     </a>
     <a name="com.microsoft.torchembedding">
      <strong>
       com.microsoft.TorchEmbedding
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id234">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id235">
       Inputs (2 - 4)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id236">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id237">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-transposematmul-a-a-name-com-microsoft-transposematmul-com-microsoft-transposematmul-a">
     <a name="com.microsoft.TransposeMatMul">
     </a>
     <a name="com.microsoft.transposematmul">
      <strong>
       com.microsoft.TransposeMatMul
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id238">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id239">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id240">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id241">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id242">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-trilu-a-a-name-com-microsoft-trilu-com-microsoft-trilu-a">
     <a name="com.microsoft.Trilu">
     </a>
     <a name="com.microsoft.trilu">
      <strong>
       com.microsoft.Trilu
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id243">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id244">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id245">
       Inputs (1 - 2)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id246">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id247">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-unique-a-a-name-com-microsoft-unique-com-microsoft-unique-a">
     <a name="com.microsoft.Unique">
     </a>
     <a name="com.microsoft.unique">
      <strong>
       com.microsoft.Unique
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id248">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id249">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id250">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id251">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-name-com-microsoft-wordconvembedding-a-a-name-com-microsoft-wordconvembedding-com-microsoft-wordconvembedding-a">
     <a name="com.microsoft.WordConvEmbedding">
     </a>
     <a name="com.microsoft.wordconvembedding">
      <strong>
       com.microsoft.WordConvEmbedding
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id252">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id253">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id254">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id255">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id256">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sub-experimental-sub-a-name-com-microsoft-isallfinite-a-a-name-com-microsoft-isallfinite-com-microsoft-isallfinite-a">
     <sub>
      experimental
     </sub>
     <a name="com.microsoft.IsAllFinite">
     </a>
     <a name="com.microsoft.isallfinite">
      <strong>
       com.microsoft.IsAllFinite
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id257">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id258">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inputs-1">
       Inputs (1 - )
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id259">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id260">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sub-experimental-sub-a-name-com-microsoft-qembedlayernormalization-a-a-name-com-microsoft-qembedlayernormalization-com-microsoft-qembedlayernormalization-a">
     <sub>
      experimental
     </sub>
     <a name="com.microsoft.QEmbedLayerNormalization">
     </a>
     <a name="com.microsoft.qembedlayernormalization">
      <strong>
       com.microsoft.QEmbedLayerNormalization
      </strong>
     </a>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id261">
       Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id262">
       Attributes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id263">
       Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id264">
       Outputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id265">
       Type Constraints
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="contrib-operator-schemas">
<h1>Contrib Operator Schemas<a class="headerlink" href="#contrib-operator-schemas" title="Permalink to this headline"></a></h1>
<p><em>This file is automatically generated from the registered contrib operator schemas by <a class="reference external" href="https://github.com/microsoft/onnxruntime/blob/master/tools/python/gen_contrib_doc.py">this script</a>.
Do not modify directly.</em></p>
<ul class="simple">
<li><p>com.microsoft</p>
<ul>
<li><p><a href="#com.microsoft.Attention">com.microsoft.Attention</a></p></li>
<li><p><a href="#com.microsoft.AttnLSTM">com.microsoft.AttnLSTM</a></p></li>
<li><p><a href="#com.microsoft.BeamSearch">com.microsoft.BeamSearch</a></p></li>
<li><p><a href="#com.microsoft.BiasDropout">com.microsoft.BiasDropout</a></p></li>
<li><p><a href="#com.microsoft.BiasGelu">com.microsoft.BiasGelu</a></p></li>
<li><p><a href="#com.microsoft.BiasSoftmax">com.microsoft.BiasSoftmax</a></p></li>
<li><p><a href="#com.microsoft.BifurcationDetector">com.microsoft.BifurcationDetector</a></p></li>
<li><p><a href="#com.microsoft.CDist">com.microsoft.CDist</a></p></li>
<li><p><a href="#com.microsoft.ComplexMul">com.microsoft.ComplexMul</a></p></li>
<li><p><a href="#com.microsoft.ComplexMulConj">com.microsoft.ComplexMulConj</a></p></li>
<li><p><a href="#com.microsoft.ConvTransposeWithDynamicPads">com.microsoft.ConvTransposeWithDynamicPads</a></p></li>
<li><p><a href="#com.microsoft.CropAndResize">com.microsoft.CropAndResize</a></p></li>
<li><p><a href="#com.microsoft.DecoderAttention">com.microsoft.DecoderAttention</a></p></li>
<li><p><a href="#com.microsoft.DequantizeLinear">com.microsoft.DequantizeLinear</a></p></li>
<li><p><a href="#com.microsoft.DynamicQuantizeLSTM">com.microsoft.DynamicQuantizeLSTM</a></p></li>
<li><p><a href="#com.microsoft.DynamicQuantizeMatMul">com.microsoft.DynamicQuantizeMatMul</a></p></li>
<li><p><a href="#com.microsoft.EmbedLayerNormalization">com.microsoft.EmbedLayerNormalization</a></p></li>
<li><p><a href="#com.microsoft.ExpandDims">com.microsoft.ExpandDims</a></p></li>
<li><p><a href="#com.microsoft.FastGelu">com.microsoft.FastGelu</a></p></li>
<li><p><a href="#com.microsoft.FusedConv">com.microsoft.FusedConv</a></p></li>
<li><p><a href="#com.microsoft.FusedGemm">com.microsoft.FusedGemm</a></p></li>
<li><p><a href="#com.microsoft.FusedMatMul">com.microsoft.FusedMatMul</a></p></li>
<li><p><a href="#com.microsoft.GatherND">com.microsoft.GatherND</a></p></li>
<li><p><a href="#com.microsoft.Gelu">com.microsoft.Gelu</a></p></li>
<li><p><a href="#com.microsoft.GridSample">com.microsoft.GridSample</a></p></li>
<li><p><a href="#com.microsoft.Inverse">com.microsoft.Inverse</a></p></li>
<li><p><a href="#com.microsoft.Irfft">com.microsoft.Irfft</a></p></li>
<li><p><a href="#com.microsoft.LongformerAttention">com.microsoft.LongformerAttention</a></p></li>
<li><p><a href="#com.microsoft.MatMulInteger16">com.microsoft.MatMulInteger16</a></p></li>
<li><p><a href="#com.microsoft.MatMulIntegerToFloat">com.microsoft.MatMulIntegerToFloat</a></p></li>
<li><p><a href="#com.microsoft.MaxpoolWithMask">com.microsoft.MaxpoolWithMask</a></p></li>
<li><p><a href="#com.microsoft.MulInteger">com.microsoft.MulInteger</a></p></li>
<li><p><a href="#com.microsoft.MurmurHash3">com.microsoft.MurmurHash3</a></p></li>
<li><p><a href="#com.microsoft.NGramRepeatBlock">com.microsoft.NGramRepeatBlock</a></p></li>
<li><p><a href="#com.microsoft.NhwcMaxPool">com.microsoft.NhwcMaxPool</a></p></li>
<li><p><a href="#com.microsoft.Pad">com.microsoft.Pad</a></p></li>
<li><p><a href="#com.microsoft.QAttention">com.microsoft.QAttention</a></p></li>
<li><p><a href="#com.microsoft.QGemm">com.microsoft.QGemm</a></p></li>
<li><p><a href="#com.microsoft.QLinearAdd">com.microsoft.QLinearAdd</a></p></li>
<li><p><a href="#com.microsoft.QLinearAveragePool">com.microsoft.QLinearAveragePool</a></p></li>
<li><p><a href="#com.microsoft.QLinearConcat">com.microsoft.QLinearConcat</a></p></li>
<li><p><a href="#com.microsoft.QLinearConv">com.microsoft.QLinearConv</a></p></li>
<li><p><a href="#com.microsoft.QLinearGlobalAveragePool">com.microsoft.QLinearGlobalAveragePool</a></p></li>
<li><p><a href="#com.microsoft.QLinearLeakyRelu">com.microsoft.QLinearLeakyRelu</a></p></li>
<li><p><a href="#com.microsoft.QLinearMul">com.microsoft.QLinearMul</a></p></li>
<li><p><a href="#com.microsoft.QLinearReduceMean">com.microsoft.QLinearReduceMean</a></p></li>
<li><p><a href="#com.microsoft.QLinearSigmoid">com.microsoft.QLinearSigmoid</a></p></li>
<li><p><a href="#com.microsoft.QuantizeLinear">com.microsoft.QuantizeLinear</a></p></li>
<li><p><a href="#com.microsoft.Range">com.microsoft.Range</a></p></li>
<li><p><a href="#com.microsoft.ReduceSumInteger">com.microsoft.ReduceSumInteger</a></p></li>
<li><p><a href="#com.microsoft.Rfft">com.microsoft.Rfft</a></p></li>
<li><p><a href="#com.microsoft.SampleOp">com.microsoft.SampleOp</a></p></li>
<li><p><a href="#com.microsoft.SkipLayerNormalization">com.microsoft.SkipLayerNormalization</a></p></li>
<li><p><a href="#com.microsoft.SparseToDenseMatMul">com.microsoft.SparseToDenseMatMul</a></p></li>
<li><p><a href="#com.microsoft.Tokenizer">com.microsoft.Tokenizer</a></p></li>
<li><p><a href="#com.microsoft.TorchEmbedding">com.microsoft.TorchEmbedding</a></p></li>
<li><p><a href="#com.microsoft.TransposeMatMul">com.microsoft.TransposeMatMul</a></p></li>
<li><p><a href="#com.microsoft.Trilu">com.microsoft.Trilu</a></p></li>
<li><p><a href="#com.microsoft.Unique">com.microsoft.Unique</a></p></li>
<li><p><a href="#com.microsoft.WordConvEmbedding">com.microsoft.WordConvEmbedding</a></p></li>
<li><p><sub>experimental</sub> <a href="#com.microsoft.IsAllFinite">com.microsoft.IsAllFinite</a></p></li>
<li><p><sub>experimental</sub> <a href="#com.microsoft.QEmbedLayerNormalization">com.microsoft.QEmbedLayerNormalization</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="com-microsoft">
<h1>com.microsoft<a class="headerlink" href="#com-microsoft" title="Permalink to this headline"></a></h1>
<section id="a-name-com-microsoft-attention-a-a-name-com-microsoft-attention-com-microsoft-attention-a">
<h2><a name="com.microsoft.Attention"></a><a name="com.microsoft.attention"><strong>com.microsoft.Attention</strong></a><a class="headerlink" href="#a-name-com-microsoft-attention-a-a-name-com-microsoft-attention-com-microsoft-attention-a" title="Permalink to this headline"></a></h2>
<p>Multi-Head Self Attention that can be either unidirectional (like GPT-2) or bidirectional (like BERT).
The mask_index input is optional. Besides raw attention mask with shape (batch_size, past_sequence_length + sequence_length)
or (batch_size, sequence_length, past_sequence_length + sequence_length) with value 0 for masked and 1 otherwise,
we also support other two formats: When input has right-side padding, mask_index is one dimension with shape (batch_size),
where value of each element is the end position, or valid length of actual sequence excluding padding. When input has
left-side padding, mask_index has shape (2 * batch_size), where the values are the exclusive end positions followed by
the inclusive start positions. When unidirectional is 1, and each token only attend to previous tokens. For GPT-2, both past
and present state are optional. Present state could appear in output even when past state is not in input.</p>
<section id="version">
<h3>Version<a class="headerlink" href="#version" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="attributes">
<h3>Attributes<a class="headerlink" href="#attributes" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>qkv_hidden_sizes</tt> : list of ints</dt>
<dd>Hidden layer sizes of Q, K, V paths in Attention</dd>
<dt><tt>unidirectional</tt> : int</dt>
<dd>Whether every token can only attend to previous tokens. Default value is 0.</dd>
</dl>
</section>
<section id="inputs-3-6">
<h3>Inputs (3 - 6)<a class="headerlink" href="#inputs-3-6" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input</tt> : T</dt>
<dd>3D input tensor with shape (batch_size, sequence_length, input_hidden_size)</dd>
<dt><tt>weight</tt> : T</dt>
<dd>2D input tensor with shape (input_hidden_size, 3 * hidden_size), where hidden_size = num_heads * head_size</dd>
<dt><tt>bias</tt> : T</dt>
<dd>1D input tensor with shape (3 * hidden_size)</dd>
<dt><tt>mask_index</tt> (optional) : M</dt>
<dd>Attention mask with shape (batch_size, 1, max_sequence_length, max_sequence_length), (batch_size, past_sequence_length + sequence_length)or (batch_size, sequence_length, past_sequence_length + sequence_length), or index with shape (batch_size) or (2 * batch_size).</dd>
<dt><tt>past</tt> (optional) : T</dt>
<dd>past state for key and value with shape (2, batch_size, num_heads, past_sequence_length, head_size).</dd>
<dt><tt>extra_add</tt> (optional) : T</dt>
<dd>additional add to QxK' with shape (batch_size, num_heads, sequence_length, sequence_length).</dd>
</dl>
</section>
<section id="outputs-1-2">
<h3>Outputs (1 - 2)<a class="headerlink" href="#outputs-1-2" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>3D output tensor with shape (batch_size, sequence_length, hidden_size)</dd>
<dt><tt>present</tt> (optional) : T</dt>
<dd>present state for key and value with shape (2, batch_size, num_heads, past_sequence_length + sequence_length, head_size)</dd>
</dl>
</section>
<section id="type-constraints">
<h3>Type Constraints<a class="headerlink" href="#type-constraints" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-attnlstm-a-a-name-com-microsoft-attnlstm-com-microsoft-attnlstm-a">
<h2><a name="com.microsoft.AttnLSTM"></a><a name="com.microsoft.attnlstm"><strong>com.microsoft.AttnLSTM</strong></a><a class="headerlink" href="#a-name-com-microsoft-attnlstm-a-a-name-com-microsoft-attnlstm-com-microsoft-attnlstm-a" title="Permalink to this headline"></a></h2>
<p>Computes an one-layer RNN where its RNN Cell is an AttentionWrapper wrapped a LSTM Cell. The RNN layer
contains following basic component: LSTM Cell, Bahdanau Attention Mechanism, AttentionWrapp.</p>
<p>Activation functions:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Relu(x)                - max(0, x)

Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})

Sigmoid(x)             - 1/(1 + e^{-x})

(NOTE: Below are optional)

Affine(x)              - alpha*x + beta

LeakyRelu(x)           - x if x &gt;= 0 else alpha * x

ThresholdedRelu(x)     - x if x &gt;= alpha else 0

ScaledTanh(x)          - alpha*Tanh(beta*x)

HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)

Elu(x)                 - x if x &gt;= 0 else alpha*(e^x - 1)

Softsign(x)            - x/(1 + |x|)

Softplus(x)            - log(1 + e^x)

Softmax(x)             - exp(x) / sum(exp(x))
</pre></div>
</div>
<p>Bahdanau Attention Mechanism:
<code class="docutils literal notranslate"><span class="pre">M</span></code> -  Memory tensor.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  `VALUES` - masked Memory by its real sequence length.

  `MW` - Memory layer weight.

  `KEYS` - Processed memory tensor by the memory layer.
           KEYS = M * MW

  `Query` - Query tensor, normally at specific time step in sequence.

  `QW` - Query layer weight in the attention mechanism

  `PQ` - processed query,  = `Query` * `QW`

  `V&#39; - attention vector

  `ALIGN` - calculated alignment based on Query and KEYS
      ALIGN = softmax(reduce_sum(`V` * Tanh(`KEYS` + `PQ`)))

  `CONTEXT` - context based on `ALIGN` and `VALUES`
      CONTEXT = `ALIGN` * `VALUES`
</pre></div>
</div>
<p>LSTM Cell:
<code class="docutils literal notranslate"><span class="pre">X</span></code> - input tensor concat with attention state in the attention wrapper</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`i` - input gate

`o` - output gate

`f` - forget gate

`c` - cell gate

`t` - time step (t-1 means previous time step)

`W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates

`R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates

`Wb[iofc]` - W bias vectors for input, output, forget, and cell gates

`Rb[iofc]` - R bias vectors for input, output, forget, and cell gates

`P[iof]`  - P peephole weight vector for input, output, and forget gates

`WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates

`RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates

`WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates

`RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates

`PB[iof]`  - P peephole weight vector for backward input, output, and forget gates

`H` - Hidden state

`num_directions` - 2 if direction == bidirectional else 1

Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):

  - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)

  - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)

  - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)

  - Ct = ft (.) Ct-1 + it (.) ct

  - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)

  - Ht = ot (.) h(Ct)
</pre></div>
</div>
<p>AttentionWrapp Notations:
`lstm() - wrapped inner cell.
Ht, Ct = lstm(concat(Xt, ATTNt-1), Ct-1)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`am()` - attention mechanism the wrapper used.
         CONTEXTt, ALIGNt = am(Ht, ALIGNt-1)

`AW` - attention layer weights, optional.

`ATTN` - attention state, initial is zero. If `AW` provided, it is the output of the attention layer,
              ATTNt = concat(Ht, CONTEXTt) * AW
         otherwise,
              ATTNt = CONTEXTt
</pre></div>
</div>
<p>RNN layer output:
<code class="docutils literal notranslate"><span class="pre">Y</span></code> - if needed is the sequence of Ht from lstm cell.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`Y_h` - is the last valid H from lstm cell.

`Y_c` - is the last valid C from lstm cell.
</pre></div>
</div>
<section id="id1">
<h3>Version<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id2">
<h3>Attributes<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>activation_alpha</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.</dd>
<dt><tt>activation_beta</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.</dd>
<dt><tt>activations</tt> : list of strings</dt>
<dd>A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.</dd>
<dt><tt>clip</tt> : float</dt>
<dd>Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.</dd>
<dt><tt>direction</tt> : string</dt>
<dd>Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.</dd>
<dt><tt>hidden_size</tt> : int</dt>
<dd>Number of neurons in the hidden layer.</dd>
<dt><tt>input_forget</tt> : int</dt>
<dd>Couple the input and forget gates if 1, default 0.</dd>
</dl>
</section>
<section id="inputs-3-14">
<h3>Inputs (3 - 14)<a class="headerlink" href="#inputs-3-14" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`</dd>
<dt><tt>W</tt> : T</dt>
<dd>The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, 4*hidden_size, input_size]`.</dd>
<dt><tt>R</tt> : T</dt>
<dd>The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 4*hidden_size, hidden_size]`.</dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd>The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.</dd>
<dt><tt>sequence_lens</tt> (optional) : T1</dt>
<dd>Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]` </dd>
<dt><tt>initial_h</tt> (optional) : T</dt>
<dd>Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.</dd>
<dt><tt>initial_c</tt> (optional) : T</dt>
<dd>Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.</dd>
<dt><tt>P</tt> (optional) : T</dt>
<dd>The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.</dd>
<dt><tt>QW</tt> (optional) : T</dt>
<dd>The weight tensor of the query layer in the attention mechanism. Should be of shape `[num_directions, am_query_depth(hidden_size of lstm), am_attn_size]` </dd>
<dt><tt>MW</tt> (optional) : T</dt>
<dd>The weight tensor of the memory layer in the attention mechanism. Should be of shape `[num_directions, memory_depth, am_attn_size]` </dd>
<dt><tt>V</tt> (optional) : T</dt>
<dd>The attention_v tensor in the attention mechanism. Should be of shape `[num_directions, am_attn_size]` </dd>
<dt><tt>M</tt> (optional) : T</dt>
<dd>The sequence of the memory (input) for attention mechanism. Should be of `[batch_size, max_memory_step, memory_depth]` </dd>
<dt><tt>memory_seq_lens</tt> (optional) : T1</dt>
<dd>The sequence length of the input memory for the attention mechanism. Should be of `[batch_size]` </dd>
<dt><tt>AW</tt> (optional) : T</dt>
<dd>The weights of attention layer in the attention wrapper. If exists, should be of shape `[num_directions, memory_depth+hidden_size, aw_attn_size]. Please note that attention mechanism context depth is also memory_depth in the attention mechanism.` </dd>
</dl>
</section>
<section id="outputs-0-3">
<h3>Outputs (0 - 3)<a class="headerlink" href="#outputs-0-3" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> (optional) : T</dt>
<dd>A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`</dd>
<dt><tt>Y_h</tt> (optional) : T</dt>
<dd>The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`. </dd>
<dt><tt>Y_c</tt> (optional) : T</dt>
<dd>The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.</dd>
</dl>
</section>
<section id="id3">
<h3>Type Constraints<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain seq_lens to integral tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-beamsearch-a-a-name-com-microsoft-beamsearch-com-microsoft-beamsearch-a">
<h2><a name="com.microsoft.BeamSearch"></a><a name="com.microsoft.beamsearch"><strong>com.microsoft.BeamSearch</strong></a><a class="headerlink" href="#a-name-com-microsoft-beamsearch-a-a-name-com-microsoft-beamsearch-com-microsoft-beamsearch-a" title="Permalink to this headline"></a></h2>
<p>Beam Search for text generation. Supports GPT-2 decoder.</p>
<section id="id4">
<h3>Version<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id5">
<h3>Attributes<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>body</tt> : graph (required)</dt>
<dd>The GPT-2 subgraph with input_ids, position_ids, attention_mask, past_0, past_1, ... as inputs, and logits, present_0, present_1, ... as output</dd>
<dt><tt>early_stopping</tt> : int</dt>
<dd>early stop or not</dd>
<dt><tt>eos_token_id</tt> : int (required)</dt>
<dd>The id of the end-of-sequence token</dd>
<dt><tt>no_repeat_ngram_size</tt> : int</dt>
<dd>no repeat ngrams size</dd>
<dt><tt>pad_token_id</tt> : int (required)</dt>
<dd>The id of the padding token</dd>
</dl>
</section>
<section id="inputs-6-9">
<h3>Inputs (6 - 9)<a class="headerlink" href="#inputs-6-9" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input_ids</tt> : I</dt>
<dd>The sequence used as a prompt for the generation. Shape is (batch_size, sequence_length)</dd>
<dt><tt>max_length</tt> : I</dt>
<dd>The maximum length of the sequence to be generated. Shape is (1)</dd>
<dt><tt>min_length</tt> (optional) : I</dt>
<dd>The minimum length below which the score of eos_token_id is set to -Inf. Shape is (1)</dd>
<dt><tt>num_beams</tt> : I</dt>
<dd>Number of beams for beam search. 1 means no beam search. Shape is (1)</dd>
<dt><tt>num_return_sequences</tt> : I</dt>
<dd>The number of returned sequences in the batch. Shape is (1)</dd>
<dt><tt>temperature</tt> : T</dt>
<dd>The value used to module the next token probabilities. Accepts value > 0.0. Shape is (1)</dd>
<dt><tt>length_penalty</tt> (optional) : T</dt>
<dd>Exponential penalty to the length. Default value 1.0 means no penalty.Value > 1.0 encourages longer sequences, while values < 1.0 produces shorter sequences.Shape is (1,)</dd>
<dt><tt>repetition_penalty</tt> (optional) : T</dt>
<dd>The parameter for repetition penalty. Default value 1.0 means no penalty. Accepts value > 0.0. Shape is (1)</dd>
<dt><tt>vocab_mask</tt> (optional) : M</dt>
<dd>Mask of vocabulary. Words that masked with 0 are not allowed to be generated, and 1 is allowed. Shape is (vacab_size)</dd>
</dl>
</section>
<section id="outputs-1-3">
<h3>Outputs (1 - 3)<a class="headerlink" href="#outputs-1-3" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>sequences</tt> : I</dt>
<dd>Word IDs of generated sequences. Shape is (batch_size, num_return_sequences, max_sequence_length)</dd>
<dt><tt>sequences_scores</tt> (optional) : T</dt>
<dd>Final beam score of the generated sequences. Shape is (batch_size, num_return_sequences)</dd>
<dt><tt>scores</tt> (optional) : T</dt>
<dd>Processed beam scores for each vocabulary token at each generation step.Beam scores consisting of log softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam.Shape is (max_length - sequence_length, batch_size, num_beams, vocab_size)</dd>
</dl>
</section>
<section id="id6">
<h3>Type Constraints<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>I</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask to integer types</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-biasdropout-a-a-name-com-microsoft-biasdropout-com-microsoft-biasdropout-a">
<h2><a name="com.microsoft.BiasDropout"></a><a name="com.microsoft.biasdropout"><strong>com.microsoft.BiasDropout</strong></a><a class="headerlink" href="#a-name-com-microsoft-biasdropout-a-a-name-com-microsoft-biasdropout-com-microsoft-biasdropout-a" title="Permalink to this headline"></a></h2>
<p>output, dropout_mask = Dropout(data + bias, ratio) + residual, Intended to specialize the dropout pattern commonly found in transformer models.</p>
<section id="id7">
<h3>Version<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id8">
<h3>Attributes<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>seed</tt> : int</dt>
<dd>(Optional) Seed to the random generator, if not specified we will auto generate one.</dd>
</dl>
</section>
<section id="inputs-2-5">
<h3>Inputs (2 - 5)<a class="headerlink" href="#inputs-2-5" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>data</tt> : T</dt>
<dd>The input data as Tensor.</dd>
<dt><tt>bias</tt> : T</dt>
<dd>The bias input, a vector with the same shape as last dim of data OR same shape with data</dd>
<dt><tt>residual</tt> (optional) : T</dt>
<dd>The residual input, must have the same shape as data</dd>
<dt><tt>ratio</tt> (optional) : T1</dt>
<dd>The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of input, which is typically the case during training.</dd>
<dt><tt>training_mode</tt> (optional) : T2</dt>
<dd>If set to true then it indicates dropout is being used for training. It is an optional value hence unless specified explicitly, it is false. If it is false, ratio is ignored and the operation mimics inference mode where nothing will be dropped from the input data and if mask is requested as output it will contain all ones.</dd>
</dl>
</section>
<section id="id9">
<h3>Outputs (1 - 2)<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>The output.</dd>
<dt><tt>mask</tt> (optional) : T2</dt>
<dd>The output mask of dropout.</dd>
</dl>
</section>
<section id="id10">
<h3>Type Constraints<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input 'ratio' types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(bool)</dt>
<dd>Constrain output 'mask' types to boolean tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-biasgelu-a-a-name-com-microsoft-biasgelu-com-microsoft-biasgelu-a">
<h2><a name="com.microsoft.BiasGelu"></a><a name="com.microsoft.biasgelu"><strong>com.microsoft.BiasGelu</strong></a><a class="headerlink" href="#a-name-com-microsoft-biasgelu-a-a-name-com-microsoft-biasgelu-com-microsoft-biasgelu-a" title="Permalink to this headline"></a></h2>
<p>Bias Gelu.
Its an extension of Gelu. It takes the sum of input A and bias input B as the input of Gelu activation.</p>
<section id="id11">
<h3>Version<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="inputs">
<h3>Inputs<a class="headerlink" href="#inputs" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>The normal input data.</dd>
<dt><tt>B</tt> : T</dt>
<dd>The bias input data that is a 1D tensor.</dd>
</dl>
</section>
<section id="outputs">
<h3>Outputs<a class="headerlink" href="#outputs" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>C</tt> : T</dt>
<dd>The output.</dd>
</dl>
</section>
<section id="id12">
<h3>Type Constraints<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-biassoftmax-a-a-name-com-microsoft-biassoftmax-com-microsoft-biassoftmax-a">
<h2><a name="com.microsoft.BiasSoftmax"></a><a name="com.microsoft.biassoftmax"><strong>com.microsoft.BiasSoftmax</strong></a><a class="headerlink" href="#a-name-com-microsoft-biassoftmax-a-a-name-com-microsoft-biassoftmax-com-microsoft-biassoftmax-a" title="Permalink to this headline"></a></h2>
<p>Y = softmax(scores + bias)) with simple broadcast on bias. Intended to specialize softmax(scores + additive_mask) commonly found in transformer models.</p>
<section id="id13">
<h3>Version<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id14">
<h3>Attributes<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>broadcast_axis</tt> : int</dt>
<dd>broadcast bias across input for dimensions broadcast_axis to softmax_axis-1</dd>
<dt><tt>softmax_axis</tt> : int</dt>
<dd>apply softmax to elements for dimensions softmax_axis or higher</dd>
</dl>
</section>
<section id="id15">
<h3>Inputs<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>data</tt> : T</dt>
<dd>The input data as Tensor.</dd>
<dt><tt>bias</tt> : T</dt>
<dd>The bias (or mask) as Tensor.</dd>
</dl>
</section>
<section id="id16">
<h3>Outputs<a class="headerlink" href="#id16" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>The output.</dd>
</dl>
</section>
<section id="id17">
<h3>Type Constraints<a class="headerlink" href="#id17" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-bifurcationdetector-a-a-name-com-microsoft-bifurcationdetector-com-microsoft-bifurcationdetector-a">
<h2><a name="com.microsoft.BifurcationDetector"></a><a name="com.microsoft.bifurcationdetector"><strong>com.microsoft.BifurcationDetector</strong></a><a class="headerlink" href="#a-name-com-microsoft-bifurcationdetector-a-a-name-com-microsoft-bifurcationdetector-com-microsoft-bifurcationdetector-a" title="Permalink to this headline"></a></h2>
<p>Component for aggressive decoding. Find the bifurcation index of predicted tokens, between source tokens,
starting from previous suffix match index, and predicted tokens.
Concat predicted tokens, starting from bifurcation index, to the back
of current tokens. This forms the output tokens.
Detect suffix match index in source tokens, between source tokens and output tokens.
Detection is based on finding the appearances of last n-gram in output tokens
in source tokens.
A match is considered found if source tokens contain a single matching n-gram.
Return the index of the start of the n-gram in source tokens.
No matching if found if src tokens contain multiple or zero matching n-grams. Return -1.</p>
<section id="id18">
<h3>Version<a class="headerlink" href="#id18" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id19">
<h3>Attributes<a class="headerlink" href="#id19" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>max_ngram_size</tt> : int</dt>
<dd>The maximum NGram size for suffix matching.</dd>
<dt><tt>min_ngram_size</tt> : int</dt>
<dd>The minimum NGram size for suffix matching.</dd>
</dl>
</section>
<section id="inputs-3-4">
<h3>Inputs (3 - 4)<a class="headerlink" href="#inputs-3-4" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>src_tokens</tt> : T</dt>
<dd>Encoder input ids.</dd>
<dt><tt>cur_tokens</tt> : T</dt>
<dd>Decoder input ids.</dd>
<dt><tt>prev_suffix_match_idx</tt> : T</dt>
<dd>Previous suffix match index</dd>
<dt><tt>pred_tokens</tt> (optional) : T</dt>
<dd>Predicted token ids from aggressive decoding</dd>
</dl>
</section>
<section id="id20">
<h3>Outputs<a class="headerlink" href="#id20" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>tokens</tt> : T</dt>
<dd>Decoder input ids after merging predicted tokens</dd>
<dt><tt>suffix_match_idx</tt> : T</dt>
<dd>new suffix match index</dd>
</dl>
</section>
<section id="id21">
<h3>Type Constraints<a class="headerlink" href="#id21" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(int64)</dt>
<dd>Constrain to integer types.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-cdist-a-a-name-com-microsoft-cdist-com-microsoft-cdist-a">
<h2><a name="com.microsoft.CDist"></a><a name="com.microsoft.cdist"><strong>com.microsoft.CDist</strong></a><a class="headerlink" href="#a-name-com-microsoft-cdist-a-a-name-com-microsoft-cdist-com-microsoft-cdist-a" title="Permalink to this headline"></a></h2>
<section id="id22">
<h3>Version<a class="headerlink" href="#id22" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id23">
<h3>Attributes<a class="headerlink" href="#id23" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>metric</tt> : string</dt>
<dd>The distance metric to use. If a string, the distance function can be "braycurtis", "canberra", "chebyshev", "cityblock", "correlation", "cosine", "dice", "euclidean", "hamming", "jaccard", "jensenshannon", "kulsinski", "mahalanobis", "matching", "minkowski", "rogerstanimoto", "russellrao", "seuclidean", "sokalmichener", "sokalsneath", "sqeuclidean", "wminkowski", "yule".</dd>
</dl>
</section>
<section id="id24">
<h3>Inputs<a class="headerlink" href="#id24" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>2D matrix with shape (M,N)</dd>
<dt><tt>B</tt> : T</dt>
<dd>2D matrix with shape (K,N)</dd>
</dl>
</section>
<section id="id25">
<h3>Outputs<a class="headerlink" href="#id25" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>C</tt> : T</dt>
<dd>A 2D Matrix that represents the distance between each pair of the two collections of inputs.</dd>
</dl>
</section>
<section id="id26">
<h3>Type Constraints<a class="headerlink" href="#id26" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(double)</dt>
<dd>Constrains input to only numeric types.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-complexmul-a-a-name-com-microsoft-complexmul-com-microsoft-complexmul-a">
<h2><a name="com.microsoft.ComplexMul"></a><a name="com.microsoft.complexmul"><strong>com.microsoft.ComplexMul</strong></a><a class="headerlink" href="#a-name-com-microsoft-complexmul-a-a-name-com-microsoft-complexmul-com-microsoft-complexmul-a" title="Permalink to this headline"></a></h2>
<section id="id27">
<h3>Version<a class="headerlink" href="#id27" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id28">
<h3>Inputs<a class="headerlink" href="#id28" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>input_0</dd>
<dt><tt>B</tt> : T</dt>
<dd>input_1</dd>
</dl>
</section>
<section id="id29">
<h3>Outputs<a class="headerlink" href="#id29" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>C</tt> : T</dt>
<dd>output tensor</dd>
</dl>
</section>
<section id="id30">
<h3>Type Constraints<a class="headerlink" href="#id30" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-complexmulconj-a-a-name-com-microsoft-complexmulconj-com-microsoft-complexmulconj-a">
<h2><a name="com.microsoft.ComplexMulConj"></a><a name="com.microsoft.complexmulconj"><strong>com.microsoft.ComplexMulConj</strong></a><a class="headerlink" href="#a-name-com-microsoft-complexmulconj-a-a-name-com-microsoft-complexmulconj-com-microsoft-complexmulconj-a" title="Permalink to this headline"></a></h2>
<section id="id31">
<h3>Version<a class="headerlink" href="#id31" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id32">
<h3>Inputs<a class="headerlink" href="#id32" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>input_0</dd>
<dt><tt>B</tt> : T</dt>
<dd>input_1</dd>
</dl>
</section>
<section id="id33">
<h3>Outputs<a class="headerlink" href="#id33" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>C</tt> : T</dt>
<dd>output tensor</dd>
</dl>
</section>
<section id="id34">
<h3>Type Constraints<a class="headerlink" href="#id34" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-convtransposewithdynamicpads-a-a-name-com-microsoft-convtransposewithdynamicpads-com-microsoft-convtransposewithdynamicpads-a">
<h2><a name="com.microsoft.ConvTransposeWithDynamicPads"></a><a name="com.microsoft.convtransposewithdynamicpads"><strong>com.microsoft.ConvTransposeWithDynamicPads</strong></a><a class="headerlink" href="#a-name-com-microsoft-convtransposewithdynamicpads-a-a-name-com-microsoft-convtransposewithdynamicpads-com-microsoft-convtransposewithdynamicpads-a" title="Permalink to this headline"></a></h2>
<section id="id35">
<h3>Version<a class="headerlink" href="#id35" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id36">
<h3>Attributes<a class="headerlink" href="#id36" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>output_padding</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>
</section>
<section id="inputs-2-4">
<h3>Inputs (2 - 4)<a class="headerlink" href="#inputs-2-4" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>Pads</tt> (optional) : tensor(int64)</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
</dl>
</section>
<section id="id37">
<h3>Outputs<a class="headerlink" href="#id37" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>
</section>
<section id="id38">
<h3>Type Constraints<a class="headerlink" href="#id38" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-cropandresize-a-a-name-com-microsoft-cropandresize-com-microsoft-cropandresize-a">
<h2><a name="com.microsoft.CropAndResize"></a><a name="com.microsoft.cropandresize"><strong>com.microsoft.CropAndResize</strong></a><a class="headerlink" href="#a-name-com-microsoft-cropandresize-a-a-name-com-microsoft-cropandresize-com-microsoft-cropandresize-a" title="Permalink to this headline"></a></h2>
<p>Extracts crops from the input image tensor and resizes them using bilinear sampling or nearest neighbor sampling
(possibly with aspect ratio change) to a common output size specified by crop_height and crop_width.
Returns a tensor with crops from the input image at positions defined at the bounding box locations in boxes.
The cropped boxes are all resized (with bilinear or nearest neighbor interpolation) to
a fixed size = [crop_height, crop_width]. The result is a 4-D tensor [num_boxes, crop_height, crop_width, depth].
The resizing is corner aligned.</p>
<section id="id39">
<h3>Version<a class="headerlink" href="#id39" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id40">
<h3>Attributes<a class="headerlink" href="#id40" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>extrapolation_value</tt> : float</dt>
<dd>Value used for extrapolation, when applicable. Default is 0.0f. </dd>
<dt><tt>mode</tt> : string</dt>
<dd>The pooling method. Two modes are supported: 'bilinear' and 'nearest'. Default is 'bilinear'.</dd>
</dl>
</section>
<section id="id41">
<h3>Inputs<a class="headerlink" href="#id41" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.</dd>
<dt><tt>rois</tt> : T1</dt>
<dd>RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[y1, x1, y2, x2], ...]. The RoIs' coordinates are normalized in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.</dd>
<dt><tt>batch_indices</tt> : T2</dt>
<dd>1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.</dd>
<dt><tt>crop_size</tt> : T2</dt>
<dd>1-D tensor of 2 elements: [crop_height, crop_width]. All cropped image patches are resized to this size. Both crop_height and crop_width need to be positive.</dd>
</dl>
</section>
<section id="id42">
<h3>Outputs<a class="headerlink" href="#id42" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T1</dt>
<dd>RoI pooled output, 4-D tensor of shape (num_rois, C, crop_height, crop_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].</dd>
</dl>
</section>
<section id="id43">
<h3>Type Constraints<a class="headerlink" href="#id43" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(int32)</dt>
<dd>Constrain types to int tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-decoderattention-a-a-name-com-microsoft-decoderattention-com-microsoft-decoderattention-a">
<h2><a name="com.microsoft.DecoderAttention"></a><a name="com.microsoft.decoderattention"><strong>com.microsoft.DecoderAttention</strong></a><a class="headerlink" href="#a-name-com-microsoft-decoderattention-a-a-name-com-microsoft-decoderattention-com-microsoft-decoderattention-a" title="Permalink to this headline"></a></h2>
<p>This DecoderAttention supports self attention and cross attention, key and value cache, and key_padding_mask. The attention mask is not support at the moment.
Some boolean parameters are passed by runtime input for generic purpose</p>
<section id="id44">
<h3>Version<a class="headerlink" href="#id44" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id45">
<h3>Attributes<a class="headerlink" href="#id45" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
</dl>
</section>
<section id="id46">
<h3>Inputs<a class="headerlink" href="#id46" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>query</tt> : T</dt>
<dd>3D input tensor with shape (sequence_length, batch_size, hidden_size), hidden_size = num_heads * head_size</dd>
<dt><tt>key</tt> : T</dt>
<dd>3D input tensor with shape (total_sequence_length, batch_size, hidden_size)</dd>
<dt><tt>q_weight</tt> : T</dt>
<dd>2D input tensor with shape (hidden_size, hidden_size)</dd>
<dt><tt>kv_weight</tt> : T</dt>
<dd>2D input tensor with shape (hidden_size, 2 * hidden_size)</dd>
<dt><tt>bias</tt> : T</dt>
<dd>1D input tensor with shape (3 * hidden_size)</dd>
<dt><tt>key_padding_mask</tt> (optional) : B</dt>
<dd>2D input tensor with shape (batch_size, total_sequence_length)</dd>
<dt><tt>key_cache</tt> (optional) : T</dt>
<dd>input tensor with shape (batch_size, num_heads, sequence_length or total_sequence_length, head_size)</dd>
<dt><tt>value_cache</tt> (optional) : T</dt>
<dd>input tensor with shape (batch_size, num_heads, sequence_length or total_sequence_length, head_size)</dd>
<dt><tt>static_kv</tt> : B</dt>
<dd>If static_kv = true, cross-attention; else self-attention</dd>
<dt><tt>use_past</tt> : B</dt>
<dd>If use_past = true, use cache; else no cache</dd>
<dt><tt>has_layer_state</tt> : B</dt>
<dd>If has_layer_state = true, layer_state = {} or [a,b]; else layer_state = None</dd>
<dt><tt>has_key_padding_mask</tt> : B</dt>
<dd>has_key_padding_mask or not</dd>
</dl>
</section>
<section id="id47">
<h3>Outputs (1 - 3)<a class="headerlink" href="#id47" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>3D output tensor with shape (sequence_length, batch_size, hidden_size)</dd>
<dt><tt>new_key_cache</tt> (optional) : T</dt>
<dd>output tensor with shape (batch_size, num_heads, new sequence_length, head_size)</dd>
<dt><tt>new_value_cache</tt> (optional) : T</dt>
<dd>output tensor with shape (batch_size, num_heads, new sequence_length, head_size)</dd>
</dl>
</section>
<section id="id48">
<h3>Type Constraints<a class="headerlink" href="#id48" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float and float16 tensors.</dd>
<dt><tt>B</tt> : tensor(bool)</dt>
<dd>Constrain key_padding_mask to bool tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-dequantizelinear-a-a-name-com-microsoft-dequantizelinear-com-microsoft-dequantizelinear-a">
<h2><a name="com.microsoft.DequantizeLinear"></a><a name="com.microsoft.dequantizelinear"><strong>com.microsoft.DequantizeLinear</strong></a><a class="headerlink" href="#a-name-com-microsoft-dequantizelinear-a-a-name-com-microsoft-dequantizelinear-com-microsoft-dequantizelinear-a" title="Permalink to this headline"></a></h2>
<p>The linear dequantization operator. It consumes a quantized data, a scale, a zero point and computes the full precision data.
The dequantization formula is y = (x - x_zero_point) * x_scale.
Scale and zero point must have same shape. They must be either scalar (per tensor) or 1-D tensor (per axis).</p>
<section id="id49">
<h3>Version<a class="headerlink" href="#id49" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id50">
<h3>Attributes<a class="headerlink" href="#id50" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>axis</tt> : int</dt>
<dd>The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.</dd>
</dl>
</section>
<section id="id51">
<h3>Inputs<a class="headerlink" href="#id51" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>x</tt> : T1</dt>
<dd>N-D quantized Input tensor to be de-quantized.</dd>
<dt><tt>x_scale</tt> : T2</dt>
<dd>Scale for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.</dd>
<dt><tt>x_zero_point</tt> : T1</dt>
<dd>Zero point for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.</dd>
</dl>
</section>
<section id="id52">
<h3>Outputs<a class="headerlink" href="#id52" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>y</tt> : T2</dt>
<dd>N-D full precision output tensor. It has same shape as input 'x'.</dd>
</dl>
</section>
<section id="id53">
<h3>Type Constraints<a class="headerlink" href="#id53" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain 'x' and 'x_zero_point' to 8-bit integer tensors.</dd>
<dt><tt>T2</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain 'y', 'x_scale' to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-dynamicquantizelstm-a-a-name-com-microsoft-dynamicquantizelstm-com-microsoft-dynamicquantizelstm-a">
<h2><a name="com.microsoft.DynamicQuantizeLSTM"></a><a name="com.microsoft.dynamicquantizelstm"><strong>com.microsoft.DynamicQuantizeLSTM</strong></a><a class="headerlink" href="#a-name-com-microsoft-dynamicquantizelstm-a-a-name-com-microsoft-dynamicquantizelstm-com-microsoft-dynamicquantizelstm-a" title="Permalink to this headline"></a></h2>
<section id="id54">
<h3>Version<a class="headerlink" href="#id54" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id55">
<h3>Attributes<a class="headerlink" href="#id55" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>activation_alpha</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.</dd>
<dt><tt>activation_beta</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.</dd>
<dt><tt>activations</tt> : list of strings</dt>
<dd>A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.</dd>
<dt><tt>clip</tt> : float</dt>
<dd>Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.</dd>
<dt><tt>direction</tt> : string</dt>
<dd>Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.</dd>
<dt><tt>hidden_size</tt> : int</dt>
<dd>Number of neurons in the hidden layer</dd>
<dt><tt>input_forget</tt> : int</dt>
<dd>Couple the input and forget gates if 1.</dd>
</dl>
</section>
<section id="id56">
<h3>Inputs<a class="headerlink" href="#id56" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.</dd>
<dt><tt>W</tt> : T2</dt>
<dd>The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, input_size, 4*hidden_size]`.</dd>
<dt><tt>R</tt> : T2</dt>
<dd>The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, hidden_size, 4*hidden_size]`.</dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd>The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.</dd>
<dt><tt>sequence_lens</tt> (optional) : T1</dt>
<dd>Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]`.</dd>
<dt><tt>initial_h</tt> (optional) : T</dt>
<dd>Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.</dd>
<dt><tt>initial_c</tt> (optional) : T</dt>
<dd>Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.</dd>
<dt><tt>P</tt> (optional) : T</dt>
<dd>The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.</dd>
<dt><tt>W_scale</tt> : T</dt>
<dd>W's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.</dd>
<dt><tt>W_zero_point</tt> : T2</dt>
<dd>W's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.</dd>
<dt><tt>R_scale</tt> : T</dt>
<dd>R's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.</dd>
<dt><tt>R_zero_point</tt> : T2</dt>
<dd>R's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.</dd>
</dl>
</section>
<section id="id57">
<h3>Outputs (0 - 3)<a class="headerlink" href="#id57" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> (optional) : T</dt>
<dd>A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. </dd>
<dt><tt>Y_h</tt> (optional) : T</dt>
<dd>The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`.</dd>
<dt><tt>Y_c</tt> (optional) : T</dt>
<dd>The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.</dd>
</dl>
</section>
<section id="id58">
<h3>Type Constraints<a class="headerlink" href="#id58" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain seq_lens to integer tensor.</dd>
<dt><tt>T2</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain weights types to 8 bit tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-dynamicquantizematmul-a-a-name-com-microsoft-dynamicquantizematmul-com-microsoft-dynamicquantizematmul-a">
<h2><a name="com.microsoft.DynamicQuantizeMatMul"></a><a name="com.microsoft.dynamicquantizematmul"><strong>com.microsoft.DynamicQuantizeMatMul</strong></a><a class="headerlink" href="#a-name-com-microsoft-dynamicquantizematmul-a-a-name-com-microsoft-dynamicquantizematmul-com-microsoft-dynamicquantizematmul-a" title="Permalink to this headline"></a></h2>
<section id="id59">
<h3>Version<a class="headerlink" href="#id59" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="inputs-3-5">
<h3>Inputs (3 - 5)<a class="headerlink" href="#inputs-3-5" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T1</dt>
<dd>N-dimensional matrix A</dd>
<dt><tt>B</tt> : T2</dt>
<dd>N-dimensional matrix B</dd>
<dt><tt>b_scale</tt> : T1</dt>
<dd>Scale of quantized input 'B'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.</dd>
<dt><tt>b_zero_point</tt> (optional) : T2</dt>
<dd>Zero point tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.</dd>
<dt><tt>bias</tt> (optional) : T1</dt>
<dd>1D input tensor, whose dimension is same as B's last dimension</dd>
</dl>
</section>
<section id="id60">
<h3>Outputs<a class="headerlink" href="#id60" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T1</dt>
<dd>Matrix multiply results from A * B</dd>
</dl>
</section>
<section id="id61">
<h3>Type Constraints<a class="headerlink" href="#id61" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(float)</dt>
<dd>Constrain input A, b_scale and output Y data type as float tensor.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input B data type to 8-bit integer tensor.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-embedlayernormalization-a-a-name-com-microsoft-embedlayernormalization-com-microsoft-embedlayernormalization-a">
<h2><a name="com.microsoft.EmbedLayerNormalization"></a><a name="com.microsoft.embedlayernormalization"><strong>com.microsoft.EmbedLayerNormalization</strong></a><a class="headerlink" href="#a-name-com-microsoft-embedlayernormalization-a-a-name-com-microsoft-embedlayernormalization-com-microsoft-embedlayernormalization-a" title="Permalink to this headline"></a></h2>
<p>EmbedLayerNormalization is the fusion of embedding layer in BERT model, with optional mask processing.
The embedding layer takes input_ids (word IDs) and segment_ids (sentence IDs) to look up word_embedding, position_embedding,
and segment_emedding; the embeddings are added then applied layer normalization using gamma and beta tensors.
The last input mask is optional. If mask is provided, mask index (that is position of first 0 in mask, or number of words)
will be calculated.</p>
<section id="id62">
<h3>Version<a class="headerlink" href="#id62" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id63">
<h3>Attributes<a class="headerlink" href="#id63" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
</dl>
</section>
<section id="inputs-7-9">
<h3>Inputs (7 - 9)<a class="headerlink" href="#inputs-7-9" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input_ids</tt> : T1</dt>
<dd>2D words IDs with shape (batch_size, sequence_length)</dd>
<dt><tt>segment_ids</tt> (optional) : T1</dt>
<dd>2D segment IDs with shape (batch_size, sequence_length)</dd>
<dt><tt>word_embedding</tt> : T</dt>
<dd>2D with shape (,hidden_size)</dd>
<dt><tt>position_embedding</tt> : T</dt>
<dd>2D with shape (, hidden_size)</dd>
<dt><tt>segment_embedding</tt> (optional) : T</dt>
<dd>2D with shape (, hidden_size)</dd>
<dt><tt>gamma</tt> : T</dt>
<dd>1D gamma tensor for layer normalization with shape (hidden_size)</dd>
<dt><tt>beta</tt> : T</dt>
<dd>1D beta tensor for layer normalization  with shape (hidden_size)</dd>
<dt><tt>mask</tt> (optional) : T1</dt>
<dd>2D attention mask with shape (batch_size, sequence_length)</dd>
<dt><tt>position_ids</tt> (optional) : T1</dt>
<dd>2D position ids with shape (batch_size, sequence_length)</dd>
</dl>
</section>
<section id="outputs-2-3">
<h3>Outputs (2 - 3)<a class="headerlink" href="#outputs-2-3" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>3D output tensor with shape (batch_size, sequence_length, hidden_size)</dd>
<dt><tt>mask_index</tt> : T1</dt>
<dd>1D mask_index tensor with shape (batch_size)</dd>
<dt><tt>embedding_sum</tt> (optional) : T</dt>
<dd>sum of word_embedding and position_embedding without layer normalization</dd>
</dl>
</section>
<section id="id64">
<h3>Type Constraints<a class="headerlink" href="#id64" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain input and output integer tensors types</dd>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output float tensors types.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-expanddims-a-a-name-com-microsoft-expanddims-com-microsoft-expanddims-a">
<h2><a name="com.microsoft.ExpandDims"></a><a name="com.microsoft.expanddims"><strong>com.microsoft.ExpandDims</strong></a><a class="headerlink" href="#a-name-com-microsoft-expanddims-a-a-name-com-microsoft-expanddims-com-microsoft-expanddims-a" title="Permalink to this headline"></a></h2>
<p>ExpandDims echo operator.</p>
<section id="id65">
<h3>Version<a class="headerlink" href="#id65" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id66">
<h3>Inputs<a class="headerlink" href="#id66" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>input</dd>
<dt><tt>axis</tt> : tensor(int32)</dt>
<dd>Specified axis to insert a dimension</dd>
</dl>
</section>
<section id="id67">
<h3>Outputs<a class="headerlink" href="#id67" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>output</dd>
</dl>
</section>
<section id="id68">
<h3>Type Constraints<a class="headerlink" href="#id68" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-fastgelu-a-a-name-com-microsoft-fastgelu-com-microsoft-fastgelu-a">
<h2><a name="com.microsoft.FastGelu"></a><a name="com.microsoft.fastgelu"><strong>com.microsoft.FastGelu</strong></a><a class="headerlink" href="#a-name-com-microsoft-fastgelu-a-a-name-com-microsoft-fastgelu-com-microsoft-fastgelu-a" title="Permalink to this headline"></a></h2>
<p>GELU (Gaussian Error Linear Unit) approximation: Y=0.5<em>X</em>(1+tanh(0.797885<em>X+0.035677</em>X<em>X</em>X)) with an optional input of bias that will be added to X before GELU.</p>
<section id="id69">
<h3>Version<a class="headerlink" href="#id69" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="inputs-1-2">
<h3>Inputs (1 - 2)<a class="headerlink" href="#inputs-1-2" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>input tensor</dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd>bias tensor</dd>
</dl>
</section>
<section id="id70">
<h3>Outputs<a class="headerlink" href="#id70" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>output tensor</dd>
</dl>
</section>
<section id="id71">
<h3>Type Constraints<a class="headerlink" href="#id71" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-fusedconv-a-a-name-com-microsoft-fusedconv-com-microsoft-fusedconv-a">
<h2><a name="com.microsoft.FusedConv"></a><a name="com.microsoft.fusedconv"><strong>com.microsoft.FusedConv</strong></a><a class="headerlink" href="#a-name-com-microsoft-fusedconv-a-a-name-com-microsoft-fusedconv-com-microsoft-fusedconv-a" title="Permalink to this headline"></a></h2>
<p>The fused convolution operator schema is the same as Conv besides it includes an attribute
activation.</p>
<section id="id72">
<h3>Version<a class="headerlink" href="#id72" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id73">
<h3>Attributes<a class="headerlink" href="#id73" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>
</section>
<section id="id74">
<h3>Inputs (2 - 4)<a class="headerlink" href="#id74" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Z</tt> (optional) : T</dt>
<dd></dd>
</dl>
</section>
<section id="id75">
<h3>Outputs<a class="headerlink" href="#id75" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>
</section>
<section id="id76">
<h3>Type Constraints<a class="headerlink" href="#id76" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-fusedgemm-a-a-name-com-microsoft-fusedgemm-com-microsoft-fusedgemm-a">
<h2><a name="com.microsoft.FusedGemm"></a><a name="com.microsoft.fusedgemm"><strong>com.microsoft.FusedGemm</strong></a><a class="headerlink" href="#a-name-com-microsoft-fusedgemm-a-a-name-com-microsoft-fusedgemm-com-microsoft-fusedgemm-a" title="Permalink to this headline"></a></h2>
<p>The FusedGemm operator schema is the same as Gemm besides it includes attributes
activation and leaky_relu_alpha.</p>
<section id="id77">
<h3>Version<a class="headerlink" href="#id77" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id78">
<h3>Attributes<a class="headerlink" href="#id78" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_alpha</tt> : float</dt>
<dd></dd>
<dt><tt>activation_beta</tt> : float</dt>
<dd></dd>
<dt><tt>activation_gamma</tt> : float</dt>
<dd></dd>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of input tensors A * B.</dd>
<dt><tt>beta</tt> : float</dt>
<dd>Scalar multiplier for input tensor C.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed</dd>
</dl>
</section>
<section id="id79">
<h3>Inputs<a class="headerlink" href="#id79" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.</dd>
<dt><tt>B</tt> : T</dt>
<dd>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.</dd>
<dt><tt>C</tt> : T</dt>
<dd>Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).</dd>
</dl>
</section>
<section id="id80">
<h3>Outputs<a class="headerlink" href="#id80" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output tensor of shape (M, N).</dd>
</dl>
</section>
<section id="id81">
<h3>Type Constraints<a class="headerlink" href="#id81" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(uint32), tensor(uint64), tensor(int32), tensor(int64)</dt>
<dd>Constrain input and output types to float/int tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-fusedmatmul-a-a-name-com-microsoft-fusedmatmul-com-microsoft-fusedmatmul-a">
<h2><a name="com.microsoft.FusedMatMul"></a><a name="com.microsoft.fusedmatmul"><strong>com.microsoft.FusedMatMul</strong></a><a class="headerlink" href="#a-name-com-microsoft-fusedmatmul-a-a-name-com-microsoft-fusedmatmul-com-microsoft-fusedmatmul-a" title="Permalink to this headline"></a></h2>
<p>Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html</p>
<section id="id82">
<h3>Version<a class="headerlink" href="#id82" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id83">
<h3>Attributes<a class="headerlink" href="#id83" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of the input tensors.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transBatchA</tt> : int</dt>
<dd>Whether A should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication</dd>
<dt><tt>transBatchB</tt> : int</dt>
<dd>Whether B should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication</dd>
</dl>
</section>
<section id="id84">
<h3>Inputs<a class="headerlink" href="#id84" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>N-dimensional matrix A</dd>
<dt><tt>B</tt> : T</dt>
<dd>N-dimensional matrix B</dd>
</dl>
</section>
<section id="id85">
<h3>Outputs<a class="headerlink" href="#id85" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Matrix multiply results</dd>
</dl>
</section>
<section id="id86">
<h3>Type Constraints<a class="headerlink" href="#id86" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-gathernd-a-a-name-com-microsoft-gathernd-com-microsoft-gathernd-a">
<h2><a name="com.microsoft.GatherND"></a><a name="com.microsoft.gathernd"><strong>com.microsoft.GatherND</strong></a><a class="headerlink" href="#a-name-com-microsoft-gathernd-a-a-name-com-microsoft-gathernd-com-microsoft-gathernd-a" title="Permalink to this headline"></a></h2>
<p>Given <code class="docutils literal notranslate"><span class="pre">data</span></code> tensor of rank r &gt;= 1, and <code class="docutils literal notranslate"><span class="pre">indices</span></code> tensor of rank q &gt;= 1, gather
slices of <code class="docutils literal notranslate"><span class="pre">data</span></code> into an output tensor of rank q - 1 + r - indices[-1].
Example 1:
data    = [[0,1],[2,3]]
indices = [[0,0],[1,1]]
output  = [0,3]
Example 2:
data    = [[0,1],[2,3]]
indices = [[1],[0]]
output  = [[2,3],[0,1]]
Example 3:
data    = [[[0,1],[2,3]],[[4,5],[6,7]]]
indices = [[0,1],[1,0]]
output  = [[2,3],[4,5]]
Example 4:
data    = [[[0,1],[2,3]],[[4,5],[6,7]]]
indices = [[[0,1]],[[1,0]]]
output  = [[[2,3]],[[4,5]]]</p>
<section id="id87">
<h3>Version<a class="headerlink" href="#id87" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id88">
<h3>Inputs<a class="headerlink" href="#id88" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>data</tt> : T</dt>
<dd>Tensor of rank r >= 1.</dd>
<dt><tt>indices</tt> : Tind</dt>
<dd>Tensor of rank q >= 1.</dd>
</dl>
</section>
<section id="id89">
<h3>Outputs<a class="headerlink" href="#id89" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>Tensor of rank q-1+r-indices[-1].</dd>
</dl>
</section>
<section id="id90">
<h3>Type Constraints<a class="headerlink" href="#id90" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain input and output types to any tensor type.</dd>
<dt><tt>Tind</tt> : tensor(int32), tensor(int64)</dt>
<dd>Constrain indice type to int32 or int64</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-gelu-a-a-name-com-microsoft-gelu-com-microsoft-gelu-a">
<h2><a name="com.microsoft.Gelu"></a><a name="com.microsoft.gelu"><strong>com.microsoft.Gelu</strong></a><a class="headerlink" href="#a-name-com-microsoft-gelu-a-a-name-com-microsoft-gelu-com-microsoft-gelu-a" title="Permalink to this headline"></a></h2>
<p>Gaussian Error Linear Unit.
A high-performing neural network activation function.The GELU nonlinearity is
the expected transformation of a stochastic regularizer which randomly applies
the identity or zero map to a neurons input. The GELU nonlinearity weights
inputs by their magnitude, rather than gates inputs by their sign as in ReLUs.</p>
<section id="id91">
<h3>Version<a class="headerlink" href="#id91" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id92">
<h3>Inputs<a class="headerlink" href="#id92" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>The input data as Tensor.</dd>
</dl>
</section>
<section id="id93">
<h3>Outputs<a class="headerlink" href="#id93" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>The output.</dd>
</dl>
</section>
<section id="id94">
<h3>Type Constraints<a class="headerlink" href="#id94" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-gridsample-a-a-name-com-microsoft-gridsample-com-microsoft-gridsample-a">
<h2><a name="com.microsoft.GridSample"></a><a name="com.microsoft.gridsample"><strong>com.microsoft.GridSample</strong></a><a class="headerlink" href="#a-name-com-microsoft-gridsample-a-a-name-com-microsoft-gridsample-com-microsoft-gridsample-a" title="Permalink to this headline"></a></h2>
<p>Given an <code class="docutils literal notranslate"><span class="pre">input</span></code> and a flow-field <code class="docutils literal notranslate"><span class="pre">grid</span></code>, computes the <code class="docutils literal notranslate"><span class="pre">output</span></code> using <code class="docutils literal notranslate"><span class="pre">input</span></code> values and pixel locations from <code class="docutils literal notranslate"><span class="pre">grid</span></code>.
Currently, only spatial (4-D) inputs are supported. For <code class="docutils literal notranslate"><span class="pre">input</span></code> with shape (N, C, H, W) and <code class="docutils literal notranslate"><span class="pre">grid</span></code> with shape (N, H_out, W_out, 2),
the <code class="docutils literal notranslate"><span class="pre">output</span></code> will have shape (N, C, H_out, W_out).
For each output location <code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">h,</span> <span class="pre">w]</span></code>, the size-2 vector <code class="docutils literal notranslate"><span class="pre">grid[n,</span> <span class="pre">h,</span> <span class="pre">w]</span></code> specifies <code class="docutils literal notranslate"><span class="pre">input</span></code> pixel locations <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>,
which are used to interpolate the output value <code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">h,</span> <span class="pre">w]</span></code>.
The GridSample operator is often used in doing grid generator and sampler in the <a class="reference external" href="https://arxiv.org/abs/1506.02025">Spatial Transformer Networks</a>.
See also in <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.functional.grid_sample.html#torch-nn-functional-grid-sample">torch.nn.functional.grid_sample</a>.</p>
<section id="id95">
<h3>Version<a class="headerlink" href="#id95" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id96">
<h3>Attributes<a class="headerlink" href="#id96" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>align_corners</tt> : int</dt>
<dd>If align_corners=1, the extrema (-1 and 1) are considered as referring to the center points of the input's corner pixels. If align_corners=0, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.</dd>
<dt><tt>mode</tt> : string</dt>
<dd>Three interpolation modes: bilinear (default), nearest and bicubic.</dd>
<dt><tt>padding_mode</tt> : string</dt>
<dd>Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations.</dd>
</dl>
</section>
<section id="id97">
<h3>Inputs<a class="headerlink" href="#id97" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T1</dt>
<dd>4-D tensor of shape (N, C, H, W), where N is the batch size, C is the numbers of channels, H and W are the height and width of the input data.</dd>
<dt><tt>Grid</tt> : T1</dt>
<dd>Input offset, 4-D tensor of shape (N, H_out, W_out, 2), where H_out and W_out are the height and width of grid and output, Grid specifies the sampling pixel locations normalized by the input spatial dimensions. Therefore, it should have most values in the range of [-1, 1]. If grid has values outside the range of [-1, 1], the corresponding outputs will be handled as defined by padding_mode.</dd>
</dl>
</section>
<section id="id98">
<h3>Outputs<a class="headerlink" href="#id98" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>4-D tensor of shape (N, C, H_out, W_out).</dd>
</dl>
</section>
<section id="id99">
<h3>Type Constraints<a class="headerlink" href="#id99" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain input types to all tensor types.</dd>
<dt><tt>T2</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-inverse-a-a-name-com-microsoft-inverse-com-microsoft-inverse-a">
<h2><a name="com.microsoft.Inverse"></a><a name="com.microsoft.inverse"><strong>com.microsoft.Inverse</strong></a><a class="headerlink" href="#a-name-com-microsoft-inverse-a-a-name-com-microsoft-inverse-com-microsoft-inverse-a" title="Permalink to this headline"></a></h2>
<section id="id100">
<h3>Version<a class="headerlink" href="#id100" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id101">
<h3>Inputs<a class="headerlink" href="#id101" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>Input tensor. Every matrix in the batch must be invertible.</dd>
</dl>
</section>
<section id="id102">
<h3>Outputs<a class="headerlink" href="#id102" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output tensor of the same type and shape as the input tensor.</dd>
</dl>
</section>
<section id="id103">
<h3>Type Constraints<a class="headerlink" href="#id103" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-irfft-a-a-name-com-microsoft-irfft-com-microsoft-irfft-a">
<h2><a name="com.microsoft.Irfft"></a><a name="com.microsoft.irfft"><strong>com.microsoft.Irfft</strong></a><a class="headerlink" href="#a-name-com-microsoft-irfft-a-a-name-com-microsoft-irfft-com-microsoft-irfft-a" title="Permalink to this headline"></a></h2>
<section id="id104">
<h3>Version<a class="headerlink" href="#id104" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id105">
<h3>Attributes<a class="headerlink" href="#id105" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>normalized</tt> : int</dt>
<dd></dd>
<dt><tt>onesided</tt> : int</dt>
<dd></dd>
<dt><tt>signal_ndim</tt> : int (required)</dt>
<dd></dd>
</dl>
</section>
<section id="id106">
<h3>Inputs<a class="headerlink" href="#id106" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>input tensor</dd>
</dl>
</section>
<section id="id107">
<h3>Outputs<a class="headerlink" href="#id107" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>output tensor</dd>
</dl>
</section>
<section id="id108">
<h3>Type Constraints<a class="headerlink" href="#id108" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-longformerattention-a-a-name-com-microsoft-longformerattention-com-microsoft-longformerattention-a">
<h2><a name="com.microsoft.LongformerAttention"></a><a name="com.microsoft.longformerattention"><strong>com.microsoft.LongformerAttention</strong></a><a class="headerlink" href="#a-name-com-microsoft-longformerattention-a-a-name-com-microsoft-longformerattention-com-microsoft-longformerattention-a" title="Permalink to this headline"></a></h2>
<p>Longformer Self Attention with a local context and a global context. Tokens attend locally: Each token
attends to its W previous tokens and W succeding tokens with W being the window length. A selected few tokens
attend globally to all other tokens.</p>
<p>The attention mask is of shape (batch_size, sequence_length), where sequence_length is a multiple of 2W after padding.
Mask value &lt; 0 (like -10000.0) means the token is masked, 0 otherwise.</p>
<p>Global attention flags have value 1 for the tokens attend globally and 0 otherwise.</p>
<section id="id109">
<h3>Version<a class="headerlink" href="#id109" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id110">
<h3>Attributes<a class="headerlink" href="#id110" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>window</tt> : int (required)</dt>
<dd>One sided attention windows length W, or half of total window length</dd>
</dl>
</section>
<section id="id111">
<h3>Inputs<a class="headerlink" href="#id111" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input</tt> : T</dt>
<dd>3D input tensor with shape (batch_size, sequence_length, hidden_size), hidden_size = num_heads * head_size</dd>
<dt><tt>weight</tt> : T</dt>
<dd>2D input tensor with shape (hidden_size, 3 * hidden_size)</dd>
<dt><tt>bias</tt> : T</dt>
<dd>1D input tensor with shape (3 * hidden_size)</dd>
<dt><tt>mask</tt> : T</dt>
<dd>Attention mask with shape (batch_size, sequence_length)</dd>
<dt><tt>global_weight</tt> : T</dt>
<dd>2D input tensor with shape (hidden_size, 3 * hidden_size)</dd>
<dt><tt>global_bias</tt> : T</dt>
<dd>1D input tensor with shape (3 * hidden_size)</dd>
<dt><tt>global</tt> : G</dt>
<dd>Global attention flags with shape (batch_size, sequence_length)</dd>
</dl>
</section>
<section id="id112">
<h3>Outputs<a class="headerlink" href="#id112" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>3D output tensor with shape (batch_size, sequence_length, hidden_size)</dd>
</dl>
</section>
<section id="id113">
<h3>Type Constraints<a class="headerlink" href="#id113" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>G</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-matmulinteger16-a-a-name-com-microsoft-matmulinteger16-com-microsoft-matmulinteger16-a">
<h2><a name="com.microsoft.MatMulInteger16"></a><a name="com.microsoft.matmulinteger16"><strong>com.microsoft.MatMulInteger16</strong></a><a class="headerlink" href="#a-name-com-microsoft-matmulinteger16-a-a-name-com-microsoft-matmulinteger16-com-microsoft-matmulinteger16-a" title="Permalink to this headline"></a></h2>
<p>Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html.
The production MUST never overflow. The accumulation may overflow if and only if in 32 bits.</p>
<section id="id114">
<h3>Version<a class="headerlink" href="#id114" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id115">
<h3>Inputs<a class="headerlink" href="#id115" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T1</dt>
<dd>N-dimensional matrix A</dd>
<dt><tt>B</tt> : T2</dt>
<dd>N-dimensional matrix B</dd>
</dl>
</section>
<section id="id116">
<h3>Outputs<a class="headerlink" href="#id116" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T3</dt>
<dd>Matrix multiply results from A * B</dd>
</dl>
</section>
<section id="id117">
<h3>Type Constraints<a class="headerlink" href="#id117" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int16), tensor(uint16)</dt>
<dd>Constrain input A data types as 16-bit integer tensor</dd>
<dt><tt>T2</tt> : tensor(int16), tensor(uint16)</dt>
<dd>Constrain input B data types as 16-bit integer tensor</dd>
<dt><tt>T3</tt> : tensor(int32), tensor(uint32)</dt>
<dd>Constrain output Y data types as 32-bit integer tensor.T3 must be tensor(uint32) when both T1 and T2 are tensor(uint16),or must be tensor(int32) when either T1 or T2 is tensor(int16).</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-matmulintegertofloat-a-a-name-com-microsoft-matmulintegertofloat-com-microsoft-matmulintegertofloat-a">
<h2><a name="com.microsoft.MatMulIntegerToFloat"></a><a name="com.microsoft.matmulintegertofloat"><strong>com.microsoft.MatMulIntegerToFloat</strong></a><a class="headerlink" href="#a-name-com-microsoft-matmulintegertofloat-a-a-name-com-microsoft-matmulintegertofloat-com-microsoft-matmulintegertofloat-a" title="Permalink to this headline"></a></h2>
<section id="id118">
<h3>Version<a class="headerlink" href="#id118" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="inputs-4-7">
<h3>Inputs (4 - 7)<a class="headerlink" href="#inputs-4-7" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T1</dt>
<dd>N-dimensional matrix A</dd>
<dt><tt>B</tt> : T2</dt>
<dd>N-dimensional matrix B</dd>
<dt><tt>a_scale</tt> : T3</dt>
<dd>Scale of quantized input 'A'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.</dd>
<dt><tt>b_scale</tt> : T3</dt>
<dd>Scale of quantized input 'B'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.</dd>
<dt><tt>a_zero_point</tt> (optional) : T1</dt>
<dd>Zero point tensor for input 'A'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.</dd>
<dt><tt>b_zero_point</tt> (optional) : T2</dt>
<dd>Zero point tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.</dd>
<dt><tt>bias</tt> (optional) : T3</dt>
<dd>1D input tensor, whose dimension is same as B's last dimension</dd>
</dl>
</section>
<section id="id119">
<h3>Outputs<a class="headerlink" href="#id119" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T3</dt>
<dd>Matrix multiply results from A * B</dd>
</dl>
</section>
<section id="id120">
<h3>Type Constraints<a class="headerlink" href="#id120" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input A data type to 8-bit integer tensor.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input B data type to 8-bit integer tensor.</dd>
<dt><tt>T3</tt> : tensor(float)</dt>
<dd>Constrain input a_scale, b_scale and output Y data type as float tensor.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-maxpoolwithmask-a-a-name-com-microsoft-maxpoolwithmask-com-microsoft-maxpoolwithmask-a">
<h2><a name="com.microsoft.MaxpoolWithMask"></a><a name="com.microsoft.maxpoolwithmask"><strong>com.microsoft.MaxpoolWithMask</strong></a><a class="headerlink" href="#a-name-com-microsoft-maxpoolwithmask-a-a-name-com-microsoft-maxpoolwithmask-com-microsoft-maxpoolwithmask-a" title="Permalink to this headline"></a></h2>
<p>For internal use.</p>
<section id="id121">
<h3>Version<a class="headerlink" href="#id121" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id122">
<h3>Attributes<a class="headerlink" href="#id122" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>storage_order</tt> : int</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>
</section>
<section id="id123">
<h3>Inputs<a class="headerlink" href="#id123" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>mask</dd>
</dl>
</section>
<section id="id124">
<h3>Outputs<a class="headerlink" href="#id124" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>
</section>
<section id="id125">
<h3>Type Constraints<a class="headerlink" href="#id125" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input0 and output types to float tensors</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-mulinteger-a-a-name-com-microsoft-mulinteger-com-microsoft-mulinteger-a">
<h2><a name="com.microsoft.MulInteger"></a><a name="com.microsoft.mulinteger"><strong>com.microsoft.MulInteger</strong></a><a class="headerlink" href="#a-name-com-microsoft-mulinteger-a-a-name-com-microsoft-mulinteger-com-microsoft-mulinteger-a" title="Permalink to this headline"></a></h2>
<p>Performs element-wise binary quantized multiplication (with Numpy-style broadcasting support).
This operator supports <strong>multidirectional (i.e., Numpy-style) broadcasting</strong>
The output of this op is the int32 accumulated result of the mul operation</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">C</span> <span class="p">(</span><span class="n">int32</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">A_zero_point</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">B</span> <span class="o">-</span> <span class="n">B_zero_point</span><span class="p">)</span>
</pre></div>
</div>
<section id="id126">
<h3>Version<a class="headerlink" href="#id126" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id127">
<h3>Inputs (3 - 4)<a class="headerlink" href="#id127" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>First operand.</dd>
<dt><tt>A_zero_point</tt> (optional) : T</dt>
<dd>Input A zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>B</tt> : T</dt>
<dd>Second operand.</dd>
<dt><tt>B_zero_point</tt> (optional) : T</dt>
<dd>Input B zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
</dl>
</section>
<section id="id128">
<h3>Outputs<a class="headerlink" href="#id128" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>C</tt> : T1</dt>
<dd>Constrain output to 32 bit tensor</dd>
</dl>
</section>
<section id="id129">
<h3>Type Constraints<a class="headerlink" href="#id129" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input types to 8 bit signed and unsigned tensors.</dd>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain output types to 32 bit tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-murmurhash3-a-a-name-com-microsoft-murmurhash3-com-microsoft-murmurhash3-a">
<h2><a name="com.microsoft.MurmurHash3"></a><a name="com.microsoft.murmurhash3"><strong>com.microsoft.MurmurHash3</strong></a><a class="headerlink" href="#a-name-com-microsoft-murmurhash3-a-a-name-com-microsoft-murmurhash3-com-microsoft-murmurhash3-a" title="Permalink to this headline"></a></h2>
<p>The underlying implementation is MurmurHash3_x86_32 generating low latency 32bits hash suitable for implementing lookup tables, Bloom filters, count min sketch or feature hashing.</p>
<section id="id130">
<h3>Version<a class="headerlink" href="#id130" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id131">
<h3>Attributes<a class="headerlink" href="#id131" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>positive</tt> : int</dt>
<dd>If value is 1, output type is uint32_t, else int32_t. Default value is 1.</dd>
<dt><tt>seed</tt> : int</dt>
<dd>Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.</dd>
</dl>
</section>
<section id="id132">
<h3>Inputs<a class="headerlink" href="#id132" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T1</dt>
<dd>An input tensor to hash.</dd>
</dl>
</section>
<section id="id133">
<h3>Outputs<a class="headerlink" href="#id133" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>32-bit hash value.</dd>
</dl>
</section>
<section id="id134">
<h3>Type Constraints<a class="headerlink" href="#id134" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(uint32), tensor(int32), tensor(uint64), tensor(int64), tensor(float), tensor(double), tensor(string)</dt>
<dd>Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.</dd>
<dt><tt>T2</tt> : tensor(uint32), tensor(int32)</dt>
<dd>Constrain output type to unsigned and signed 32-bit integer tensor.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-ngramrepeatblock-a-a-name-com-microsoft-ngramrepeatblock-com-microsoft-ngramrepeatblock-a">
<h2><a name="com.microsoft.NGramRepeatBlock"></a><a name="com.microsoft.ngramrepeatblock"><strong>com.microsoft.NGramRepeatBlock</strong></a><a class="headerlink" href="#a-name-com-microsoft-ngramrepeatblock-a-a-name-com-microsoft-ngramrepeatblock-com-microsoft-ngramrepeatblock-a" title="Permalink to this headline"></a></h2>
<p>Enforce no repetition of n-grams. Scores are set to <code class="docutils literal notranslate"><span class="pre">-inf</span></code> for tokens that form a repeated n-gram if added to the back of the input_ids.</p>
<section id="id135">
<h3>Version<a class="headerlink" href="#id135" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id136">
<h3>Attributes<a class="headerlink" href="#id136" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>ngram_size</tt> : int (required)</dt>
<dd>The NGram size.</dd>
</dl>
</section>
<section id="id137">
<h3>Inputs<a class="headerlink" href="#id137" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input_ids</tt> : Tid</dt>
<dd>2D input tensor with shape (batch_size, sequence_length)</dd>
<dt><tt>scores</tt> : T</dt>
<dd>2D input tensor with shape (batch_size, vocab_size)</dd>
</dl>
</section>
<section id="id138">
<h3>Outputs<a class="headerlink" href="#id138" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>scores_out</tt> : T</dt>
<dd>2D output tensor with shape (batch_size, vocab_size)</dd>
</dl>
</section>
<section id="id139">
<h3>Type Constraints<a class="headerlink" href="#id139" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Tid</tt> : tensor(int64)</dt>
<dd>Constrain indices to integer types</dd>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain scores input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-nhwcmaxpool-a-a-name-com-microsoft-nhwcmaxpool-com-microsoft-nhwcmaxpool-a">
<h2><a name="com.microsoft.NhwcMaxPool"></a><a name="com.microsoft.nhwcmaxpool"><strong>com.microsoft.NhwcMaxPool</strong></a><a class="headerlink" href="#a-name-com-microsoft-nhwcmaxpool-a-a-name-com-microsoft-nhwcmaxpool-com-microsoft-nhwcmaxpool-a" title="Permalink to this headline"></a></h2>
<section id="id140">
<h3>Version<a class="headerlink" href="#id140" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id141">
<h3>Attributes<a class="headerlink" href="#id141" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>ceil_mode</tt> : int</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>
</section>
<section id="id142">
<h3>Inputs<a class="headerlink" href="#id142" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>x</tt> : T</dt>
<dd></dd>
</dl>
</section>
<section id="id143">
<h3>Outputs<a class="headerlink" href="#id143" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>y</tt> : T</dt>
<dd></dd>
</dl>
</section>
<section id="id144">
<h3>Type Constraints<a class="headerlink" href="#id144" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-pad-a-a-name-com-microsoft-pad-com-microsoft-pad-a">
<h2><a name="com.microsoft.Pad"></a><a name="com.microsoft.pad"><strong>com.microsoft.Pad</strong></a><a class="headerlink" href="#a-name-com-microsoft-pad-a-a-name-com-microsoft-pad-com-microsoft-pad-a" title="Permalink to this headline"></a></h2>
<p>Given <code class="docutils literal notranslate"><span class="pre">data</span></code> tensor, pads, mode, and value.
Example:
Insert 0 pads to the beginning of the second dimension.
data = [
[1.0, 1.2],
[2.3, 3.4],
[4.5, 5.7],
]
pads = [0, 2, 0, 0]
output = [
[
[0.0, 0.0, 1.0, 1.2],
[0.0, 0.0, 2.3, 3.4],
[0.0, 0.0, 4.5, 5.7],
],
]</p>
<section id="id145">
<h3>Version<a class="headerlink" href="#id145" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id146">
<h3>Attributes<a class="headerlink" href="#id146" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>mode</tt> : string</dt>
<dd>Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array</dd>
</dl>
</section>
<section id="inputs-2-3">
<h3>Inputs (2 - 3)<a class="headerlink" href="#inputs-2-3" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>data</tt> : T</dt>
<dd>Input tensor.</dd>
<dt><tt>pads</tt> : tensor(int64)</dt>
<dd>Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.</dd>
<dt><tt>value</tt> (optional) : T</dt>
<dd>(Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).</dd>
</dl>
</section>
<section id="id147">
<h3>Outputs<a class="headerlink" href="#id147" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>Tensor after padding.</dd>
</dl>
</section>
<section id="id148">
<h3>Type Constraints<a class="headerlink" href="#id148" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qattention-a-a-name-com-microsoft-qattention-com-microsoft-qattention-a">
<h2><a name="com.microsoft.QAttention"></a><a name="com.microsoft.qattention"><strong>com.microsoft.QAttention</strong></a><a class="headerlink" href="#a-name-com-microsoft-qattention-a-a-name-com-microsoft-qattention-com-microsoft-qattention-a" title="Permalink to this headline"></a></h2>
<p>Quantization of Multi-Head Self Attention.</p>
<section id="id149">
<h3>Version<a class="headerlink" href="#id149" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id150">
<h3>Attributes<a class="headerlink" href="#id150" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>unidirectional</tt> : int</dt>
<dd>Whether every token can only attend to previous tokens. Default value is 0.</dd>
</dl>
</section>
<section id="inputs-5-9">
<h3>Inputs (5 - 9)<a class="headerlink" href="#inputs-5-9" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input</tt> : T1</dt>
<dd>3D input tensor with shape (batch_size, sequence_length, input_hidden_size)</dd>
<dt><tt>weight</tt> : T2</dt>
<dd>2D input tensor with shape (input_hidden_size, 3 * hidden_size), hidden_size = num_heads * head_size</dd>
<dt><tt>bias</tt> : T3</dt>
<dd>1D input tensor with shape (3 * hidden_size)</dd>
<dt><tt>input_scale</tt> : T3</dt>
<dd>scale of quantized input tensor. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>weight_scale</tt> : T3</dt>
<dd>scale of weight scale. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization</dd>
<dt><tt>mask_index</tt> (optional) : T4</dt>
<dd>Attention mask index with shape (batch_size)</dd>
<dt><tt>input_zero_point</tt> (optional) : T1</dt>
<dd>zero point of quantized input tensor.It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>weight_zero_point</tt> (optional) : T2</dt>
<dd>zero point of quantized weight tensor. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization</dd>
<dt><tt>past</tt> (optional) : T3</dt>
<dd>past state for key and value with shape (2, batch_size, num_heads, past_sequence_length, head_size).</dd>
</dl>
</section>
<section id="id151">
<h3>Outputs (1 - 2)<a class="headerlink" href="#id151" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T3</dt>
<dd>3D output tensor with shape (batch_size, sequence_length, hidden_size)</dd>
<dt><tt>present</tt> (optional) : T3</dt>
<dd>present state for key and value with shape (2, batch_size, num_heads, past_sequence_length + sequence_length, head_size)</dd>
</dl>
</section>
<section id="id152">
<h3>Type Constraints<a class="headerlink" href="#id152" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>T3</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T4</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qgemm-a-a-name-com-microsoft-qgemm-com-microsoft-qgemm-a">
<h2><a name="com.microsoft.QGemm"></a><a name="com.microsoft.qgemm"><strong>com.microsoft.QGemm</strong></a><a class="headerlink" href="#a-name-com-microsoft-qgemm-a-a-name-com-microsoft-qgemm-com-microsoft-qgemm-a" title="Permalink to this headline"></a></h2>
<p>Quantized Gemm</p>
<section id="id153">
<h3>Version<a class="headerlink" href="#id153" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id154">
<h3>Attributes<a class="headerlink" href="#id154" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of input tensors A * B.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed</dd>
</dl>
</section>
<section id="id155">
<h3>Inputs (6 - 9)<a class="headerlink" href="#id155" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : TA</dt>
<dd>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.</dd>
<dt><tt>a_scale</tt> : T</dt>
<dd>Scale of quantized input 'A'. It is a scalar,which means a per-tensor quantization.</dd>
<dt><tt>a_zero_point</tt> : TA</dt>
<dd>Zero point tensor for input 'A'. It is a scalar.</dd>
<dt><tt>B</tt> : TB</dt>
<dd>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.</dd>
<dt><tt>b_scale</tt> : T</dt>
<dd>Scale of quantized input 'B'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.</dd>
<dt><tt>b_zero_point</tt> : TB</dt>
<dd>Zero point tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.</dd>
<dt><tt>C</tt> (optional) : TC</dt>
<dd>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). Its type is int32_t and must be quantized with zero_point = 0 and scale = alpha / beta * a_scale * b_scale.</dd>
<dt><tt>y_scale</tt> (optional) : T</dt>
<dd>Scale of output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.</dd>
<dt><tt>y_zero_point</tt> (optional) : TYZ</dt>
<dd>Zero point tensor for output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.</dd>
</dl>
</section>
<section id="id156">
<h3>Outputs<a class="headerlink" href="#id156" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : TY</dt>
<dd>Output tensor of shape (M, N).</dd>
</dl>
</section>
<section id="id157">
<h3>Type Constraints<a class="headerlink" href="#id157" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain scale types to float tensors.</dd>
<dt><tt>TA</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input A and its zero point types to 8 bit tensors.</dd>
<dt><tt>TB</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input B and its zero point types to 8 bit tensors.</dd>
<dt><tt>TC</tt> : tensor(int32)</dt>
<dd>Constrain input C to 32 bit integer tensors.</dd>
<dt><tt>TYZ</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain output zero point types to 8 bit tensors.</dd>
<dt><tt>TY</tt> : tensor(float), tensor(uint8), tensor(int8)</dt>
<dd>Constrain output type to float32 or 8 bit tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearadd-a-a-name-com-microsoft-qlinearadd-com-microsoft-qlinearadd-a">
<h2><a name="com.microsoft.QLinearAdd"></a><a name="com.microsoft.qlinearadd"><strong>com.microsoft.QLinearAdd</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearadd-a-a-name-com-microsoft-qlinearadd-com-microsoft-qlinearadd-a" title="Permalink to this headline"></a></h2>
<p>Performs element-wise binary addition on 8 bit data types (with Numpy-style broadcasting support).</p>
<p>C = (A_scale * (A - A_zero_point) + B_scale * (B - B_zero_point))/C_scale + C_zero_point</p>
<section id="id158">
<h3>Version<a class="headerlink" href="#id158" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="inputs-7-8">
<h3>Inputs (7 - 8)<a class="headerlink" href="#inputs-7-8" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>First operand.</dd>
<dt><tt>A_scale</tt> : tensor(float)</dt>
<dd>Input A's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>A_zero_point</tt> (optional) : T</dt>
<dd>Input A zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>B</tt> : T</dt>
<dd>Second operand.</dd>
<dt><tt>B_scale</tt> : tensor(float)</dt>
<dd>Input B's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>B_zero_point</tt> (optional) : T</dt>
<dd>Input B zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>C_scale</tt> : tensor(float)</dt>
<dd>Output scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>C_zero_point</tt> (optional) : T</dt>
<dd>Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
</dl>
</section>
<section id="id159">
<h3>Outputs<a class="headerlink" href="#id159" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>C</tt> : T</dt>
<dd>Result, has same element type as two inputs</dd>
</dl>
</section>
<section id="id160">
<h3>Type Constraints<a class="headerlink" href="#id160" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearaveragepool-a-a-name-com-microsoft-qlinearaveragepool-com-microsoft-qlinearaveragepool-a">
<h2><a name="com.microsoft.QLinearAveragePool"></a><a name="com.microsoft.qlinearaveragepool"><strong>com.microsoft.QLinearAveragePool</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearaveragepool-a-a-name-com-microsoft-qlinearaveragepool-com-microsoft-qlinearaveragepool-a" title="Permalink to this headline"></a></h2>
<p>QLinearAveragePool consumes an input tensor X and applies average pooling across
the tensor according to kernel sizes, stride sizes, and pad lengths.
average pooling consisting of computing the average on all values of a
subset of the input tensor according to the kernel size and downsampling the
data into the output tensor Y for further processing. The output spatial shape will be following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">input_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">pad_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">kernel_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">strides_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>or</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">input_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">pad_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">kernel_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">strides_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>if ceil_mode is enabled</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*</span> <span class="n">pad_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="nb">sum</span> <span class="n">of</span> <span class="n">pads</span> <span class="n">along</span> <span class="n">axis</span> <span class="n">i</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">auto_pad</span></code> is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">VALID</span><span class="p">:</span> <span class="n">output_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">input_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">kernel_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">strides_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">SAME_UPPER</span> <span class="ow">or</span> <span class="n">SAME_LOWER</span><span class="p">:</span> <span class="n">output_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">input_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">strides_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
<p>And pad shape will be following if <code class="docutils literal notranslate"><span class="pre">SAME_UPPER</span></code> or <code class="docutils literal notranslate"><span class="pre">SAME_LOWER</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pad_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">strides_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">kernel_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">input_spatial_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<p>The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).</p>
<p>Input and output scales and zero points are used to convert the output to a new quantization range.
Output = Dequantize(Input) -&gt; AveragePool on fp32 data -&gt; Quantize(output)</p>
<section id="id161">
<h3>Version<a class="headerlink" href="#id161" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id162">
<h3>Attributes<a class="headerlink" href="#id162" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd>auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.</dd>
<dt><tt>ceil_mode</tt> : int</dt>
<dd>Whether to use ceil or floor (default) to compute the output shape.</dd>
<dt><tt>channels_last</tt> : int</dt>
<dd>Works on NHWC layout or not? Default not.</dd>
<dt><tt>count_include_pad</tt> : int</dt>
<dd>Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.</dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd>The size of the kernel along each axis.</dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd>Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.</dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd>Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.</dd>
</dl>
</section>
<section id="inputs-4-5">
<h3>Inputs (4 - 5)<a class="headerlink" href="#inputs-4-5" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].</dd>
<dt><tt>x_scale</tt> : tensor(float)</dt>
<dd>Input scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>x_zero_point</tt> (optional) : T</dt>
<dd>Input zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd>Output scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>y_zero_point</tt> (optional) : T</dt>
<dd>Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
</dl>
</section>
<section id="id163">
<h3>Outputs<a class="headerlink" href="#id163" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used</dd>
</dl>
</section>
<section id="id164">
<h3>Type Constraints<a class="headerlink" href="#id164" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearconcat-a-a-name-com-microsoft-qlinearconcat-com-microsoft-qlinearconcat-a">
<h2><a name="com.microsoft.QLinearConcat"></a><a name="com.microsoft.qlinearconcat"><strong>com.microsoft.QLinearConcat</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearconcat-a-a-name-com-microsoft-qlinearconcat-com-microsoft-qlinearconcat-a" title="Permalink to this headline"></a></h2>
<p>Concatenate a list of tensors into a single tensor.All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.</p>
<section id="id165">
<h3>Version<a class="headerlink" href="#id165" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id166">
<h3>Attributes<a class="headerlink" href="#id166" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>axis</tt> : int (required)</dt>
<dd>Which axis to concat on</dd>
</dl>
</section>
<section id="inputs-3">
<h3>Inputs (3 - )<a class="headerlink" href="#inputs-3" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y_scale</tt> : TF</dt>
<dd>Y's scale.</dd>
<dt><tt>Y_zero_point</tt> : T8</dt>
<dd>Y's zero point.</dd>
<dt><tt>inputs</tt> (variadic, heterogeneous) : TV</dt>
<dd>List of tensors/scale/zero_point for concatenation</dd>
</dl>
</section>
<section id="id167">
<h3>Outputs<a class="headerlink" href="#id167" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T8</dt>
<dd>Concatenated tensor</dd>
</dl>
</section>
<section id="id168">
<h3>Type Constraints<a class="headerlink" href="#id168" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T8</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
<dt><tt>TF</tt> : tensor(float)</dt>
<dd>Constrain scale types to any float tensor type.</dd>
<dt><tt>TV</tt> : tensor(uint8), tensor(int8), tensor(float)</dt>
<dd>Sequence of (Tensor, Scale, ZeroPoint) tuples. The type is sequence of (T8, TF, T8).</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearconv-a-a-name-com-microsoft-qlinearconv-com-microsoft-qlinearconv-a">
<h2><a name="com.microsoft.QLinearConv"></a><a name="com.microsoft.qlinearconv"><strong>com.microsoft.QLinearConv</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearconv-a-a-name-com-microsoft-qlinearconv-com-microsoft-qlinearconv-a" title="Permalink to this headline"></a></h2>
<section id="id169">
<h3>Version<a class="headerlink" href="#id169" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id170">
<h3>Attributes<a class="headerlink" href="#id170" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>channels_last</tt> : int</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>
</section>
<section id="inputs-8-9">
<h3>Inputs (8 - 9)<a class="headerlink" href="#inputs-8-9" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>x</tt> : T1</dt>
<dd></dd>
<dt><tt>x_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> : T1</dt>
<dd></dd>
<dt><tt>w</tt> : T2</dt>
<dd></dd>
<dt><tt>w_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>w_zero_point</tt> : T2</dt>
<dd></dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> : T3</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T4</dt>
<dd></dd>
</dl>
</section>
<section id="id171">
<h3>Outputs<a class="headerlink" href="#id171" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>y</tt> : T3</dt>
<dd></dd>
</dl>
</section>
<section id="id172">
<h3>Type Constraints<a class="headerlink" href="#id172" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
<dt><tt>T3</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
<dt><tt>T4</tt> : tensor(int32)</dt>
<dd></dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearglobalaveragepool-a-a-name-com-microsoft-qlinearglobalaveragepool-com-microsoft-qlinearglobalaveragepool-a">
<h2><a name="com.microsoft.QLinearGlobalAveragePool"></a><a name="com.microsoft.qlinearglobalaveragepool"><strong>com.microsoft.QLinearGlobalAveragePool</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearglobalaveragepool-a-a-name-com-microsoft-qlinearglobalaveragepool-com-microsoft-qlinearglobalaveragepool-a" title="Permalink to this headline"></a></h2>
<p>QLinearGlobalAveragePool consumes an input tensor X and applies Average pooling across
the values in the same channel. This is equivalent to AveragePool with kernel size
equal to the spatial dimension of input tensor. Input is of type uint8_t or int8_t.</p>
<section id="id173">
<h3>Version<a class="headerlink" href="#id173" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id174">
<h3>Attributes<a class="headerlink" href="#id174" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>channels_last</tt> : int</dt>
<dd></dd>
</dl>
</section>
<section id="id175">
<h3>Inputs<a class="headerlink" href="#id175" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>Input data tensor from the previous operator; According to channels_last, dimensions for image case are (N x C x H x W), or (N x H x W x C) where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), or (N x D1 X D2 ... Dn x C) where N is the batch size.</dd>
<dt><tt>x_scale</tt> : tensor(float)</dt>
<dd>Scale of quantized input 'X'. It must be a scalar.</dd>
<dt><tt>x_zero_point</tt> : T</dt>
<dd>Zero point tensor for input 'X'. It must be a scalar.</dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd>Scale of quantized output 'Y'. It must be a scalar.</dd>
<dt><tt>y_zero_point</tt> : T</dt>
<dd>Zero point tensor for output 'Y'. It must be a scalar.</dd>
</dl>
</section>
<section id="id176">
<h3>Outputs<a class="headerlink" href="#id176" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. with the N and C value keep it value, while the otherdimensions are all 1.</dd>
</dl>
</section>
<section id="id177">
<h3>Type Constraints<a class="headerlink" href="#id177" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to singed/unsigned int8 tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearleakyrelu-a-a-name-com-microsoft-qlinearleakyrelu-com-microsoft-qlinearleakyrelu-a">
<h2><a name="com.microsoft.QLinearLeakyRelu"></a><a name="com.microsoft.qlinearleakyrelu"><strong>com.microsoft.QLinearLeakyRelu</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearleakyrelu-a-a-name-com-microsoft-qlinearleakyrelu-com-microsoft-qlinearleakyrelu-a" title="Permalink to this headline"></a></h2>
<p>QLinearLeakyRelu takes quantized input data (Tensor), an argument alpha, and quantize parameter for output,
and produces one output data (Tensor<T>) where the function <code class="docutils literal notranslate"><span class="pre">f(x)</span> <span class="pre">=</span> <span class="pre">quantize(alpha</span> <span class="pre">*</span> <span class="pre">dequantize(x))</span> <span class="pre">for</span> <span class="pre">dequantize(x)</span> <span class="pre">&lt;</span> <span class="pre">0</span></code>,
<code class="docutils literal notranslate"><span class="pre">f(x)</span> <span class="pre">=</span> <span class="pre">quantize(dequantize(x))</span> <span class="pre">for</span> <span class="pre">dequantize(x)</span> <span class="pre">&gt;=</span> <span class="pre">0</span></code>, is applied to the data tensor elementwise.</p>
<section id="id178">
<h3>Version<a class="headerlink" href="#id178" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id179">
<h3>Attributes<a class="headerlink" href="#id179" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Coefficient of leakage.</dd>
</dl>
</section>
<section id="id180">
<h3>Inputs (4 - 5)<a class="headerlink" href="#id180" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>Input tensor</dd>
<dt><tt>X_scale</tt> : tensor(float)</dt>
<dd>Input X's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>X_zero_point</tt> (optional) : T</dt>
<dd>Input X's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>Y_scale</tt> : tensor(float)</dt>
<dd>Output Y's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>Y_zero_point</tt> (optional) : T</dt>
<dd>Output Y's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
</dl>
</section>
<section id="id181">
<h3>Outputs<a class="headerlink" href="#id181" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output tensor</dd>
</dl>
</section>
<section id="id182">
<h3>Type Constraints<a class="headerlink" href="#id182" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearmul-a-a-name-com-microsoft-qlinearmul-com-microsoft-qlinearmul-a">
<h2><a name="com.microsoft.QLinearMul"></a><a name="com.microsoft.qlinearmul"><strong>com.microsoft.QLinearMul</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearmul-a-a-name-com-microsoft-qlinearmul-com-microsoft-qlinearmul-a" title="Permalink to this headline"></a></h2>
<p>Performs element-wise binary multiplication on 8 bit data types (with Numpy-style broadcasting support).</p>
<p>C = ((A - A_zero_point) * (B - B_zero_point)) * (A_scale * B_scale)/C_scale + C_zero_point</p>
<section id="id183">
<h3>Version<a class="headerlink" href="#id183" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id184">
<h3>Inputs (7 - 8)<a class="headerlink" href="#id184" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>First operand.</dd>
<dt><tt>A_scale</tt> : tensor(float)</dt>
<dd>Input A's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>A_zero_point</tt> (optional) : T</dt>
<dd>Input A zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>B</tt> : T</dt>
<dd>Second operand.</dd>
<dt><tt>B_scale</tt> : tensor(float)</dt>
<dd>Input B's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>B_zero_point</tt> (optional) : T</dt>
<dd>Input B zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>C_scale</tt> : tensor(float)</dt>
<dd>Output scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>C_zero_point</tt> (optional) : T</dt>
<dd>Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
</dl>
</section>
<section id="id185">
<h3>Outputs<a class="headerlink" href="#id185" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>C</tt> : T</dt>
<dd>Result, has same element type as two inputs</dd>
</dl>
</section>
<section id="id186">
<h3>Type Constraints<a class="headerlink" href="#id186" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearreducemean-a-a-name-com-microsoft-qlinearreducemean-com-microsoft-qlinearreducemean-a">
<h2><a name="com.microsoft.QLinearReduceMean"></a><a name="com.microsoft.qlinearreducemean"><strong>com.microsoft.QLinearReduceMean</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearreducemean-a-a-name-com-microsoft-qlinearreducemean-com-microsoft-qlinearreducemean-a" title="Permalink to this headline"></a></h2>
<p>Computes the mean of the low-precision input tensors element along the provided axes.
The resulting tensor has the same rank as the input if keepdims equal 1. If keepdims equal 0,
then the resulting tensor have the reduced dimension pruned. The above behavior is similar to numpy,
with the exception that numpy default keepdims to False instead of True.
Input and Output scales and zero points are used to requantize the output in a new range.
This helps to improve accuracy as after ReduceMean operation the range of the output is expected to decrease.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;Output = Dequantize(Input) -&gt; ReduceMean on fp32 data -&gt; Quantize(output)&quot;</span><span class="p">,</span>

</pre></div>
</div>
<section id="id187">
<h3>Version<a class="headerlink" href="#id187" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id188">
<h3>Attributes<a class="headerlink" href="#id188" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>axes</tt> : list of ints (required)</dt>
<dd>A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.</dd>
<dt><tt>keepdims</tt> : int (required)</dt>
<dd>Keep the reduced dimension or not, default 1 mean keep reduced dimension.</dd>
</dl>
</section>
<section id="id189">
<h3>Inputs (4 - 5)<a class="headerlink" href="#id189" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>data</tt> : T</dt>
<dd>An input tensor.</dd>
<dt><tt>data_scale</tt> : tensor(float)</dt>
<dd>Input scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>data_zero_point</tt> (optional) : T</dt>
<dd>Input zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>reduced_scale</tt> : tensor(float)</dt>
<dd>Output scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>reduced_zero_point</tt> (optional) : T</dt>
<dd>Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
</dl>
</section>
<section id="id190">
<h3>Outputs<a class="headerlink" href="#id190" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>reduced</tt> : T</dt>
<dd>Reduced output tensor.</dd>
</dl>
</section>
<section id="id191">
<h3>Type Constraints<a class="headerlink" href="#id191" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input types to 8 bit signed and unsigned tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-qlinearsigmoid-a-a-name-com-microsoft-qlinearsigmoid-com-microsoft-qlinearsigmoid-a">
<h2><a name="com.microsoft.QLinearSigmoid"></a><a name="com.microsoft.qlinearsigmoid"><strong>com.microsoft.QLinearSigmoid</strong></a><a class="headerlink" href="#a-name-com-microsoft-qlinearsigmoid-a-a-name-com-microsoft-qlinearsigmoid-com-microsoft-qlinearsigmoid-a" title="Permalink to this headline"></a></h2>
<p>QLinearSigmoid takes quantized input data (Tensor), and quantize parameter for output, and produces one output data
(Tensor<T>) where the function <code class="docutils literal notranslate"><span class="pre">f(x)</span> <span class="pre">=</span> <span class="pre">quantize(Sigmoid(dequantize(x)))</span></code>, is applied to the data tensor elementwise.
Wwhere the function <code class="docutils literal notranslate"><span class="pre">Sigmoid(x)</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">/</span> <span class="pre">(1</span> <span class="pre">+</span> <span class="pre">exp(-x))</span></code></p>
<section id="id192">
<h3>Version<a class="headerlink" href="#id192" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id193">
<h3>Inputs (4 - 5)<a class="headerlink" href="#id193" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>Input tensor</dd>
<dt><tt>X_scale</tt> : tensor(float)</dt>
<dd>Input X's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>X_zero_point</tt> (optional) : T</dt>
<dd>Input X's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>Y_scale</tt> : tensor(float)</dt>
<dd>Output Y's scale. It's a scalar, which means a per-tensor/layer quantization.</dd>
<dt><tt>Y_zero_point</tt> (optional) : T</dt>
<dd>Output Y's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.</dd>
</dl>
</section>
<section id="id194">
<h3>Outputs<a class="headerlink" href="#id194" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output tensor</dd>
</dl>
</section>
<section id="id195">
<h3>Type Constraints<a class="headerlink" href="#id195" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-quantizelinear-a-a-name-com-microsoft-quantizelinear-com-microsoft-quantizelinear-a">
<h2><a name="com.microsoft.QuantizeLinear"></a><a name="com.microsoft.quantizelinear"><strong>com.microsoft.QuantizeLinear</strong></a><a class="headerlink" href="#a-name-com-microsoft-quantizelinear-a-a-name-com-microsoft-quantizelinear-com-microsoft-quantizelinear-a" title="Permalink to this headline"></a></h2>
<p>The linear quantization operator. It consumes a full precision data, a scale, a zero point to compute the low precision / quantized tensor.
The quantization formula is y = saturate ((x / y_scale) + y_zero_point).For saturation, it saturates to [0, 255] if its uint8, or [-128, 127] if its int8.
For (x / y_scale), its rounding to nearest ties to even. Refer to https://en.wikipedia.org/wiki/Rounding for details.
Scale and zero point must have same shape. They must be either scalar (per tensor) or 1-D tensor (per axis).</p>
<section id="id196">
<h3>Version<a class="headerlink" href="#id196" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id197">
<h3>Attributes<a class="headerlink" href="#id197" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>axis</tt> : int</dt>
<dd>The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.</dd>
</dl>
</section>
<section id="id198">
<h3>Inputs<a class="headerlink" href="#id198" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>x</tt> : T1</dt>
<dd>N-D full precision Input tensor to be quantized.</dd>
<dt><tt>y_scale</tt> : T1</dt>
<dd>Scale for doing quantization to get 'y'. It could be a scalar or a 1-D tensor,which means a per-tensor or per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.</dd>
<dt><tt>y_zero_point</tt> : T2</dt>
<dd>Zero point for doing quantization to get 'y'. It could be a scalar or a 1-D tensor, which means a per-tensoror per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.</dd>
</dl>
</section>
<section id="id199">
<h3>Outputs<a class="headerlink" href="#id199" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>y</tt> : T2</dt>
<dd>N-D quantized output tensor. It has same shape as input 'x'.</dd>
</dl>
</section>
<section id="id200">
<h3>Type Constraints<a class="headerlink" href="#id200" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain 'x', 'y_scale' to float tensors.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-range-a-a-name-com-microsoft-range-com-microsoft-range-a">
<h2><a name="com.microsoft.Range"></a><a name="com.microsoft.range"><strong>com.microsoft.Range</strong></a><a class="headerlink" href="#a-name-com-microsoft-range-a-a-name-com-microsoft-range-com-microsoft-range-a" title="Permalink to this headline"></a></h2>
<p>Creates a sequence of numbers that begins at <code class="docutils literal notranslate"><span class="pre">start</span></code> and extends by increments of <code class="docutils literal notranslate"><span class="pre">delta</span></code>
up to but not including <code class="docutils literal notranslate"><span class="pre">limit</span></code>.</p>
<section id="id201">
<h3>Version<a class="headerlink" href="#id201" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id202">
<h3>Inputs (2 - 3)<a class="headerlink" href="#id202" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>start</tt> : T</dt>
<dd>Tensor(scalar, or dims=[1]). First entry in the range.</dd>
<dt><tt>limit</tt> : T</dt>
<dd>Tensor(scalar, or dims=[1]). Upper limit of sequence, exclusive.</dd>
<dt><tt>delta</tt> (optional) : T</dt>
<dd>Tensor(scalar, or dims=[1]). Number that increments start. Defaults to 1.</dd>
</dl>
</section>
<section id="id203">
<h3>Outputs<a class="headerlink" href="#id203" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>1-D Tensor of the range.</dd>
</dl>
</section>
<section id="id204">
<h3>Type Constraints<a class="headerlink" href="#id204" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(int16), tensor(int32), tensor(int64)</dt>
<dd>Constrain input and output types.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-reducesuminteger-a-a-name-com-microsoft-reducesuminteger-com-microsoft-reducesuminteger-a">
<h2><a name="com.microsoft.ReduceSumInteger"></a><a name="com.microsoft.reducesuminteger"><strong>com.microsoft.ReduceSumInteger</strong></a><a class="headerlink" href="#a-name-com-microsoft-reducesuminteger-a-a-name-com-microsoft-reducesuminteger-com-microsoft-reducesuminteger-a" title="Permalink to this headline"></a></h2>
<p>Computes the sum of the low-precision input tensors element along the provided axes.
The resulting tensor has the same rank as the input if keepdims equal 1. If keepdims equal 0,
then the resulting tensor have the reduced dimension pruned. The above behavior is similar to numpy,
with the exception that numpy default keepdims to False instead of True.</p>
<section id="id205">
<h3>Version<a class="headerlink" href="#id205" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id206">
<h3>Attributes<a class="headerlink" href="#id206" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>axes</tt> : list of ints (required)</dt>
<dd>A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.</dd>
<dt><tt>keepdims</tt> : int (required)</dt>
<dd>Keep the reduced dimension or not, default 1 mean keep reduced dimension.</dd>
</dl>
</section>
<section id="id207">
<h3>Inputs<a class="headerlink" href="#id207" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>data</tt> : T1</dt>
<dd>An input tensor.</dd>
</dl>
</section>
<section id="id208">
<h3>Outputs<a class="headerlink" href="#id208" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>reduced</tt> : T2</dt>
<dd>Reduced output tensor.</dd>
</dl>
</section>
<section id="id209">
<h3>Type Constraints<a class="headerlink" href="#id209" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input type to 8-bit integer tensor.</dd>
<dt><tt>T2</tt> : tensor(int32), tensor(uint32)</dt>
<dd>Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-rfft-a-a-name-com-microsoft-rfft-com-microsoft-rfft-a">
<h2><a name="com.microsoft.Rfft"></a><a name="com.microsoft.rfft"><strong>com.microsoft.Rfft</strong></a><a class="headerlink" href="#a-name-com-microsoft-rfft-a-a-name-com-microsoft-rfft-com-microsoft-rfft-a" title="Permalink to this headline"></a></h2>
<section id="id210">
<h3>Version<a class="headerlink" href="#id210" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id211">
<h3>Attributes<a class="headerlink" href="#id211" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>normalized</tt> : int</dt>
<dd></dd>
<dt><tt>onesided</tt> : int</dt>
<dd></dd>
<dt><tt>signal_ndim</tt> : int</dt>
<dd></dd>
</dl>
</section>
<section id="id212">
<h3>Inputs<a class="headerlink" href="#id212" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>input tensor</dd>
</dl>
</section>
<section id="id213">
<h3>Outputs<a class="headerlink" href="#id213" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>output tensor</dd>
</dl>
</section>
<section id="id214">
<h3>Type Constraints<a class="headerlink" href="#id214" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-sampleop-a-a-name-com-microsoft-sampleop-com-microsoft-sampleop-a">
<h2><a name="com.microsoft.SampleOp"></a><a name="com.microsoft.sampleop"><strong>com.microsoft.SampleOp</strong></a><a class="headerlink" href="#a-name-com-microsoft-sampleop-a-a-name-com-microsoft-sampleop-com-microsoft-sampleop-a" title="Permalink to this headline"></a></h2>
<p>Sample echo operator.</p>
<section id="id215">
<h3>Version<a class="headerlink" href="#id215" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id216">
<h3>Inputs<a class="headerlink" href="#id216" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>input</dd>
</dl>
</section>
<section id="id217">
<h3>Outputs<a class="headerlink" href="#id217" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>output</dd>
</dl>
</section>
<section id="id218">
<h3>Type Constraints<a class="headerlink" href="#id218" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint32), tensor(uint64), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-skiplayernormalization-a-a-name-com-microsoft-skiplayernormalization-com-microsoft-skiplayernormalization-a">
<h2><a name="com.microsoft.SkipLayerNormalization"></a><a name="com.microsoft.skiplayernormalization"><strong>com.microsoft.SkipLayerNormalization</strong></a><a class="headerlink" href="#a-name-com-microsoft-skiplayernormalization-a-a-name-com-microsoft-skiplayernormalization-com-microsoft-skiplayernormalization-a" title="Permalink to this headline"></a></h2>
<p>Skip and Layer Normalization Fusion</p>
<section id="id219">
<h3>Version<a class="headerlink" href="#id219" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id220">
<h3>Attributes<a class="headerlink" href="#id220" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
</dl>
</section>
<section id="id221">
<h3>Inputs (3 - 5)<a class="headerlink" href="#id221" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input</tt> : T</dt>
<dd>3D input tensor with shape (batch_size, sequence_length, hidden_size)</dd>
<dt><tt>skip</tt> : T</dt>
<dd>3D skip tensor with shape (batch_size, sequence_length, hidden_size)</dd>
<dt><tt>gamma</tt> : T</dt>
<dd>1D input tensor with shape (hidden_size)</dd>
<dt><tt>beta</tt> (optional) : T</dt>
<dd>1D skip tensor with shape (hidden_size</dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd>1D bias tensor with shape (hidden_size</dd>
</dl>
</section>
<section id="id222">
<h3>Outputs (1 - 3)<a class="headerlink" href="#id222" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>3D output tensor with shape (batch_size, sequence_length, hidden_size)</dd>
<dt><tt>mean</tt> (optional) : U</dt>
<dd>Saved mean used during training to speed up gradient computation</dd>
<dt><tt>inv_std_var</tt> (optional) : U</dt>
<dd>Saved inverse standard variance used during training to speed up gradient computation.</dd>
</dl>
</section>
<section id="id223">
<h3>Type Constraints<a class="headerlink" href="#id223" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
<dt><tt>U</tt> : tensor(float)</dt>
<dd>Constrain mean and inv_std_var to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-sparsetodensematmul-a-a-name-com-microsoft-sparsetodensematmul-com-microsoft-sparsetodensematmul-a">
<h2><a name="com.microsoft.SparseToDenseMatMul"></a><a name="com.microsoft.sparsetodensematmul"><strong>com.microsoft.SparseToDenseMatMul</strong></a><a class="headerlink" href="#a-name-com-microsoft-sparsetodensematmul-a-a-name-com-microsoft-sparsetodensematmul-com-microsoft-sparsetodensematmul-a" title="Permalink to this headline"></a></h2>
<section id="id224">
<h3>Version<a class="headerlink" href="#id224" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id225">
<h3>Attributes<a class="headerlink" href="#id225" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of the input tensors.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication</dd>
</dl>
</section>
<section id="id226">
<h3>Inputs<a class="headerlink" href="#id226" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>2-dimensional sparse matrix A. Either COO or CSR format</dd>
<dt><tt>B</tt> : T1</dt>
<dd>N-dimensional dense matrix B</dd>
</dl>
</section>
<section id="id227">
<h3>Outputs<a class="headerlink" href="#id227" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T1</dt>
<dd>Matrix multiply results</dd>
</dl>
</section>
<section id="id228">
<h3>Type Constraints<a class="headerlink" href="#id228" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : sparse_tensor(float), sparse_tensor(double), sparse_tensor(int64), sparse_tensor(int32), sparse_tensor(uint64), sparse_tensor(uint32)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(float), tensor(double), tensor(int64), tensor(int32), tensor(uint64), tensor(uint32)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-tokenizer-a-a-name-com-microsoft-tokenizer-com-microsoft-tokenizer-a">
<h2><a name="com.microsoft.Tokenizer"></a><a name="com.microsoft.tokenizer"><strong>com.microsoft.Tokenizer</strong></a><a class="headerlink" href="#a-name-com-microsoft-tokenizer-a-a-name-com-microsoft-tokenizer-com-microsoft-tokenizer-a" title="Permalink to this headline"></a></h2>
<p>Tokenizer divides each string in X into a vector of strings along the last axis. Allowed input shapes are [C] and [N, C].
If the maximum number of tokens found per input string is D, the output shape would be [N, C, D] when input shape is [N, C].
Similarly, if input shape is [C] then the output should be [C, D]. Tokenizer has two different operation modes.
The first mode is selected when tokenexp is not set and separators is set. If tokenexp is set and separators is not set,
the second mode will be used. The first mode breaks each input string into tokens by matching and removing separators.
separators is a list of strings which are regular expressions. tokenexp is a single regular expression.
Lets assume separators is [ ] and consider an example.
If input is
[Hello World, I love computer science !] whose shape is [2],
then the output would be
[[Hello, World, padvalue, padvalue, padvalue],
[I, love, computer, science, !]]
whose shape is [2, 5] because you can find at most 5 tokens per input string.
Note that the input at most can have two axes, so 3-D and higher dimension are not supported.
If separators contains a single empty string, the Tokenizer will enter into character tokenezation mode. This means all strings
will be broken part into individual characters.
For each input string, the second mode searches matches of tokenexp and each match will be a token in Y.
The matching of tokenexp is conducted greedily (i.e., a match should be as long as possible).
This operator searches for the first match starting from the beginning of the considered string,
and then launches another search starting from the first remained character after the first matched token.
If no match found, this operator will remove the first character from the remained string and do another search.
This procedure will be repeated until reaching the end of the considered string.
Lets consider another example to illustrate the effect of setting mark to true.
If input is [Hello, World],
then the corresponding output would be [0x02, Hello, World, 0x03].
This implies that if mark is true, [C]/[N, C] - inputs output shape becomes [C, D+2]/[N, C, D+2].
If tokenizer removes the entire content of [C]-input, it will produce [[]].
I.e. the output shape should be [C][0] or [N][C][0] if input shape was [N][C].
If the tokenizer receives empty input of [0] then the output is [0] if empty input
of [N, 0] then [N, 0].</p>
<section id="id229">
<h3>Version<a class="headerlink" href="#id229" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id230">
<h3>Attributes<a class="headerlink" href="#id230" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>mark</tt> : int (required)</dt>
<dd>Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).</dd>
<dt><tt>mincharnum</tt> : int (required)</dt>
<dd>Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored</dd>
<dt><tt>pad_value</tt> : string (required)</dt>
<dd>The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.</dd>
<dt><tt>separators</tt> : list of strings</dt>
<dd>an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.</dd>
<dt><tt>tokenexp</tt> : string</dt>
<dd>An optional string. Token's regular expression in basic POSIX format (pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.</dd>
</dl>
</section>
<section id="id231">
<h3>Inputs<a class="headerlink" href="#id231" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>Strings to tokenize</dd>
</dl>
</section>
<section id="id232">
<h3>Outputs<a class="headerlink" href="#id232" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Tokenized strings</dd>
</dl>
</section>
<section id="id233">
<h3>Type Constraints<a class="headerlink" href="#id233" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(string)</dt>
<dd>Input/Output is a string tensor</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-torchembedding-a-a-name-com-microsoft-torchembedding-com-microsoft-torchembedding-a">
<h2><a name="com.microsoft.TorchEmbedding"></a><a name="com.microsoft.torchembedding"><strong>com.microsoft.TorchEmbedding</strong></a><a class="headerlink" href="#a-name-com-microsoft-torchembedding-a-a-name-com-microsoft-torchembedding-com-microsoft-torchembedding-a" title="Permalink to this headline"></a></h2>
<p>Based on Torch operator Embedding, creates a lookup table of embedding vectors of fixed size,
for a dictionary of fixed size.</p>
<section id="id234">
<h3>Version<a class="headerlink" href="#id234" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id235">
<h3>Inputs (2 - 4)<a class="headerlink" href="#id235" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>weight</tt> : T</dt>
<dd>The embedding matrix of size N x M. 'N' is equal to the maximum possible index + 1, and 'M' is equal to the embedding size</dd>
<dt><tt>indices</tt> : tensor(int64)</dt>
<dd>Long tensor containing the indices to extract from embedding matrix.</dd>
<dt><tt>padding_idx</tt> (optional) : tensor(int64)</dt>
<dd>A 0-D scalar tensor. If specified, the entries at `padding_idx` do not contribute to the gradient; therefore, the embedding vector at `padding_idx` is not updated during training, i.e. it remains as a fixed pad.</dd>
<dt><tt>scale_grad_by_freq</tt> (optional) : tensor(bool)</dt>
<dd>A 0-D bool tensor. If given, this will scale gradients by the inverse of frequency of the indices (words) in the mini-batch. Default  is ``False``</dd>
</dl>
</section>
<section id="id236">
<h3>Outputs<a class="headerlink" href="#id236" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output tensor of the same type as the input tensor. Shape of the output is * x M, where '*' is the shape of input indices, and 'M' is the embedding size.</dd>
</dl>
</section>
<section id="id237">
<h3>Type Constraints<a class="headerlink" href="#id237" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16), tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64)</dt>
<dd>Constrain input and output types to all numeric tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-transposematmul-a-a-name-com-microsoft-transposematmul-com-microsoft-transposematmul-a">
<h2><a name="com.microsoft.TransposeMatMul"></a><a name="com.microsoft.transposematmul"><strong>com.microsoft.TransposeMatMul</strong></a><a class="headerlink" href="#a-name-com-microsoft-transposematmul-a-a-name-com-microsoft-transposematmul-com-microsoft-transposematmul-a" title="Permalink to this headline"></a></h2>
<p>Duplicate of FusedMatMul. Going forward FusedMatMul should be used. This OP will be supported for backward compatibility.
Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html</p>
<section id="id238">
<h3>Version<a class="headerlink" href="#id238" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id239">
<h3>Attributes<a class="headerlink" href="#id239" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of the input tensors.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication</dd>
</dl>
</section>
<section id="id240">
<h3>Inputs<a class="headerlink" href="#id240" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>A</tt> : T</dt>
<dd>N-dimensional matrix A</dd>
<dt><tt>B</tt> : T</dt>
<dd>N-dimensional matrix B</dd>
</dl>
</section>
<section id="id241">
<h3>Outputs<a class="headerlink" href="#id241" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Matrix multiply results</dd>
</dl>
</section>
<section id="id242">
<h3>Type Constraints<a class="headerlink" href="#id242" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-trilu-a-a-name-com-microsoft-trilu-com-microsoft-trilu-a">
<h2><a name="com.microsoft.Trilu"></a><a name="com.microsoft.trilu"><strong>com.microsoft.Trilu</strong></a><a class="headerlink" href="#a-name-com-microsoft-trilu-a-a-name-com-microsoft-trilu-com-microsoft-trilu-a" title="Permalink to this headline"></a></h2>
<p>Returns the upper or lower triangular part of a 2-D matrix, or batches of 2-D matrices. If the attribute upper is set to true,
the upper triangular matrix is retained. Lower triangular matrix is retained otherwise. Default value for upper is true.
Trilu takes one input tensor of shape [*, N, M], where * is zero or more batch dimensions. The upper triangular part consists
of the elements on and above the given diagonal (k). The lower triangular part consists of elements on and below the diagonal.
All other elements in the matrix are set to zero.
If k = 0, the triangular part on and above/below the main diagonal is retained.
If upper is set to true, a positive k retains the upper triangular matrix excluding k diagonals above
the main diagonal. A negative k value includes as many diagonals below the main diagonal.
If upper is set to false, a positive k retains the lower triangular matrix including k diagonals above
the main diagonal. A negative k value excludes as many diagonals below the main diagonal.</p>
<section id="id243">
<h3>Version<a class="headerlink" href="#id243" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id244">
<h3>Attributes<a class="headerlink" href="#id244" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>upper</tt> : int</dt>
<dd>Boolean. Indicates whether upper or lower part of matrix is retained. Default is true.</dd>
</dl>
</section>
<section id="id245">
<h3>Inputs (1 - 2)<a class="headerlink" href="#id245" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>X</tt> : T</dt>
<dd>Input tensor of rank 2 or higher.</dd>
<dt><tt>k</tt> (optional) : tensor(int64)</dt>
<dd>A 0-D tensor containing a single value corresponding to the number diagonals above or the main diagonal to exclude or include.Default value is 0 if it's not specified.</dd>
</dl>
</section>
<section id="id246">
<h3>Outputs<a class="headerlink" href="#id246" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T</dt>
<dd>Output tensor of the same type and shape as the input tensor.</dd>
</dl>
</section>
<section id="id247">
<h3>Type Constraints<a class="headerlink" href="#id247" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16), tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(bool)</dt>
<dd>Constrain input and output types to all numeric tensors and bool tensors.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-unique-a-a-name-com-microsoft-unique-com-microsoft-unique-a">
<h2><a name="com.microsoft.Unique"></a><a name="com.microsoft.unique"><strong>com.microsoft.Unique</strong></a><a class="headerlink" href="#a-name-com-microsoft-unique-a-a-name-com-microsoft-unique-com-microsoft-unique-a" title="Permalink to this headline"></a></h2>
<p>Finds all the unique values (deduped list) present in the given input tensor.
This operator returns 3 outputs.
The first output tensor uniques contains all of the unique elements of the input,
sorted in the same order that they occur in the input.
The second output tensor idx is the same size as the input and it contains the index
of each value of the input in uniques.
The third output tensor counts contains the count of each element of uniques in the input.
Example:
input_x = [2, 1, 1, 3, 4, 3]
output_uniques = [2, 1, 3, 4]
output_idx = [0, 1, 1, 2, 3, 2]
output_counts = [1, 2, 2, 1]</p>
<section id="id248">
<h3>Version<a class="headerlink" href="#id248" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id249">
<h3>Inputs<a class="headerlink" href="#id249" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>x</tt> : T</dt>
<dd>A 1-D input tensor that is to be processed.</dd>
</dl>
</section>
<section id="id250">
<h3>Outputs<a class="headerlink" href="#id250" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>y</tt> : T</dt>
<dd>A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'</dd>
<dt><tt>idx</tt> : tensor(int64)</dt>
<dd>A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'</dd>
<dt><tt>counts</tt> : tensor(int64)</dt>
<dd>A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'</dd>
</dl>
</section>
<section id="id251">
<h3>Type Constraints<a class="headerlink" href="#id251" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Input can be of any tensor type.</dd>
</dl>
</section>
</section>
<section id="a-name-com-microsoft-wordconvembedding-a-a-name-com-microsoft-wordconvembedding-com-microsoft-wordconvembedding-a">
<h2><a name="com.microsoft.WordConvEmbedding"></a><a name="com.microsoft.wordconvembedding"><strong>com.microsoft.WordConvEmbedding</strong></a><a class="headerlink" href="#a-name-com-microsoft-wordconvembedding-a-a-name-com-microsoft-wordconvembedding-com-microsoft-wordconvembedding-a" title="Permalink to this headline"></a></h2>
<p>The WordConvEmbedding takes in a batch of sequence words and embed each word to a vector.</p>
<section id="id252">
<h3>Version<a class="headerlink" href="#id252" title="Permalink to this headline"></a></h3>
<p>This version of the operator has been available since version 1 of the com.microsoft operator set.</p>
</section>
<section id="id253">
<h3>Attributes<a class="headerlink" href="#id253" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>char_embedding_size</tt> : int</dt>
<dd>Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.</dd>
<dt><tt>conv_window_size</tt> : int</dt>
<dd>This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernal shape.</dd>
<dt><tt>embedding_size</tt> : int</dt>
<dd>Integer representing the embedding vector size for each word.If not provide, use the fileter size of conv weight</dd>
</dl>
</section>
<section id="id254">
<h3>Inputs<a class="headerlink" href="#id254" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Sequence</tt> : T</dt>
<dd>Specify batchs of sequence words to embedding</dd>
<dt><tt>W</tt> : T1</dt>
<dd>Specify weights of conv</dd>
<dt><tt>B</tt> : T1</dt>
<dd>Specify bias of conv</dd>
<dt><tt>C</tt> : T1</dt>
<dd>Specify embedding vector of char</dd>
</dl>
</section>
<section id="id255">
<h3>Outputs<a class="headerlink" href="#id255" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>Y</tt> : T1</dt>
<dd>output</dd>
</dl>
</section>
<section id="id256">
<h3>Type Constraints<a class="headerlink" href="#id256" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T</tt> : tensor(int32)</dt>
<dd>Constrain to tensor(int32).</dd>
<dt><tt>T1</tt> : tensor(float)</dt>
<dd>Constrain to tensor(float).</dd>
</dl>
</section>
</section>
<section id="sub-experimental-sub-a-name-com-microsoft-isallfinite-a-a-name-com-microsoft-isallfinite-com-microsoft-isallfinite-a">
<h2><sub>experimental</sub> <a name="com.microsoft.IsAllFinite"></a><a name="com.microsoft.isallfinite"><strong>com.microsoft.IsAllFinite</strong></a><a class="headerlink" href="#sub-experimental-sub-a-name-com-microsoft-isallfinite-a-a-name-com-microsoft-isallfinite-com-microsoft-isallfinite-a" title="Permalink to this headline"></a></h2>
<p>IsAllFinite</p>
<section id="id257">
<h3>Version<a class="headerlink" href="#id257" title="Permalink to this headline"></a></h3>
<p>No versioning maintained for experimental ops.</p>
</section>
<section id="id258">
<h3>Attributes<a class="headerlink" href="#id258" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>isinf_only</tt> : int</dt>
<dd>If true, check only for Inf, -Inf.</dd>
<dt><tt>isnan_only</tt> : int</dt>
<dd>If true, check only for NaN.</dd>
</dl>
</section>
<section id="inputs-1">
<h3>Inputs (1 - )<a class="headerlink" href="#inputs-1" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input</tt> (variadic) : V</dt>
<dd>Input tensors to check.</dd>
</dl>
</section>
<section id="id259">
<h3>Outputs<a class="headerlink" href="#id259" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>output</tt> : T</dt>
<dd>The output scalar. Its value is true if all input tensors are finite. Otherwise, the output value would be false.</dd>
</dl>
</section>
<section id="id260">
<h3>Type Constraints<a class="headerlink" href="#id260" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>V</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T</tt> : tensor(bool)</dt>
<dd>Constrain the output to a boolean tensor.</dd>
</dl>
</section>
</section>
<section id="sub-experimental-sub-a-name-com-microsoft-qembedlayernormalization-a-a-name-com-microsoft-qembedlayernormalization-com-microsoft-qembedlayernormalization-a">
<h2><sub>experimental</sub> <a name="com.microsoft.QEmbedLayerNormalization"></a><a name="com.microsoft.qembedlayernormalization"><strong>com.microsoft.QEmbedLayerNormalization</strong></a><a class="headerlink" href="#sub-experimental-sub-a-name-com-microsoft-qembedlayernormalization-a-a-name-com-microsoft-qembedlayernormalization-com-microsoft-qembedlayernormalization-a" title="Permalink to this headline"></a></h2>
<p>QEmbedLayerNormalization is the quantized fusion of embedding layer in BERT model, with optional mask processing.
The embedding layer takes input_ids (word IDs) and segment_ids (sentence IDs) to look up word_embedding, position_embedding,
and segment_emedding; the embeddings are added then applied layer normalization using gamma and beta tensors. The input_ids
and segment_ids remain int32. All embeddings, gamma, and beta tensors are converted to int8/uint8. The last input mask is optional.
If mask is provided, mask index (that is position of first 0 in mask, or number of words will be calculated.</p>
<section id="id261">
<h3>Version<a class="headerlink" href="#id261" title="Permalink to this headline"></a></h3>
<p>No versioning maintained for experimental ops.</p>
</section>
<section id="id262">
<h3>Attributes<a class="headerlink" href="#id262" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
</dl>
</section>
<section id="id263">
<h3>Inputs<a class="headerlink" href="#id263" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>input_ids</tt> : T1</dt>
<dd>2D words IDs with shape (batch_size, sequence_length)</dd>
<dt><tt>segment_ids</tt> (optional) : T1</dt>
<dd>2D segment IDs with shape (batch_size, sequence_length)</dd>
<dt><tt>word_embedding_quant</tt> : T2</dt>
<dd>2D with shape (,hidden_size)</dd>
<dt><tt>position_embedding_quant</tt> : T2</dt>
<dd>2D with shape (, hidden_size)</dd>
<dt><tt>segment_embedding</tt> (optional) : T2</dt>
<dd>2D with shape (, hidden_size)</dd>
<dt><tt>gamma_quant</tt> : T2</dt>
<dd>1D gamma tensor for layer normalization with shape (hidden_size)</dd>
<dt><tt>beta_quant</tt> : T2</dt>
<dd>1D beta tensor for layer normalization  with shape (hidden_size)</dd>
<dt><tt>mask</tt> (optional) : T1</dt>
<dd>Mask</dd>
<dt><tt>word_embedding_scale</tt> : T</dt>
<dd>Scale for word embeddings</dd>
<dt><tt>position_embedding_scale</tt> : T</dt>
<dd>Scale for position embeddings</dd>
<dt><tt>segment_embedding_scale</tt> (optional) : T</dt>
<dd>Scale for segment embeddings</dd>
<dt><tt>gamma_scale</tt> : T</dt>
<dd>Scale for 1D gamma tensor</dd>
<dt><tt>beta_scale</tt> : T</dt>
<dd>Scale for 1D beta tensor</dd>
<dt><tt>word_embedding_zero_point</tt> : T2</dt>
<dd>Zero point for word embeddings</dd>
<dt><tt>position_embedding_zero_point</tt> : T2</dt>
<dd>Zero point for position embeddings</dd>
<dt><tt>segment_embedding_zero_point</tt> (optional) : T2</dt>
<dd>Zero Point for segment embeddings</dd>
<dt><tt>gamma_zero_point</tt> : T2</dt>
<dd>Zero Point for 1D gamma tensor</dd>
<dt><tt>beta_zero_point</tt> : T2</dt>
<dd>Zero Point for 1D beta tensor</dd>
</dl>
</section>
<section id="id264">
<h3>Outputs<a class="headerlink" href="#id264" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>layernorm_out</tt> : T</dt>
<dd>LayerNorm Output</dd>
<dt><tt>mask_index_out</tt> : T1</dt>
<dd>Mask Index Output</dd>
</dl>
</section>
<section id="id265">
<h3>Type Constraints<a class="headerlink" href="#id265" title="Permalink to this headline"></a></h3>
<dl>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float32 tensors.</dd>
</dl>
</section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupr.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>