
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Issues when switching to float &#8212; onnxcustom</title>
    
    <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style_notebook_snippet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinxtrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my-styles.css" />
    
    <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/require.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script src="../_static/sphinxtrib-images/LightBox2/lightbox2_customize/jquery-noconflict.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Funny discrepancies" href="plot_funny_sigmoid.html" />
    <link rel="prev" title="Choose appropriate output of a classifier" href="plot_dbegin_options_zipmap.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/project_ico.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/apis.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../all_notebooks.html">
  Notebooks Gallery
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../other_pages.html">
  Other pages
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../blog/blogindex.html">
  Blog Gallery
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnx/index.html">
   Introduction to ONNX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_onnxruntime/index.html">
   Introduction to onnxruntime
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../tutorials/tutorial_skl/index.html">
   scikit-learn to ONNX Tutorial
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../tutorials/tutorial_skl/tutorial_1_simple.html">
     The easy case
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="plot_abegin_convert_pipeline.html">
       Train and deploy a scikit-learn pipeline
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_bbegin_measure_time.html">
       Benchmark ONNX conversion
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_cbegin_opset.html">
       What is the opset number?
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_dbegin_options.html">
       One model, many possible conversions with options
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_dbegin_options_list.html">
       Black list operators when converting
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_dbegin_options_zipmap.html">
       Choose appropriate output of a classifier
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Issues when switching to float
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_funny_sigmoid.html">
       Funny discrepancies
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_fbegin_investigate.html">
       Intermediate results and investigation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_gbegin_dataframe.html">
       Dataframe as an input
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_gbegin_transfer_learning.html">
       Transfer Learning with ONNX
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_gbegin_cst.html">
       Store arrays in one onnx graph
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="plot_gconverting.html">
       Modify the ONNX graph
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_skl/tutorial_1-5_external.html">
     Using converter from other libraries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_skl/tutorial_2_new_converter.html">
     A custom converter for a custom model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_skl/tutorial_3_new_operator.html">
     Extend ONNX, extend runtime
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/tutorial_skl/tutorial_4_complex.html">
     Complex Scenarios
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_training/index.html">
   Training Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tutorial_bench/index.html">
   Benchmarking and profiling Tutorial
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-into-the-issue">
   More into the issue
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-pipeline-and-the-data">
   The pipeline and the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-discrepencies">
   The discrepencies
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#casttransformer">
   CastTransformer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sledgehammer">
   Sledgehammer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#no-discrepencies-at-all">
   No discrepencies at all?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#castregressor">
   CastRegressor
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gyexamples-plot-ebegin-float-double-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="issues-when-switching-to-float">
<span id="l-example-discrepencies-float-double"></span><span id="sphx-glr-gyexamples-plot-ebegin-float-double-py"></span><h1>Issues when switching to float<a class="headerlink" href="#issues-when-switching-to-float" title="Permalink to this headline">¶</a></h1>
<p id="index-0">Most models in <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> do computation with double,
not float. Most models in deep learning use float because
that’s the most common situation with GPU. ONNX was initially
created to facilitate the deployment of deep learning models
and that explains why many converters assume the converted models
should use float. That assumption does not usually harm
the predictions, the conversion to float introduce small
discrepencies compare to double predictions.
That assumption is usually true if the prediction
function is continuous, <img class="math" src="../_images/math/973db6fa3d2e1026d57f4f39a812de7e503d7ebc.svg" alt="y = f(x)"/>, then
<img class="math" src="../_images/math/5db7c24d343b550b67bbdb608d940c9476174a75.svg" alt="dy = f'(x) dx"/>. We can determine an upper bound
to the discrepencies :
<img class="math" src="../_images/math/db129e7eadaca1e405f1ab44ad06cf7a7447eb0f.svg" alt="\Delta(y) \leqslant \sup_x \left\Vert f'(x)\right\Vert dx"/>.
<em>dx</em> is the discrepency introduced by a float conversion,
<code class="docutils literal notranslate"><span class="pre">dx</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">numpy.float32(x)</span></code>.</p>
<p>However, that’s not the case for every model. A decision tree
trained for a regression is not a continuous function. Therefore,
even a small <em>dx</em> may introduce a huge discrepency. Let’s look into
an example which always produces discrepencies and some ways
to overcome this situation.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#more-into-the-issue" id="id1">More into the issue</a></p></li>
<li><p><a class="reference internal" href="#the-pipeline-and-the-data" id="id2">The pipeline and the data</a></p></li>
<li><p><a class="reference internal" href="#the-discrepencies" id="id3">The discrepencies</a></p></li>
<li><p><a class="reference internal" href="#casttransformer" id="id4">CastTransformer</a></p></li>
<li><p><a class="reference internal" href="#sledgehammer" id="id5">Sledgehammer</a></p></li>
<li><p><a class="reference internal" href="#no-discrepencies-at-all" id="id6">No discrepencies at all?</a></p></li>
<li><p><a class="reference internal" href="#castregressor" id="id7">CastRegressor</a></p></li>
</ul>
</div>
<section id="more-into-the-issue">
<h2><a class="toc-backref" href="#id1">More into the issue</a><a class="headerlink" href="#more-into-the-issue" title="Permalink to this headline">¶</a></h2>
<p>The below example is built to fail.
It contains integer features with different order
of magnitude rounded to integer. A decision tree compares
features to thresholds. In most cases, float and double
comparison gives the same result. We denote
<img class="math" src="../_images/math/4d0128c48ce356dc90aec28580d6aa988a5e467d.svg" alt="[x]_{f32}"/> the conversion (or cast)
<code class="docutils literal notranslate"><span class="pre">numpy.float32(x)</span></code>.</p>
<div class="math">
<p><img src="../_images/math/2ef873c65200a9cd435fe378b2800bfa1f62c445.svg" alt="x \leqslant y = [x]_{f32} \leqslant [y]_{f32}"/></p>
</div><p>However, the probability that both comparisons give
different results is not null. The following graph shows
the discord areas.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skl2onnx.sklapi</span> <span class="kn">import</span> <span class="n">CastRegressor</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt</span> <span class="kn">import</span> <span class="n">OnnxInference</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span> <span class="k">as</span> <span class="n">to_onnx_extended</span>
<span class="kn">from</span> <span class="nn">mlprodict.sklapi</span> <span class="kn">import</span> <span class="n">OnnxPipeline</span>
<span class="kn">from</span> <span class="nn">skl2onnx.sklapi</span> <span class="kn">import</span> <span class="n">CastTransformer</span>
<span class="kn">from</span> <span class="nn">skl2onnx</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">area_mismatch_rule</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">rule</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rule</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">xst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">yst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">xsf</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ysf</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
            <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">dy</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">rule</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">key</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">c1</span> <span class="o">-</span> <span class="n">c2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">xsf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span>
                <span class="n">ysf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span>
                <span class="n">yst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xst</span><span class="p">,</span> <span class="n">yst</span><span class="p">,</span> <span class="n">xsf</span><span class="p">,</span> <span class="n">ysf</span>


<span class="n">delta</span> <span class="o">=</span> <span class="mf">36e-10</span>
<span class="n">factor</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">xst</span><span class="p">,</span> <span class="n">yst</span><span class="p">,</span> <span class="n">xsf</span><span class="p">,</span> <span class="n">ysf</span> <span class="o">=</span> <span class="n">area_mismatch_rule</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">factor</span><span class="p">)</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xst</span><span class="p">,</span> <span class="n">yst</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;agree&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xsf</span><span class="p">,</span> <span class="n">ysf</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;disagree&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Region where x &lt;= y and (float)x &lt;= (float)y agree&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">xst</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">xst</span><span class="p">)],</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">yst</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">yst</span><span class="p">)],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_ebegin_float_double_001.png" srcset="../_images/sphx_glr_plot_ebegin_float_double_001.png" alt="Region where x <= y and (float)x <= (float)y agree" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend object at 0x7f5cdc20a7c0&gt;
</pre></div>
</div>
</section>
<section id="the-pipeline-and-the-data">
<h2><a class="toc-backref" href="#id2">The pipeline and the data</a><a class="headerlink" href="#the-pipeline-and-the-data" title="Permalink to this headline">¶</a></h2>
<p>We can now build an example where the learned decision tree
does many comparisons in this discord area. This is done
by rounding features to integers, a frequent case
happening when dealing with categorical features.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">Xi_test</span><span class="p">,</span> <span class="n">yi_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">Xi_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xi_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">Xi_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xi_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">max_depth</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;dt&#39;, DecisionTreeRegressor(max_depth=10))])
</pre></div>
</div>
</section>
<section id="the-discrepencies">
<h2><a class="toc-backref" href="#id3">The discrepencies</a><a class="headerlink" href="#the-discrepencies" title="Permalink to this headline">¶</a></h2>
<p>Let’s reuse the function implemented in the
first example <a class="reference internal" href="plot_abegin_convert_pipeline.html#l-diff-dicrepencies"><span class="std std-ref">Comparison</span></a> and
look into the conversion.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">diff</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">p2</span> <span class="o">-</span> <span class="n">p1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="p">(</span><span class="n">d</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">p1</span><span class="p">))</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>


<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                        <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>

<span class="n">X32</span> <span class="o">=</span> <span class="n">Xi_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">skl</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl</span><span class="p">,</span> <span class="n">ort</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(84.52466935398928, 6.980041539088254)
</pre></div>
</div>
<p>The discrepencies are significant.
The ONNX model keeps float at every step.</p>
<div class="align-default"><img height="120" src="../_images/blockdiag-93cbf409f95e8fcf3d4828de7d9adaafafd69550.png" width="1024" /></div>
<p>In <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>:</p>
<div class="align-default"><img height="120" src="../_images/blockdiag-5b571352ec916d18002a2d25df9e97f2ce3fe74d.png" width="1024" /></div>
</section>
<section id="casttransformer">
<h2><a class="toc-backref" href="#id4">CastTransformer</a><a class="headerlink" href="#casttransformer" title="Permalink to this headline">¶</a></h2>
<p>We could try to use double everywhere. Unfortunately,
<a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md">ONNX ML Operators</a> only allows float coefficients
for the operator <em>TreeEnsembleRegressor</em>. We may want
to compromise by casting the output of the normalizer into
float in the <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> pipeline.</p>
<div class="align-default"><img height="120" src="../_images/blockdiag-e89f2384bd3fdbe24f74a006f4b52d484055dc82.png" width="1408" /></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;cast&#39;</span><span class="p">,</span> <span class="n">CastTransformer</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()), (&#39;cast&#39;, CastTransformer()),
                (&#39;dt&#39;, DecisionTreeRegressor(max_depth=10))])
</pre></div>
</div>
<p>The discrepencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx2</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model2</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess2</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx2</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                         <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>

<span class="n">skl2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort2</span> <span class="o">=</span> <span class="n">sess2</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl2</span><span class="p">,</span> <span class="n">ort2</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(70.40040571810144, 6.980041539088254)
</pre></div>
</div>
<p>That still fails because the normalizer
in <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> and in <a class="reference external" href="https://onnx.ai/">ONNX</a>
use different types. The cast still happens and
the <em>dx</em> is still here. To remove it, we need to use
double in ONNX normalizer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model3</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;cast64&#39;</span><span class="p">,</span> <span class="n">CastTransformer</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;cast&#39;</span><span class="p">,</span> <span class="n">CastTransformer</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
<span class="n">onx3</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model3</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
               <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="n">StandardScaler</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;div&#39;</span><span class="p">:</span> <span class="s1">&#39;div_cast&#39;</span><span class="p">}})</span>

<span class="n">sess3</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx3</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                         <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>

<span class="n">skl3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort3</span> <span class="o">=</span> <span class="n">sess3</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl3</span><span class="p">,</span> <span class="n">ort3</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(2.441649940010393e-05, 5.533155989632114e-08)
</pre></div>
</div>
<p>It works. That also means that it is difficult to change
the computation type when a pipeline includes a discontinuous
function. It is better to keep the same types all along
before using a decision tree.</p>
</section>
<section id="sledgehammer">
<h2><a class="toc-backref" href="#id5">Sledgehammer</a><a class="headerlink" href="#sledgehammer" title="Permalink to this headline">¶</a></h2>
<p>The idea here is to always train the next step based
on ONNX outputs. That way, every step of the pipeline
is trained based on ONNX output.</p>
<ul class="simple">
<li><p>Trains the first step.</p></li>
<li><p>Converts the step into ONNX</p></li>
<li><p>Computes ONNX outputs.</p></li>
<li><p>Trains the second step on these outputs.</p></li>
<li><p>Converts the second step into ONNX.</p></li>
<li><p>Merges it with the first step.</p></li>
<li><p>Computes ONNX outputs of the merged two first steps.</p></li>
<li><p>…</p></li>
</ul>
<p>It is implemented in
class <a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/mlprodict/sklapi/onnx_pipeline.html">OnnxPipeline</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_onx</span> <span class="o">=</span> <span class="n">OnnxPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model_onx</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>OnnxPipeline(steps=[(&#39;scaler&#39;,
                     OnnxTransformer(onnx_bytes=b&#39;\x08\x08\x12\x08skl2onnx\x1a\x041.11&quot;\x07ai.onnx(\x002\x00:\xf6\x01\n\xa6\x01\n\x01X\x12\x08variable\x1a\x06Scaler&quot;\x06Scaler*=\n\x06offset=\xcaT\xc1&lt;=\xc0\x11\xca&lt;=\xfa\xa3\x15\xbd=\x0et\xda&lt;=1\xbe\x15\xbf=-\xd7\x08\xbf=\x04\xe7\x0c?=\x11\xc7z?=f\xad\x8e@=\xc7pr\xc0\xa0\x01\x06*&lt;\n\x05scal...1^\x83==\x91 \xff&lt;=c\xd6\x82&lt;=\x00\x1f\x01&lt;=\x13\xc2\x7f;=\x19\xa4\x00;\xa0\x01\x06:\nai.onnx.ml\x12\x1emlprodict_ONNX(StandardScaler)Z\x11\n\x01X\x12\x0c\n\n\x08\x01\x12\x06\n\x00\n\x02\x08\nb\x18\n\x08variable\x12\x0c\n\n\x08\x01\x12\x06\n\x00\n\x02\x08\nB\x0e\n\nai.onnx.ml\x10\x01B\x04\n\x00\x10\x0f&#39;)),
                    (&#39;dt&#39;, DecisionTreeRegressor(max_depth=10))])
</pre></div>
</div>
<p>The conversion.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx4</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model_onx</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess4</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx4</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                         <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>

<span class="n">skl4</span> <span class="o">=</span> <span class="n">model_onx</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort4</span> <span class="o">=</span> <span class="n">sess4</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl4</span><span class="p">,</span> <span class="n">ort4</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(1.5132379814986052e-05, 5.533155968131901e-08)
</pre></div>
</div>
<p>It works too in a more simple way.</p>
</section>
<section id="no-discrepencies-at-all">
<h2><a class="toc-backref" href="#id6">No discrepencies at all?</a><a class="headerlink" href="#no-discrepencies-at-all" title="Permalink to this headline">¶</a></h2>
<p>Is it possible to get no error at all?
There is one major obstacle: <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>
stores the predicted values in every leave with double
(<a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_tree.pyx#L1096">_tree.pyx - _get_value_ndarray</a>), <a class="reference external" href="https://onnx.ai/">ONNX</a> defines the
the predicted values as floats: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md#ai.onnx.ml.TreeEnsembleRegressor">TreeEnsembleRegressor</a>.
What can we do to solve it?
What if we could extend ONNX specifications to support
double instead of floats.
We reuse what was developped in example
<a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/notebooks/onnx_discrepencies.html?highlight=treeensembleregressordouble#other-way-to-convert">Other way to convert</a>
and a custom ONNX node <a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/api/onnxrt_ops.html?highlight=treeensembleregressordouble#treeensembleregressordouble">TreeEnsembleRegressorDouble</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>

<span class="n">model_onx</span> <span class="o">=</span> <span class="n">to_onnx_extended</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
                             <span class="n">rewrite_ops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">oinf5</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">model_onx</span><span class="p">,</span> <span class="n">runtime</span><span class="o">=</span><span class="s1">&#39;python_compiled&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">oinf5</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>OnnxInference(...)
    def compiled_run(dict_inputs, yield_ops=None):
        if yield_ops is not None:
            raise NotImplementedError(&#39;yields_ops should be None.&#39;)
        # inputs
        X = dict_inputs[&#39;X&#39;]
        (variable, ) = n0_treeensembleregressordouble(X)
        return {
            &#39;variable&#39;: variable,
        }
</pre></div>
</div>
<p>Let’s measure the discrepencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X64</span> <span class="o">=</span> <span class="n">Xi_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">skl5</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X64</span><span class="p">)</span>
<span class="n">ort5</span> <span class="o">=</span> <span class="n">oinf5</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X64</span><span class="p">})[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Perfect, no discrepencies at all.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl5</span><span class="p">,</span> <span class="n">ort5</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(0.0, 0.0)
</pre></div>
</div>
</section>
<section id="castregressor">
<h2><a class="toc-backref" href="#id7">CastRegressor</a><a class="headerlink" href="#castregressor" title="Permalink to this headline">¶</a></h2>
<p>The previous example demonstrated the type difference for
the predicted values explains the small differences between
<a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> and <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a>. But it does not
with the current ONNX. Another option is to cast the
the predictions into floats in the <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> pipeline.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ctree</span> <span class="o">=</span> <span class="n">CastRegressor</span><span class="p">(</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="n">ctree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>

<span class="n">onx6</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">ctree</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess6</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx6</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
                         <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>

<span class="n">skl6</span> <span class="o">=</span> <span class="n">ctree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort6</span> <span class="o">=</span> <span class="n">sess6</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl6</span><span class="p">,</span> <span class="n">ort6</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(0.0, 0.0)
</pre></div>
</div>
<p>Success!</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.856 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-gyexamples-plot-ebegin-float-double-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/4bcecc278816784247eac9faa4f274f1/plot_ebegin_float_double.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_ebegin_float_double.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ca89fc7c22e0c0760aee11ac0b022e4f/plot_ebegin_float_double.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_ebegin_float_double.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="plot_dbegin_options_zipmap.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Choose appropriate output of a classifier</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="plot_funny_sigmoid.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Funny discrepancies</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Xavier Dupré.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>