{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Funny discrepancies\n\nFunction sigmoid is $sig(x) = \\frac{1}{1 + e^{-x}}$.\nFor small or high value, implementation has to do approximation\nand they are not always the same. It may be a tradeoff between\nprecision and computation time...\nIt is always a tradeoff.\n\n.. index:: discrepencies, sigmoid\n\n\n## Precision\n\nThis section compares the precision of a couple of implementations\nof the ssigmoid function. The custom implementation is done with\na Taylor expansion of exponential function:\n$e^x \\sim 1 + x + \\frac{x^2}{2} + ... + \\frac{x^n}{n!} + o(x^n)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport numpy\nimport pandas\nfrom tqdm import tqdm\nfrom scipy.special import expit\n\nfrom skl2onnx.algebra.onnx_ops import OnnxSigmoid\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom onnxruntime import InferenceSession\nfrom mlprodict.onnxrt import OnnxInference\nfrom onnxcustom import get_max_opset\nimport matplotlib.pyplot as plt\n\none = numpy.array([1], dtype=numpy.float64)\n\n\ndef taylor_approximation_exp(x, degre=50):\n    y = numpy.zeros(x.shape, dtype=x.dtype)\n    a = numpy.ones(x.shape, dtype=x.dtype)\n    for i in range(1, degre + 1):\n        a *= x / i\n        y += a\n    return y\n\n\ndef taylor_sigmoid(x, degre=50):\n    den = one + taylor_approximation_exp(-x, degre)\n    return one / (den)\n\n\nopset = get_max_opset()\nN = 300\nmin_values = [-20 + float(i) * 10 / N for i in range(N)]\ndata = numpy.array([0], dtype=numpy.float32)\n\nnode = OnnxSigmoid('X', op_version=opset, output_names=['Y'])\nonx = node.to_onnx({'X': FloatTensorType()},\n                   {'Y': FloatTensorType()},\n                   target_opset=opset)\nrts = ['numpy', 'python', 'onnxruntime', 'taylor20', 'taylor40']\n\noinf = OnnxInference(onx)\nsess = InferenceSession(onx.SerializeToString())\n\ngraph = []\nfor mv in tqdm(min_values):\n    data[0] = mv\n    for rt in rts:\n        lab = \"\"\n        if rt == 'numpy':\n            y = expit(data)\n        elif rt == 'python':\n            y = oinf.run({'X': data})['Y']\n            # * 1.2 to avoid curves to be superimposed\n            y *= 1.2\n            lab = \"x1.2\"\n        elif rt == 'onnxruntime':\n            y = sess.run(None, {'X': data})[0]\n        elif rt == 'taylor40':\n            y = taylor_sigmoid(data, 40)\n            # * 0.8 to avoid curves to be superimposed\n            y *= 0.8\n            lab = \"x0.8\"\n        elif rt == 'taylor20':\n            y = taylor_sigmoid(data, 20)\n            # * 0.6 to avoid curves to be superimposed\n            y *= 0.6\n            lab = \"x0.6\"\n        else:\n            raise AssertionError(\"Unknown runtime %r.\" % rt)\n        value = y[0]\n        graph.append(dict(rt=rt + lab, x=mv, y=value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, ax = plt.subplots(1, 1, figsize=(12, 4))\ndf = pandas.DataFrame(graph)\npiv = df.pivot('x', 'rt', 'y')\nprint(piv.T.head())\npiv.plot(ax=ax, logy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$log(sig(x)) = -log(1 + e^{-x})$. When *x* is very negative,\n$log(sig(x)) \\\\sim -x$. That explains the graph.\nWe also see :epkg:`onnxruntime` is less precise for these values.\nWhat's the benefit?\n\n## Computation time\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = []\nfor mv in tqdm(min_values):\n    data = numpy.array([mv] * 10000, dtype=numpy.float32)\n    for rt in rts:\n        begin = time.perf_counter()\n        if rt == 'numpy':\n            y = expit(data)\n        elif rt == 'python':\n            y = oinf.run({'X': data})['Y']\n        elif rt == 'onnxruntime':\n            y = sess.run(None, {'X': data})[0]\n        elif rt == 'taylor40':\n            y = taylor_sigmoid(data, 40)\n        elif rt == 'taylor20':\n            y = taylor_sigmoid(data, 20)\n        else:\n            raise AssertionError(\"Unknown runtime %r.\" % rt)\n        duration = time.perf_counter() - begin\n        graph.append(dict(rt=rt, x=mv, y=duration))\n\n_, ax = plt.subplots(1, 1, figsize=(12, 4))\ndf = pandas.DataFrame(graph)\npiv = df.pivot('x', 'rt', 'y')\npiv.plot(ax=ax, logy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nThe implementation from :epkg:`onnxruntime` is faster but\nis much less contiguous for extremes. It explains why\nprobabilities may be much different when an observation\nis far from every classification border. In that case,\n:epkg:`onnxruntime` implementation of the sigmoid function\nreturns 0 when :func:`numpy.sigmoid` returns a smoother value.\nProbabilites of logistic regression are obtained after the raw\nscores are transformed with the sigmoid function and\nnormalized. If the raw scores are very negative,\nthe sum of probabilities becomes null with :epkg:`onnxruntime`.\nThe normalization fails.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}