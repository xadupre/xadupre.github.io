{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Benchmark, comparison torch - forward-backward\n\nThe benchmark compares the processing time between :epkg:`pytorch`\nand :epkg:`onnxruntime-training` on a linear regression and a neural network.\nThis example starts from `l-orttraining-linreg-fwbw`\nbut uses :epkg:`pytorch` to replace the parts updating the gradients\nand computing the error gradient. The training algorithm becomes:\n\n<img src=\"file://images/onnxfwbwtorch.png\">\n\nClass :epkg:`TrainingAgent` (from :epkg:`onnxruntime-training`) is still\nused and wrapped into :epkg:`ORTModule`. This script then\nfollows the same instructions as `l-orttraining-benchmark-fwbw`\nto compare :epkg:`pytorch` only against :epkg:`pytorch` and\n:epkg:`onnxruntime-training`.\n\n## First comparison: neural network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport numpy\nfrom pandas import DataFrame\nimport torch\nfrom onnxruntime import get_device\nfrom onnxruntime.training.ortmodule import ORTModule\nfrom pyquickhelper.pycode.profiling import profile, profile2graph\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\n\n\nX, y = make_regression(2000, n_features=100, bias=2)\nX = X.astype(numpy.float32)\ny = y.astype(numpy.float32)\nX_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common parameters and training algorithm\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def from_numpy(v, device=None, requires_grad=False):\n    \"\"\"\n    Convers a numpy array into a torch array and\n    sets *device* and *requires_grad*.\n    \"\"\"\n    v = torch.from_numpy(v)\n    if device is not None:\n        v = v.to(device)\n    v.requires_grad_(requires_grad)\n    return v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training, two functions with same code but it is easier\nto distinguish between in the profiling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_model_torch(model, device, x, y, n_iter=100, learning_rate=1e-5,\n                      profiler=None):\n    model = model.to(device)\n    x = from_numpy(x, requires_grad=True, device=device)\n    y = from_numpy(y, requires_grad=True, device=device)\n\n    criterion = torch.nn.MSELoss(reduction='sum')\n    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n    losses = []\n    for t in range(n_iter):\n\n        def step_train_torch():\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            return loss\n\n        loss = step_train_torch()\n        losses.append(loss)\n        if profiler is not None:\n            profiler.step()\n\n    return losses\n\n\ndef train_model_ort(model, device, x, y, n_iter=100, learning_rate=1e-5,\n                    profiler=None):\n    model = model.to(device)\n    x = from_numpy(x, requires_grad=True, device=device)\n    y = from_numpy(y, requires_grad=True, device=device)\n\n    criterion = torch.nn.MSELoss(reduction='sum')\n    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n    losses = []\n    for t in range(n_iter):\n\n        def step_train_ort():\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            return loss\n\n        loss = step_train_ort()\n        losses.append(loss)\n        if profiler is not None:\n            profiler.step()\n\n    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmark function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def benchmark(model_torch, model_ort, device, name, verbose=True):\n\n    print(\"[benchmark] %s\" % name)\n    begin = time.perf_counter()\n    losses = train_model_torch(\n        model_torch, device, X_train, y_train, n_iter=200)\n    duration_torch = time.perf_counter() - begin\n    length_torch = len(losses)\n    print(\"[benchmark] torch=%r iterations - %r seconds\" % (\n        length_torch, duration_torch))\n\n    begin = time.perf_counter()\n    losses = train_model_ort(model_ort, device, X_train, y_train, n_iter=200)\n    duration_ort = time.perf_counter() - begin\n    length_ort = len(losses)\n    print(\"[benchmark] onxrt=%r iteration - %r seconds\" % (\n        length_ort, duration_ort))\n\n    return dict(torch=duration_torch, ort=duration_ort, name=name,\n                iter_torch=length_torch, iter_ort=length_ort)\n\n\nclass MLPNet(torch.nn.Module):\n    def __init__(self, D_in, D_out):\n        super(MLPNet, self).__init__()\n        self.linear1 = torch.nn.Linear(D_in, 50)\n        self.linear2 = torch.nn.Linear(50, 10)\n        self.linear3 = torch.nn.Linear(10, D_out)\n\n    def forward(self, x):\n        o1 = torch.sigmoid(self.linear1(x))\n        o2 = torch.sigmoid(self.linear2(o1))\n        return self.linear3(o2)\n\n\nd_in, d_out, N = X.shape[1], 1, X.shape[0]\nmodel_torch = MLPNet(d_in, d_out)\nmodel_ort = ORTModule(MLPNet(d_in, d_out))\n\ndevice = torch.device('cpu')\nbenches = [benchmark(model_torch, model_ort, device, name='NN-CPU')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Profiling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def clean_name(text):\n    pos = text.find('onnxruntime')\n    if pos >= 0:\n        return text[pos:]\n    pos = text.find('onnxcustom')\n    if pos >= 0:\n        return text[pos:]\n    pos = text.find('torch')\n    if pos >= 0:\n        return text[pos:]\n    pos = text.find('site-packages')\n    if pos >= 0:\n        return text[pos:]\n    return text\n\n\nps = profile(lambda: benchmark(\n    model_torch, model_ort, device, name='LR-CPU'))[0]\nroot, nodes = profile2graph(ps, clean_text=clean_name)\ntext = root.to_text()\nprint(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## if GPU is available\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if get_device().upper() == 'GPU':\n\n    device = torch.device('cuda:0')\n    benches.append(benchmark(model_torch, model_ort, device, name='LR-GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class LinearRegressionNet(torch.nn.Module):\n    def __init__(self, D_in, D_out):\n        super(LinearRegressionNet, self).__init__()\n        self.linear = torch.nn.Linear(D_in, D_out)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nd_in, d_out, N = X.shape[1], 1, X.shape[0]\nmodel_torch = LinearRegressionNet(d_in, d_out)\nmodel_ort = ORTModule(LinearRegressionNet(d_in, d_out))\n\ndevice = torch.device('cpu')\nbenches.append(benchmark(model_torch, model_ort, device, name='LR-CPU'))\n\n\nif get_device().upper() == 'GPU':\n\n    device = torch.device('cuda:0')\n    benches.append(benchmark(model_torch, model_ort, device, name='LR-GPU'))\n\n    ######################################\n    # GPU profiling\n    # +++++++++++++\n\n    if get_device().upper() == 'GPU':\n        ps = profile(lambda: benchmark(\n            model_torch, model_ort, device, name='LR-GPU'))[0]\n        root, nodes = profile2graph(ps, clean_text=clean_name)\n        text = root.to_text()\n        print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graphs\n\nDataframe first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = DataFrame(benches).set_index('name')\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "text output\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graphs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(df.columns)\nax = df[['torch', 'ort']].plot.bar(title=\"Processing time\")\nax.tick_params(axis='x', rotation=30)\n\n# import matplotlib.pyplot as plt\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}