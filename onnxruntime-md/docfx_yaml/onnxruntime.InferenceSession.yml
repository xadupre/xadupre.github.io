### YamlMime:UniversalReference
api_name: []
items:
- children:
  - onnxruntime.InferenceSession.end_profiling
  - onnxruntime.InferenceSession.get_inputs
  - onnxruntime.InferenceSession.get_modelmeta
  - onnxruntime.InferenceSession.get_outputs
  - onnxruntime.InferenceSession.run
  class: onnxruntime.InferenceSession
  fullName: onnxruntime.InferenceSession
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: onnxruntime
  name: InferenceSession
  source:
    id: InferenceSession
    path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
    remote:
      branch: doc
      path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
      repo: https://github.com/xadupre/onnxruntime.git
    startLine: 12
  summary: This is the main class used to run a model.
  syntax:
    content: InferenceSession(path_or_bytes, sess_options=None)
  type: class
  uid: onnxruntime.InferenceSession
- class: onnxruntime.InferenceSession
  fullName: onnxruntime.InferenceSession.end_profiling
  langs:
  - python
  module: onnxruntime
  name: end_profiling
  source:
    id: end_profiling
    path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
    remote:
      branch: doc
      path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
      repo: https://github.com/xadupre/onnxruntime.git
    startLine: 74
  summary: 'End profiling and return results in a file.


    The results are stored in a filename if the option

    <xref:onnxruntime-SessionOptions.enable_profiling.md>.'
  syntax:
    content: end_profiling()
    parameters: []
  type: method
  uid: onnxruntime.InferenceSession.end_profiling
- class: onnxruntime.InferenceSession
  fullName: onnxruntime.InferenceSession.get_inputs
  langs:
  - python
  module: onnxruntime
  name: get_inputs
  source:
    id: get_inputs
    path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
    remote:
      branch: doc
      path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
      repo: https://github.com/xadupre/onnxruntime.git
    startLine: 41
  summary: Return the inputs metadata as a list of <xref:onnxruntime.NodeArg.md>.
  syntax:
    content: get_inputs()
    parameters: []
  type: method
  uid: onnxruntime.InferenceSession.get_inputs
- class: onnxruntime.InferenceSession
  fullName: onnxruntime.InferenceSession.get_modelmeta
  langs:
  - python
  module: onnxruntime
  name: get_modelmeta
  source:
    id: get_modelmeta
    path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
    remote:
      branch: doc
      path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
      repo: https://github.com/xadupre/onnxruntime.git
    startLine: 49
  summary: Return the metadata. See <xref:onnxruntime.ModelMetadata>.
  syntax:
    content: get_modelmeta()
    parameters: []
  type: method
  uid: onnxruntime.InferenceSession.get_modelmeta
- class: onnxruntime.InferenceSession
  fullName: onnxruntime.InferenceSession.get_outputs
  langs:
  - python
  module: onnxruntime
  name: get_outputs
  source:
    id: get_outputs
    path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
    remote:
      branch: doc
      path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
      repo: https://github.com/xadupre/onnxruntime.git
    startLine: 45
  summary: Return the outputs metadata as a list of <xref:onnxruntime.NodeArg.md>.
  syntax:
    content: get_outputs()
    parameters: []
  type: method
  uid: onnxruntime.InferenceSession.get_outputs
- class: onnxruntime.InferenceSession
  fullName: onnxruntime.InferenceSession.run
  langs:
  - python
  module: onnxruntime
  name: run
  source:
    id: run
    path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
    remote:
      branch: doc
      path: C:\xavierdupre\microsoft_github\onnxruntime\build\docs\md\xavierdupre\microsoft_github\onnxruntime\build\Windows\Release\Release\onnxruntime\capi\session.py
      repo: https://github.com/xadupre/onnxruntime.git
    startLine: 53
  summary: "Compute the predictions.\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\"\
    , \"language\": \"default\", \"force_highlighting\": false, \"linenos\": false}\
    \ -->\n\n````default\n\n   sess.run([output_name], {input_name: x})\n   ````"
  syntax:
    content: run(output_names, input_feed, run_options=None)
    parameters:
    - defaultValue: <class 'inspect._empty'>
      description: name of the outputs
      id: output_names
    - defaultValue: <class 'inspect._empty'>
      description: 'dictionary `{ input_name: input_value }`'
      id: input_feed
    - defaultValue: None
      description: See <xref:onnxruntime.RunOptions.md>.
      id: run_options
  type: method
  uid: onnxruntime.InferenceSession.run
references:
- fullName: onnxruntime.InferenceSession.end_profiling
  isExternal: false
  name: end_profiling
  parent: onnxruntime.InferenceSession
  uid: onnxruntime.InferenceSession.end_profiling
- fullName: onnxruntime.InferenceSession.get_inputs
  isExternal: false
  name: get_inputs
  parent: onnxruntime.InferenceSession
  uid: onnxruntime.InferenceSession.get_inputs
- fullName: onnxruntime.InferenceSession.get_modelmeta
  isExternal: false
  name: get_modelmeta
  parent: onnxruntime.InferenceSession
  uid: onnxruntime.InferenceSession.get_modelmeta
- fullName: onnxruntime.InferenceSession.get_outputs
  isExternal: false
  name: get_outputs
  parent: onnxruntime.InferenceSession
  uid: onnxruntime.InferenceSession.get_outputs
- fullName: onnxruntime.InferenceSession.run
  isExternal: false
  name: run
  parent: onnxruntime.InferenceSession
  uid: onnxruntime.InferenceSession.run
