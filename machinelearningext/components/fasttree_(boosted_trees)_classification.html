
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>FastTree (Boosted Trees) Classification &#8212; Custom Extensions to ML.net 0.8.0 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="https://unpkg.com/font-awesome@4.5.0/css/font-awesome.min.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script type="text/javascript" src="https://unpkg.com/@jupyter-widgets/html-manager@^0.14.0/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Field-aware Factorization Machine" href="field-aware_factorization_machine.html" />
    <link rel="prev" title="Fast Linear (SA-SDCA)" href="fast_linear_(sa-sdca).html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="fasttree-boosted-trees-classification">
<span id="l-fasttree-boosted-trees-classification"></span><h1>FastTree (Boosted Trees) Classification<a class="headerlink" href="#fasttree-boosted-trees-classification" title="Permalink to this headline">¶</a></h1>
<p>The documentation is generated based on the sources available at
<a class="reference external" href="https://github.com/dotnet/machinelearning">dotnet/machinelearning</a> and released under <a class="reference external" href="https://github.com/dotnet/machinelearning/blob/master/LICENSE">MIT License</a>.</p>
<p><strong>Type:</strong> binaryclassifiertrainer
<strong>Aliases:</strong> <em>FastTreeBinaryClassification, FastTreeClassification, FastTree, ft, ftc, FastRankBinaryClassification, FastRankBinaryClassificationWrapper, FastRankClassification, fr, btc, frc, fastrank, fastrankwrapper</em>
<strong>Namespace:</strong> Microsoft.ML.Trainers.FastTree
<strong>Assembly:</strong> Microsoft.ML.FastTree.dll
<strong>Microsoft Documentation:</strong> <a class="reference external" href="https://docs.microsoft.com/dotnet/api/microsoft.ml.trainers.fasttree.fasttree(boostedtrees)classification">FastTree (Boosted Trees) Classification</a></p>
<p><strong>Description</strong></p>
<p>Uses a logit-boost boosted tree learner to perform binary classification.</p>
<p><strong>Parameters</strong></p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="57%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Name</th>
<th class="head">Short name</th>
<th class="head">Default</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>allowEmptyTrees</td>
<td>allowempty</td>
<td>True</td>
<td>When a root split is impossible, allow training to proceed</td>
</tr>
<tr class="row-odd"><td>baggingSize</td>
<td>bag</td>
<td>0</td>
<td>Number of trees in each bag (0 for disabling bagging)</td>
</tr>
<tr class="row-even"><td>baggingTrainFraction</td>
<td>bagfrac</td>
<td>0.7</td>
<td>Percentage of training examples used in each bag</td>
</tr>
<tr class="row-odd"><td>baselineAlphaRisk</td>
<td>basealpha</td>
<td>&#160;</td>
<td>Baseline alpha for tradeoffs of risk (0 is normal training)</td>
</tr>
<tr class="row-even"><td>baselineScoresFormula</td>
<td>basescores</td>
<td>&#160;</td>
<td>Freeform defining the scores that should be used as the baseline ranker</td>
</tr>
<tr class="row-odd"><td>bestStepRankingRegressionTrees</td>
<td>bsr</td>
<td>False</td>
<td>Use best regression step trees?</td>
</tr>
<tr class="row-even"><td>bias</td>
<td>&#160;</td>
<td>0</td>
<td>Bias for calculating gradient for each feature bin for a categorical feature.</td>
</tr>
<tr class="row-odd"><td>bundling</td>
<td>bundle</td>
<td>None</td>
<td>Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.</td>
</tr>
<tr class="row-even"><td>categoricalSplit</td>
<td>cat</td>
<td>False</td>
<td>Whether to do split based on multiple categorical feature values.</td>
</tr>
<tr class="row-odd"><td>compressEnsemble</td>
<td>cmp</td>
<td>False</td>
<td>Compress the tree Ensemble</td>
</tr>
<tr class="row-even"><td>diskTranspose</td>
<td>dt</td>
<td>&#160;</td>
<td>Whether to utilize the disk or the data’s native transposition facilities (where applicable) when performing the transpose</td>
</tr>
<tr class="row-odd"><td>dropoutRate</td>
<td>tdrop</td>
<td>0</td>
<td>Dropout rate for tree regularization</td>
</tr>
<tr class="row-even"><td>earlyStoppingMetrics</td>
<td>esmt</td>
<td>0</td>
<td>Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG&#64;1, 3:NDCG&#64;3)</td>
</tr>
<tr class="row-odd"><td>earlyStoppingRule</td>
<td>esr</td>
<td>&#160;</td>
<td>Early stopping rule. (Validation set (/valid) is required.)</td>
</tr>
<tr class="row-even"><td>enablePruning</td>
<td>pruning</td>
<td>False</td>
<td>Enable post-training pruning to avoid overfitting. (a validation set is required)</td>
</tr>
<tr class="row-odd"><td>entropyCoefficient</td>
<td>e</td>
<td>0</td>
<td>The entropy (regularization) coefficient between 0 and 1</td>
</tr>
<tr class="row-even"><td>executionTimes</td>
<td>et</td>
<td>False</td>
<td>Print execution time breakdown to stdout</td>
</tr>
<tr class="row-odd"><td>featureCompressionLevel</td>
<td>fcomp</td>
<td>1</td>
<td>The level of feature compression to use</td>
</tr>
<tr class="row-even"><td>featureFirstUsePenalty</td>
<td>ffup</td>
<td>0</td>
<td>The feature first use penalty coefficient</td>
</tr>
<tr class="row-odd"><td>featureFlocks</td>
<td>flocks</td>
<td>True</td>
<td>Whether to collectivize features during dataset preparation to speed up training</td>
</tr>
<tr class="row-even"><td>featureFraction</td>
<td>ff</td>
<td>1</td>
<td>The fraction of features (chosen randomly) to use on each iteration</td>
</tr>
<tr class="row-odd"><td>featureReusePenalty</td>
<td>frup</td>
<td>0</td>
<td>The feature re-use penalty (regularization) coefficient</td>
</tr>
<tr class="row-even"><td>featureSelectSeed</td>
<td>r3</td>
<td>123</td>
<td>The seed of the active feature selection</td>
</tr>
<tr class="row-odd"><td>filterZeroLambdas</td>
<td>fzl</td>
<td>False</td>
<td>Filter zero lambdas during training</td>
</tr>
<tr class="row-even"><td>gainConfidenceLevel</td>
<td>gainconf</td>
<td>0</td>
<td>Tree fitting gain confidence requirement (should be in the range [0,1) ).</td>
</tr>
<tr class="row-odd"><td>getDerivativesSampleRate</td>
<td>sr</td>
<td>1</td>
<td>Sample each query 1 in k times in the GetDerivatives function</td>
</tr>
<tr class="row-even"><td>histogramPoolSize</td>
<td>ps</td>
<td>-1</td>
<td>The number of histograms in the pool (between 2 and numLeaves)</td>
</tr>
<tr class="row-odd"><td>learningRates</td>
<td>lr</td>
<td>0.2</td>
<td>The learning rate</td>
</tr>
<tr class="row-even"><td>maxBins</td>
<td>mb</td>
<td>255</td>
<td>Maximum number of distinct values (bins) per feature</td>
</tr>
<tr class="row-odd"><td>maxCategoricalGroupsPerNode</td>
<td>mcg</td>
<td>64</td>
<td>Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.</td>
</tr>
<tr class="row-even"><td>maxCategoricalSplitPoints</td>
<td>maxcat</td>
<td>64</td>
<td>Maximum categorical split points to consider when splitting on a categorical feature.</td>
</tr>
<tr class="row-odd"><td>maxTreeOutput</td>
<td>mo</td>
<td>100</td>
<td>Upper bound on absolute value of single tree output</td>
</tr>
<tr class="row-even"><td>maxTreesAfterCompression</td>
<td>cmpmax</td>
<td>-1</td>
<td>Maximum Number of trees after compression</td>
</tr>
<tr class="row-odd"><td>minDocsForCategoricalSplit</td>
<td>mdo</td>
<td>100</td>
<td>Minimum categorical doc count in a bin to consider for a split.</td>
</tr>
<tr class="row-even"><td>minDocsPercentageForCategoricalSplit</td>
<td>mdop</td>
<td>0.001</td>
<td>Minimum categorical docs percentage in a bin to consider for a split.</td>
</tr>
<tr class="row-odd"><td>minDocumentsInLeafs</td>
<td>mil</td>
<td>10</td>
<td>The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data</td>
</tr>
<tr class="row-even"><td>minStepSize</td>
<td>minstep</td>
<td>0</td>
<td>Minimum line search step size</td>
</tr>
<tr class="row-odd"><td>numLeaves</td>
<td>nl</td>
<td>20</td>
<td>The max number of leaves in each regression tree</td>
</tr>
<tr class="row-even"><td>numPostBracketSteps</td>
<td>lssteps</td>
<td>0</td>
<td>Number of post-bracket line search steps</td>
</tr>
<tr class="row-odd"><td>numThreads</td>
<td>t</td>
<td>&#160;</td>
<td>The number of threads to use</td>
</tr>
<tr class="row-even"><td>numTrees</td>
<td>iter</td>
<td>100</td>
<td>Total number of decision trees to create in the ensemble</td>
</tr>
<tr class="row-odd"><td>optimizationAlgorithm</td>
<td>oa</td>
<td>GradientDescent</td>
<td>Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)</td>
</tr>
<tr class="row-even"><td>parallelTrainer</td>
<td>parag</td>
<td>Microsoft. ML. Trainers. FastTree. SingleTrainerFactory</td>
<td>Allows to choose Parallel FastTree Learning Algorithm</td>
</tr>
<tr class="row-odd"><td>positionDiscountFreeform</td>
<td>pdff</td>
<td>&#160;</td>
<td>The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)</td>
</tr>
<tr class="row-even"><td>printTestGraph</td>
<td>graph</td>
<td>False</td>
<td>Print metrics graph for the first test set</td>
</tr>
<tr class="row-odd"><td>printTrainValidGraph</td>
<td>graphtv</td>
<td>False</td>
<td>Print Train and Validation metrics in graph</td>
</tr>
<tr class="row-even"><td>pruningThreshold</td>
<td>prth</td>
<td>0.004</td>
<td>The tolerance threshold for pruning</td>
</tr>
<tr class="row-odd"><td>pruningWindowSize</td>
<td>prws</td>
<td>5</td>
<td>The moving window size for pruning</td>
</tr>
<tr class="row-even"><td>randomStart</td>
<td>rs</td>
<td>False</td>
<td>Training starts from random ordering (determined by /r1)</td>
</tr>
<tr class="row-odd"><td>rngSeed</td>
<td>r1</td>
<td>123</td>
<td>The seed of the random number generator</td>
</tr>
<tr class="row-even"><td>shrinkage</td>
<td>shrk</td>
<td>1</td>
<td>Shrinkage</td>
</tr>
<tr class="row-odd"><td>smoothing</td>
<td>s</td>
<td>0</td>
<td>Smoothing paramter for tree regularization</td>
</tr>
<tr class="row-even"><td>softmaxTemperature</td>
<td>smtemp</td>
<td>0</td>
<td>The temperature of the randomized softmax distribution for choosing the feature</td>
</tr>
<tr class="row-odd"><td>sparsifyThreshold</td>
<td>sp</td>
<td>0.7</td>
<td>Sparsity level needed to use sparse feature representation</td>
</tr>
<tr class="row-even"><td>splitFraction</td>
<td>sf</td>
<td>1</td>
<td>The fraction of features (chosen randomly) to use on each split</td>
</tr>
<tr class="row-odd"><td>testFrequency</td>
<td>tf</td>
<td>2147483647</td>
<td>Calculate metric values for train/valid/test every k rounds</td>
</tr>
<tr class="row-even"><td>unbalancedSets</td>
<td>us</td>
<td>False</td>
<td>Should we use derivatives optimized for unbalanced sets</td>
</tr>
<tr class="row-odd"><td>useLineSearch</td>
<td>ls</td>
<td>False</td>
<td>Should we use line search for a step size</td>
</tr>
<tr class="row-even"><td>useTolerantPruning</td>
<td>prtol</td>
<td>False</td>
<td>Use window and tolerance for pruning</td>
</tr>
<tr class="row-odd"><td>writeLastEnsemble</td>
<td>hl</td>
<td>False</td>
<td>Write the last ensemble instead of the one determined by early stopping</td>
</tr>
</tbody>
</table>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/project_ico.png" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../index.html">Custom Extensions to ML.net</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataframe.html">DataFrames in C#</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commandline.html">Command Line</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">ML.net Components</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="anomalydetectortrainer.html">Anomaly Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="argument.html">Arguments</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="binaryclassifiertrainer.html">Binary Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="clusteringtrainer.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="command.html">Commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataloader.html">Data Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasaver.html">Data Saver</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensembledataselector.html">Data Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="evaluator.html">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiclassclassifiertrainer.html">Multiclass Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="ngramextractorfactory.html">N-Grams</a></li>
<li class="toctree-l2"><a class="reference internal" href="rankertrainer.html">Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="regressortrainer.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="datascorer.html">Scoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="datatransform.html">Transforms (all)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../machinelearning_docs.html">ML.net details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Scikit.ML details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apicsharpdoc.html">CSharp API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../aonnx.html">ML.net and ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../incompatibilities.html">ML.net customization</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">ML.net Components</a><ul>
  <li><a href="binaryclassifiertrainer.html">Binary Classification</a><ul>
      <li>Previous: <a href="fast_linear_(sa-sdca).html" title="previous chapter">Fast Linear (SA-SDCA)</a></li>
      <li>Next: <a href="field-aware_factorization_machine.html" title="next chapter">Field-aware Factorization Machine</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/components/fasttree_(boosted_trees)_classification.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>